
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2024-09-04</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-09-04 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Bridging Episodes and Semantics: A Novel Framework for Long-Form Video  Understanding</h3>
<p><a href='http://arxiv.org/abs/2408.17443v1'>http://arxiv.org/abs/2408.17443v1</a></p>
<p><b>Compressor summary</b>: BREASE is a novel model that simulates human cognition for long-form video understanding by combining episodic memory with semantic knowledge, achieving state-of-the-art performance on multiple benchmarks.</p><hr><h3>SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic  CheckLists</h3>
<p><a href='http://arxiv.org/abs/2408.17437v1'>http://arxiv.org/abs/2408.17437v1</a></p>
<p><b>Compressor summary</b>: SYNTHEVEL uses large language models to create diverse test types for evaluating NLP models' performance and weaknesses.</p><hr><h3>DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised  Vector-LoRA of the Foundation Model</h3>
<p><a href='http://arxiv.org/abs/2408.17433v1'>http://arxiv.org/abs/2408.17433v1</a></p>
<p><b>Compressor summary</b>: The DARES method improves robotic-assisted surgery depth estimation by adapting Depth Anything Models with Vector Low-Rank Adaptation and a reprojection loss, achieving better performance than existing techniques.</p><hr><h3>CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language  Models</h3>
<p><a href='http://arxiv.org/abs/2408.17428v1'>http://arxiv.org/abs/2408.17428v1</a></p>
<p><b>Compressor summary</b>: This paper introduces CLOCR-C, a method that uses transformer-based language models to correct OCR errors in historical print media archives, improving downstream NLP tasks and showing the importance of socio-cultural context.</p><hr><h3>CinePreGen: Camera Controllable Video Previsualization via  Engine-powered Diffusion</h3>
<p><a href='http://arxiv.org/abs/2408.17424v1'>http://arxiv.org/abs/2408.17424v1</a></p>
<p><b>Compressor summary</b>: CinePreGen is a visual previsualization system that uses engine-powered diffusion to enable dynamic control over camera placement and storyboarding, improving video production quality and reducing development challenges.</p><hr><h3>Open-vocabulary Temporal Action Localization using VLMs</h3>
<p><a href='http://arxiv.org/abs/2408.17422v1'>http://arxiv.org/abs/2408.17422v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a learning-free method to find actions in videos using vision-language models and iterative visual prompting.</p><hr><h3>Exploring the Effect of Explanation Content and Format on User  Comprehension and Trust</h3>
<p><a href='http://arxiv.org/abs/2408.17401v1'>http://arxiv.org/abs/2408.17401v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how users understand and trust different methods of explaining AI-based cancer risk assessments, finding that simpler text explanations are preferred over complex charts and game-theoretic approaches.</p><hr><h3>How Knowledge Distillation Mitigates the Synthetic Gap in Fair Face  Recognition</h3>
<p><a href='http://arxiv.org/abs/2408.17399v1'>http://arxiv.org/abs/2408.17399v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Knowledge Distillation strategy that uses pretrained models on real data to train smaller models on synthetic or mixed data, improving face recognition accuracy and reducing bias.</p><hr><h3>Fairness-Aware Estimation of Graphical Models</h3>
<p><a href='http://arxiv.org/abs/2408.17396v1'>http://arxiv.org/abs/2408.17396v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to reduce bias in graphical models related to sensitive attributes by using a multi-objective optimization problem.</p><hr><h3>Continual learning with the neural tangent ensemble</h3>
<p><a href='http://arxiv.org/abs/2408.17394v1'>http://arxiv.org/abs/2408.17394v1</a></p>
<p><b>Compressor summary</b>: The text proposes interpreting a neural network as an ensemble of fixed or adaptive experts, which can help prevent forgetting in continual learning.</p><hr><h3>LASSO-MOGAT: A Multi-Omics Graph Attention Framework for Cancer  Classification</h3>
<p><a href='http://arxiv.org/abs/2408.17384v1'>http://arxiv.org/abs/2408.17384v1</a></p>
<p><b>Compressor summary</b>: LASSO-MOGAT is a novel deep learning framework that uses gene expression, microRNA, and DNA methylation data to classify 31 types of cancer by integrating multi-omics data and protein-protein interaction networks.</p><hr><h3>MoRe Fine-Tuning with 10x Fewer Parameters</h3>
<p><a href='http://arxiv.org/abs/2408.17383v1'>http://arxiv.org/abs/2408.17383v1</a></p>
<p><b>Compressor summary</b>: MoRe is a simple framework that uses the Monarch matrix class to search for optimal adapter architectures for fine-tuning pretrained models, outperforming existing techniques in terms of parameter efficiency and performance.</p><hr><h3>Traffic expertise meets residual RL: Knowledge-informed model-based  residual reinforcement learning for CAV trajectory control</h3>
<p><a href='http://arxiv.org/abs/2408.17380v1'>http://arxiv.org/abs/2408.17380v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a knowledge-informed model-based residual reinforcement learning framework that integrates traffic expert knowledge into a virtual environment model to enhance learning efficiency and improve CAV trajectory control in mixed traffic flow.</p><hr><h3>NDP: Next Distribution Prediction as a More Broad Target</h3>
<p><a href='http://arxiv.org/abs/2408.17377v1'>http://arxiv.org/abs/2408.17377v1</a></p>
<p><b>Compressor summary</b>: The authors critique large language models trained on next-token prediction (NTP) due to its limitations and propose Next Distribution Prediction (NDP), which uses $n$-gram distributions instead of one-hot targets, resulting in significant improvements across various tasks.</p><hr><h3>Exploring the Impact of Environmental Pollutants on Multiple Sclerosis  Progression</h3>
<p><a href='http://arxiv.org/abs/2408.17376v1'>http://arxiv.org/abs/2408.17376v1</a></p>
<p><b>Compressor summary</b>: The study used data from a project to examine how environmental factors affect relapse frequency in Multiple Sclerosis patients, finding that certain variables like air pollution and weather conditions play a role.</p><hr><h3>Leveraging Graph Neural Networks to Forecast Electricity Consumption</h3>
<p><a href='http://arxiv.org/abs/2408.17366v1'>http://arxiv.org/abs/2408.17366v1</a></p>
<p><b>Compressor summary</b>: The text proposes a new method for accurate electricity demand forecasting using graph-based models that consider the spatial distribution and interconnectedness of consumers in a decentralized network structure.</p><hr><h3>Assessing Generative Language Models in Classification Tasks:  Performance and Self-Evaluation Capabilities in the Environmental and Climate  Change Domain</h3>
<p><a href='http://arxiv.org/abs/2408.17362v1'>http://arxiv.org/abs/2408.17362v1</a></p>
<p><b>Compressor summary</b>: The paper compares three language models' performance in climate change classification tasks and evaluates their calibration of confidence scores.</p><hr><h3>C-RADAR: A Centralized Deep Learning System for Intrusion Detection in  Software Defined Networks</h3>
<p><a href='http://arxiv.org/abs/2408.17356v1'>http://arxiv.org/abs/2408.17356v1</a></p>
<p><b>Compressor summary</b>: The research proposes using deep learning for intrusion detection in software defined networks, showing better accuracy and efficiency than traditional methods.</p><hr><h3>Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language  Models for Privacy Leakage</h3>
<p><a href='http://arxiv.org/abs/2408.17354v1'>http://arxiv.org/abs/2408.17354v1</a></p>
<p><b>Compressor summary</b>: The study presents a model-unlearning poisoning technique that increases data leakage during fine-tuning and warns against using unverified pre-trained models.</p><hr><h3>Enhancing Underwater Imaging with 4-D Light Fields: Dataset and Method</h3>
<p><a href='http://arxiv.org/abs/2408.17339v1'>http://arxiv.org/abs/2408.17339v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a 4-D light field imaging framework to improve underwater image quality and depth estimation, and introduces a new dataset for this task.</p><hr><h3>Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature  and Confidence-Based OOD Detection</h3>
<p><a href='http://arxiv.org/abs/2408.17337v1'>http://arxiv.org/abs/2408.17337v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper studies OOD detection methods for medical image analysis using two new benchmarks with artefacts
- Confidence-based methods are less effective than feature-based methods, but both have limitations
- A combination of both methods is suggested to improve OOD detection performance

Summary:
The paper compares confidence- and feature-based methods for out-of-distribution (OOD) detection in medical image analysis using new benchmarks with artefacts. It shows that both methods have weaknesses and proposes a hybrid approach.</p><hr><h3>Impact of ChatGPT on the writing style of condensed matter physicists</h3>
<p><a href='http://arxiv.org/abs/2408.17325v1'>http://arxiv.org/abs/2408.17325v1</a></p>
<p><b>Compressor summary</b>: The text studies how ChatGPT's release affected condensed matter paper abstracts on arXiv, finding improved English quality for non-native speakers and changes in word usage.</p><hr><h3>Modularity in Transformers: Investigating Neuron Separability &  Specialization</h3>
<p><a href='http://arxiv.org/abs/2408.17324v1'>http://arxiv.org/abs/2408.17324v1</a></p>
<p><b>Compressor summary</b>: The paper explores how neurons within transformer models specialize for different tasks, finding task-specific clusters and suggesting an inherent structure that training refines.</p><hr><h3>Investigating Neuron Ablation in Attention Heads: The Case for Peak  Activation Centering</h3>
<p><a href='http://arxiv.org/abs/2408.17322v1'>http://arxiv.org/abs/2408.17322v1</a></p>
<p><b>Compressor summary</b>: The authors explore different ways to interpret neuron activations in transformer models and evaluate their effectiveness using various ablation methods, finding that each method has its own advantages and disadvantages depending on the model and regime.</p><hr><h3>Bridging Domain Knowledge and Process Discovery Using Large Language  Models</h3>
<p><a href='http://arxiv.org/abs/2408.17316v1'>http://arxiv.org/abs/2408.17316v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using Large Language Models to incorporate domain knowledge into automated process discovery, resulting in more robust models and practical benefits, demonstrated through a case study.</p><hr><h3>Fair Best Arm Identification with Fixed Confidence</h3>
<p><a href='http://arxiv.org/abs/2408.17313v1'>http://arxiv.org/abs/2408.17313v1</a></p>
<p><b>Compressor summary</b>: F-BAI is a framework that identifies the best arm under fairness constraints and shows how fairness impacts sample complexity using an instance-specific lower bound, with F-TaS as an efficient algorithm for this setting.</p><hr><h3>Towards Tailored Recovery of Lexical Diversity in Literary Machine  Translation</h3>
<p><a href='http://arxiv.org/abs/2408.17308v1'>http://arxiv.org/abs/2408.17308v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Machine translations have lower lexical diversity than human translations
- Lexical diversity matters for literature translation
- Current methods for increasing lexical diversity are rigid
- The approach proposed is reranking translation candidates with a classifier
- The approach achieves high lexical diversity scores for some books

Summary:
The paper proposes a novel method to recover lost lexical diversity in machine translations of literature by reranking translation candidates with a classifier that distinguishes between original and translated text.</p><hr><h3>Stationary Policies are Optimal in Risk-averse Total-reward MDPs with  EVaR</h3>
<p><a href='http://arxiv.org/abs/2408.17286v1'>http://arxiv.org/abs/2408.17286v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a simple and interpretable method to optimize risk-averse objectives in discounted MDPs using a stationary policy and various optimization techniques.</p><hr><h3>DCUDF2: Improving Efficiency and Accuracy in Extracting Zero Level Sets  from Unsigned Distance Fields</h3>
<p><a href='http://arxiv.org/abs/2408.17284v1'>http://arxiv.org/abs/2408.17284v1</a></p>
<p><b>Compressor summary</b>: DCUDF2 is a new method to accurately extract surfaces from complex models using self-adaptive weights and topology correction, improving on previous state-of-the-art methods.</p><hr><h3>Flexible and Effective Mixing of Large Language Models into a Mixture of  Domain Experts</h3>
<p><a href='http://arxiv.org/abs/2408.17280v1'>http://arxiv.org/abs/2408.17280v1</a></p>
<p><b>Compressor summary</b>: The text introduces a toolkit that helps create cost-effective Mixture-of-Domain-Experts (MOE) models or adapters, with tips and resources for using it.</p><hr><h3>The Transferability of Downsampling Sparse Graph Convolutional Networks</h3>
<p><a href='http://arxiv.org/abs/2408.17274v1'>http://arxiv.org/abs/2408.17274v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a method to reduce the size of large sparse graphs by preserving their topological structure while maintaining sparsity levels.</p><hr><h3>UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal  Models in Multi-View Urban Scenarios</h3>
<p><a href='http://arxiv.org/abs/2408.17267v1'>http://arxiv.org/abs/2408.17267v1</a></p>
<p><b>Compressor summary</b>: UrBench is a comprehensive benchmark for evaluating Large Multimodal Models in complex multi-view urban scenarios, revealing their limitations and inconsistencies.</p><hr><h3>Joint Estimation and Prediction of City-wide Delivery Demand: A Large  Language Model Empowered Graph-based Learning Approach</h3>
<p><a href='http://arxiv.org/abs/2408.17258v1'>http://arxiv.org/abs/2408.17258v1</a></p>
<p><b>Compressor summary</b>: The authors propose a machine learning model that predicts city-wide delivery demand by using message-passing neural networks and geospatial knowledge from large language models, achieving better performance than existing methods on real-world datasets.</p><hr><h3>Self-supervised learning for crystal property prediction via denoising</h3>
<p><a href='http://arxiv.org/abs/2408.17255v1'>http://arxiv.org/abs/2408.17255v1</a></p>
<p><b>Compressor summary</b>: CDSSL is a new self-supervised learning method for predicting crystalline material properties by recovering valid structures from perturbed ones.</p><hr><h3>VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time  Series Forecasters</h3>
<p><a href='http://arxiv.org/abs/2408.17253v1'>http://arxiv.org/abs/2408.17253v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method to improve time series forecasting by leveraging visual models pre-trained on natural images, which outperforms existing approaches with minimal fine-tuning.</p><hr><h3>Categorical data clustering: 25 years beyond K-modes</h3>
<p><a href='http://arxiv.org/abs/2408.17244v1'>http://arxiv.org/abs/2408.17244v1</a></p>
<p><b>Compressor summary</b>: This paper reviews the past 25 years of categorical data clustering methods, comparing different algorithms and their applications across various fields.</p><hr><h3>A methodological framework for Resilience as a Service (RaaS) in  multimodal urban transportation networks</h3>
<p><a href='http://arxiv.org/abs/2408.17233v1'>http://arxiv.org/abs/2408.17233v1</a></p>
<p><b>Compressor summary</b>: The study proposes an optimization model for managing public transport disruptions using resilience as a service strategies, considering various transportation options and factors to allocate resources effectively and minimize costs and adverse effects on stakeholders.</p><hr><h3>OG-Mapping: Octree-based Structured 3D Gaussians for Online Dense  Mapping</h3>
<p><a href='http://arxiv.org/abs/2408.17223v1'>http://arxiv.org/abs/2408.17223v1</a></p>
<p><b>Compressor summary</b>: OG-Mapping uses sparse octrees and structured 3D Gaussians for efficient and robust online dense mapping, addressing redundancy, depth noise sensitivity, storage challenges, and recovery issues.</p><hr><h3>Geometry of Lightning Self-Attention: Identifiability and Dimension</h3>
<p><a href='http://arxiv.org/abs/2408.17221v1'>http://arxiv.org/abs/2408.17221v1</a></p>
<p><b>Compressor summary</b>: The paper studies the geometry and identifiability of function spaces defined by polynomial self-attention networks using algebraic geometry tools.</p><hr><h3>Covariance-corrected Whitening Alleviates Network Degeneration on  Imbalanced Classification</h3>
<p><a href='http://arxiv.org/abs/2408.17197v1'>http://arxiv.org/abs/2408.17197v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Whitening-Net, a framework to improve image classification with class imbalance by normalizing and decorrelating batch samples using ZCA whitening and two covariance-corrected modules.</p><hr><h3>Reasoning with maximal consistent signatures</h3>
<p><a href='http://arxiv.org/abs/2408.17190v1'>http://arxiv.org/abs/2408.17190v1</a></p>
<p><b>Compressor summary</b>: The paper studies a method for dealing with inconsistent information by focusing on maximal consistent subsets that allow forgetting to restore consistency, and explores its implications for non-monotonic reasoning, computational complexity, and related concepts.</p><hr><h3>Hybrid Classification-Regression Adaptive Loss for Dense Object  Detection</h3>
<p><a href='http://arxiv.org/abs/2408.17182v1'>http://arxiv.org/abs/2408.17182v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method, HCRAL, for object detection that improves performance by considering inconsistencies across tasks and focusing on difficult samples using a hybrid loss function and additional sample selection strategy.</p><hr><h3>Improving Extraction of Clinical Event Contextual Properties from  Electronic Health Records: A Comparative Study</h3>
<p><a href='http://arxiv.org/abs/2408.17181v1'>http://arxiv.org/abs/2408.17181v1</a></p>
<p><b>Compressor summary</b>: The study compares natural language models, finding that BERT with class imbalance mitigation performs best at extracting relevant and contextualized clinical events from electronic health records text.</p><hr><h3>Identifying and Clustering Counter Relationships of Team Compositions in  PvP Games for Efficient Balance Analysis</h3>
<p><a href='http://arxiv.org/abs/2408.17180v1'>http://arxiv.org/abs/2408.17180v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two advanced measures to quantify balance in competitive games, using win value estimations and vector quantization, and validates them in popular online games.</p><hr><h3>SafeTail: Efficient Tail Latency Optimization in Edge Service Scheduling  via Computational Redundancy Management</h3>
<p><a href='http://arxiv.org/abs/2408.17171v1'>http://arxiv.org/abs/2408.17171v1</a></p>
<p><b>Compressor summary</b>: SafeTail is a framework that uses deep learning to selectively replicate services across multiple edge servers to meet latency targets while minimizing resource usage in uncertain edge computing environments.</p><hr><h3>Efficient Testable Learning of General Halfspaces with Adversarial Label  Noise</h3>
<p><a href='http://arxiv.org/abs/2408.17165v1'>http://arxiv.org/abs/2408.17165v1</a></p>
<p><b>Compressor summary</b>: The paper presents a polynomial time tester-learner for robustly learning non-homogeneous halfspaces with adversarial label noise, using a new method to reduce the problem to nearly homogeneous halfspaces.</p><hr><h3>The Iterative Optimal Brain Surgeon: Faster Sparse Recovery by  Leveraging Second-Order Information</h3>
<p><a href='http://arxiv.org/abs/2408.17163v1'>http://arxiv.org/abs/2408.17163v1</a></p>
<p><b>Compressor summary</b>: The paper proposes new sparse recovery algorithms based on the Optimal Brain Surgeon framework that improve accuracy-vs-sparsity in deep neural networks, with theoretical guarantees and practical performance.</p><hr><h3>Deep Feature Embedding for Tabular Data</h3>
<p><a href='http://arxiv.org/abs/2408.17162v1'>http://arxiv.org/abs/2408.17162v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new framework that uses deep neural networks to create feature embeddings for tabular data with numerical and categorical features, improving their representation and capture complex relationships.</p><hr><h3>Self-supervised Anomaly Detection Pretraining Enhances Long-tail ECG  Diagnosis</h3>
<p><a href='http://arxiv.org/abs/2408.17154v1'>http://arxiv.org/abs/2408.17154v1</a></p>
<p><b>Compressor summary</b>: The study introduces a novel anomaly detection method for ECG diagnosis that significantly improves accuracy, especially for rare cardiac anomalies, and enhances clinical efficiency in emergency care settings.</p><hr><h3>Look, Compare, Decide: Alleviating Hallucination in Large  Vision-Language Models via Multi-View Multi-Path Reasoning</h3>
<p><a href='http://arxiv.org/abs/2408.17150v1'>http://arxiv.org/abs/2408.17150v1</a></p>
<p><b>Compressor summary</b>: Our method, Multi-View Multi-Path Reasoning (MVP), reduces hallucinations in large vision-language models by enhancing their information perception and considering the certainty of answer tokens.</p><hr><h3>GMM-IKRS: Gaussian Mixture Models for Interpretable Keypoint Refinement  and Scoring</h3>
<p><a href='http://arxiv.org/abs/2408.17149v1'>http://arxiv.org/abs/2408.17149v1</a></p>
<p><b>Compressor summary</b>: Keypoints are important features in computer vision, but their quality scores are not easy to compare; a new framework refines and scores keypoints based on how well they survive viewpoint changes and localization accuracy.</p><hr><h3>The Many Faces of Optimal Weak-to-Strong Learning</h3>
<p><a href='http://arxiv.org/abs/2408.17148v1'>http://arxiv.org/abs/2408.17148v1</a></p>
<p><b>Compressor summary</b>: A new Boosting algorithm combines multiple classifiers with optimal sample complexity and fast runtime using a simple majority vote.</p><hr><h3>RenDetNet: Weakly-supervised Shadow Detection with Shadow Caster  Verification</h3>
<p><a href='http://arxiv.org/abs/2408.17143v1'>http://arxiv.org/abs/2408.17143v1</a></p>
<p><b>Compressor summary</b>: This paper introduces RenDetNet, a learning-based shadow detection model that verifies shadows are real by re-rendering the scene and uses self-supervised signals for training.</p><hr><h3>Flow Matching for Optimal Reaction Coordinates of Biomolecular System</h3>
<p><a href='http://arxiv.org/abs/2408.17139v1'>http://arxiv.org/abs/2408.17139v1</a></p>
<p><b>Compressor summary</b>: Flow Matching for Reaction Coordinates (FMRC) is a deep learning algorithm that efficiently identifies optimal reaction coordinates in biomolecular reversible dynamics using conditional probability and generative models.</p><hr><h3>Temporal and Interactive Modeling for Efficient Human-Human Motion  Generation</h3>
<p><a href='http://arxiv.org/abs/2408.17135v1'>http://arxiv.org/abs/2408.17135v1</a></p>
<p><b>Compressor summary</b>: TIM is a new method for generating human-human motion sequences that uses RWKV, Causal Interactive Injection, Role-Evolving Mixing, and Localized Pattern Amulation to model temporal and interactive properties of motion while being efficient and effective.</p><hr><h3>VQ4DiT: Efficient Post-Training Vector Quantization for Diffusion  Transformers</h3>
<p><a href='http://arxiv.org/abs/2408.17131v1'>http://arxiv.org/abs/2408.17131v1</a></p>
<p><b>Compressor summary</b>: VQ4DiT is a fast post-training vector quantization method for Diffusion Transformers Models that reduces their memory usage and achieves state-of-the-art performance in image generation quality.</p><hr><h3>Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph  Neural Networks for Drug Response Prediction</h3>
<p><a href='http://arxiv.org/abs/2408.17129v1'>http://arxiv.org/abs/2408.17129v1</a></p>
<p><b>Compressor summary</b>: CETExplainer is a novel post-hoc interpretability algorithm for predicting cancer drug responses that provides biologically meaningful explanations using edge-type-specific weighting and mutual information between subgraphs and predictions.</p><hr><h3>Efficient Estimation of Unique Components in Independent Component  Analysis by Matrix Representation</h3>
<p><a href='http://arxiv.org/abs/2408.17118v1'>http://arxiv.org/abs/2408.17118v1</a></p>
<p><b>Compressor summary</b>: The paper presents a faster method to estimate the unique global optimum of independent component analysis (ICA) using matrix representation and fewer calculations, which was previously achieved through time-consuming random initializations.</p>