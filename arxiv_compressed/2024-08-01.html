
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-08-01</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-08-01 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Generalized Out-of-Distribution Detection and Beyond in Vision Language  Model Era: A Survey</h3>
<p><a href='http://arxiv.org/abs/2407.21794v1'>http://arxiv.org/abs/2407.21794v1</a></p>
<p><b>Compressor summary</b>: This text summarizes the evolution of out-of-distribution detection and related problems in vision language models, highlights the changes in definitions and benchmarks, and discusses future challenges and directions.</p><hr><h3>Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?</h3>
<p><a href='http://arxiv.org/abs/2407.21792v1'>http://arxiv.org/abs/2407.21792v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes AI safety benchmarks and their relationship with general capabilities, suggesting that many benchmarks may be misleadingly correlated with capability improvements, and proposing a clearer framework for AI safety research.</p><hr><h3>Vision-Language Model Based Handwriting Verification</h3>
<p><a href='http://arxiv.org/abs/2407.21788v1'>http://arxiv.org/abs/2407.21788v1</a></p>
<p><b>Compressor summary</b>: The paper explores using vision language models to improve handwriting verification by providing clear explanations and adapting to diverse styles, but finds that CNN-based ResNet-18 performs better.</p><hr><h3>Large Language Monkeys: Scaling Inference Compute with Repeated Sampling</h3>
<p><a href='http://arxiv.org/abs/2407.21787v1'>http://arxiv.org/abs/2407.21787v1</a></p>
<p><b>Compressor summary</b>: Repeated inference sampling improves language model performance on various tasks by increasing coverage and cost-effectiveness.</p><hr><h3>The Llama 3 Herd of Models</h3>
<p><a href='http://arxiv.org/abs/2407.21783v1'>http://arxiv.org/abs/2407.21783v1</a></p>
<p><b>Compressor summary</b>: Llama 3 is a multilingual language model with various capabilities that compares well to GPT-4 and can be integrated with other modalities like image, video, and speech.</p><hr><h3>Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool  Libraries</h3>
<p><a href='http://arxiv.org/abs/2407.21778v1'>http://arxiv.org/abs/2407.21778v1</a></p>
<p><b>Compressor summary</b>: Tulip agent is an autonomous AI agent that can search for tools in a large library, reducing inference costs and enabling adaptation and extension of its tool set.</p><hr><h3>RainMamba: Enhanced Locality Learning with State Space Models for Video  Deraining</h3>
<p><a href='http://arxiv.org/abs/2407.21773v1'>http://arxiv.org/abs/2407.21773v1</a></p>
<p><b>Compressor summary</b>: RainMamba is a new video deraining method that uses state space models, Hilbert scanning, and dynamic contrastive locality learning to effectively remove rain from outdoor vision systems.</p><hr><h3>ShieldGemma: Generative AI Content Moderation Based on Gemma</h3>
<p><a href='http://arxiv.org/abs/2407.21772v1'>http://arxiv.org/abs/2407.21772v1</a></p>
<p><b>Compressor summary</b>: ShieldGemma is a suite of models that use large language models to accurately predict safety risks in user input and generated output, outperforming existing models and providing a valuable resource to the research community.</p><hr><h3>Paying More Attention to Image: A Training-Free Method for Alleviating  Hallucination in LVLMs</h3>
<p><a href='http://arxiv.org/abs/2407.21771v1'>http://arxiv.org/abs/2407.21771v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an algorithm to address text inertia and reduce hallucination in large vision-language models by adjusting attention weights and subtracting logits of multi-modal inputs.</p><hr><h3>MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware  Experts</h3>
<p><a href='http://arxiv.org/abs/2407.21770v1'>http://arxiv.org/abs/2407.21770v1</a></p>
<p><b>Compressor summary</b>: MoMa is a new architecture that improves the efficiency of mixed-modal language models by dividing expert modules into modality-specific groups and routing them to optimize pre-training.</p><hr><h3>Learning Video Context as Interleaved Multimodal Sequences</h3>
<p><a href='http://arxiv.org/abs/2407.21757v1'>http://arxiv.org/abs/2407.21757v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MovieSeq, a multimodal language model that represents videos as interleaved sequences of images, plots, videos, subtitles, and other information to improve understanding and interaction with narrative videos.</p><hr><h3>HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph  Out-of-Distribution Detection</h3>
<p><a href='http://arxiv.org/abs/2407.21742v1'>http://arxiv.org/abs/2407.21742v1</a></p>
<p><b>Compressor summary</b>: HGOE is a model-agnostic framework that uses external and internal outliers to improve OOD detection for graph data by adaptively assigning weights to them with a boundary-aware loss function.</p><hr><h3>Contrastive Factor Analysis</h3>
<p><a href='http://arxiv.org/abs/2407.21740v1'>http://arxiv.org/abs/2407.21740v1</a></p>
<p><b>Compressor summary</b>: Contrastive Factor Analysis is a novel framework that combines contrastive learning and factor analysis to leverage their respective advantages in unsupervised representational learning.</p><hr><h3>Unifying Event-based Flow, Stereo and Depth Estimation via Feature  Similarity Matching</h3>
<p><a href='http://arxiv.org/abs/2407.21735v1'>http://arxiv.org/abs/2407.21735v1</a></p>
<p><b>Compressor summary</b>: The EventMatch framework uses a single model to perform optical flow, stereo matching, and depth estimation with event cameras by comparing feature similarities across different inputs.</p><hr><h3>ParLS-PBO: A Parallel Local Search Solver for Pseudo Boolean  Optimization</h3>
<p><a href='http://arxiv.org/abs/2407.21729v1'>http://arxiv.org/abs/2407.21729v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an improved local search solver for Pseudo-Boolean Optimization problems that balances hard constraints and objective function scores, and develops a parallel version that shares solutions to guide the search and enhances scoring with polarity density.</p><hr><h3>Artificial Intelligence Approaches for Energy Efficiency: A Review</h3>
<p><a href='http://arxiv.org/abs/2407.21726v1'>http://arxiv.org/abs/2407.21726v1</a></p>
<p><b>Compressor summary</b>: The paper discusses AI applications for energy efficiency in smart buildings, focusing on multi-agent systems, IoT, Big Data, anomaly detection, and Intelligent Energy Management Systems classifications.</p><hr><h3>Detecting, Explaining, and Mitigating Memorization in Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2407.21720v1'>http://arxiv.org/abs/2407.21720v1</a></p>
<p><b>Compressor summary</b>: The authors present a method to detect and mitigate memorization in diffusion models, ensuring that generated images are not replications of training data and addressing legal concerns.</p><hr><h3>Assessing the State of AI Policy</h3>
<p><a href='http://arxiv.org/abs/2407.21717v1'>http://arxiv.org/abs/2407.21717v1</a></p>
<p><b>Compressor summary</b>: The text discusses the need for oversight of AI technologies by policymakers who lack technical knowledge, and provides an overview of existing guidelines and regulations at various levels.</p><hr><h3>UMMAN: Unsupervised Multi-graph Merge Adversarial Network for Disease  Prediction Based on Intestinal Flora</h3>
<p><a href='http://arxiv.org/abs/2407.21714v1'>http://arxiv.org/abs/2407.21714v1</a></p>
<p><b>Compressor summary</b>: UMMAN is a novel method that uses Graph Neural Networks to predict intestinal flora diseases by learning the complex associations among gut microbes in an unsupervised way.</p><hr><h3>Social Learning through Interactions with Other Agents: A Survey</h3>
<p><a href='http://arxiv.org/abs/2407.21713v1'>http://arxiv.org/abs/2407.21713v1</a></p>
<p><b>Compressor summary</b>: The text discusses the role of social learning in human intelligence development and its potential application in machine learning, focusing on the use of embodied agents and natural language processing techniques.</p><hr><h3>Adaptive Retrieval-Augmented Generation for Conversational Systems</h3>
<p><a href='http://arxiv.org/abs/2407.21712v1'>http://arxiv.org/abs/2407.21712v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a gating model (RAGate) to determine whether external knowledge is needed for improved system responses in conversational systems, based on human judgements and conversation context.</p><hr><h3>CEAR: Automatic construction of a knowledge graph of chemical entities  and roles from scientific literature</h3>
<p><a href='http://arxiv.org/abs/2407.21708v1'>http://arxiv.org/abs/2407.21708v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to recognize chemical entities and their roles in scientific text using ontological knowledge from ChEBI and language understanding from LLMs, and create a knowledge graph (CEAR) to extend ChEBI.</p><hr><h3>Tora: Trajectory-oriented Diffusion Transformer for Video Generation</h3>
<p><a href='http://arxiv.org/abs/2407.21705v1'>http://arxiv.org/abs/2407.21705v1</a></p>
<p><b>Compressor summary</b>: Tora is a framework that generates videos with controllable motion by integrating trajectory information into a diffusion transformer model, enabling high-quality and dynamic video generation.</p><hr><h3>Hyper-parameter tuning for text guided image editing</h3>
<p><a href='http://arxiv.org/abs/2407.21703v1'>http://arxiv.org/abs/2407.21703v1</a></p>
<p><b>Compressor summary</b>: Forgedit is a text-guided image editing method that can handle complex problems by remembering and understanding input images during finetuning, and uses a simple workflow with efficient hyper-parameter tuning for editing.</p><hr><h3>TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue  System with Transfer Capabilities</h3>
<p><a href='http://arxiv.org/abs/2407.21693v1'>http://arxiv.org/abs/2407.21693v1</a></p>
<p><b>Compressor summary</b>: The study introduces a new dataset for task-oriented dialogue systems, called TransferTOD, which simulates human-machine conversations in 30 life service scenarios and improves the performance of large language models in information gathering.</p><hr><h3>Explainable Artificial Intelligence for Quantifying Interfering and  High-Risk Behaviors in Autism Spectrum Disorder in a Real-World Classroom  Environment Using Privacy-Preserving Video Analysis</h3>
<p><a href='http://arxiv.org/abs/2407.21691v1'>http://arxiv.org/abs/2407.21691v1</a></p>
<p><b>Compressor summary</b>: This study uses video-based group activity recognition to develop a machine learning model that can objectively and continuously quantify behaviors in autism spectrum disorder (ASD) in real-world classroom environments, helping to track intervention effectiveness and allocate resources.</p><hr><h3>Dynamic Object Queries for Transformer-based Incremental Object  Detection</h3>
<p><a href='http://arxiv.org/abs/2407.21687v1'>http://arxiv.org/abs/2407.21687v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Transformer-based method for incremental object detection that uses dynamic learnable queries to represent new and old classes and mitigates catastrophic forgetting through bipartite matching and risk-balanced calibration.</p><hr><h3>Expressive Whole-Body 3D Gaussian Avatar</h3>
<p><a href='http://arxiv.org/abs/2407.21686v1'>http://arxiv.org/abs/2407.21686v1</a></p>
<p><b>Compressor summary</b>: ExAvatar is a 3D human avatar that learns from monocular video and supports expressive whole-body movements, addressing challenges like limited diversity and absent 3D observations with a hybrid representation of mesh and 3D Gaussians.</p><hr><h3>Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation</h3>
<p><a href='http://arxiv.org/abs/2407.21674v1'>http://arxiv.org/abs/2407.21674v1</a></p>
<p><b>Compressor summary</b>: Synthetic data can introduce simplicity bias in neural networks when there is a strong correlation between the data source and the task label, leading to poor deployment performance.</p><hr><h3>Universal Approximation Theory: Foundations for Parallelism in Neural  Networks</h3>
<p><a href='http://arxiv.org/abs/2407.21670v1'>http://arxiv.org/abs/2407.21670v1</a></p>
<p><b>Compressor summary</b>: This paper presents a parallelization strategy for deep learning models based on the Universal Approximation Theorem to reduce training and inference times as more layers are added.</p><hr><h3>Synth-Empathy: Towards High-Quality Synthetic Empathy Data</h3>
<p><a href='http://arxiv.org/abs/2407.21669v1'>http://arxiv.org/abs/2407.21669v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Synth-Empathy, a system that uses large language models to generate and select high-quality empathetic data, improving empathetic response performance and achieving state-of-the-art results on benchmarks and human evaluations.</p><hr><h3>An Explainable Vision Transformer with Transfer Learning Combined with  Support Vector Machine Based Efficient Drought Stress Identification</h3>
<p><a href='http://arxiv.org/abs/2407.21666v1'>http://arxiv.org/abs/2407.21666v1</a></p>
<p><b>Compressor summary</b>: The text describes an explainable deep learning pipeline using vision transformers that detects drought stress in potato crops from aerial images, achieving high accuracy and providing insights into the plant features associated with stress.</p><hr><h3>Defending Jailbreak Attack in VLMs via Cross-modality Information  Detector</h3>
<p><a href='http://arxiv.org/abs/2407.21659v1'>http://arxiv.org/abs/2407.21659v1</a></p>
<p><b>Compressor summary</b>: The text introduces CIDER, a cross-modality information detector that uses image and text similarity to detect jailbreaking attacks on vision language models.</p><hr><h3>Comgra: A Tool for Analyzing and Debugging Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2407.21656v1'>http://arxiv.org/abs/2407.21656v1</a></p>
<p><b>Compressor summary</b>: Comgra is a PyTorch library that helps inspect neural networks by visualizing their internal activations and gradients in a GUI.</p><hr><h3>Spatial Transformer Network YOLO Model for Agricultural Object Detection</h3>
<p><a href='http://arxiv.org/abs/2407.21652v1'>http://arxiv.org/abs/2407.21652v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve YOLO's performance in object detection by integrating spatial transformer networks, which focus on important image areas and enhance spatial invariance.</p><hr><h3>Human interaction classifier for LLM based chatbot</h3>
<p><a href='http://arxiv.org/abs/2407.21647v1'>http://arxiv.org/abs/2407.21647v1</a></p>
<p><b>Compressor summary</b>: The study finds that using an SVM model with Cohere embeddings is the best way to classify human interactions in AIDA, a chatbot system, based on speed and accuracy.</p><hr><h3>Towards Achieving Human Parity on End-to-end Simultaneous Speech  Translation via LLM Agent</h3>
<p><a href='http://arxiv.org/abs/2407.21646v1'>http://arxiv.org/abs/2407.21646v1</a></p>
<p><b>Compressor summary</b>: CLASI is a human-like simultaneous speech translation system that uses a data-driven read-write strategy and multi-modal retrieval to convey information accurately and efficiently in various languages and scenarios.</p><hr><h3>Lyapunov weights to convey the meaning of time in physics-informed  neural networks</h3>
<p><a href='http://arxiv.org/abs/2407.21642v1'>http://arxiv.org/abs/2407.21642v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a principled way to adapt time weighting in Physics-Informed Neural Networks using Lyapunov exponents to handle different dynamics.</p><hr><h3>Quality Control for Radiology Report Generation Models via Auxiliary  Auditing Components</h3>
<p><a href='http://arxiv.org/abs/2407.21638v1'>http://arxiv.org/abs/2407.21638v1</a></p>
<p><b>Compressor summary</b>: The authors propose a framework for quality control of AI-generated radiology reports by using auxiliary auditing components that assess the reliability and importance of the diagnoses.</p><hr><h3>Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank  Adaptation</h3>
<p><a href='http://arxiv.org/abs/2407.21633v1'>http://arxiv.org/abs/2407.21633v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Dual Low-Rank Adaptation (DualLoRA), a method to improve zero-shot dialogue state tracking by enhancing prompt influence in transformer models without increasing inference latency.</p><hr><h3>RoadFormer+: Delivering RGB-X Scene Parsing through Scale-Aware  Information Decoupling and Advanced Heterogeneous Feature Fusion</h3>
<p><a href='http://arxiv.org/abs/2407.21631v1'>http://arxiv.org/abs/2407.21631v1</a></p>
<p><b>Compressor summary</b>: RoadFormer+ is a model that fuses different types of data for urban scene parsing, improving efficiency and performance over the previous RoadFormer model.</p><hr><h3>TAROT: Task-Oriented Authorship Obfuscation Using Policy Optimization  Methods</h3>
<p><a href='http://arxiv.org/abs/2407.21630v1'>http://arxiv.org/abs/2407.21630v1</a></p>
<p><b>Compressor summary</b>: TAROT is a new method for hiding an author's identity in a text while maintaining its usefulness, using policy optimization over small language models.</p><hr><h3>EZSR: Event-based Zero-Shot Recognition</h3>
<p><a href='http://arxiv.org/abs/2407.21616v1'>http://arxiv.org/abs/2407.21616v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new event encoder for zero-shot object recognition using event camera data and synthetic RGB images, improving performance over previous methods that relied on RGB frame reconstructions.</p><hr><h3>MicroMIL: Graph-based Contextual Multiple Instance Learning for Patient  Diagnosis Using Microscopy Images</h3>
<p><a href='http://arxiv.org/abs/2407.21604v1'>http://arxiv.org/abs/2407.21604v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MicroMIL, a weakly-supervised framework that uses deep cluster embedding and Gumbel Softmax to analyze microscopy images for histopathology research, improving efficiency and accuracy over existing methods.</p><hr><h3>Measuring What Matters: Intrinsic Distance Preservation as a Robust  Metric for Embedding Quality</h3>
<p><a href='http://arxiv.org/abs/2407.21590v1'>http://arxiv.org/abs/2407.21590v1</a></p>
<p><b>Compressor summary</b>: This paper introduces IDPE, a novel method for evaluating unsupervised embeddings based on preserving Mahalanobis distances between data points in original and embedded spaces, providing a more reliable and comprehensive assessment than traditional extrinsic metrics.</p><hr><h3>InScope: A New Real-world 3D Infrastructure-side Collaborative  Perception Dataset for Open Traffic Scenarios</h3>
<p><a href='http://arxiv.org/abs/2407.21581v1'>http://arxiv.org/abs/2407.21581v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Autonomous vehicles' perception systems can miss occluded objects due to vehicle-centric perspective
- V2X paradigm proposes infrastructure-side perception system (IPS) to complement autonomous vehicles
- InScope is a new 3D infrastructure-side collaborative perception dataset with LiDAR sensors on infrastructure side
- InScope provides benchmarks for various tasks related to occlusion challenges in V2X scenarios
- InScope improves detection and tracking of obscured, small, and distant objects

Summary:
InScope is a new dataset that helps autonomous vehicles detect and track occluded objects by using LiDAR sensors on the infrastructure side. It also provides benchmarks for evaluating V2X technologies in occlusion scenarios.</p><hr><h3>Multi-Site Class-Incremental Learning with Weighted Experts in  Echocardiography</h3>
<p><a href='http://arxiv.org/abs/2407.21577v1'>http://arxiv.org/abs/2407.21577v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a class-incremental learning method for echocardiography view classification that combines expert networks with a score fusion model to handle data diversity and privacy concerns.</p><hr><h3>PMoE: Progressive Mixture of Experts with Asymmetric Transformer for  Continual Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21571v1'>http://arxiv.org/abs/2407.21571v1</a></p>
<p><b>Compressor summary</b>: PMoE is a novel method that uses an asymmetric Transformer to reduce forgetting in large Language Models by adding progressive experts and routing new knowledge to appropriate layers.</p><hr><h3>TRGR: Transmissive RIS-aided Gait Recognition Through Walls</h3>
<p><a href='http://arxiv.org/abs/2407.21566v1'>http://arxiv.org/abs/2407.21566v1</a></p>
<p><b>Compressor summary</b>: TRGR is a novel system that uses transmissive RIS to enhance gait recognition through walls using only magnitude measurements of RF signals.</p><hr><h3>Generative Sentiment Analysis via Latent Category Distribution and  Constrained Decoding</h3>
<p><a href='http://arxiv.org/abs/2407.21560v1'>http://arxiv.org/abs/2407.21560v1</a></p>
<p><b>Compressor summary</b>: The study introduces a generative sentiment analysis model that addresses challenges in fine-grained sentiment analysis by using a latent category distribution variable, a variational autoencoder, and a trie data structure with constrained decoding.</p><hr><h3>Operator-based semantics for choice programs: is choosing losing? (full  version)</h3>
<p><a href='http://arxiv.org/abs/2407.21556v1'>http://arxiv.org/abs/2407.21556v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a framework to compare different semantics of choice constructs in logic programming.</p><hr><h3>Conditioned Prompt-Optimization for Continual Deepfake Detection</h3>
<p><a href='http://arxiv.org/abs/2407.21554v1'>http://arxiv.org/abs/2407.21554v1</a></p>
<p><b>Compressor summary</b>: Prompt2Guard is a novel deepfake detection method that uses vision-language models and multimodal prompts to continuously detect photorealistic fake images without relying on prompt selection accuracy or multiple forward passes.</p><hr><h3>CXSimulator: A User Behavior Simulation using LLM Embeddings for  Web-Marketing Campaign Assessment</h3>
<p><a href='http://arxiv.org/abs/2407.21553v1'>http://arxiv.org/abs/2407.21553v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a CX Simulator that uses large language models to predict user behavior transitions and simulate web-marketing campaign effects without costly online testing.</p><hr><h3>Black box meta-learning intrinsic rewards for sparse-reward environments</h3>
<p><a href='http://arxiv.org/abs/2407.21546v1'>http://arxiv.org/abs/2407.21546v1</a></p>
<p><b>Compressor summary</b>: This paper explores how meta-learning can enhance reinforcement learning by optimizing intrinsic rewards without using meta-gradients, and compares it to other methods in continuous control tasks with sparse rewards.</p><hr><h3>Probabilistic Scoring Lists for Interpretable Machine Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21535v1'>http://arxiv.org/abs/2407.21535v1</a></p>
<p><b>Compressor summary</b>: The paper proposes probabilistic scoring lists (PSL), an extension of scoring systems that represent uncertainty with probability distributions, and a method for learning PSLs from data to improve explainability in AI decisions.</p><hr><h3>ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large  Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.21534v1'>http://arxiv.org/abs/2407.21534v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a way to improve multimodal language models' visual referring ability by adjusting visual tokens based on text prompts during inference, without needing extra training.</p><hr><h3>Data Contamination Report from the 2024 CONDA Shared Task</h3>
<p><a href='http://arxiv.org/abs/2407.21530v1'>http://arxiv.org/abs/2407.21530v1</a></p>
<p><b>Compressor summary</b>: The CONDA 2024 workshop investigates data contamination in natural language processing and aims to create a shared task and database to collect evidence and prevent evaluation results on contaminated resources.</p><hr><h3>Skeleton-Based Action Recognition with Spatial-Structural Graph  Convolution</h3>
<p><a href='http://arxiv.org/abs/2407.21525v1'>http://arxiv.org/abs/2407.21525v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Spatial-Structural GCN, a new method for skeleton-based human activity recognition that leverages both the topological structure and the dynamic similarity of edge node sequences in graph convolutional networks.</p><hr><h3>Tabular Data Augmentation for Machine Learning: Progress and Prospects  of Embracing Generative AI</h3>
<p><a href='http://arxiv.org/abs/2407.21523v1'>http://arxiv.org/abs/2407.21523v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Tabular data augmentation (TDA) enhances tabular data for machine learning tasks
- TDA pipeline consists of pre-augmentation, augmentation, and post-augmentation procedures
- Generative AI is a trending approach for TDA

Summary:
The text reviews the progress and prospects of TDA, which improves tabular data for ML using generative AI and other methods.</p><hr><h3>PhysFlow: Skin tone transfer for remote heart rate estimation through  conditional normalizing flows</h3>
<p><a href='http://arxiv.org/abs/2407.21519v1'>http://arxiv.org/abs/2407.21519v1</a></p>
<p><b>Compressor summary</b>: PhysFlow is a method for improving remote heart rate estimation by augmenting skin diversity using conditional normalizing flows, reducing errors especially in darker skin tones.</p><hr><h3>A Simple Low-bit Quantization Framework for Video Snapshot Compressive  Imaging</h3>
<p><a href='http://arxiv.org/abs/2407.21517v1'>http://arxiv.org/abs/2407.21517v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a simple framework to reduce computational cost in video snapshot compressive imaging using low-bit quantization and improves the performance of existing methods.</p><hr><h3>PEAR: Phrase-Based Hand-Object Interaction Anticipation</h3>
<p><a href='http://arxiv.org/abs/2407.21510v1'>http://arxiv.org/abs/2407.21510v1</a></p>
<p><b>Compressor summary</b>: PEAR is a novel model that anticipates both interaction intention and manipulation in first-person hand-object interaction, addressing uncertainties using cross-alignment and bidirectional constraints.</p><hr><h3>Root Cause Analysis Of Productivity Losses In Manufacturing Systems  Utilizing Ensemble Machine Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21503v1'>http://arxiv.org/abs/2407.21503v1</a></p>
<p><b>Compressor summary</b>: The study proposes a data-driven ensemble approach that analyzes productivity losses in automation systems, identifies root causes, and improves efficiency by integrating information theory and machine learning methods with stream processing.</p><hr><h3>Mitral Regurgitation Recogniton based on Unsupervised  Out-of-Distribution Detection with Residual Diffusion Amplification</h3>
<p><a href='http://arxiv.org/abs/2407.21497v1'>http://arxiv.org/abs/2407.21497v1</a></p>
<p><b>Compressor summary</b>: The text proposes an unsupervised out-of-distribution detection method for mitral regurgitation diagnosis using ultrasound videos, which can improve accuracy and reduce misdiagnosis.</p><hr><h3>Generative Expressive Conversational Speech Synthesis</h3>
<p><a href='http://arxiv.org/abs/2407.21491v1'>http://arxiv.org/abs/2407.21491v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new system called GPT-Talker that generates natural and expressive conversational speech for user-agent interactions using multimodal information, and proposes a large dataset to evaluate its performance.</p><hr><h3>Maverick: Efficient and Accurate Coreference Resolution Defying Recent  Trends</h3>
<p><a href='http://arxiv.org/abs/2407.21489v1'>http://arxiv.org/abs/2407.21489v1</a></p>
<p><b>Compressor summary</b>: Maverick is a simple and efficient pipeline for coreference resolution that outperforms large generative models with up to 13 billion parameters using only 500 million parameters, achieving state-of-the-art results on the CoNLL-2012 benchmark.</p><hr><h3>Parallel Strategies for Best-First Generalized Planning</h3>
<p><a href='http://arxiv.org/abs/2407.21485v1'>http://arxiv.org/abs/2407.21485v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates how to speed up generalized planning by applying parallel search techniques to a novel algorithm called Best-First Generalized Planning (BFGP).</p><hr><h3>eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in  RDF-star Knowledge Graphs</h3>
<p><a href='http://arxiv.org/abs/2407.21483v1'>http://arxiv.org/abs/2407.21483v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a four-valued logic query language called eSPARQL for operating with multiple and sometimes conflicting beliefs in epistemic RDF-star metadata.</p><hr><h3>On the Problem of Text-To-Speech Model Selection for Synthetic Data  Generation in Automatic Speech Recognition</h3>
<p><a href='http://arxiv.org/abs/2407.21476v1'>http://arxiv.org/abs/2407.21476v1</a></p>
<p><b>Compressor summary</b>: The text discusses how different TTS architectures affect synthetic data generation for ASR and SLT, but finds no clear relation between TTS performance and ASR performance.</p><hr><h3>Fine-gained Zero-shot Video Sampling</h3>
<p><a href='http://arxiv.org/abs/2407.21475v1'>http://arxiv.org/abs/2407.21475v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel algorithm that generates high-quality videos from image synthesis models without extra training or optimization, using dependency noise model and temporal momentum attention for content consistency and animation coherence.</p><hr><h3>Deep Learning-Based Longitudinal Prediction of Childhood Myopia  Progression Using Fundus Image Sequences and Baseline Refraction Data</h3>
<p><a href='http://arxiv.org/abs/2407.21467v1'>http://arxiv.org/abs/2407.21467v1</a></p>
<p><b>Compressor summary</b>: The study introduces a deep learning method that accurately predicts myopia progression and risk in children using fundus images and refraction data, enabling early interventions and reducing healthcare costs.</p><hr><h3>MarvelOVD: Marrying Object Recognition and Vision-Language Models for  Robust Open-Vocabulary Object Detection</h3>
<p><a href='http://arxiv.org/abs/2407.21465v1'>http://arxiv.org/abs/2407.21465v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method, coded MarvelOVD, to improve open vocabulary detection by using the detector as an auxiliary guidance for vision language models and addressing the noise and bias issues in pseudo-labels.</p><hr><h3>Multi-agent Assessment with QoS Enhancement for HD Map Updates in a  Vehicular Network</h3>
<p><a href='http://arxiv.org/abs/2407.21460v1'>http://arxiv.org/abs/2407.21460v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates a multi-agent Q-learning solution for improving network performance in VANETs without increasing computational burden or compatibility issues.</p><hr><h3>KemenkeuGPT: Leveraging a Large Language Model on Indonesia's Government  Financial Data and Regulations to Enhance Decision Making</h3>
<p><a href='http://arxiv.org/abs/2407.21459v1'>http://arxiv.org/abs/2407.21459v1</a></p>
<p><b>Compressor summary</b>: This study develops KemenkeuGPT, a Large Language Model using LLM techniques, to help Indonesia's Ministry of Finance make decisions with complex financial data and regulations, showing its potential as an essential tool.</p><hr><h3>StreetSurfaceVis: a dataset of crowdsourced street-level imagery with  semi-automated annotations of road surface type and quality</h3>
<p><a href='http://arxiv.org/abs/2407.21454v1'>http://arxiv.org/abs/2407.21454v1</a></p>
<p><b>Compressor summary</b>: The paper introduces StreetSurfaceVis, a dataset with 9,122 street images annotated for road surface type and quality to train models for assessing road surfaces, addressing the imbalance and reducing manual annotation using various strategies.</p><hr><h3>TinyChirp: Bird Song Recognition Using TinyML Models on Low-power  Wireless Acoustic Sensors</h3>
<p><a href='http://arxiv.org/abs/2407.21453v1'>http://arxiv.org/abs/2407.21453v1</a></p>
<p><b>Compressor summary</b>: The paper compares tinyML neural network architectures and compression techniques for bird song detection, focusing on the corn bunning species.</p><hr><h3>Forecasting Future Videos from Novel Views via Disentangled 3D Scene  Representation</h3>
<p><a href='http://arxiv.org/abs/2407.21450v1'>http://arxiv.org/abs/2407.21450v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a 3D video extrapolation method that disentangles geometry and motion, improving accuracy and quality of future video predictions.</p><hr><h3>Accelerating Image Super-Resolution Networks with Pixel-Level  Classification</h3>
<p><a href='http://arxiv.org/abs/2407.21448v1'>http://arxiv.org/abs/2407.21448v1</a></p>
<p><b>Compressor summary</b>: The proposed method (PCSR) adaptively allocates computational resources to pixels based on their restoration difficulty, improving efficiency and performance for single image super-resolution.</p><hr><h3>Improving Faithfulness of Large Language Models in Summarization via  Sliding Generation and Self-Consistency</h3>
<p><a href='http://arxiv.org/abs/2407.21443v1'>http://arxiv.org/abs/2407.21443v1</a></p>
<p><b>Compressor summary</b>: SliSum is a novel summary generation strategy that improves the faithfulness of LLMs by dividing the source article into overlapping windows and generating local summaries for each window, then aggregating them using clustering and majority voting.</p><hr><h3>QuestGen: Effectiveness of Question Generation Methods for Fact-Checking  Applications</h3>
<p><a href='http://arxiv.org/abs/2407.21441v1'>http://arxiv.org/abs/2407.21441v1</a></p>
<p><b>Compressor summary</b>: The paper shows that automated question generation can improve fact-checking efficiency and sometimes yield better evidence than human-written questions.</p><hr><h3>MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented  Generation via Knowledge-enhanced Reranking and Noise-injected Training</h3>
<p><a href='http://arxiv.org/abs/2407.21439v1'>http://arxiv.org/abs/2407.21439v1</a></p>
<p><b>Compressor summary</b>: RagLLaVA is a novel framework that uses knowledge-enhanced reranking and noise-injected training to improve multimodal retrieval-augmented generation for dynamic contexts, addressing the multi-granularity noisy correspondence problem.</p><hr><h3>A Plug-and-Play Method for Rare Human-Object Interactions Detection by  Bridging Domain Gap</h3>
<p><a href='http://arxiv.org/abs/2407.21438v1'>http://arxiv.org/abs/2407.21438v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Human-object interactions (HOI) detection is important for visual reasoning and scene understanding
- Existing methods struggle with rare human-object pairs due to real world bias
- CEFA is a novel framework that aligns generated data with original data at the feature level and bridges the domain gap
- CEFA consists of a feature alignment module and a context enhancement module

Summary:
CEFA is a new framework for improving HOI detection on rare categories by aligning features and enhancing context of generated and original data.</p><hr><h3>Enriching thermal point clouds of buildings using semantic 3D building  modelsenriching thermal point clouds of buildings using semantic 3D building  models</h3>
<p><a href='http://arxiv.org/abs/2407.21436v1'>http://arxiv.org/abs/2407.21436v1</a></p>
<p><b>Compressor summary</b>: The proposed method enhances thermal point clouds with building semantics and location, improving thermal analysis and supporting deep learning models.</p><hr><h3>Analyzing the impact of semantic LoD3 building models on image-based  vehicle localization</h3>
<p><a href='http://arxiv.org/abs/2407.21432v1'>http://arxiv.org/abs/2407.21432v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel car localization method using image features and detailed 3D building models, improving accuracy in GNSS-denied urban areas.</p><hr><h3>Cost-Effective Hallucination Detection for LLMs</h3>
<p><a href='http://arxiv.org/abs/2407.21424v1'>http://arxiv.org/abs/2407.21424v1</a></p>
<p><b>Compressor summary</b>: The text describes a pipeline for detecting hallucinations in large language models' outputs by scoring, calibrating, and thresholding their confidence, and proposes a multi-scoring framework to improve performance and reduce costs.</p><hr><h3>Generalized Tampered Scene Text Detection in the era of Generative AI</h3>
<p><a href='http://arxiv.org/abs/2407.21422v1'>http://arxiv.org/abs/2407.21422v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new task, dataset, and framework for detecting text tampering in images by generative AI models, aiming to improve generalization and perception of forgery detection.</p><hr><h3>FTuner: A Fast Dynamic Shape Tensors Program Auto-Tuner for Deep  Learning Compilers</h3>
<p><a href='http://arxiv.org/abs/2407.21418v1'>http://arxiv.org/abs/2407.21418v1</a></p>
<p><b>Compressor summary</b>: FTuner is a new technique for deep learning compilers that uses uKernels to patch together small tensors, achieving comparable performance and speedup while reducing tuning time significantly.</p><hr><h3>Dancing in Chains: Reconciling Instruction Following and Faithfulness in  Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.21417v1'>http://arxiv.org/abs/2407.21417v1</a></p>
<p><b>Compressor summary</b>: ReSet is a method to improve language models by combining self-instruction and rejection sampling, which enhances both faithfulness and instruction following compared to multi-task learning.</p><hr><h3>VIPeR: Visual Incremental Place Recognition with Adaptive Mining and  Lifelong Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21416v1'>http://arxiv.org/abs/2407.21416v1</a></p>
<p><b>Compressor summary</b>: VIPeR is a novel visual incremental place recognition method that adapts to new environments while preserving previous ones, using an adaptive mining strategy and a memory bank with probabilistic knowledge distillation.</p><hr><h3>Benchmarking AIGC Video Quality Assessment: A Dataset and Unified Model</h3>
<p><a href='http://arxiv.org/abs/2407.21408v1'>http://arxiv.org/abs/2407.21408v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Paper investigates subjective and objective quality assessment of AI-generated video (AIGC)
- Constructs LGVQ dataset with 2,808 AIGC videos from 6 models and 468 text prompts
- Evaluates existing metrics on LGVQ dataset and proposes UGVQ model to assess quality across three aspects

Summary:
The paper presents a large dataset and a new metric for evaluating the quality of AI-generated video from different perspectives, including spatial, temporal, and text-to-video alignment.</p><hr><h3>DD-rPPGNet: De-interfering and Descriptive Feature Learning for  Unsupervised rPPG Estimation</h3>
<p><a href='http://arxiv.org/abs/2407.21402v1'>http://arxiv.org/abs/2407.21402v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel network, DD-rPPGNet, that eliminates interference in remote photoplethysmography (rPPG) signals to improve estimation performance.</p><hr><h3>SmileyNet -- Towards the Prediction of the Lottery by Reading Tea Leaves  with AI</h3>
<p><a href='http://arxiv.org/abs/2407.21385v1'>http://arxiv.org/abs/2407.21385v1</a></p>
<p><b>Compressor summary</b>: SmileyNet is a neural network that uses smiley faces and positive reinforcement to predict coin flips using tea leaf images, outperforming other models and enabling lottery wins.</p><hr><h3>GEGA: Graph Convolutional Networks and Evidence Retrieval Guided  Attention for Enhanced Document-level Relation Extraction</h3>
<p><a href='http://arxiv.org/abs/2407.21384v1'>http://arxiv.org/abs/2407.21384v1</a></p>
<p><b>Compressor summary</b>: GEGA is a novel graph neural network-based model for extracting relations between entities from unstructured document text, addressing challenges in evidence retrieval and complex cross-relations.</p><hr><h3>An Extended Kalman Filter Integrated Latent Feature Model on Dynamic  Weighted Directed Graphs</h3>
<p><a href='http://arxiv.org/abs/2407.21376v1'>http://arxiv.org/abs/2407.21376v1</a></p>
<p><b>Compressor summary</b>: The study proposes a novel EKLF model that uses an Extended Kalman Filter to track complex temporal patterns and an ALS algorithm to train latent features for representing dynamic weighted directed graphs, achieving better prediction accuracy and efficiency than existing models.</p><hr><h3>Prompting Medical Large Vision-Language Models to Diagnose Pathologies  by Visual Question Answering</h3>
<p><a href='http://arxiv.org/abs/2407.21368v1'>http://arxiv.org/abs/2407.21368v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Large Vision-Language Models (LVLMs) are successful in medical VQA but suffer from hallucination and imbalanced data problems
- Two prompting strategies reduce hallucination and improve VQA performance on complex pathologies
- The methods can be extended to general LVLM domains

Summary:
The authors propose two prompting strategies that enhance LVLMs' ability to diagnose complex medical pathologies by reducing hallucination and leveraging weak learners.</p><hr><h3>ESIQA: Perceptual Quality Assessment of Vision-Pro-based Egocentric  Spatial Images</h3>
<p><a href='http://arxiv.org/abs/2407.21363v1'>http://arxiv.org/abs/2407.21363v1</a></p>
<p><b>Compressor summary</b>: This paper introduces ESIQAD, the first quality assessment database for egocentrical spatial images in eXtended Reality, and evaluates 22 IQA models using it.</p><hr><h3>ProSpec RL: Plan Ahead, then Execute</h3>
<p><a href='http://arxiv.org/abs/2407.21359v1'>http://arxiv.org/abs/2407.21359v1</a></p>
<p><b>Compressor summary</b>: ProSpec is a Reinforcement Learning method that uses prospective thinking to make optimal, lower-risk decisions by imagining future trajectories and employing cycle consistency for state reversibility and data efficiency.</p><hr><h3>Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting  Black-box Language Models with Knowledge Graphs</h3>
<p><a href='http://arxiv.org/abs/2407.21358v1'>http://arxiv.org/abs/2407.21358v1</a></p>
<p><b>Compressor summary</b>: Tree-of-Traversals is a new algorithm that helps large language models use knowledge graphs for better reasoning and question answering.</p><hr><h3>Differentially Private Block-wise Gradient Shuffle for Deep Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21347v1'>http://arxiv.org/abs/2407.21347v1</a></p>
<p><b>Compressor summary</b>: DP-BloGS is a new privacy-preserving algorithm for deep learning that shuffles gradients probabilistically and achieves fast training with strong protection against data extraction.</p><hr><h3>Dual-Constrained Dynamical Neural ODEs for Ambiguity-aware Continuous  Emotion Prediction</h3>
<p><a href='http://arxiv.org/abs/2407.21344v1'>http://arxiv.org/abs/2407.21344v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to model how emotions change over time using neural networks and constraints, and shows good results on a speech emotion database.</p><hr><h3>High-throughput 3D shape completion of potato tubers on a harvester</h3>
<p><a href='http://arxiv.org/abs/2407.21341v1'>http://arxiv.org/abs/2407.21341v1</a></p>
<p><b>Compressor summary</b>: The authors developed a 3D shape completion network (CoRe++) that uses RGB-D cameras to estimate potato yield more accurately by completing the 3D shape of individual tubers and achieved fast and accurate results on an operational harvester.</p><hr><h3>Image-Based Deep Reinforcement Learning with Intrinsically Motivated  Stimuli: On the Execution of Complex Robotic Tasks</h3>
<p><a href='http://arxiv.org/abs/2407.21338v1'>http://arxiv.org/abs/2407.21338v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new reinforcement learning method called NaSA-TD3 that uses intrinsic motivation to improve exploration and achieve better performance in complex, sparse environments with image inputs.</p><hr><h3>Chat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM</h3>
<p><a href='http://arxiv.org/abs/2407.21333v1'>http://arxiv.org/abs/2407.21333v1</a></p>
<p><b>Compressor summary</b>: Chat2Layout is an interactive system that uses large language models to generate and arrange furniture layouts in response to user input, enabling seamless communication and feedback-driven refinement.</p><hr><h3>CAMAv2: A Vision-Centric Approach for Static Map Element Annotation</h3>
<p><a href='http://arxiv.org/abs/2407.21331v1'>http://arxiv.org/abs/2407.21331v1</a></p>
<p><b>Compressor summary</b>: CAMAv2 is a vision-centric approach that generates high-quality, consistent, and accurate 3D annotations of static map elements without LiDAR inputs, improving the performance of models trained with these annotations.</p><hr><h3>Performance of Recent Large Language Models for a Low-Resourced Language</h3>
<p><a href='http://arxiv.org/abs/2407.21330v1'>http://arxiv.org/abs/2407.21330v1</a></p>
<p><b>Compressor summary</b>: Recent large language models, especially Claude and GPT 4o, have improved Sinhala performance compared to previous versions and other models, while Llama and Mistral can be enhanced by fine-tuning for better results.</p><hr><h3>MetaOpenFOAM: an LLM-based multi-agent framework for CFD</h3>
<p><a href='http://arxiv.org/abs/2407.21320v1'>http://arxiv.org/abs/2407.21320v1</a></p>
<p><b>Compressor summary</b>: MetaOpenFOAM is a novel framework that automates complex CFD simulations using natural language input and LLMs, achieving high pass rates and low costs per task.</p><hr><h3>Big Cooperative Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21319v1'>http://arxiv.org/abs/2407.21319v1</a></p>
<p><b>Compressor summary</b>: The text discusses how cooperation in training foundation models leads to advancements in artificial intelligence and proposes a new model, BigLearn-GAN, as an example.</p><hr><h3>Pathology Foundation Models</h3>
<p><a href='http://arxiv.org/abs/2407.21317v1'>http://arxiv.org/abs/2407.21317v1</a></p>
<p><b>Compressor summary</b>: Pathology AI, especially Foundation Models, has greatly improved diagnosis and decision-making, but faces challenges for clinical application.</p><hr><h3>State-observation augmented diffusion model for nonlinear assimilation</h3>
<p><a href='http://arxiv.org/abs/2407.21314v1'>http://arxiv.org/abs/2407.21314v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new data-driven algorithm (SOAD) for assimilating nonlinear physical and observational models, which improves accuracy over traditional methods.</p><hr><h3>EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised  Vision Transformer</h3>
<p><a href='http://arxiv.org/abs/2407.21311v1'>http://arxiv.org/abs/2407.21311v1</a></p>
<p><b>Compressor summary</b>: The paper introduces EUDA, an efficient domain adaptation framework that uses DINOv2 as a feature extractor and SDAL to balance adaptation and alignment, achieving comparable results with significantly fewer parameters.</p><hr><h3>Enhanced Self-Checkout System for Retail Based on Improved YOLOv10</h3>
<p><a href='http://arxiv.org/abs/2407.21308v1'>http://arxiv.org/abs/2407.21308v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an improved self-checkout system using YOLOv10 for retail automation, with better product recognition and faster checkout speed than existing methods.</p><hr><h3>A Vectorization Method Induced By Maximal Margin Classification For  Persistent Diagrams</h3>
<p><a href='http://arxiv.org/abs/2407.21298v1'>http://arxiv.org/abs/2407.21298v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new geometric vectorization method for persistent diagrams, which improves protein function prediction by using topological data analysis.</p><hr><h3>TrackSorter: A Transformer-based sorting algorithm for track finding in  High Energy Physics</h3>
<p><a href='http://arxiv.org/abs/2407.21290v1'>http://arxiv.org/abs/2407.21290v1</a></p>
<p><b>Compressor summary</b>: The paper introduces TrackSorter, a novel algorithm based on Transformers, that converts particle data into discrete tokens and sorts them to find tracks in High Energy Physics.</p><hr><h3>Multi-Level Querying using A Knowledge Pyramid</h3>
<p><a href='http://arxiv.org/abs/2407.21276v1'>http://arxiv.org/abs/2407.21276v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a multi-layer knowledge pyramid approach in Retrieval-Augmented Generation methods to improve precision and recall, and shows better results than existing methods on two benchmarks.</p><hr><h3>FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig  Relations</h3>
<p><a href='http://arxiv.org/abs/2407.21275v1'>http://arxiv.org/abs/2407.21275v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method for long-term time series forecasting using frequency domain representations and a novel attention mechanism based on Kramer-Kronig relations, achieving significant performance improvements over existing methods.</p><hr><h3>Automated Quantification of Hyperreflective Foci in SD-OCT With Diabetic  Retinopathy</h3>
<p><a href='http://arxiv.org/abs/2407.21272v1'>http://arxiv.org/abs/2407.21272v1</a></p>
<p><b>Compressor summary</b>: The authors propose an automated algorithm to measure hyperreflective foci in retinal images, which could help diagnose and monitor various retinal diseases.</p><hr><h3>Model Attribution in Machine-Generated Disinformation: A Domain  Generalization Approach with Supervised Contrastive Learning</h3>
<p><a href='http://arxiv.org/abs/2407.21264v1'>http://arxiv.org/abs/2407.21264v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel Supervised Contrastive Learning method to improve model attribution for machine-generated disinformation by focusing on the differences between large language models.</p><hr><h3>Tractable and Provably Efficient Distributional Reinforcement Learning  with General Value Function Approximation</h3>
<p><a href='http://arxiv.org/abs/2407.21260v1'>http://arxiv.org/abs/2407.21260v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes how distributional reinforcement learning can improve performance in stochastic environments by using Bellman unbiasedness and moment functionals, and proposes an efficient algorithm with a regret bound.</p><hr><h3>Lifelong Person Search</h3>
<p><a href='http://arxiv.org/abs/2407.21252v1'>http://arxiv.org/abs/2407.21252v1</a></p>
<p><b>Compressor summary</b>: The paper introduces lifelong person search, a problem where models are incrementally trained on new datasets while preserving old dataset knowledge, using techniques like knowledge distillation and rehearsal-based instance matching.</p>