
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2023-11-29</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2023-11-29 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion  Models</h3>
<p>Daniel Geng,Inbum Park,Andrew Owens</p>
<p><a href='http://arxiv.org/abs/2311.17919v1'>http://arxiv.org/abs/2311.17919v1</a></p>
<p><b>Compressor summary</b>: The authors propose a simple method to create multi-view optical illusions using text-to-image diffusion models and noise estimation from different views, resulting in visual anagrams that change appearance under certain transformations.</p><hr><h3>Do text-free diffusion models learn discriminative visual  representations?</h3>
<p>Soumik Mukhopadhyay,Matthew Gwilliam,Yosuke Yamaguchi,Vatsal Agarwal,Namitha Padmanabhan,Archana Swaminathan,Tianyi Zhou,Abhinav Shrivastava</p>
<p><a href='http://arxiv.org/abs/2311.17921v1'>http://arxiv.org/abs/2311.17921v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a unified representation learner that combines generative and discriminative tasks using diffusion models, which use U-Nets to remove noise and produce diverse, high-quality images, and introduces new mechanisms for feature fusion and feedback to improve performance on various image tasks.</p><hr><h3>A Simple Recipe for Language-guided Domain Generalized Segmentation</h3>
<p>Mohammad Fahes,Tuan-Hung Vu,Andrei Bursuc,Patrick Pérez,Raoul de Charette</p>
<p><a href='http://arxiv.org/abs/2311.17922v1'>http://arxiv.org/abs/2311.17922v1</a></p>
<p><b>Compressor summary</b>: The paper presents a framework for improving semantic segmentation with neural networks by using language to randomize and augment the data, while preserving CLIP's robustness.</p><hr><h3>Driving into the Future: Multiview Visual Forecasting and Planning with  World Model for Autonomous Driving</h3>
<p>Yuqi Wang,Jiawei He,Lue Fan,Hongxin Li,Yuntao Chen,Zhaoxiang Zhang</p>
<p><a href='http://arxiv.org/abs/2311.17918v1'>http://arxiv.org/abs/2311.17918v1</a></p>
<p><b>Compressor summary</b>: Drive-WM is a driving world model that generates high-fidelity multiview videos in driving scenes to enhance autonomous vehicle safety and efficiency by predicting future events and evaluating risks.</p><hr><h3>OPERA: Alleviating Hallucination in Multi-Modal Large Language Models  via Over-Trust Penalty and Retrospection-Allocation</h3>
<p>Qidong Huang,Xiaoyi Dong,Pan Zhang,Bin Wang,Conghui He,Jiaqi Wang,Dahua Lin,Weiming Zhang,Nenghai Yu</p>
<p><a href='http://arxiv.org/abs/2311.17911v1'>http://arxiv.org/abs/2311.17911v1</a></p>
<p><b>Compressor summary</b>: OPERA is a new method to reduce hallucination in multi-modal language models by penalizing over-trust and retrospecting token selection during decoding.</p><hr><h3>HUGS: Human Gaussian Splats</h3>
<p>Muhammed Kocabas,Jen-Hao Rick Chang,James Gabriel,Oncel Tuzel,Anurag Ranjan</p>
<p><a href='http://arxiv.org/abs/2311.17910v1'>http://arxiv.org/abs/2311.17910v1</a></p>
<p><b>Compressor summary</b>: HUGS uses 3D Gaussian Splatting and a monocular video with a small number of frames to learn an animatable human avatar from a static scene, achieving state-of-the-art rendering quality and speed.</p><hr><h3>CG3D: Compositional Generation for Text-to-3D via Gaussian Splatting</h3>
<p>Alexander Vilesov,Pradyumna Chari,Achuta Kadambi</p>
<p><a href='http://arxiv.org/abs/2311.17907v1'>http://arxiv.org/abs/2311.17907v1</a></p>
<p><b>Compressor summary</b>: CG3D is a method for generating detailed 3D graphics with text-conditioned guidance, overcoming constraints such as limited scene complexity and physically unrealistic compositions.</p><hr><h3>Language-conditioned Detection Transformer</h3>
<p>Jang Hyun Cho,Philipp Krähenbühl</p>
<p><a href='http://arxiv.org/abs/2311.17902v1'>http://arxiv.org/abs/2311.17902v1</a></p>
<p><b>Compressor summary</b>: The paper introduces DECOLA, an open-vocabulary detection framework that uses image-level labels and detailed annotations to train language-conditioned and unconditioned detectors for zero-shot performance on various benchmarks.</p><hr><h3>SODA: Bottleneck Diffusion Models for Representation Learning</h3>
<p>Drew A. Hudson,Daniel Zoran,Mateusz Malinowski,Andrew K. Lampinen,Andrew Jaegle,James L. McClelland,Loic Matthey,Felix Hill,Alexander Lerchner</p>
<p><a href='http://arxiv.org/abs/2311.17901v1'>http://arxiv.org/abs/2311.17901v1</a></p>
<p><b>Compressor summary</b>: SODA is a self-supervised diffusion model that learns strong visual representations by generating related novel views from compact source view encodings, enabling unsupervised ImageNet classification, reconstruction, editing, and synthesis tasks.</p><hr><h3>Knowledge Pursuit Prompting for Zero-Shot Multimodal Synthesis</h3>
<p>Jinqi Luo,Kwan Ho Ryan Chan,Dimitris Dimos,René Vidal</p>
<p><a href='http://arxiv.org/abs/2311.17898v1'>http://arxiv.org/abs/2311.17898v1</a></p>
<p><b>Compressor summary</b>: KPP is a zero-shot framework that uses external knowledge to enhance text-driven generative models' quality and faithfulness in multiple tasks without accessing their parameters.</p><hr><h3>Betrayed by Attention: A Simple yet Effective Approach for  Self-supervised Video Object Segmentation</h3>
<p>Shuangrui Ding,Rui Qian,Haohang Xu,Dahua Lin,Hongkai Xiong</p>
<p><a href='http://arxiv.org/abs/2311.17893v1'>http://arxiv.org/abs/2311.17893v1</a></p>
<p><b>Compressor summary</b>: The paper presents a simple self-supervised video object segmentation method that uses DINO-pretrained Transformers and clustering to achieve state-of-the-art results without auxiliary modalities or slot attention.</p><hr><h3>A Pipeline For Discourse Circuits From CCG</h3>
<p>Jonathon Liu,Razin A. Shaikh,Benjamin Rodatz,Richie Yeung,Bob Coecke</p>
<p><a href='http://arxiv.org/abs/2311.17892v1'>http://arxiv.org/abs/2311.17892v1</a></p>
<p><b>Compressor summary</b>: DisCoCirc is a new model that connects linguistic theory and modern NLP by representing text as circuits that capture meaning and can be used with classical or quantum methods.</p><hr><h3>Pose Anything: A Graph-Based Approach for Category-Agnostic Pose  Estimation</h3>
<p>Or Hirschorn,Shai Avidan</p>
<p><a href='http://arxiv.org/abs/2311.17891v1'>http://arxiv.org/abs/2311.17891v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new category-agnostic pose estimation method that uses a Graph Transformer Decoder to capture geometrical relations between keypoints, improving accuracy on the MP-100 benchmark.</p><hr><h3>TSDF-Sampling: Efficient Sampling for Neural Surface Field using  Truncated Signed Distance Field</h3>
<p>Chaerin Min,Sehyun Cha,Changhee Won,Jongwoo Lim</p>
<p><a href='http://arxiv.org/abs/2311.17878v1'>http://arxiv.org/abs/2311.17878v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to speed up multi-view neural surface reconstruction by using the Truncated Signed Distance Field (TSDF) of the scene, which reduces the number of samplings and maintains high rendering quality.</p><hr><h3>Enhancing Post-Hoc Explanation Benchmark Reliability for Image  Classification</h3>
<p>Tristan Gomez,Harold Mouchère</p>
<p><a href='http://arxiv.org/abs/2311.17876v1'>http://arxiv.org/abs/2311.17876v1</a></p>
<p><b>Compressor summary</b>: This paper uses Krippendorf's alpha to measure the reliability of image classification explanation methods and suggests model modifications to improve it.</p><hr><h3>FisherRF: Active View Selection and Uncertainty Quantification for  Radiance Fields using Fisher Information</h3>
<p>Wen Jiang,Boshu Lei,Kostas Daniilidis</p>
<p><a href='http://arxiv.org/abs/2311.17874v1'>http://arxiv.org/abs/2311.17874v1</a></p>
<p><b>Compressor summary</b>: The study proposes a new method using Fisher Information to efficiently select informative views and quantify uncertainty in Neural Radiance Fields, achieving state-of-the-art results and fast performance.</p><hr><h3>SAIBench: A Structural Interpretation of AI for Science Through  Benchmarks</h3>
<p>Yatao Li,Jianfeng Zhan</p>
<p><a href='http://arxiv.org/abs/2311.17869v1'>http://arxiv.org/abs/2311.17869v1</a></p>
<p><b>Compressor summary</b>: AI4S research uses machine learning to improve scientific computing, but needs better benchmarking methods like structural interpretation to ensure accuracy in real-world applications.</p><hr><h3>Gaussian Shell Maps for Efficient 3D Human Generation</h3>
<p>Rameen Abdal,Wang Yifan,Zifan Shi,Yinghao Xu,Ryan Po,Zhengfei Kuang,Qifeng Chen,Dit-Yan Yeung,Gordon Wetzstein</p>
<p><a href='http://arxiv.org/abs/2311.17857v1'>http://arxiv.org/abs/2311.17857v1</a></p>
<p><b>Compressor summary</b>: Gaussian Shell Maps (GSMs) are a new framework for generating high-quality, multi-view consistent 3D digital humans using an articulable scaffold of inflated and deflated shells with 3D Gaussian rendering primitives, avoiding the need for volume representations or view-inconsistent upsamplers.</p><hr><h3>Leveraging Graph Diffusion Models for Network Refinement Tasks</h3>
<p>Puja Trivedi,Ryan Rossi,David Arbour,Tong Yu,Franck Dernoncourt,Sungchul Kim,Nedim Lipka,Namyong Park,Nesreen K. Ahmed,Danai Koutra</p>
<p><a href='http://arxiv.org/abs/2311.17856v1'>http://arxiv.org/abs/2311.17856v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces a new graph generative framework called SGDM that uses subgraph diffusion to refine noisy and incomplete networks in various ways, such as removing unwanted subgraphs, expanding existing ones, and changing their style.</p><hr><h3>Maximum Entropy Model Correction in Reinforcement Learning</h3>
<p>Amin Rakhsha,Mete Kemertas,Mohammad Ghavamzadeh,Amir-massoud Farahmand</p>
<p><a href='http://arxiv.org/abs/2311.17855v1'>http://arxiv.org/abs/2311.17855v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for planning in reinforcement learning using an approximate model that can reduce error, accelerate convergence, and outperform traditional approaches.</p><hr><h3>Evaluating VLMs for Score-Based, Multi-Probe Annotation of 3D Objects</h3>
<p>Rishabh Kabra,Loic Matthey,Alexander Lerchner,Niloy J. Mitra</p>
<p><a href='http://arxiv.org/abs/2311.17851v1'>http://arxiv.org/abs/2311.17851v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to leverage pretrained vision language models for various annotation tasks involving unlabeled 3D objects by aggregating their scores and improving downstream predictions.</p><hr><h3>Towards Real-World Focus Stacking with Deep Learning</h3>
<p>Alexandre Araujo,Jean Ponce,Julien Mairal</p>
<p><a href='http://arxiv.org/abs/2311.17846v1'>http://arxiv.org/abs/2311.17846v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new dataset and deep learning algorithm for focus stacking in photography that works well with long bursts of real-world images and is more robust to noise.</p><hr><h3>SPiC-E : Structural Priors in 3D Diffusion Models using Cross Entity  Attention</h3>
<p>Etai Sella,Gal Fiebelman,Noam Atia,Hadar Averbuch-Elor</p>
<p><a href='http://arxiv.org/abs/2311.17834v1'>http://arxiv.org/abs/2311.17834v1</a></p>
<p><b>Compressor summary</b>: SPiC-E is a neural network that improves 3D diffusion models by using cross-entity attention to learn structural guidance from auxiliary shapes, enabling various applications with high quality and speed.</p><hr><h3>Analyzing and Explaining Image Classifiers via Diffusion Guidance</h3>
<p>Maximilian Augustin,Yannic Neuhaus,Matthias Hein</p>
<p><a href='http://arxiv.org/abs/2311.17833v1'>http://arxiv.org/abs/2311.17833v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework for generating images that help analyze and improve image classifiers' reliability and explainability, revealing new and existing failure modes.</p><hr><h3>Anomalous Behavior Detection in Trajectory Data of Older Drivers</h3>
<p>Seyedeh Gol Ara Ghoreishi,Sonia Moshfeghi,Muhammad Tanveer Jan,Joshua Conniff,KwangSoo Yang,Jinwoo Jang,Borko Furht,Ruth Tappen,David Newman,Monica Rosselli,Jiannan Zhai</p>
<p><a href='http://arxiv.org/abs/2311.17822v1'>http://arxiv.org/abs/2311.17822v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to detect drivers with unusual behavior from large datasets of detailed trajectories, which can help with applications like MCI detection and safe route recommendations for older drivers.</p><hr><h3>Higher-Order DisCoCat (Peirce-Lambek-Montague semantics)</h3>
<p>Alexis Toumi,Giovanni de Felice</p>
<p><a href='http://arxiv.org/abs/2311.17813v1'>http://arxiv.org/abs/2311.17813v1</a></p>
<p><b>Compressor summary</b>: The authors introduce a new type of linguistic model based on diagram-valued functions that can handle non-linear language phenomena and have a Python implementation.</p><hr><h3>DAP: Domain-aware Prompt Learning for Vision-and-Language Navigation</h3>
<p>Ting Liu,Yue Hu,Wansen Wu,Youkai Wang,Kai Xu,Quanjun Yin</p>
<p><a href='http://arxiv.org/abs/2311.17812v1'>http://arxiv.org/abs/2311.17812v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a new method (DAP) for improving vision-and-language models' performance in navigation tasks by learning soft visual prompts from in-domain image-text pairs.</p><hr><h3>Coloring the Past: Neural Historical Buildings Reconstruction from  Archival Photography</h3>
<p>David Komorowicz,Lu Sang,Ferdinand Maiwald,Daniel Cremers</p>
<p><a href='http://arxiv.org/abs/2311.17810v1'>http://arxiv.org/abs/2311.17810v1</a></p>
<p><b>Compressor summary</b>: The authors propose a volumetric rendering technique to reconstruct 3D models of historical buildings from limited datasets, including color appearance loss and a new historical dataset.</p><hr><h3>Aggregation Model Hyperparameters Matter in Digital Pathology</h3>
<p>Gustav Bredell,Marcel Fischer,Przemyslaw Szostak,Samaneh Abbasi-Sureshjani,Alvaro Gomariz</p>
<p><a href='http://arxiv.org/abs/2311.17804v1'>http://arxiv.org/abs/2311.17804v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses how the performance of feature extractor models in digital pathology depends on the choice of aggregation model hyperparameters, and proposes a comprehensive evaluation approach to understand this relationship better.</p><hr><h3>Learning to Simulate: Generative Metamodeling via Quantile Regression</h3>
<p>L. Jeff Hong,Yanxi Hou,Qingkai Zhang,Xiaowei Zhang</p>
<p><a href='http://arxiv.org/abs/2311.17797v1'>http://arxiv.org/abs/2311.17797v1</a></p>
<p><b>Compressor summary</b>: Generative metamodeling is a new technique that quickly generates outputs from complex simulation models for real-time decision-making, while preserving the distribution of inputs, and the paper proposes a new algorithm called quantile-regression-based generative metamodeling (QRGMM).</p><hr><h3>Marginal Laplacian Score</h3>
<p>Guy Hay,Ohad Volk</p>
<p><a href='http://arxiv.org/abs/2311.17795v1'>http://arxiv.org/abs/2311.17795v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Marginal Laplacian Score, a modified unsupervised feature selection method for handling imbalanced data, which improves the performance of Differentiable Unsupervised Feature Selection on synthetic and real-world data sets.</p><hr><h3>Propagate & Distill: Towards Effective Graph Learners Using  Propagation-Embracing MLPs</h3>
<p>Yong-Min Shin,Won-Yong Shin</p>
<p><a href='http://arxiv.org/abs/2311.17781v1'>http://arxiv.org/abs/2311.17781v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method called Propagate & Distill (P&D) to train a student MLP using knowledge distillation from a teacher GNN, which injects structural information by propagating the output of the teacher before distillation.</p><hr><h3>One-Shot Open Affordance Learning with Foundation Models</h3>
<p>Gen Li,Deqing Sun,Laura Sevilla-Lara,Varun Jampani</p>
<p><a href='http://arxiv.org/abs/2311.17776v1'>http://arxiv.org/abs/2311.17776v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a vision-language framework for learning object affordances from one example per category, which improves upon existing models' understanding and performance in this task.</p><hr><h3>Supervising the Centroid Baseline for Extractive Multi-Document  Summarization</h3>
<p>Simão Gonçalves,Gonçalo Correia,Diogo Pernes,Afonso Mendes</p>
<p><a href='http://arxiv.org/abs/2311.17771v1'>http://arxiv.org/abs/2311.17771v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes an enhanced version of the centroid method for extractive multi-document summarization that uses beam search and attention to achieve better performance across multiple languages.</p><hr><h3>PillarNeSt: Embracing Backbone Scaling and Pretraining for Pillar-based  3D Object Detection</h3>
<p>Weixin Mao,Tiancai Wang,Diankun Zhang,Junjie Yan,Osamu Yoshie</p>
<p><a href='http://arxiv.org/abs/2311.17770v1'>http://arxiv.org/abs/2311.17770v1</a></p>
<p><b>Compressor summary</b>: The paper improves pillar-based 3D object detection by using pretrained 2D ConvNets as backbones, which adapt to point cloud features like sparsity and irregularity.</p><hr><h3>Robustness Approaches for the Examination Timetabling Problem under Data  Uncertainty</h3>
<p>Bernd Bassimir,Rolf Wanka</p>
<p><a href='http://arxiv.org/abs/2311.17766v1'>http://arxiv.org/abs/2311.17766v1</a></p>
<p><b>Compressor summary</b>: The authors discuss different robust optimization methods for solving the examination timetabling problem with uncertainty, and evaluate their performance on real and random instances.</p><hr><h3>Cinematic Behavior Transfer via NeRF-based Differentiable Filming</h3>
<p>Xuekun Jiang,Anyi Rao,Jingbo Wang,Dahua Lin,Bo Dai</p>
<p><a href='http://arxiv.org/abs/2311.17754v1'>http://arxiv.org/abs/2311.17754v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method for optimizing camera movements and transferring shot types to new videos or virtual environments using NeRF and SMPL techniques.</p><hr><h3>BAND-2k: Banding Artifact Noticeable Database for Banding Detection and  Quality Assessment</h3>
<p>Zijian Chen,Wei Sun,Jun Jia,Fangfang Lu,Zicheng Zhang,Jing Liu,Ru Huang,Xiongkuo Min,Guangtao Zhai</p>
<p><a href='http://arxiv.org/abs/2311.17752v1'>http://arxiv.org/abs/2311.17752v1</a></p>
<p><b>Compressor summary</b>: The paper presents a large dataset for image banding assessment, proposes an effective method for detecting and evaluating banding artifacts using convolutional neural networks, and shows high correlation between banding intensity and perceptual quality.</p><hr><h3>Variational Bayes image restoration with compressive autoencoders</h3>
<p>Maud Biquard,Marie Chabert,Thomas Oberlin</p>
<p><a href='http://arxiv.org/abs/2311.17744v1'>http://arxiv.org/abs/2311.17744v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new algorithm (VBLE) for regularization in computational imaging using compressive autoencoders, which are smaller and easier to train than generative models, and shows that it performs well and fasts compared to existing methods.</p><hr><h3>Mukhyansh: A Headline Generation Dataset for Indic Languages</h3>
<p>Lokesh Madasu,Gopichand Kanumolu,Nirmal Surange,Manish Shrivastava</p>
<p><a href='http://arxiv.org/abs/2311.17743v1'>http://arxiv.org/abs/2311.17743v1</a></p>
<p><b>Compressor summary</b>: Mukhyansh is a large multilingual dataset for headline generation in Indian languages, overcoming challenges due to low-resource and limited data quality.</p><hr><h3>End-to-end Joint Rich and Normalized ASR with a limited amount of rich  training data</h3>
<p>Can Cui,Imran Ahamad Sheikh,Mostafa Sadeghi,Emmanuel Vincent</p>
<p><a href='http://arxiv.org/abs/2311.17741v1'>http://arxiv.org/abs/2311.17741v1</a></p>
<p><b>Compressor summary</b>: The paper compares two methods to train a speech recognition model that produces transcriptions with punctuation and capitalization, using limited labeled data and achieving different performance on out-of-domain data.</p><hr><h3>GenZI: Zero-Shot 3D Human-Scene Interaction Generation</h3>
<p>Lei Li,Angela Dai</p>
<p><a href='http://arxiv.org/abs/2311.17737v1'>http://arxiv.org/abs/2311.17737v1</a></p>
<p><b>Compressor summary</b>: GenZI is a method for generating 3D human-scene interactions using natural language descriptions and no 3D data, by distilling interaction priors from vision-language models and optimizing a 3D model's pose and shape.</p><hr><h3>Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via  Lightweight Erasers</h3>
<p>Chi-Pin Huang,Kai-Po Chang,Chung-Ting Tsai,Yung-Hsuan Lai,Yu-Chiang Frank Wang</p>
<p><a href='http://arxiv.org/abs/2311.17717v1'>http://arxiv.org/abs/2311.17717v1</a></p>
<p><b>Compressor summary</b>: Receler is a method to remove specific concepts from text-to-image models by using locality and robustness, improving performance over previous erasing methods.</p><hr><h3>SAMPro3D: Locating SAM Prompts in 3D for Zero-Shot Scene Segmentation</h3>
<p>Mutian Xu,Xingyilang Yin,Lingteng Qiu,Yang Liu,Xin Tong,Xiaoguang Han</p>
<p><a href='http://arxiv.org/abs/2311.17707v1'>http://arxiv.org/abs/2311.17707v1</a></p>
<p><b>Compressor summary</b>: SAMPro3D is a method for segmenting 3D indoor scenes from 2D frames using pretrained SAM, with techniques to improve alignment, quality, and diversity of results without additional training.</p><hr><h3>How to Build an AI Tutor that Can Adapt to Any Course and Provide  Accurate Answers Using Large Language Model and Retrieval-Augmented  Generation</h3>
<p>Chenxi Dong</p>
<p><a href='http://arxiv.org/abs/2311.17696v1'>http://arxiv.org/abs/2311.17696v1</a></p>
<p><b>Compressor summary</b>: AI Tutor is a web application that uses a large language model to provide personalized, evidence-based tutoring in any subject based on course materials.</p><hr><h3>Fair Text-to-Image Diffusion via Fair Mapping</h3>
<p>Jia Li,Lijie Hu,Jingfeng Zhang,Tianhang Zheng,Hua Zhang,Di Wang</p>
<p><a href='http://arxiv.org/abs/2311.17695v1'>http://arxiv.org/abs/2311.17695v1</a></p>
<p><b>Compressor summary</b>: Fair Mapping is a model-agnostic method for generating fair and diverse images from text-to-image diffusion models by controlling prompts and using a linear mapping network.</p><hr><h3>AviationGPT: A Large Language Model for the Aviation Domain</h3>
<p>Liya Wang,Jason Chou,Xin Zhou,Alex Tien,Diane M Baumgartner</p>
<p><a href='http://arxiv.org/abs/2311.17686v1'>http://arxiv.org/abs/2311.17686v1</a></p>
<p><b>Compressor summary</b>: AviationGPT is a large language model designed for the aviation domain that can handle various NLP tasks and improve the efficiency and safety of NAS operations.</p><hr><h3>Improving Minority Stress Detection with Emotions</h3>
<p>Jonathan Ivey,Susan Gauch</p>
<p><a href='http://arxiv.org/abs/2311.17676v1'>http://arxiv.org/abs/2311.17676v1</a></p>
<p><b>Compressor summary</b>: The authors evaluate psychological stress models on detecting minority stress and suggest using emotion-infused models to improve performance for these vulnerable populations.</p><hr><h3>TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in  Large Language Models</h3>
<p>Zheng Chu,Jingchang Chen,Qianglong Chen,Weijiang Yu,Haotian Wang,Ming Liu,Bing Qin</p>
<p><a href='http://arxiv.org/abs/2311.17667v1'>http://arxiv.org/abs/2311.17667v1</a></p>
<p><b>Compressor summary</b>: The paper introduces TimeBench, a benchmark for testing the temporal reasoning abilities of large language models, which reveals a performance gap between current LLMs and humans.</p><hr><h3>Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in  Autonomous Driving Applications</h3>
<p>Junyi Ma,Xieyuanli Chen,Jiawei Huang,Jingyi Xu,Zhen Luo,Jintao Xu,Weihao Gu,Rui Ai,Hesheng Wang</p>
<p><a href='http://arxiv.org/abs/2311.17663v1'>http://arxiv.org/abs/2311.17663v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces a new benchmark, Cam4DOcc, for camera-only 4D occupancy forecasting in autonomous driving applications that considers future scene changes based on multiple public datasets and evaluates four baseline methods.</p><hr><h3>Volumetric Cloud Field Reconstruction</h3>
<p>Jacob Lin,Miguel Farinha,Edward Gryspeerdt,Ronald Clark</p>
<p><a href='http://arxiv.org/abs/2311.17657v1'>http://arxiv.org/abs/2311.17657v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel deep learning approach that uses stereo images to reconstruct the shape and dynamics of volumetric phenomena like clouds and fog.</p><hr><h3>Multiple Toddler Tracking in Indoor Videos</h3>
<p>Somaieh Amraee,Bishoy Galoaa,Matthew Goodwin,Elaheh Hatamimajoumerd,Sarah Ostadabbas</p>
<p><a href='http://arxiv.org/abs/2311.17656v1'>http://arxiv.org/abs/2311.17656v1</a></p>
<p><b>Compressor summary</b>: The paper presents MTTSort, a method for accurately tracking toddlers in indoor videos using DeepSort algorithm and addressing challenges such as unpredictable movements, occlusions, and limited fields of view.</p><hr><h3>Vulnerability of Automatic Identity Recognition to Audio-Visual  Deepfakes</h3>
<p>Pavel Korshunov,Haolin Chen,Philip N. Garner,Sebastien Marcel</p>
<p><a href='http://arxiv.org/abs/2311.17655v1'>http://arxiv.org/abs/2311.17655v1</a></p>
<p><b>Compressor summary</b>: The paper introduces SWAN-DF, a realistic audio-visual deepfakes database that tests the vulnerability of face and speech recognition systems to synthetic media.</p><hr><h3>VIM: Probing Multimodal Large Language Models for Visual Embedded  Instruction Following</h3>
<p>Yujie Lu,Xiujun Li,William Yang Wang,Yejin Choi</p>
<p><a href='http://arxiv.org/abs/2311.17647v1'>http://arxiv.org/abs/2311.17647v1</a></p>
<p><b>Compressor summary</b>: VIM is a framework that tests how well multimodal language models understand visual instructions by embedding them in scenes, revealing performance differences among models.</p><hr><h3>Neural Fields with Thermal Activations for Arbitrary-Scale  Super-Resolution</h3>
<p>Alexander Becker,Rodrigo Caye Daudt,Nando Metzger,Jan Dirk Wegner,Konrad Schindler</p>
<p><a href='http://arxiv.org/abs/2311.17643v1'>http://arxiv.org/abs/2311.17643v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel way to design neural fields for single image super-resolution that incorporates Gaussian PSF as an anti-aliasing technique without increasing computational cost.</p><hr><h3>Erasing the Ephemeral: Joint Camera Refinement and Transient Object  Removal for Street View Synthesis</h3>
<p>Mreenav Shyam Deka,Lu Sang,Daniel Cremers</p>
<p><a href='http://arxiv.org/abs/2311.17634v1'>http://arxiv.org/abs/2311.17634v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method for creating new views of outdoor urban scenes using neural point light fields and dynamic object detection, while optimizing camera pose and refining both elements.</p><hr><h3>Introduction to Transformers: an NLP Perspective</h3>
<p>Tong Xiao,Jingbo Zhu</p>
<p><a href='http://arxiv.org/abs/2311.17633v1'>http://arxiv.org/abs/2311.17633v1</a></p>
<p><b>Compressor summary</b>: The paper provides an overview of Transformers, their architecture, refinements, applications, and limitations in natural language processing.</p><hr><h3>Efficient Decoder for End-to-End Oriented Object Detection in Remote  Sensing Images</h3>
<p>Jiaqi Zhao,Zeyu Ding,Yong Zhou,Hancheng Zhu,Wenliang Du,Rui Yao,Abdulmotaleb El Saddik</p>
<p><a href='http://arxiv.org/abs/2311.17629v1'>http://arxiv.org/abs/2311.17629v1</a></p>
<p><b>Compressor summary</b>: The proposed end-to-end oriented detector uses RRoI attention for multi-scale feature alignment and SDQ for efficient query optimization, achieving state-of-the-art performance on multiple datasets.</p><hr><h3>Focus on Query: Adversarial Mining Transformer for Few-Shot Segmentation</h3>
<p>Yuan Wang,Naisong Luo,Tianzhu Zhang</p>
<p><a href='http://arxiv.org/abs/2311.17626v1'>http://arxiv.org/abs/2311.17626v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new few-shot segmentation model, AMFormer, that focuses on query information and achieves accurate results with minimal support guidance or labels.</p><hr><h3>ShapeGPT: 3D Shape Generation with A Unified Multi-modal Language Model</h3>
<p>Fukun Yin,Xin Chen,Chi Zhang,Biao Jiang,Zibo Zhao,Jiayuan Fan,Gang Yu,Taihao Li,Tao Chen</p>
<p><a href='http://arxiv.org/abs/2311.17618v1'>http://arxiv.org/abs/2311.17618v1</a></p>
<p><b>Compressor summary</b>: ShapeGPT is a multimodal framework that uses language models to generate and edit 3D shapes based on instructions in natural language.</p><hr><h3>AnyLens: A Generative Diffusion Model with Any Rendering Lens</h3>
<p>Andrey Voynov,Amir Hertz,Moab Arar,Shlomi Fruchter,Daniel Cohen-Or</p>
<p><a href='http://arxiv.org/abs/2311.17609v1'>http://arxiv.org/abs/2311.17609v1</a></p>
<p><b>Compressor summary</b>: The study presents a framework that combines a text-to-image diffusion model with lens geometry to create realistic images with diverse visual effects like fish-eye and panorama.</p><hr><h3>Adversarial Robust Memory-Based Continual Learner</h3>
<p>Xiaoyue Mi,Fan Tang,Zonghan Yang,Danding Wang,Juan Cao,Peng Li,Yang Liu</p>
<p><a href='http://arxiv.org/abs/2311.17608v1'>http://arxiv.org/abs/2311.17608v1</a></p>
<p><b>Compressor summary</b>: The study proposes a new memory-based continual learning method that improves robustness against adversarial attacks by adjusting data logits and using gradient-based data selection.</p><hr><h3>Topology-Preserving Adversarial Training</h3>
<p>Xiaoyue Mi,Fan Tang,Yepeng Weng,Danding Wang,Juan Cao,Sheng Tang,Peng Li,Yang Liu</p>
<p><a href='http://arxiv.org/abs/2311.17607v1'>http://arxiv.org/abs/2311.17607v1</a></p>
<p><b>Compressor summary</b>: The study proposes TRAIN, a method that preserves the structure of natural samples in the representation space during adversarial training, improving both natural and robust accuracies on various image datasets.</p><hr><h3>Continual Learning with Low Rank Adaptation</h3>
<p>Martin Wistuba,Prabhu Teja Sivaprasad,Lukas Balles,Giovanni Zappella</p>
<p><a href='http://arxiv.org/abs/2311.17601v1'>http://arxiv.org/abs/2311.17601v1</a></p>
<p><b>Compressor summary</b>: The paper proposes CoLoR, a continual learning method that uses Low Rank Adaptation (LoRA) to update pre-trained transformers and maintain their performance on new data without relying on prompt tuning.</p><hr><h3>Improving embedding of graphs with missing data by soft manifolds</h3>
<p>Andrea Marinoni,Pietro Lio',Alessandro Barp,Christian Jutten,Mark Girolami</p>
<p><a href='http://arxiv.org/abs/2311.17598v1'>http://arxiv.org/abs/2311.17598v1</a></p>
<p><b>Compressor summary</b>: The paper introduces soft manifolds, a new class of mathematical structures for graph embedding that can handle weighted connections and missing data in complex datasets, leading to more accurate and reliable graph analysis.</p><hr><h3>Continual Self-supervised Learning: Towards Universal Multi-modal  Medical Data Representation Learning</h3>
<p>Yiwen Ye,Yutong Xie,Jianpeng Zhang,Ziyang Chen,Qi Wu,Yong Xia</p>
<p><a href='http://arxiv.org/abs/2311.17597v1'>http://arxiv.org/abs/2311.17597v1</a></p>
<p><b>Compressor summary</b>: The paper proposes MedCoSS, a continuous self-supervised learning approach for multi-modal medical data that addresses representation conflicts and catastrophic forgetting using rehearsal-based continual learning and feature distillation.</p><hr><h3>LanGWM: Language Grounded World Model</h3>
<p>Rudra P. K. Poudel,Harit Pandya,Chao Zhang,Roberto Cipolla</p>
<p><a href='http://arxiv.org/abs/2311.17593v1'>http://arxiv.org/abs/2311.17593v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method called LanGWM that uses language to improve reinforcement learning models' ability to handle out-of-distribution tasks and demonstrate its effectiveness in iGibson point navigation tasks.</p><hr><h3>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</h3>
<p>Ziqiao Peng,Wentao Hu,Yue Shi,Xiangyu Zhu,Xiaomei Zhang,Hao Zhao,Jun He,Hongyan Liu,Zhaoxin Fan</p>
<p><a href='http://arxiv.org/abs/2311.17590v1'>http://arxiv.org/abs/2311.17590v1</a></p>
<p><b>Compressor summary</b>: SyncTalk is a NeRF-based method that improves the realism of talking head videos by synchronizing facial expressions, lip movements, and head poses using innovative techniques.</p><hr><h3>CLIPC8: Face liveness detection algorithm based on image-text pairs and  contrastive learning</h3>
<p>Xu Liu,Shu Zhou,Yurong Song,Wenzhe Luo,Xin Zhang</p>
<p><a href='http://arxiv.org/abs/2311.17583v1'>http://arxiv.org/abs/2311.17583v1</a></p>
<p><b>Compressor summary</b>: The proposed face liveness detection method uses image-text pairs and contrastive learning to detect eight types of financial field attack behaviors, achieving high performance and robustness on various datasets.</p><hr><h3>LoCoMotif: Discovering time-warped motifs in time series</h3>
<p>Daan Van Wesenbeeck,Aras Yurtman,Wannes Meert,Hendrik Blockeel</p>
<p><a href='http://arxiv.org/abs/2311.17582v1'>http://arxiv.org/abs/2311.17582v1</a></p>
<p><b>Compressor summary</b>: LoCoMotif is a novel method for time series motif discovery that overcomes existing limitations and performs better in a physiotherapy use case.</p><hr><h3>LGFCTR: Local and Global Feature Convolutional Transformer for Image  Matching</h3>
<p>Wenhao Zhong,Jie Jiang</p>
<p><a href='http://arxiv.org/abs/2311.17571v1'>http://arxiv.org/abs/2311.17571v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel convolutional transformer that captures both local and global features for image matching under extreme conditions, outperforming existing methods.</p><hr><h3>Bias Resilient Multi-Step Off-Policy Goal-Conditioned Reinforcement  Learning</h3>
<p>Lisheng Wu,Ke Chen</p>
<p><a href='http://arxiv.org/abs/2311.17565v1'>http://arxiv.org/abs/2311.17565v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes two types of off-policy biases in goal-conditioned reinforcement learning, proposes solutions to leverage their benefits, and shows improved efficiency and performance in challenging ten-step scenarios.</p><hr><h3>Interpreting Differentiable Latent States for Healthcare Time-series  Data</h3>
<p>Yu Chen,Nivedita Bijlani,Samaneh Kouchaki,Payam Barnaghi</p>
<p><a href='http://arxiv.org/abs/2311.17560v1'>http://arxiv.org/abs/2311.17560v1</a></p>
<p><b>Compressor summary</b>: The paper presents an algorithm to interpret latent states and predictions in machine learning models, which can help identify patterns and predict patient outcomes in digital healthcare.</p><hr><h3>VINNA for Neonates -- Orientation Independence through Latent  Augmentations</h3>
<p>Leonie Henschel,David Kügler,Lilla Zöllei,Martin Reuter</p>
<p><a href='http://arxiv.org/abs/2311.17546v1'>http://arxiv.org/abs/2311.17546v1</a></p>
<p><b>Compressor summary</b>: The paper presents VINNA, a method for segmenting neonatal brain images that uses resolution-aware internal augmentations and 4-DOF transform module to improve accuracy and robustness.</p><hr><h3>TaskWeaver: A Code-First Agent Framework</h3>
<p>Bo Qiao,Liqun Li,Xu Zhang,Shilin He,Yu Kang,Chaoyun Zhang,Fangkai Yang,Hang Dong,Jue Zhang,Lu Wang,Minghua Ma,Pu Zhao,Si Qin,Xiaoting Qin,Chao Du,Yong Xu,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang</p>
<p><a href='http://arxiv.org/abs/2311.17541v1'>http://arxiv.org/abs/2311.17541v1</a></p>
<p><b>Compressor summary</b>: TaskWeaver is a framework that uses LLMs to create chatbots with rich data structures, flexible plugins, and secure code execution for complex tasks in specific domains.</p><hr><h3>The Effects of Overparameterization on Sharpness-aware Minimization: An  Empirical and Theoretical Analysis</h3>
<p>Sungbin Shin,Dongyeop Lee,Maksym Andriushchenko,Namhoon Lee</p>
<p><a href='http://arxiv.org/abs/2311.17539v1'>http://arxiv.org/abs/2311.17539v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how overparameterization affects sharpness-aware minimization (SAM) and finds that it improves generalization, convergence rate, and stability of minima in neural networks.</p><hr><h3>Smooth Video Synthesis with Noise Constraints on Diffusion Models for  One-shot Video Tuning</h3>
<p>Liang Peng,Haoran Cheng,Zheng Yang,Ruisi Zhao,Linxuan Xia,Chaotian Song,Qinglin Lu,Wei Liu,Boxi Wu</p>
<p><a href='http://arxiv.org/abs/2311.17536v1'>http://arxiv.org/abs/2311.17536v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a noise constraint for one-shot video tuning methods to improve consistency and smoothness, and introduces a new metric to evaluate video smoothness better.</p><hr><h3>Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech  Gesture Generation</h3>
<p>Xingqun Qi,Jiahao Pan,Peng Li,Ruibin Yuan,Xiaowei Chi,Mengfei Li,Wenhan Luo,Wei Xue,Shanghang Zhang,Qifeng Liu,Yike Guo</p>
<p><a href='http://arxiv.org/abs/2311.17532v1'>http://arxiv.org/abs/2311.17532v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method for generating realistic 3D co-speech gestures with emotional transitions using ChatGPT-4, audio inpainting, weakly supervised training, and keyframe sampling.</p><hr><h3>HiDiffusion: Unlocking High-Resolution Creativity and Efficiency in  Low-Resolution Trained Diffusion Models</h3>
<p>Shen Zhang,Zhaowei Chen,Zhenyu Zhao,Zhenyuan Chen,Yao Tang,Yuhao Chen,Wengang Cao,Jiajun Liang</p>
<p><a href='http://arxiv.org/abs/2311.17528v1'>http://arxiv.org/abs/2311.17528v1</a></p>
<p><b>Compressor summary</b>: HiDiffusion is a framework that improves high-resolution image synthesis by adjusting feature map size and using dynamic window attention in U-Net, achieving state-of-the-art performance without tuning.</p>