
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-08-29</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-08-29 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of  Encoders</h3>
<p><a href='http://arxiv.org/abs/2408.15998v1'>http://arxiv.org/abs/2408.15998v1</a></p>
<p><b>Compressor summary</b>: This study explores the design space for multimodal language models using vision encoders, finding that simple concatenation of visual tokens and pre-alignment improves performance on complex tasks.</p><hr><h3>Mamba or Transformer for Time Series Forecasting? Mixture of Universals  (MoU) Is All You Need</h3>
<p><a href='http://arxiv.org/abs/2408.15997v1'>http://arxiv.org/abs/2408.15997v1</a></p>
<p><b>Compressor summary</b>: Mixture of Universals (MoU) is a versatile model that combines short-term and long-time dependencies for enhanced time series forecasting performance with low computational costs.</p><hr><h3>Spatio-Temporal Context Prompting for Zero-Shot Action Detection</h3>
<p><a href='http://arxiv.org/abs/2408.15996v1'>http://arxiv.org/abs/2408.15996v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method that uses pretrained image-language models for spatio-temporal action detection, incorporating person-context interaction and context prompting to handle unseen actions and multi-action videos.</p><hr><h3>TEDRA: Text-based Editing of Dynamic and Photoreal Actors</h3>
<p><a href='http://arxiv.org/abs/2408.15995v1'>http://arxiv.org/abs/2408.15995v1</a></p>
<p><b>Compressor summary</b>: TEDRA is a method that allows text-based editing of realistic 3D avatars while maintaining their fidelity, dynamics, and pose control.</p><hr><h3>Perceive-IR: Learning to Perceive Degradation Better for All-in-One  Image Restoration</h3>
<p><a href='http://arxiv.org/abs/2408.15994v1'>http://arxiv.org/abs/2408.15994v1</a></p>
<p><b>Compressor summary</b>: Perceive-IR is an all-in-one image restorer that uses prompt learning and quality-aware strategies to achieve fine-grained quality control for different types and severities of image degradation.</p><hr><h3>ClimDetect: A Benchmark Dataset for Climate Change Detection and  Attribution</h3>
<p><a href='http://arxiv.org/abs/2408.15993v1'>http://arxiv.org/abs/2408.15993v1</a></p>
<p><b>Compressor summary</b>: ClimDetect is a standardized dataset that helps improve detection and attribution of climate change signals using deep learning and vision transformers, enabling better model evaluations and climate science.</p><hr><h3>CoGen: Learning from Feedback with Coupled Comprehension and Generation</h3>
<p><a href='http://arxiv.org/abs/2408.15992v1'>http://arxiv.org/abs/2408.15992v1</a></p>
<p><b>Compressor summary</b>: The text describes a study that improves language comprehension and generation by tightly integrating them and learning from user interactions, resulting in a more human-like system with up to 26% better performance.</p><hr><h3>Distribution Backtracking Builds A Faster Convergence Trajectory for  One-step Diffusion Distillation</h3>
<p><a href='http://arxiv.org/abs/2408.15991v1'>http://arxiv.org/abs/2408.15991v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new method called Distribution Backtracking Distillation (DisBack) that improves the speed and quality of training student diffusion models by using the entire convergence trajectory of teacher models.</p><hr><h3>WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task  Execution with Strategic Exploration</h3>
<p><a href='http://arxiv.org/abs/2408.15978v1'>http://arxiv.org/abs/2408.15978v1</a></p>
<p><b>Compressor summary</b>: WebPilot is a multi-agent system that combines strategic exploration and complex decision-making using MCTS to improve LLM-based web agents' adaptability and performance in dynamic, uncertain tasks.</p><hr><h3>BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition  Capabilities of Language Models in Multi-Agent Systems</h3>
<p><a href='http://arxiv.org/abs/2408.15971v1'>http://arxiv.org/abs/2408.15971v1</a></p>
<p><b>Compressor summary</b>: BattleAgentBench is a benchmark to evaluate language models' collaboration abilities in single-agent, paired-agent, and multi-agent scenarios of varying difficulty levels.</p><hr><h3>More Text, Less Point: Towards 3D Data-Efficient Point-Language  Understanding</h3>
<p><a href='http://arxiv.org/abs/2408.15966v1'>http://arxiv.org/abs/2408.15966v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new task for large language models to understand 3D objects with minimal data, introducing GreenPLM that uses more text data to compensate for the lack of 3D data and achieve robust 3D understanding.</p><hr><h3>Efficient Slice Anomaly Detection Network for 3D Brain MRI Volume</h3>
<p><a href='http://arxiv.org/abs/2408.15958v1'>http://arxiv.org/abs/2408.15958v1</a></p>
<p><b>Compressor summary</b>: SimpleSliceNet uses a pre-trained 2D model to extract features from 3D brain MRI slices, improving anomaly detection accuracy and reducing computational cost.</p><hr><h3>Fall Detection for Smart Living using YOLOv5</h3>
<p><a href='http://arxiv.org/abs/2408.15955v1'>http://arxiv.org/abs/2408.15955v1</a></p>
<p><b>Compressor summary</b>: The paper presents a highly accurate fall detection system using YOLOv5mu that works well in different smart home settings and can be improved with more data and sensors.</p><hr><h3>Atari-GPT: Investigating the Capabilities of Multimodal Large Language  Models as Low-Level Policies for Atari Games</h3>
<p><a href='http://arxiv.org/abs/2408.15950v1'>http://arxiv.org/abs/2408.15950v1</a></p>
<p><b>Compressor summary</b>: This paper explores using multimodal LLMs as low-level controllers in Atari games, evaluating their performance against traditional RL agents and human players.</p><hr><h3>Local Descriptors Weighted Adaptive Threshold Filtering For Few-Shot  Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15924v1'>http://arxiv.org/abs/2408.15924v1</a></p>
<p><b>Compressor summary</b>: The text proposes WATF, a strategy for local descriptor selection that adapts to image context and improves few-shot image classification by reducing background noise and focusing on category-related information.</p><hr><h3>DiffAge3D: Diffusion-based 3D-aware Face Aging</h3>
<p><a href='http://arxiv.org/abs/2408.15922v1'>http://arxiv.org/abs/2408.15922v1</a></p>
<p><b>Compressor summary</b>: DiffAge3D is a novel 3D face aging framework that performs faithful aging, identity preservation, and works in a 3D setting using a 3D GAN and CLIP model.</p><hr><h3>Leveraging Open Knowledge for Advancing Task Expertise in Large Language  Models</h3>
<p><a href='http://arxiv.org/abs/2408.15915v1'>http://arxiv.org/abs/2408.15915v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to improve large language models' expertise in specific domains by using few human-annotated samples and a mixture-of-expert system that emphasizes diversity and problem-solving abilities.</p><hr><h3>CoRe: Context-Regularized Text Embedding Learning for Text-to-Image  Personalization</h3>
<p><a href='http://arxiv.org/abs/2408.15914v1'>http://arxiv.org/abs/2408.15914v1</a></p>
<p><b>Compressor summary</b>: CoRe is a method to improve text-to-image personalization by regularizing the context tokens around a new concept, enhancing its semantic understanding and integration with existing tokens.</p><hr><h3>MetaGFN: Exploring Distant Modes with Adapted Metadynamics for  Continuous GFlowNets</h3>
<p><a href='http://arxiv.org/abs/2408.15905v1'>http://arxiv.org/abs/2408.15905v1</a></p>
<p><b>Compressor summary</b>: MetaGFN is a novel exploration algorithm for continuous generative models that uses Adapted Metadynamics to balance exploration and exploitation, resulting in faster convergence and better rewards.</p><hr><h3>LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration  in Evolving Environments</h3>
<p><a href='http://arxiv.org/abs/2408.15903v1'>http://arxiv.org/abs/2408.15903v1</a></p>
<p><b>Compressor summary</b>: GMeLLo is a method that combines Knowledge Graphs and Large Language Models to efficiently update and reason about facts in multi-hop questions.</p><hr><h3>Nexus: Specialization meets Adaptability for Efficiently Training  Mixture of Experts</h3>
<p><a href='http://arxiv.org/abs/2408.15901v1'>http://arxiv.org/abs/2408.15901v1</a></p>
<p><b>Compressor summary</b>: Nexus is an enhanced MoE architecture that upcycles dense expert models for improved specialization and adaptability to new tasks, achieving significant gains in performance with limited data.</p><hr><h3>Airfoil Diffusion: Denoising Diffusion Model For Conditional Airfoil  Generation</h3>
<p><a href='http://arxiv.org/abs/2408.15898v1'>http://arxiv.org/abs/2408.15898v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new method to generate airfoils using a data-driven diffusion model that can produce realistic and innovative designs with desired aerodynamic properties.</p><hr><h3>A New Method for Cross-Lingual-based Semantic Role Labeling</h3>
<p><a href='http://arxiv.org/abs/2408.15896v1'>http://arxiv.org/abs/2408.15896v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a deep learning model that improves semantic role labeling across multiple languages by using model transfer and limited data from English and Persian corpora, achieving better results than previous models.</p><hr><h3>Bias in LLMs as Annotators: The Effect of Party Cues on Labelling  Decision by Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15895v1'>http://arxiv.org/abs/2408.15895v1</a></p>
<p><b>Compressor summary</b>: The study shows that Large Language Models (LLMs) have political biases similar to human coders, but unlike humans, LLMs are biased even when faced with statements from moderate parties.</p><hr><h3>The Role of Fibration Symmetries in Geometric Deep Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15894v1'>http://arxiv.org/abs/2408.15894v1</a></p>
<p><b>Compressor summary</b>: Geometric Deep Learning (GDL) is improved by incorporating local symmetries in graphs, which enhances the performance and efficiency of Graph Neural Networks (GNNs).</p><hr><h3>Disentangled Diffusion Autoencoder for Harmonization of Multi-site  Neuroimaging Data</h3>
<p><a href='http://arxiv.org/abs/2408.15890v1'>http://arxiv.org/abs/2408.15890v1</a></p>
<p><b>Compressor summary</b>: The disentangled diffusion autoencoder (DDAE) is a novel diffusion model that generates high-quality, harmonized 2D MR images by controlling specific aspects of an image and preserving biological variability.</p><hr><h3>LLaVA-MoD: Making LLaVA Tiny via MoE Knowledge Distillation</h3>
<p><a href='http://arxiv.org/abs/2408.15881v1'>http://arxiv.org/abs/2408.15881v1</a></p>
<p><b>Compressor summary</b>: LLaVA-MoD is a novel framework that efficiently trains small-scale multimodal language models by distilling knowledge from large-scale ones using a sparse Mixture of Experts architecture and a progressive knowledge transfer strategy.</p><hr><h3>Persuasion Games using Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15879v1'>http://arxiv.org/abs/2408.15879v1</a></p>
<p><b>Compressor summary</b>: Large Language Models can enhance persuasive dialogue in diverse domains by collaborating with auxiliary agents that perform various tasks, counteracting user resistance, and adapting to different personality types.</p><hr><h3>Robust Statistical Scaling of Outlier Scores: Improving the Quality of  Outlier Probabilities for Outliers (Extended Version)</h3>
<p><a href='http://arxiv.org/abs/2408.15874v1'>http://arxiv.org/abs/2408.15874v1</a></p>
<p><b>Compressor summary</b>: Robust statistical scaling improves outlier probability transformation using robust estimators, addressing a limitation of common statistical scaling methods in outlier detection.</p><hr><h3>microYOLO: Towards Single-Shot Object Detection on Microcontrollers</h3>
<p><a href='http://arxiv.org/abs/2408.15865v1'>http://arxiv.org/abs/2408.15865v1</a></p>
<p><b>Compressor summary</b>: MicroYOLO is a single-shot object detector that works on small microcontrollers, achieving fast speeds and low memory usage.</p><hr><h3>What is YOLOv8: An In-Depth Exploration of the Internal Features of the  Next-Generation Object Detector</h3>
<p><a href='http://arxiv.org/abs/2408.15857v1'>http://arxiv.org/abs/2408.15857v1</a></p>
<p><b>Compressor summary</b>: The study analyzes the YOLOv8 object detection model, its innovations, performance improvements, benchmark results, and developer-friendly features, showcasing it as a leading approach in object detection.</p><hr><h3>Network transferability of adversarial patches in real-time object  detection</h3>
<p><a href='http://arxiv.org/abs/2408.15833v1'>http://arxiv.org/abs/2408.15833v1</a></p>
<p><b>Compressor summary</b>: This paper explores how adversarial patches can make objects invisible to object detectors and finds that patches optimized with larger models have better transferability across networks and datasets.</p><hr><h3>SITransformer: Shared Information-Guided Transformer for Extreme  Multimodal Summarization</h3>
<p><a href='http://arxiv.org/abs/2408.15829v1'>http://arxiv.org/abs/2408.15829v1</a></p>
<p><b>Compressor summary</b>: SITransformer is a new method for extreme multimodal summarization that uses cross-modal information to create accurate and concise summaries from various types of data.</p><hr><h3>Automatic Differential Diagnosis using Transformer-Based Multi-Label  Sequence Classification</h3>
<p><a href='http://arxiv.org/abs/2408.15827v1'>http://arxiv.org/abs/2408.15827v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Assistive technologies, such as automatic diagnostic systems, are being developed for healthcare
- The study proposes a transformer-based approach for providing differential diagnoses based on patient data
- The study uses the DDXPlus dataset and modifies the data to improve model robustness and generalization
- The models achieve over 97% F1 score on the test set and show promising results on a custom set

Summary:
The study develops a transformer-based system for differential diagnosis in healthcare using patient data from the DDXPlus dataset and data modification modules, achieving high F1 scores and generalizing well.</p><hr><h3>Mining Field Data for Tree Species Recognition at Scale</h3>
<p><a href='http://arxiv.org/abs/2408.15816v1'>http://arxiv.org/abs/2408.15816v1</a></p>
<p><b>Compressor summary</b>: The method automatically labels tree species in aerial images using pretrained models and public forest inventory data, requiring minimal human input and handling noisy data well.</p><hr><h3>Object Detection for Vehicle Dashcams using Transformers</h3>
<p><a href='http://arxiv.org/abs/2408.15809v1'>http://arxiv.org/abs/2408.15809v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using transformers for object detection in dashcams, improving productivity and accuracy in the automotive industry.</p><hr><h3>Visual Prompt Engineering for Medical Vision Language Models in  Radiology</h3>
<p><a href='http://arxiv.org/abs/2408.15802v1'>http://arxiv.org/abs/2408.15802v1</a></p>
<p><b>Compressor summary</b>: The paper explores how visual prompts, like arrows and circles, can improve VLMs' ability to classify lung nodule malignancy using BiomedCLIP.</p><hr><h3>Scaling Up Summarization: Leveraging Large Language Models for Long Text  Extractive Summarization</h3>
<p><a href='http://arxiv.org/abs/2408.15801v1'>http://arxiv.org/abs/2408.15801v1</a></p>
<p><b>Compressor summary</b>: EYEGLAXS is a framework that uses large language models to efficiently and accurately summarize long text documents by extracting relevant information, overcoming common issues with abstractive methods.</p><hr><h3>Language Adaptation on a Tight Academic Compute Budget: Tokenizer  Swapping Works and Pure bfloat16 Is Enough</h3>
<p><a href='http://arxiv.org/abs/2408.15793v1'>http://arxiv.org/abs/2408.15793v1</a></p>
<p><b>Compressor summary</b>: Continued pretraining of LLMs on a tight budget may help Arabic adaptation but hurts German adaptation, and suggests that training precision and tokenizer swapping can improve efficiency.</p><hr><h3>Efficient LLM Scheduling by Learning to Rank</h3>
<p><a href='http://arxiv.org/abs/2408.15792v1'>http://arxiv.org/abs/2408.15792v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel scheduler for large language models that uses ranking information to approximate the shortest-job-first schedule and improve performance in serving applications.</p><hr><h3>Interactive Agents: Simulating Counselor-Client Psychological Counseling  via Role-Playing LLM-to-LLM Interactions</h3>
<p><a href='http://arxiv.org/abs/2408.15787v1'>http://arxiv.org/abs/2408.15787v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Virtual counselors using large language models (LLMs) aim to assist clients with mental health challenges
- Researchers propose a framework that simulates counselor-client interactions with two LLMs
- They evaluate the synthetic data and compare it with human-generated conversations

Summary:
Researchers use LLMs to create virtual counselors that can interact with clients and assess their effectiveness by generating and comparing synthetic dialogues.</p><hr><h3>Implicit Regularization Paths of Weighted Neural Representations</h3>
<p><a href='http://arxiv.org/abs/2408.15784v1'>http://arxiv.org/abs/2408.15784v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how different weightings of pretrained features affect the regularization of ridge estimators and proposes a cross-validation method for tuning these weights.</p><hr><h3>LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language  Models</h3>
<p><a href='http://arxiv.org/abs/2408.15778v1'>http://arxiv.org/abs/2408.15778v1</a></p>
<p><b>Compressor summary</b>: LogicGame is a novel benchmark for evaluating large language models' comprehension and application of predefined rules in diverse scenarios with varying difficulty levels.</p><hr><h3>A Survey on Facial Expression Recognition of Static and Dynamic Emotions</h3>
<p><a href='http://arxiv.org/abs/2408.15777v1'>http://arxiv.org/abs/2408.15777v1</a></p>
<p><b>Compressor summary</b>: This paper surveys facial expression recognition methods, covering image-based and video-based approaches, and discussing challenges and future directions in both domains.</p><hr><h3>A Survey on Evaluation of Multimodal Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15769v1'>http://arxiv.org/abs/2408.15769v1</a></p>
<p><b>Compressor summary</b>: This paper reviews various methods to evaluate multimodal large language models (MLLMs) that integrate different sensory encoders with powerful language models, aiming to help researchers improve these models for achieving artificial general intelligence (AGI).</p><hr><h3>Harmonized Speculative Sampling</h3>
<p><a href='http://arxiv.org/abs/2408.15766v1'>http://arxiv.org/abs/2408.15766v1</a></p>
<p><b>Compressor summary</b>: HASS improves speculative sampling for LLaMA models by harmonizing training and decoding to increase acceptance rate and reduce inference overhead.</p><hr><h3>A Neural Material Point Method for Particle-based Simulations</h3>
<p><a href='http://arxiv.org/abs/2408.15753v1'>http://arxiv.org/abs/2408.15753v1</a></p>
<p><b>Compressor summary</b>: NeuralMPM is a neural emulation framework that uses image-to-image neural networks to simulate particle-based physics, reducing training times and achieving comparable or superior accuracy compared to existing methods.</p><hr><h3>Adaptive Traffic Signal Control Using Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15751v1'>http://arxiv.org/abs/2408.15751v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using reinforcement learning to optimize traffic signals at intersections, reducing congestion and costs, and presents two RL algorithms that perform better than conventional systems in simulations.</p><hr><h3>Form and meaning co-determine the realization of tone in Taiwan Mandarin  spontaneous speech: the case of Tone 3 sandhi</h3>
<p><a href='http://arxiv.org/abs/2408.15747v1'>http://arxiv.org/abs/2408.15747v1</a></p>
<p><b>Compressor summary</b>: The study examines how contextual factors affect the pitch contours of two-character words with different tone patterns in spontaneous Taiwan Mandarin conversations.</p><hr><h3>MambaPlace:Text-to-Point-Cloud Cross-Modal Place Recognition with  Attention Mamba Mechanisms</h3>
<p><a href='http://arxiv.org/abs/2408.15740v1'>http://arxiv.org/abs/2408.15740v1</a></p>
<p><b>Compressor summary</b>: MambaPlace is a new framework that uses language and 3D point cloud information to improve robot localization accuracy by fusing complementary cross modal features through novel attention mechanisms.</p><hr><h3>LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of  Relational Knowledge in Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15729v1'>http://arxiv.org/abs/2408.15729v1</a></p>
<p><b>Compressor summary</b>: LM-PUB-QUIZ is an open-source framework and leaderboard that uses the BEAR probe to evaluate relational knowledge in language models and help compare them.</p><hr><h3>Defending Text-to-image Diffusion Models: Surprising Efficacy of Textual  Perturbations Against Backdoor Attacks</h3>
<p><a href='http://arxiv.org/abs/2408.15721v1'>http://arxiv.org/abs/2408.15721v1</a></p>
<p><b>Compressor summary</b>: Text-to-image diffusion models are vulnerable to backdoor attacks, but can be protected by adding small textual perturbations without compromising image quality.</p><hr><h3>An Evaluation of Sindhi Word Embedding in Semantic Analogies and  Downstream Tasks</h3>
<p><a href='http://arxiv.org/abs/2408.15720v1'>http://arxiv.org/abs/2408.15720v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Autoregressive model path dependence near Ising criticality</h3>
<p><a href='http://arxiv.org/abs/2408.15715v1'>http://arxiv.org/abs/2408.15715v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Pixels to Prose: Understanding the art of Image Captioning</h3>
<p><a href='http://arxiv.org/abs/2408.15714v1'>http://arxiv.org/abs/2408.15714v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Conan-embedding: General Text Embedding with More and Better Negative  Samples</h3>
<p><a href='http://arxiv.org/abs/2408.15710v1'>http://arxiv.org/abs/2408.15710v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Synthetic Forehead-creases Biometric Generation for Reliable User  Verification</h3>
<p><a href='http://arxiv.org/abs/2408.15693v1'>http://arxiv.org/abs/2408.15693v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>TempoFormer: A Transformer for Temporally-aware Representations in  Change Detection</h3>
<p><a href='http://arxiv.org/abs/2408.15689v1'>http://arxiv.org/abs/2408.15689v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Deep Learning Based Speckle Filtering for Polarimetric SAR Images.  Application to Sentinel-1</h3>
<p><a href='http://arxiv.org/abs/2408.15678v1'>http://arxiv.org/abs/2408.15678v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Towards reliable respiratory disease diagnosis based on cough sounds and  vision transformers</h3>
<p><a href='http://arxiv.org/abs/2408.15667v1'>http://arxiv.org/abs/2408.15667v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>StyleRemix: Interpretable Authorship Obfuscation via Distillation and  Perturbation of Style Elements</h3>
<p><a href='http://arxiv.org/abs/2408.15666v1'>http://arxiv.org/abs/2408.15666v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts</h3>
<p><a href='http://arxiv.org/abs/2408.15664v1'>http://arxiv.org/abs/2408.15664v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Merging and Splitting Diffusion Paths for Semantically Coherent  Panoramas</h3>
<p><a href='http://arxiv.org/abs/2408.15660v1'>http://arxiv.org/abs/2408.15660v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Realigned Softmax Warping for Deep Metric Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15656v1'>http://arxiv.org/abs/2408.15656v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Harnessing the Intrinsic Knowledge of Pretrained Language Models for  Challenging Text Classification Settings</h3>
<p><a href='http://arxiv.org/abs/2408.15650v1'>http://arxiv.org/abs/2408.15650v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Hierarchical Blockmodelling for Knowledge Graphs</h3>
<p><a href='http://arxiv.org/abs/2408.15649v1'>http://arxiv.org/abs/2408.15649v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Leveraging Persistent Homology for Differential Diagnosis of Mild  Cognitive Impairment</h3>
<p><a href='http://arxiv.org/abs/2408.15647v1'>http://arxiv.org/abs/2408.15647v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>μgat: Improving Single-Page Document Parsing by Providing Multi-Page  Context</h3>
<p><a href='http://arxiv.org/abs/2408.15646v1'>http://arxiv.org/abs/2408.15646v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>RIDE: Boosting 3D Object Detection for LiDAR Point Clouds via  Rotation-Invariant Analysis</h3>
<p><a href='http://arxiv.org/abs/2408.15643v1'>http://arxiv.org/abs/2408.15643v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Can SAR improve RSVQA performance?</h3>
<p><a href='http://arxiv.org/abs/2408.15642v1'>http://arxiv.org/abs/2408.15642v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>MMDRFuse: Distilled Mini-Model with Dynamic Refresh for Multi-Modality  Image Fusion</h3>
<p><a href='http://arxiv.org/abs/2408.15641v1'>http://arxiv.org/abs/2408.15641v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>GANs Conditioning Methods: A Survey</h3>
<p><a href='http://arxiv.org/abs/2408.15640v1'>http://arxiv.org/abs/2408.15640v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Transfer Learning from Simulated to Real Scenes for Monocular 3D Object  Detection</h3>
<p><a href='http://arxiv.org/abs/2408.15637v1'>http://arxiv.org/abs/2408.15637v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Can Visual Language Models Replace OCR-Based Visual Question Answering  Pipelines in Production? A Case Study in Retail</h3>
<p><a href='http://arxiv.org/abs/2408.15626v1'>http://arxiv.org/abs/2408.15626v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>CAPER: Enhancing Career Trajectory Prediction using Temporal Knowledge  Graph and Ternary Relationship</h3>
<p><a href='http://arxiv.org/abs/2408.15620v1'>http://arxiv.org/abs/2408.15620v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Large-Scale Demand Prediction in Urban Rail using Multi-Graph Inductive  Representation Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15619v1'>http://arxiv.org/abs/2408.15619v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Beyond Levenshtein: Leveraging Multiple Algorithms for Robust Word Error  Rate Computations And Granular Error Classifications</h3>
<p><a href='http://arxiv.org/abs/2408.15616v1'>http://arxiv.org/abs/2408.15616v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Geometry-guided Feature Learning and Fusion for Indoor Scene  Reconstruction</h3>
<p><a href='http://arxiv.org/abs/2408.15608v1'>http://arxiv.org/abs/2408.15608v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Skills Regularized Task Decomposition for Multi-task Offline  Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15593v1'>http://arxiv.org/abs/2408.15593v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Hierarchical Visual Categories Modeling: A Joint Representation Learning  and Density Estimation Framework for Out-of-Distribution Detection</h3>
<p><a href='http://arxiv.org/abs/2408.15580v1'>http://arxiv.org/abs/2408.15580v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Temporal Attention for Cross-View Sequential Image Localization</h3>
<p><a href='http://arxiv.org/abs/2408.15569v1'>http://arxiv.org/abs/2408.15569v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>TagOOD: A Novel Approach to Out-of-Distribution Detection via  Vision-Language Representations and Class Center Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15566v1'>http://arxiv.org/abs/2408.15566v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large  Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15565v1'>http://arxiv.org/abs/2408.15565v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Boosting Lossless Speculative Decoding via Feature Sampling and Partial  Alignment Distillation</h3>
<p><a href='http://arxiv.org/abs/2408.15562v1'>http://arxiv.org/abs/2408.15562v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Divide, Conquer and Combine: A Training-Free Framework for  High-Resolution Image Perception in Multimodal Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15556v1'>http://arxiv.org/abs/2408.15556v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>A Novel Denoising Technique and Deep Learning Based Hybrid Wind Speed  Forecasting Model for Variable Terrain Conditions</h3>
<p><a href='http://arxiv.org/abs/2408.15554v1'>http://arxiv.org/abs/2408.15554v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Trustworthy and Responsible AI for Human-Centric Autonomous  Decision-Making Systems</h3>
<p><a href='http://arxiv.org/abs/2408.15550v1'>http://arxiv.org/abs/2408.15550v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback</h3>
<p><a href='http://arxiv.org/abs/2408.15549v1'>http://arxiv.org/abs/2408.15549v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>ConsistencyTrack: A Robust Multi-Object Tracker with a Generation  Strategy of Consistency Model</h3>
<p><a href='http://arxiv.org/abs/2408.15548v1'>http://arxiv.org/abs/2408.15548v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding</h3>
<p><a href='http://arxiv.org/abs/2408.15545v1'>http://arxiv.org/abs/2408.15545v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>An Investigation of Warning Erroneous Chat Translations in Cross-lingual  Communication</h3>
<p><a href='http://arxiv.org/abs/2408.15543v1'>http://arxiv.org/abs/2408.15543v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Kangaroo: A Powerful Video-Language Model Supporting Long-context Video  Input</h3>
<p><a href='http://arxiv.org/abs/2408.15542v1'>http://arxiv.org/abs/2408.15542v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>TrafficGamer: Reliable and Flexible Traffic Simulation for  Safety-Critical Scenarios with Game-Theoretic Oracles</h3>
<p><a href='http://arxiv.org/abs/2408.15538v1'>http://arxiv.org/abs/2408.15538v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Improving Thompson Sampling via Information Relaxation for Budgeted  Multi-armed Bandits</h3>
<p><a href='http://arxiv.org/abs/2408.15535v1'>http://arxiv.org/abs/2408.15535v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via  Layer-wise Relevance Propagation</h3>
<p><a href='http://arxiv.org/abs/2408.15533v1'>http://arxiv.org/abs/2408.15533v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Ray-Distance Volume Rendering for Neural Scene Reconstruction</h3>
<p><a href='http://arxiv.org/abs/2408.15524v1'>http://arxiv.org/abs/2408.15524v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Dolphin: Long Context as a New Modality for Energy-Efficient On-Device  Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.15518v1'>http://arxiv.org/abs/2408.15518v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Continual-learning-based framework for structural damage recognition</h3>
<p><a href='http://arxiv.org/abs/2408.15513v1'>http://arxiv.org/abs/2408.15513v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Towards Fully Autonomous Research Powered by LLMs: Case Study on  Simulations</h3>
<p><a href='http://arxiv.org/abs/2408.15512v1'>http://arxiv.org/abs/2408.15512v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Measuring the Reliability of Causal Probing Methods: Tradeoffs,  Limitations, and the Plight of Nullifying Interventions</h3>
<p><a href='http://arxiv.org/abs/2408.15510v1'>http://arxiv.org/abs/2408.15510v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>What Machine Learning Tells Us About the Mathematical Structure of  Concepts</h3>
<p><a href='http://arxiv.org/abs/2408.15507v1'>http://arxiv.org/abs/2408.15507v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>MODULI: Unlocking Preference Generalization via Diffusion Models for  Offline Multi-Objective Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2408.15501v1'>http://arxiv.org/abs/2408.15501v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single  Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep  Feed-forward Neural Network</h3>
<p><a href='http://arxiv.org/abs/2408.15498v1'>http://arxiv.org/abs/2408.15498v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>ReMamba: Equip Mamba with Effective Long-Sequence Modeling</h3>
<p><a href='http://arxiv.org/abs/2408.15496v1'>http://arxiv.org/abs/2408.15496v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Remove Symmetries to Control Model Expressivity</h3>
<p><a href='http://arxiv.org/abs/2408.15495v1'>http://arxiv.org/abs/2408.15495v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Enhancing and Accelerating Large Language Models via Instruction-Aware  Contextual Compression</h3>
<p><a href='http://arxiv.org/abs/2408.15491v1'>http://arxiv.org/abs/2408.15491v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Legilimens: Practical and Unified Content Moderation for Large Language  Model Services</h3>
<p><a href='http://arxiv.org/abs/2408.15488v1'>http://arxiv.org/abs/2408.15488v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>NAS-BNN: Neural Architecture Search for Binary Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2408.15484v1'>http://arxiv.org/abs/2408.15484v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Dynamic Reconstruction from Neuromorphic Data</h3>
<p><a href='http://arxiv.org/abs/2408.15465v1'>http://arxiv.org/abs/2408.15465v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Hand1000: Generating Realistic Hands from Text with Only 1,000 Images</h3>
<p><a href='http://arxiv.org/abs/2408.15461v1'>http://arxiv.org/abs/2408.15461v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>PersonalizedUS: Interpretable Breast Cancer Risk Assessment with Local  Coverage Uncertainty Quantification</h3>
<p><a href='http://arxiv.org/abs/2408.15458v1'>http://arxiv.org/abs/2408.15458v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Avoiding Generative Model Writer's Block With Embedding Nudging</h3>
<p><a href='http://arxiv.org/abs/2408.15450v1'>http://arxiv.org/abs/2408.15450v1</a></p>
<p><b>Compressor summary</b>: </p>