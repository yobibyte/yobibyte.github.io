
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="stylesheet" href="../style.css"/>
		<title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
		<h1>arxiv compressed, 2023-11-28</h1>
		<p>This page contains one-sentence summaries of cs.AI/ML/CV papers announced on 2023-11-28 generated by the compressor, my personal LLM-based project.</p>
	<hr><h3>Material Palette: Extraction of Materials from a Single Image</h3>
<p>Ivan Lopes,Fabio Pizzati,Raoul de Charette</p>
<p><a href='http://arxiv.org/abs/2311.17060v1'>http://arxiv.org/abs/2311.17060v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to create physically-based rendering materials from real images using diffusion model, texture generation, SVBRDF decomposition, and unsupervised domain adaptation.</p><hr><h3>HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting</h3>
<p>Xian Liu,Xiaohang Zhan,Jiaxiang Tang,Ying Shan,Gang Zeng,Dahua Lin,Xihui Liu,Ziwei Liu</p>
<p><a href='http://arxiv.org/abs/2311.17061v1'>http://arxiv.org/abs/2311.17061v1</a></p>
<p><b>Compressor summary</b>: HumanGaussian is a new method to generate realistic 3D human models from text prompts using adaptive Gaussian Splatting and Structure-Aware Score Distillation Sampling.</p><hr><h3>Panoptic Video Scene Graph Generation</h3>
<p>Jingkang Yang,Wenxuan Peng,Xiangtai Li,Zujin Guo,Liangyu Chen,Bo Li,Zheng Ma,Kaiyang Zhou,Wayne Zhang,Chen Change Loy,Ziwei Liu</p>
<p><a href='http://arxiv.org/abs/2311.17058v1'>http://arxiv.org/abs/2311.17058v1</a></p>
<p><b>Compressor summary</b>: PVSG is a new problem that aims to generate pixel-level segmented scene graphs from videos, overcoming the limitations of VidSGG that uses bounding boxes.</p><hr><h3>ReMoS: Reactive 3D Motion Synthesis for Two-Person Interactions</h3>
<p>Anindita Ghosh,Rishabh Dabral,Vladislav Golyanik,Christian Theobalt,Philipp Slusallek</p>
<p><a href='http://arxiv.org/abs/2311.17057v1'>http://arxiv.org/abs/2311.17057v1</a></p>
<p><b>Compressor summary</b>: ReMoS is a model that generates realistic reactive motions for two people interacting, such as dancing or fighting, given the motion of one person, and can handle complex scenarios with full-body and hand interactions.</p><hr><h3>Self-Supervised Motion Magnification by Backpropagating Through Optical  Flow</h3>
<p>Zhaoying Pan,Daniel Geng,Andrew Owens</p>
<p><a href='http://arxiv.org/abs/2311.17056v1'>http://arxiv.org/abs/2311.17056v1</a></p>
<p><b>Compressor summary</b>: The paper presents a self-supervised method to magnify subtle motions in video using a loss function that estimates the optical flow and penalizes deviations from the desired magnification factor, which can be adapted at test time and applied to selected objects without needing synthetic datasets.</p><hr><h3>Rethinking Directional Integration in Neural Radiance Fields</h3>
<p>Congyue Deng,Jiawei Yang,Leonidas Guibas,Yue Wang</p>
<p><a href='http://arxiv.org/abs/2311.16504v1'>http://arxiv.org/abs/2311.16504v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a simple modification to the NeRF rendering equation to improve view-dependent effects and achieve better rendering quality.</p><hr><h3>No Representation Rules Them All in Category Discovery</h3>
<p>Sagar Vaze,Andrea Vedaldi,Andrew Zisserman</p>
<p><a href='http://arxiv.org/abs/2311.17055v1'>http://arxiv.org/abs/2311.17055v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Clevr-4, a synthetic dataset for Generalized Category Discovery (GCD) that requires models to extrapolate the taxonomy from labels and outperforms existing methods on it.</p><hr><h3>Surf-D: High-Quality Surface Generation for Arbitrary Topologies using  Diffusion Models</h3>
<p>Zhengming Yu,Zhiyang Dou,Xiaoxiao Long,Cheng Lin,Zekun Li,Yuan Liu,Norman Müller,Taku Komura,Marc Habermann,Christian Theobalt,Xin Li,Wenping Wang</p>
<p><a href='http://arxiv.org/abs/2311.17050v1'>http://arxiv.org/abs/2311.17050v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Surf-D, a method for generating high-quality 3D shapes using Diffusion models and Unsigned Distance Field representation, which handles arbitrary topologies and performs well in various shape generation tasks.</p><hr><h3>MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced  Training</h3>
<p>Pavan Kumar Anasosalu Vasu,Hadi Pouransari,Fartash Faghri,Raviteja Vemulapalli,Oncel Tuzel</p>
<p><a href='http://arxiv.org/abs/2311.17049v1'>http://arxiv.org/abs/2311.17049v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MobileCLIP, a family of efficient image-text models optimized for runtime performance and a novel multi-modal reinforced training approach that improves accuracy and learning efficiency.</p><hr><h3>Zero-shot Referring Expression Comprehension via Structural Similarity  Between Images and Captions</h3>
<p>Zeyu Han,Fangrui Zhu,Qianru Lao,Huaizu Jiang</p>
<p><a href='http://arxiv.org/abs/2311.17048v1'>http://arxiv.org/abs/2311.17048v1</a></p>
<p><b>Compressor summary</b>: Zero-shot referring expression comprehension involves locating objects in an image based on textual prompts, and the authors propose a method using foundation models, triplets, and fine-tuning VLA models for improved performance.</p><hr><h3>LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models</h3>
<p>Yanwei Li,Chengyao Wang,Jiaya Jia</p>
<p><a href='http://arxiv.org/abs/2311.17043v1'>http://arxiv.org/abs/2311.17043v1</a></p>
<p><b>Compressor summary</b>: The LLaMA-VID method generates tokens for VLMs to process long videos by using context and content tokens, reducing computational burdens and improving performance on video and image benchmarks.</p><hr><h3>Adversarial Diffusion Distillation</h3>
<p>Axel Sauer,Dominik Lorenz,Andreas Blattmann,Robin Rombach</p>
<p><a href='http://arxiv.org/abs/2311.17042v1'>http://arxiv.org/abs/2311.17042v1</a></p>
<p><b>Compressor summary</b>: ADD trains large-scale image diffusion models to generate high-quality images in just 1-4 steps using score distillation and adversarial losses.</p><hr><h3>Efficient In-Context Learning in Vision-Language Models for Egocentric  Videos</h3>
<p>Keunwoo Peter Yu,Zheyuan Zhang,Fengyuan Hu,Joyce Chai</p>
<p><a href='http://arxiv.org/abs/2311.17041v1'>http://arxiv.org/abs/2311.17041v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to train vision-language models for egocentric videos using in-context learning with minimal data, achieving better performance and adaptability than existing methods.</p><hr><h3>Scalable Extraction of Training Data from (Production) Language Models</h3>
<p>Milad Nasr,Nicholas Carlini,Jonathan Hayase,Matthew Jagielski,A. Feder Cooper,Daphne Ippolito,Christopher A. Choquette-Choo,Eric Wallace,Florian Tramèr,Katherine Lee</p>
<p><a href='http://arxiv.org/abs/2311.17035v1'>http://arxiv.org/abs/2311.17035v1</a></p>
<p><b>Compressor summary</b>: The paper demonstrates how adversaries can efficiently extract training data from various machine learning models, including closed models like ChatGPT, by developing a new attack technique that exploits model misbehavior.</p><hr><h3>Telling Left from Right: Identifying Geometry-Aware Semantic  Correspondence</h3>
<p>Junyi Zhang,Charles Herrmann,Junhwa Hur,Eric Chen,Varun Jampani,Deqing Sun,Ming-Hsuan Yang</p>
<p><a href='http://arxiv.org/abs/2311.17034v1'>http://arxiv.org/abs/2311.17034v1</a></p>
<p><b>Compressor summary</b>: The paper proposes geometry-aware solutions to improve semantic correspondence in vision models, creating a new benchmark dataset and achieving state-of-the-art results.</p><hr><h3>Is This the Subspace You Are Looking for? An Interpretability Illusion  for Subspace Activation Patching</h3>
<p>Aleksandar Makelov,Georg Lange,Neel Nanda</p>
<p><a href='http://arxiv.org/abs/2311.17030v1'>http://arxiv.org/abs/2311.17030v1</a></p>
<p><b>Compressor summary</b>: The paper explores how subspace interventions in models can lead to misleading interpretability, but also provides examples of successful cases and suggests more evidence is needed for faithfulness.</p><hr><h3>When the Few Outweigh the Many: Illicit Content Recognition with  Few-Shot Learning</h3>
<p>G. Cascavilla,G. Catolino,M. Conti,D. Mellios,D. A. Tamburri</p>
<p><a href='http://arxiv.org/abs/2311.17026v1'>http://arxiv.org/abs/2311.17026v1</a></p>
<p><b>Compressor summary</b>: The paper explores using Siamese neural networks for recognizing illegal activities on the Dark Web from images, showing promising results with 90.9% accuracy on a small dataset.</p><hr><h3>Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with  Distilled Semantic Features</h3>
<p>Niladri Shekhar Dutt,Sanjeev Muralikrishnan,Niloy J. Mitra</p>
<p><a href='http://arxiv.org/abs/2311.17024v1'>http://arxiv.org/abs/2311.17024v1</a></p>
<p><b>Compressor summary</b>: Diff3F is a feature descriptor for untextured shapes that uses conditional image synthesis from depth and normal maps to create robust, semantic features for correspondence across shape families.</p><hr><h3>Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer</h3>
<p>Danah Yatim,Rafail Fridman,Omer Bar Tal,Yoni Kasten,Tali Dekel</p>
<p><a href='http://arxiv.org/abs/2311.17009v1'>http://arxiv.org/abs/2311.17009v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a text-driven motion transfer method that can synthesize videos with different objects and motions, using a pre-trained model and a new space-time feature loss.</p><hr><h3>Computational Hypergraph Discovery, a Gaussian Process framework for  connecting the dots</h3>
<p>Théo Bourdais,Pau Batlle,Xianjin Yang,Ricardo Baptista,Nicolas Rouquette,Houman Owhadi</p>
<p><a href='http://arxiv.org/abs/2311.17007v1'>http://arxiv.org/abs/2311.17007v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a GP framework for discovering and completing computational hypergraphs from partial observations, using a kernel generalization of Row Echelon Form reduction.</p><hr><h3>An Investigation of Time Reversal Symmetry in Reinforcement Learning</h3>
<p>Brett Barkley,Amy Zhang,David Fridovich-Keil</p>
<p><a href='http://arxiv.org/abs/2311.17008v1'>http://arxiv.org/abs/2311.17008v1</a></p>
<p><b>Compressor summary</b>: The paper explores using time reversal symmetry in Markov decision processes to increase sample efficiency in reinforcement learning, but notes that it may not work well in all environments.</p><hr><h3>On the Impact of Sampling on Deep Sequential State Estimation</h3>
<p>Helena Calatrava,Ricardo Augusto Borsoi,Tales Imbiriba,Pau Closas</p>
<p><a href='http://arxiv.org/abs/2311.17006v1'>http://arxiv.org/abs/2311.17006v1</a></p>
<p><b>Compressor summary</b>: The paper proposes IW-DKF, which uses importance sampling to improve state inference and parameter learning in deep Kalman filter for sequential models, showing better generative modeling performance and state estimation accuracy.</p><hr><h3>MVBench: A Comprehensive Multi-modal Video Understanding Benchmark</h3>
<p>Kunchang Li,Yali Wang,Yinan He,Yizhuo Li,Yi Wang,Yi Liu,Zun Wang,Jilan Xu,Guo Chen,Ping Luo,Limin Wang,Yu Qiao</p>
<p><a href='http://arxiv.org/abs/2311.17005v1'>http://arxiv.org/abs/2311.17005v1</a></p>
<p><b>Compressor summary</b>: MVBench is a benchmark for evaluating multi-modal language models' comprehension of dynamic videos, covering 20 challenging tasks that require temporal understanding.</p><hr><h3>Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following</h3>
<p>Yutong Feng,Biao Gong,Di Chen,Yujun Shen,Yu Liu,Jingren Zhou</p>
<p><a href='http://arxiv.org/abs/2311.17002v1'>http://arxiv.org/abs/2311.17002v1</a></p>
<p><b>Compressor summary</b>: The authors propose Ranni, a system that improves text-to-image diffusion models by using a semantic panel as a middleware to better follow complex instructions and enable more convenient interaction for users.</p><hr><h3>Goal-conditioned Offline Planning from Curious Exploration</h3>
<p>Marco Bagatella,Georg Martius</p>
<p><a href='http://arxiv.org/abs/2311.16996v1'>http://arxiv.org/abs/2311.16996v1</a></p>
<p><b>Compressor summary</b>: The text discusses using exploration techniques in deep reinforcement learning to extract goal-conditioned behavior without additional environment interaction, and proposes a method to combine model-based planning with graph-based value aggregation to improve zero-shot goal-reaching performance.</p><hr><h3>ChatGPT's One-year Anniversary: Are Open-Source Large Language Models  Catching up?</h3>
<p>Hailin Chen,Fangkai Jiao,Xingxuan Li,Chengwei Qin,Mathieu Ravaut,Ruochen Zhao,Caiming Xiong,Shafiq Joty</p>
<p><a href='http://arxiv.org/abs/2311.16989v1'>http://arxiv.org/abs/2311.16989v1</a></p>
<p><b>Compressor summary</b>: ChatGPT's release in 2022 sparked a surge in interest and development of large language models (LLMs), leading to rapid progress in both open-source and closed-source LLMs, with significant implications for research and business.</p><hr><h3>Assessing the influence of attractor-verb distance on grammatical  agreement in humans and language models</h3>
<p>Christos-Nikolaos Zacharopoulos,Théo Desbordes,Mathias Sablé-Meyer</p>
<p><a href='http://arxiv.org/abs/2311.16978v1'>http://arxiv.org/abs/2311.16978v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses how the distance between an attractor noun and a verb affects grammatical judgments and reaction times, with neural networks performing differently from humans.</p><hr><h3>COLE: A Hierarchical Generation Framework for Graphic Design</h3>
<p>Peidong Jia,Chenxuan Li,Zeyu Liu,Yichao Shen,Xingru Chen,Yuhui Yuan,Yinglin Zheng,Dong Chen,Ji Li,Xiaodong Xie,Shanghang Zhang,Baining Guo</p>
<p><a href='http://arxiv.org/abs/2311.16974v1'>http://arxiv.org/abs/2311.16974v1</a></p>
<p><b>Compressor summary</b>: COLE is a hierarchical framework that uses specialized models to generate and edit high-quality graphic designs based on user input, enhancing reliability and streamlining the process.</p><hr><h3>Natural Language Processing Through Transfer Learning: A Case Study on  Sentiment Analysis</h3>
<p>Aman Yadav,Abhishek Vichare</p>
<p><a href='http://arxiv.org/abs/2311.16965v1'>http://arxiv.org/abs/2311.16965v1</a></p>
<p><b>Compressor summary</b>: The paper shows that using pre-trained BERT models for sentiment analysis on IMDb movie reviews improves accuracy, but cautions against overfitting or lack of generalization without further analysis.</p><hr><h3>HumanRef: Single Image to 3D Human Generation via Reference-Guided  Diffusion</h3>
<p>Jingbo Zhang,Xiaoyu Li,Qi Zhang,Yanpei Cao,Ying Shan,Jing Liao</p>
<p><a href='http://arxiv.org/abs/2311.16961v1'>http://arxiv.org/abs/2311.16961v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method called HumanRef for creating realistic 3D human models from one image that preserves texture details and maintains consistency in different views using reference-guided score distillation sampling and region-aware attention.</p><hr><h3>UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras  in autonomous driving</h3>
<p>Kai Cheng,Xiaoxiao Long,Wei Yin,Jin Wang,Zhiqiang Wu,Yuexin Ma,Kaixuan Wang,Xiaozhi Chen,Xuejin Chen</p>
<p><a href='http://arxiv.org/abs/2311.16945v1'>http://arxiv.org/abs/2311.16945v1</a></p>
<p><b>Compressor summary</b>: The paper introduces UC-NeRF, a method to improve NeRF's performance in under-calibrated multi-camera systems by addressing color inconsistency and pose calibration issues through layer-based correction, virtual warping, and spatiotemporal constraint refinement.</p><hr><h3>Image segmentation with traveling waves in an exactly solvable recurrent  neural network</h3>
<p>Luisa H. B. Liboni,Roberto C. Budzinski,Alexandra N. Busch,Sindy Löwe,Thomas A. Keller,Max Welling,Lyle E. Muller</p>
<p><a href='http://arxiv.org/abs/2311.16943v1'>http://arxiv.org/abs/2311.16943v1</a></p>
<p><b>Compressor summary</b>: The text describes a recurrent neural network that uses complex numbers to perform image segmentation by dividing an image into groups based on structural characteristics, with a simple algorithm that generalizes across different input types.</p><hr><h3>Debiasing Multimodal Models via Causal Information Minimization</h3>
<p>Vaidehi Patil,Adyasha Maharana,Mohit Bansal</p>
<p><a href='http://arxiv.org/abs/2311.16941v1'>http://arxiv.org/abs/2311.16941v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel debiasing method for multimodal models using causally-motivated information minimization to learn confounder representations and improve OOD performance without sacrificing in-distribution performance.</p><hr><h3>The Sky's the Limit: Re-lightable Outdoor Scenes via a Sky-pixel  Constrained Illumination Prior and Outside-In Visibility</h3>
<p>James A. D. Gardner,Evgenii Kashin,Bernhard Egger,William A. P. Smith</p>
<p><a href='http://arxiv.org/abs/2311.16937v1'>http://arxiv.org/abs/2311.16937v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to infer albedo, geometry, illumination, and sky visibility from unconstrained images using neural networks, achieving state-of-the-art results on a benchmark dataset.</p><hr><h3>SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models</h3>
<p>Yuwei Guo,Ceyuan Yang,Anyi Rao,Maneesh Agrawala,Dahua Lin,Bo Dai</p>
<p><a href='http://arxiv.org/abs/2311.16933v1'>http://arxiv.org/abs/2311.16933v1</a></p>
<p><b>Compressor summary</b>: SparseCtrl is a method for controlling video generation with minimal input signals, such as sketches or depth maps, improving flexibility and practicality for various applications.</p><hr><h3>LLaFS: When Large-Language Models Meet Few-Shot Segmentation</h3>
<p>Lanyun Zhu,Tianrun Chen,Deyi Ji,Jieping Ye,Jun Liu</p>
<p><a href='http://arxiv.org/abs/2311.16926v1'>http://arxiv.org/abs/2311.16926v1</a></p>
<p><b>Compressor summary</b>: The paper introduces LLaFS, a method that uses large language models to improve few-shot segmentation by incorporating prior knowledge and providing multi-modal guidance.</p><hr><h3>Super-Resolution through StyleGAN Regularized Latent Search: A  Realism-Fidelity Trade-off</h3>
<p>Marzieh Gheisari,Auguste Genovesio</p>
<p><a href='http://arxiv.org/abs/2311.16923v1'>http://arxiv.org/abs/2311.16923v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to improve super-resolution by constraining the search in the latent space of StyleGAN and expanding the image prior around the optimal code, achieving realistic and high-quality results.</p><hr><h3>Mitigating Object Hallucinations in Large Vision-Language Models through  Visual Contrastive Decoding</h3>
<p>Sicong Leng,Hang Zhang,Guanzheng Chen,Xin Li,Shijian Lu,Chunyan Miao,Lidong Bing</p>
<p><a href='http://arxiv.org/abs/2311.16922v1'>http://arxiv.org/abs/2311.16922v1</a></p>
<p><b>Compressor summary</b>: The Visual Contrastive Decoding method reduces object hallucinations in large vision-language models by contrasting output distributions from original and distorted visual inputs without additional training or external tools.</p><hr><h3>RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail  Richness in Text-to-3D</h3>
<p>Lingteng Qiu,Guanying Chen,Xiaodong Gu,Qi Zuo,Mutian Xu,Yushuang Wu,Weihao Yuan,Zilong Dong,Liefeng Bo,Xiaoguang Han</p>
<p><a href='http://arxiv.org/abs/2311.16918v1'>http://arxiv.org/abs/2311.16918v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Normal-Depth diffusion model for 3D generation using LAION dataset and introduces an albedo diffusion model to handle mixed illumination effects, achieving state-of-the-art results.</p><hr><h3>UGG: Unified Generative Grasping</h3>
<p>Jiaxin Lu,Hao Kang,Haoxiang Li,Bo Liu,Yiding Yang,Qixing Huang,Gang Hua</p>
<p><a href='http://arxiv.org/abs/2311.16917v1'>http://arxiv.org/abs/2311.16917v1</a></p>
<p><b>Compressor summary</b>: The UGG model generates diverse and successful grasping postures for objects by using a diffusion-based approach that incorporates object, hand, and contact information.</p><hr><h3>Brain-ID: Learning Robust Feature Representations for Brain Imaging</h3>
<p>Peirong Liu,Oula Puonti,Xiaoling Hu,Daniel C. Alexander,Juan Eugenio Iglesias</p>
<p><a href='http://arxiv.org/abs/2311.16914v1'>http://arxiv.org/abs/2311.16914v1</a></p>
<p><b>Compressor summary</b>: Brain-ID is a robust feature representation learning strategy for brain imaging that works well on various tasks and datasets, even with limited training data.</p><hr><h3>Lane-Keeping Control of Autonomous Vehicles Through a Soft-Constrained  Iterative LQR</h3>
<p>Der-Hau Lee</p>
<p><a href='http://arxiv.org/abs/2311.16900v1'>http://arxiv.org/abs/2311.16900v1</a></p>
<p><b>Compressor summary</b>: The soft-CILQR algorithm improves the stability and smoothness of autonomous vehicle steering by using slack variables to soften constraints in the optimization process.</p><hr><h3>Dendrogram distance: an evaluation metric for generative networks using  hierarchical clustering</h3>
<p>Gustavo Sutter Carvalho,Moacir Antonelli Ponti</p>
<p><a href='http://arxiv.org/abs/2311.16894v1'>http://arxiv.org/abs/2311.16894v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new way to measure how well generative models capture all aspects of the data using dendrograms and shows it performs as well as existing methods.</p><hr><h3>Compressing the Backward Pass of Large-Scale Neural Architectures by  Structured Activation Pruning</h3>
<p>Daniel Barley,Holger Fröning</p>
<p><a href='http://arxiv.org/abs/2311.16883v1'>http://arxiv.org/abs/2311.16883v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a method to reduce memory usage in DNNs during training by pruning activations using structured pruning and block sparsity, achieving up to 32% memory reduction without sacrificing accuracy on image classification tasks.</p><hr><h3>Optimisation-Based Multi-Modal Semantic Image Editing</h3>
<p>Bowen Li,Yongxin Yang,Steven McDonagh,Shifeng Zhang,Petru-Daniel Tudosiu,Sarah Parisot</p>
<p><a href='http://arxiv.org/abs/2311.16882v1'>http://arxiv.org/abs/2311.16882v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an image editing method that allows various types of instructions and balances local modifications with global consistency using two loss functions.</p><hr><h3>Imputation using training labels and classification via label imputation</h3>
<p>Thu Nguyen,Pål Halvorsen,Michael A. Riegler</p>
<p><a href='http://arxiv.org/abs/2311.16877v1'>http://arxiv.org/abs/2311.16877v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method that stacks the label with the input for imputation, improving the performance of classification models with missing data.</p><hr><h3>A unified weighting framework for evaluating nearest neighbour  classification</h3>
<p>Oliver Urs Lenz,Henri Bollaert,Chris Cornelis</p>
<p><a href='http://arxiv.org/abs/2311.16872v1'>http://arxiv.org/abs/2311.16872v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates different methods for nearest neighbor classification using fuzzy logic and kernel functions, finding that some perform best with Boscovich distance and others with Yager negation.</p><hr><h3>The Falcon Series of Open Language Models</h3>
<p>Ebtesam Almazrouei,Hamza Alobeidli,Abdulaziz Alshamsi,Alessandro Cappelli,Ruxandra Cojocaru,Daniel Hesslow,Julien Launay,Quentin Malartic,Daniele Mazzotta,Badreddine Noune,Baptiste Pannier,Guilherme Penedo</p>
<p><a href='http://arxiv.org/abs/2311.16867v1'>http://arxiv.org/abs/2311.16867v1</a></p>
<p><b>Compressor summary</b>: The Falcon series are causal decoder-only models with different sizes, pretrained on a large web dataset, and achieve high performance while being cost-effective.</p><hr><h3>A Benchmark for Evaluating Machine Translation Metrics on Dialects  Without Standard Orthography</h3>
<p>Noëmi Aepli,Chantal Amrhein,Florian Schottmann,Rico Sennrich</p>
<p><a href='http://arxiv.org/abs/2311.16865v1'>http://arxiv.org/abs/2311.16865v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates how well evaluation metrics work for Swiss German dialects and proposes improvements to make them more robust.</p><hr><h3>Power Hungry Processing: Watts Driving the Cost of AI Deployment?</h3>
<p>Alexandra Sasha Luccioni,Yacine Jernite,Emma Strubell</p>
<p><a href='http://arxiv.org/abs/2311.16863v1'>http://arxiv.org/abs/2311.16863v1</a></p>
<p><b>Compressor summary</b>: This paper compares the environmental cost of different types of machine learning systems, finding that multi-purpose generative models are much more energy-intensive than task-specific ones.</p><hr><h3>Data-efficient operator learning for solving high Mach number fluid flow  problems</h3>
<p>Noah Ford,Victor J. Leon,Honest Merman,Jeffrey Gilbert,Alexander New</p>
<p><a href='http://arxiv.org/abs/2311.16860v1'>http://arxiv.org/abs/2311.16860v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses using SciML with Neural Basis Functions to improve predictions for high Mach fluid flows over irregular geometries when data is limited.</p><hr><h3>Attentional Graph Neural Networks for Robust Massive Network  Localization</h3>
<p>Wenzhong Yan,Juntao Wang,Feng Yin,Abdelhak M. Zoubir</p>
<p><a href='http://arxiv.org/abs/2311.16856v1'>http://arxiv.org/abs/2311.16856v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel GNN-based method for network localization that is stable, accurate, and robust to NLOS propagations, and introduces two attentional graph neural networks (AGNNs) that improve accuracy and flexibility by learning optimal hyperparameters.</p><hr><h3>A Unified Approach for Text- and Image-guided 4D Scene Generation</h3>
<p>Yufeng Zheng,Xueting Li,Koki Nagano,Sifei Liu,Otmar Hilliges,Shalini De Mello</p>
<p><a href='http://arxiv.org/abs/2311.16854v1'>http://arxiv.org/abs/2311.16854v1</a></p>
<p><b>Compressor summary</b>: The authors propose Dream-in-4D, a novel two-stage method that leverages diffusion guidance to generate high-quality static and dynamic 3D scenes from text prompts, achieving significant improvements in quality and controllability compared to existing approaches.</p><hr><h3>Wavelet-based Fourier Information Interaction with Frequency Diffusion  Adjustment for Underwater Image Restoration</h3>
<p>Chen Zhao,Weiling Cai,Chenyu Dong,Chengwei Hu</p>
<p><a href='http://arxiv.org/abs/2311.16845v1'>http://arxiv.org/abs/2311.16845v1</a></p>
<p><b>Compressor summary</b>: The paper introduces WF-Diff, a novel framework for enhancing underwater images using frequency domain information and diffusion models, which improves the visual quality of underwater images.</p><hr><h3>Self-training solutions for the ICCV 2023 GeoNet Challenge</h3>
<p>Lijun Sheng,Zhengbo Wang,Jian Liang</p>
<p><a href='http://arxiv.org/abs/2311.16843v1'>http://arxiv.org/abs/2311.16843v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new domain adaptation benchmark called GeoNet with three challenges and presents a two-stage source-free method using Swin Transformer to achieve high performance in all challenges.</p><hr><h3>The Claire French Dialogue Dataset</h3>
<p>Julie Hunter,Jérôme Louradour,Virgile Rennard,Ismaïl Harrando,Guokan Shang,Jean-Pierre Lorré</p>
<p><a href='http://arxiv.org/abs/2311.16840v1'>http://arxiv.org/abs/2311.16840v1</a></p>
<p><b>Compressor summary</b>: The Claire French Dialogue Dataset (CFDD) is a large corpus of diverse French texts released for developing multilingual language models, and this paper describes its composition, categories, and format.</p><hr><h3>Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware  Direct Preference Optimization</h3>
<p>Zhiyuan Zhao,Bin Wang,Linke Ouyang,Xiaoyi Dong,Jiaqi Wang,Conghui He</p>
<p><a href='http://arxiv.org/abs/2311.16839v1'>http://arxiv.org/abs/2311.16839v1</a></p>
<p><b>Compressor summary</b>: The paper proposes HA-DPO, a novel approach to address the hallucination problem in multimodal language models by training them to prefer accurate responses over hallucinating ones, leading to improved accuracy and generalization.</p><hr><h3>Unified-modal Salient Object Detection via Adaptive Prompt Learning</h3>
<p>Kunpeng Wang,Chenglong Li,Zhengzheng Tu,Bin Luo</p>
<p><a href='http://arxiv.org/abs/2311.16835v1'>http://arxiv.org/abs/2311.16835v1</a></p>
<p><b>Compressor summary</b>: UniSOD is a framework that combines single-modal and multi-modal salient object detection using modality-aware prompts with task-specific hints, achieving consistent performance improvement on various datasets.</p><hr><h3>Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention</h3>
<p>Qiqi Su,Christos Kloukinas,Artur d'Garcez</p>
<p><a href='http://arxiv.org/abs/2311.16834v1'>http://arxiv.org/abs/2311.16834v1</a></p>
<p><b>Compressor summary</b>: The paper presents an interpretable modular neural network model for multivariate time series prediction that combines a recurrent neural network with an attention-based feature selection component and achieves high performance comparable to non-interpretable methods.</p><hr><h3>1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness</h3>
<p>Bernd Prach,Fabio Brau,Giorgio Buttazzo,Christoph H. Lampert</p>
<p><a href='http://arxiv.org/abs/2311.16833v1'>http://arxiv.org/abs/2311.16833v1</a></p>
<p><b>Compressor summary</b>: This paper compares different methods for creating 1-Lipschitz neural networks, which are more robust against input perturbations, and provides guidelines to choose the best method depending on available resources.</p><hr><h3>CharacterGLM: Customizing Chinese Conversational AI Characters with  Large Language Models</h3>
<p>Jinfeng Zhou,Zhuang Chen,Dazhen Wan,Bosi Wen,Yi Song,Jifan Yu,Yongkang Huang,Libiao Peng,Jiaming Yang,Xiyao Xiao,Sahand Sabour,Xiaohan Zhang,Wenjing Hou,Yijia Zhang,Yuxiao Dong,Jie Tang,Minlie Huang</p>
<p><a href='http://arxiv.org/abs/2311.16832v1'>http://arxiv.org/abs/2311.16832v1</a></p>
<p><b>Compressor summary</b>: CharacterGLM is a series of large language models that can generate character-based dialogues for conversational AI systems, with better performance than most existing models in terms of consistency, human-likeness, and engagement.</p><hr><h3>Decomposer: Semi-supervised Learning of Image Restoration and Image  Decomposition</h3>
<p>Boris Meinardus,Mariusz Trzeciakiewicz,Tim Herzig,Monika Kwiatkowski,Simon Matern,Olaf Hellwich</p>
<p><a href='http://arxiv.org/abs/2311.16829v1'>http://arxiv.org/abs/2311.16829v1</a></p>
<p><b>Compressor summary</b>: Decomposer is a semi-supervised model that uses 3D Swin-Transformers and 3D U-Nets to separate distorted images into their original components and the applied augmentations like shadows, lighting, and occlusions.</p><hr><h3>SARA: Controllable Makeup Transfer with Spatial Alignment and  Region-Adaptive Normalization</h3>
<p>Xiaojing Zhong,Xinyi Huang,Zhonghua Wu,Guosheng Lin,Qingyao Wu</p>
<p><a href='http://arxiv.org/abs/2311.16828v1'>http://arxiv.org/abs/2311.16828v1</a></p>
<p><b>Compressor summary</b>: SARA is a novel method for makeup transfer that can handle large spatial misalignments, preserve the source images' identities, and achieve part-specific and shade-controllable results using three modules: spatial alignment, region-adaptive normalization, and makeup fusion.</p><hr><h3>Large Language Models Suffer From Their Own Output: An Analysis of the  Self-Consuming Training Loop</h3>
<p>Martin Briesch,Dominik Sobania,Franz Rothlauf</p>
<p><a href='http://arxiv.org/abs/2311.16822v1'>http://arxiv.org/abs/2311.16822v1</a></p>
<p><b>Compressor summary</b>: The study examines how large language models generate and consume content in a self-consuming loop, finding that this process improves quality and diversity at first but then decreases diversity over time.</p><hr><h3>DI-Net : Decomposed Implicit Garment Transfer Network for Digital  Clothed 3D Human</h3>
<p>Xiaojing Zhong,Yukun Su,Zhonghua Wu,Guosheng Lin,Qingyao Wu</p>
<p><a href='http://arxiv.org/abs/2311.16818v1'>http://arxiv.org/abs/2311.16818v1</a></p>
<p><b>Compressor summary</b>: DI-Net is a new method for 3D virtual try-on that uses two modules to reconstruct a human mesh with accurate pose and texture preservation.</p><hr><h3>Panacea: Panoramic and Controllable Video Generation for Autonomous  Driving</h3>
<p>Yuqing Wen,Yucheng Zhao,Yingfei Liu,Fan Jia,Yanhui Wang,Chong Luo,Chi Zhang,Tiancai Wang,Xiaoyan Sun,Xiangyu Zhang</p>
<p><a href='http://arxiv.org/abs/2311.16813v1'>http://arxiv.org/abs/2311.16813v1</a></p>
<p><b>Compressor summary</b>: Panacea is a method to create diverse, annotated videos for autonomous driving research that ensures consistency and controllability in driving scenarios.</p><hr><h3>Agent-Aware Training for Agent-Agnostic Action Advising in Deep  Reinforcement Learning</h3>
<p>Yaoquan Wei,Shunyu Liu,Jie Song,Tongya Zheng,Kaixuan Chen,Yong Wang,Mingli Song</p>
<p><a href='http://arxiv.org/abs/2311.16807v1'>http://arxiv.org/abs/2311.16807v1</a></p>
<p><b>Compressor summary</b>: The proposed A7 framework uses state feature similarity, proxy models, and behavior cloning to efficiently advise agents in DRL without relying on specific agents or expert teachers.</p><hr><h3>A Survey of the Evolution of Language Model-Based Dialogue Systems</h3>
<p>Hongru Wang,Lingzhi Wang,Yiming Du,Liang Chen,Jingyan Zhou,Yufei Wang,Kam-Fai Wong</p>
<p><a href='http://arxiv.org/abs/2311.16789v1'>http://arxiv.org/abs/2311.16789v1</a></p>
<p><b>Compressor summary</b>: The survey describes the four stages of dialogue system evolution, highlighting their dependence on language model advancements and discussing current challenges and future directions for LLM-based systems.</p><hr><h3>Evaluating Optimal Reference Translations</h3>
<p>Vilém Zouhar,Věra Kloudová,Martin Popel,Ondřej Bojar</p>
<p><a href='http://arxiv.org/abs/2311.16787v1'>http://arxiv.org/abs/2311.16787v1</a></p>
<p><b>Compressor summary</b>: The article introduces a method to create more reliable human reference translations for machine translation evaluation by raising the bar of human translation quality.</p><hr><h3>The curse of language biases in remote sensing VQA: the role of spatial  attributes, language diversity, and the need for clear evaluation</h3>
<p>Christel Chappuis,Eliot Walt,Vincent Mendez,Sylvain Lobry,Bertrand Le Saux,Devis Tuia</p>
<p><a href='http://arxiv.org/abs/2311.16782v1'>http://arxiv.org/abs/2311.16782v1</a></p>
<p><b>Compressor summary</b>: The text discusses language biases in remote sensing visual question answering (RSVQA), their impact on model performance and robustness, and the need for less-biased datasets and more informative evaluation metrics.</p><hr><h3>Multi-Channel Cross Modal Detection of Synthetic Face Images</h3>
<p>M. Ibsen,C. Rathgeb,S. Marcel,C. Busch</p>
<p><a href='http://arxiv.org/abs/2311.16773v1'>http://arxiv.org/abs/2311.16773v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new method for detecting synthetic face images using Cross Modal Focal Loss, which performs better than existing methods in cross-model experiments.</p><hr><h3>Rescuing referral failures during automated diagnosis of domain-shifted  medical images</h3>
<p>Anuj Srivastava,Karm Patel,Pradeep Shenoy,Devarajan Sridharan</p>
<p><a href='http://arxiv.org/abs/2311.16766v1'>http://arxiv.org/abs/2311.16766v1</a></p>
<p><b>Compressor summary</b>: The paper discusses the problem of selective classification during automated diagnosis with domain-shifted medical images and how current approaches fail to handle uncertainty in such cases, leading to poor performance and a need for human intervention.</p><hr><h3>Radiology-Aware Model-Based Evaluation Metric for Report Generation</h3>
<p>Amos Calamida,Farhad Nooralahzadeh,Morteza Rohanian,Koji Fujimoto,Mizuho Nishio,Michael Krauthammer</p>
<p><a href='http://arxiv.org/abs/2311.16764v1'>http://arxiv.org/abs/2311.16764v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new evaluation metric for machine-generated radiology reports using COMET architecture, train models, and show that their metric correlates well with existing metrics and human judgment.</p><hr><h3>Towards Full-scene Domain Generalization in Multi-agent Collaborative  Bird's Eye View Segmentation for Connected and Autonomous Driving</h3>
<p>Senkang Hu,Zhengru Fang,Xianhao Chen,Yuguang Fang,Sam Kwong</p>
<p><a href='http://arxiv.org/abs/2311.16754v1'>http://arxiv.org/abs/2311.16754v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses a framework for improving collaborative perception in autonomous vehicles by addressing domain shifts and data heterogeneity using Amplitude Augmentation and meta-consistency training, as well as an intra-system domain alignment mechanism during inference.</p><hr><h3>As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D  Diffusion Priors</h3>
<p>Seungwoo Yoo,Kunho Kim,Vladimir G. Kim,Minhyuk Sung</p>
<p><a href='http://arxiv.org/abs/2311.16739v1'>http://arxiv.org/abs/2311.16739v1</a></p>
<p><b>Compressor summary</b>: APAP is a mesh deformation technique that uses 2D diffusion models and user input to create realistic and plausible edits of 2D and 3D meshes.</p><hr><h3>Riemannian Self-Attention Mechanism for SPD Networks</h3>
<p>Rui Wang,Xiao-Jun Wu,Hui Li,Josef Kittler</p>
<p><a href='http://arxiv.org/abs/2311.16738v1'>http://arxiv.org/abs/2311.16738v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an SPD manifold self-attention mechanism (SMSA) for learning features in scientific areas, which uses geometric operations like Riemannian metric and optimization to capture dependencies of data on a curved Riemannian manifold.</p><hr><h3>Point'n Move: Interactive Scene Object Manipulation on Gaussian  Splatting Radiance Fields</h3>
<p>Jiajun Huang,Hongchuan Yu</p>
<p><a href='http://arxiv.org/abs/2311.16737v1'>http://arxiv.org/abs/2311.16737v1</a></p>
<p><b>Compressor summary</b>: Point'n Move is an interactive scene manipulation method that uses Gaussian Splatting Radiance Field for real-time editing and inpainting of selected objects in scenes.</p><hr><h3>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic  Mapping for Monocular, Stereo, and RGB-D Cameras</h3>
<p>Huajian Huang,Longwei Li,Hui Cheng,Sai-Kit Yeung</p>
<p><a href='http://arxiv.org/abs/2311.16728v1'>http://arxiv.org/abs/2311.16728v1</a></p>
<p><b>Compressor summary</b>: Photo-SLAM is a novel SLAM framework that uses explicit geometric features and implicit photometric features for efficient online photorealistic mapping on portable devices.</p><hr><h3>Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld</h3>
<p>Yijun Yang,Tianyi Zhou,Kanxue Li,Dapeng Tao,Lusong Li,Li Shen,Xiaodong He,Jing Jiang,Yuhui Shi</p>
<p><a href='http://arxiv.org/abs/2311.16714v1'>http://arxiv.org/abs/2311.16714v1</a></p>
<p><b>Compressor summary</b>: The paper presents EMMA, an embodied multi-modal agent that adapts quickly to a visual world by distilling knowledge from a large language model in a parallel text world.</p><hr><h3>LEDITS++: Limitless Image Editing using Text-to-Image Models</h3>
<p>Manuel Brack,Felix Friedrich,Katharina Kornmeier,Linoy Tsaban,Patrick Schramowski,Kristian Kersting,Apolinário Passos</p>
<p><a href='http://arxiv.org/abs/2311.16711v1'>http://arxiv.org/abs/2311.16711v1</a></p>
<p><b>Compressor summary</b>: LEDITS++ is a text-based image editing technique that is efficient, versatile, and precise, supporting multiple edits without fine-tuning or optimization.</p><hr><h3>Sinkhorn Flow: A Continuous-Time Framework for Understanding and  Generalizing the Sinkhorn Algorithm</h3>
<p>Mohammad Reza Karimi,Ya-Ping Hsieh,Andreas Krause</p>
<p><a href='http://arxiv.org/abs/2311.16706v1'>http://arxiv.org/abs/2311.16706v1</a></p>
<p><b>Compressor summary</b>: The text discusses entropy-regularized optimal transport problems in machine learning, introducing a continuous-time version of the Sinkhorn algorithm that can handle noise and bias and connects to other related dynamics.</p><hr><h3>CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD  Programs</h3>
<p>Haocheng Yuan,Jing Xu,Hao Pan,Adrien Bousseau,Niloy Mitra,Changjian Li</p>
<p><a href='http://arxiv.org/abs/2311.16703v1'>http://arxiv.org/abs/2311.16703v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to semantically comment on CAD programs by parsing them, generating shapes and images, and using visual-semantic analysis to assign labels to code blocks.</p><hr><h3>Rethinking Intermediate Layers design in Knowledge Distillation for  Kidney and Liver Tumor Segmentation</h3>
<p>Vandan Gorade,Sparsh Mittal,Debesh Jha,Ulas Bagci</p>
<p><a href='http://arxiv.org/abs/2311.16700v1'>http://arxiv.org/abs/2311.16700v1</a></p>
<p><b>Compressor summary</b>: HLFD is a novel method that improves knowledge distillation for medical imaging tasks by strategically transferring knowledge from middle to earlier layers and vice versa, leading to better focus on tumor-specific features and improved performance.</p><hr><h3>Hyper-Relational Knowledge Graph Neural Network for Next POI</h3>
<p>Jixiao Zhang,Yongkang Li,Ruotong Zou,Jingyuan Zhang,Zipei Fan,Xuan Song</p>
<p><a href='http://arxiv.org/abs/2311.16683v1'>http://arxiv.org/abs/2311.16683v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new model, HKGNN, for POI recommendation in LBSN that considers hyper-relations, structural information, and side information to address data sparsity and improve recommendations.</p><hr><h3>ContextSeg: Sketch Semantic Segmentation by Querying the Context with  Attention</h3>
<p>Jiawei Wang,Changjian Li</p>
<p><a href='http://arxiv.org/abs/2311.16682v1'>http://arxiv.org/abs/2311.16682v1</a></p>
<p><b>Compressor summary</b>: ContextSeg is a novel method that uses an autoencoder with dense distance fields and a Transformer with group-based labeling to achieve state-of-the-art semantic segmentation of strokes in computer vision.</p><hr><h3>Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with  Prototypical Concept-based Explanations</h3>
<p>Maximilian Dreyer,Reduan Achtibat,Wojciech Samek,Sebastian Lapuschkin</p>
<p><a href='http://arxiv.org/abs/2311.16681v1'>http://arxiv.org/abs/2311.16681v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel XAI framework that uses prototypes to convey both local and global decision-making strategies of DNNs, enabling better understanding, model validation, and detection of outlier behavior.</p><hr><h3>Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained  Sentiment Analysis</h3>
<p>Dan Ma,Jun Xu,Zongyu Wang,Xuezhi Cao,Yunsen Xian</p>
<p><a href='http://arxiv.org/abs/2311.16678v1'>http://arxiv.org/abs/2311.16678v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new task (EASQE) for aspect-based sentiment analysis that decomposes aspect terms into entities and aspects, and proposes a baseline method (Trigger-Opinion) that outperforms existing approaches.</p><hr><h3>A Distribution-Based Threshold for Determining Sentence Similarity</h3>
<p>Gioele Cadamuro,Marco Gruppo</p>
<p><a href='http://arxiv.org/abs/2311.16675v1'>http://arxiv.org/abs/2311.16675v1</a></p>
<p><b>Compressor summary</b>: The authors propose a neural network based on siamese architecture to solve a semantic textual similarity problem with highly specific information, using a threshold to distinguish similar from dissimilar pairs and combining features from both distributions and distance functions to score predictions.</p><hr><h3>Large Language Models Meet Computer Vision: A Brief Survey</h3>
<p>Raby Hamadi</p>
<p><a href='http://arxiv.org/abs/2311.16673v1'>http://arxiv.org/abs/2311.16673v1</a></p>
<p><b>Compressor summary</b>: The paper surveys the latest advancements in transformers and their impact on computer vision and large language models, comparing different models and datasets, and suggesting future directions for research.</p><hr><h3>SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry,  Illumination, and Material Estimation</h3>
<p>Jesus Zarzar,Bernard Ghanem</p>
<p><a href='http://arxiv.org/abs/2311.16671v1'>http://arxiv.org/abs/2311.16671v1</a></p>
<p><b>Compressor summary</b>: The novel approach digitizes real-world objects by estimating their geometry, material properties, and lighting from posed images with fixed lighting using Neural Radiance Fields and image-based lighting.</p><hr><h3>PyTorch Geometric High Order: A Unified Library for High Order Graph  Neural Network</h3>
<p>Xiyuan Wang,Muhan Zhang</p>
<p><a href='http://arxiv.org/abs/2311.16670v1'>http://arxiv.org/abs/2311.16670v1</a></p>
<p><b>Compressor summary</b>: PyTorch Geometric High Order (PyGHO) is a library that simplifies the implementation of high-order graph neural networks and improves their performance on real-world tasks.</p><hr><h3>LiveNVS: Neural View Synthesis on Live RGB-D Streams</h3>
<p>Laura Fink,Darius Rückert,Linus Franke,Joachim Keinert,Marc Stamminger</p>
<p><a href='http://arxiv.org/abs/2311.16668v1'>http://arxiv.org/abs/2311.16668v1</a></p>
<p><b>Compressor summary</b>: LiveNVS is a system that enables real-time, high-quality neural novel view synthesis for live RGB-D input using projected neural features and a generalizable neural network.</p><hr><h3>MultiModal-Learning for Predicting Molecular Properties: A Framework  Based on Image and Graph Structures</h3>
<p>Zhuoyuan Wang,Jiacong Mi,Shan Lu,Jieyue He</p>
<p><a href='http://arxiv.org/abs/2311.16666v1'>http://arxiv.org/abs/2311.16666v1</a></p>
<p><b>Compressor summary</b>: MolIG is a novel framework that uses both image and graph structures to predict drug molecule properties, outperforming existing models.</p><hr><h3>DGNR: Density-Guided Neural Point Rendering of Large Driving Scenes</h3>
<p>Zhuopeng Li,Chenming Wu,Liangjun Zhang,Jianke Zhu</p>
<p><a href='http://arxiv.org/abs/2311.16664v1'>http://arxiv.org/abs/2311.16664v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method called Density-Guided Neural Rendering (DGNR) that learns a density space from scenes to guide the construction of a point-based renderer for large-scale driving scenes, eliminating the need for geometric priors and achieving photorealistic and efficient rendering.</p><hr><h3>SCALAR-NeRF: SCAlable LARge-scale Neural Radiance Fields for Scene  Reconstruction</h3>
<p>Yu Chen,Gim Hee Lee</p>
<p><a href='http://arxiv.org/abs/2311.16657v1'>http://arxiv.org/abs/2311.16657v1</a></p>
<p><b>Compressor summary</b>: SCALAR-NeRF is a framework that uses an encoder-decoder architecture and a coarse-to-fine strategy to reconstruct large-scale scenes efficiently and effectively, outperforming existing NeRF methods.</p><hr><h3>Pseudo-Likelihood Inference</h3>
<p>Theo Gruner,Boris Belousov,Fabio Muratore,Daniel Palenicek,Jan Peters</p>
<p><a href='http://arxiv.org/abs/2311.16656v1'>http://arxiv.org/abs/2311.16656v1</a></p>
<p><b>Compressor summary</b>: Pseudo-Likelihood Inference (PLI) is a new method that improves Simulation-Based Inference by combining neural approximation with likelihood kernel, making it better at handling challenging Bayesian system identification tasks on higher dimensions and dynamic systems.</p><hr><h3>Elucidating Discrepancy in Explanations of Predictive Models Developed  using EMR</h3>
<p>Aida Brankovic,Wenjie Huang,David Cook,Sankalp Khanna,Konstanty Bialkowski</p>
<p><a href='http://arxiv.org/abs/2311.16654v1'>http://arxiv.org/abs/2311.16654v1</a></p>
<p><b>Compressor summary</b>: The study evaluates how well explainable AI methods align with expert medical knowledge in clinical decision support algorithms for EMR data, identifying discrepancies and suggesting ways to improve trustworthiness.</p><hr><h3>Augmenting x-ray single particle imaging reconstruction with  self-supervised machine learning</h3>
<p>Zhantao Chen,Cong Wang,Mingye Gao,Chun Hong Yoon,Jana B. Thayer,Joshua J. Turner</p>
<p><a href='http://arxiv.org/abs/2311.16652v1'>http://arxiv.org/abs/2311.16652v1</a></p>
<p><b>Compressor summary</b>: The authors present a machine learning approach that improves Single Particle Imaging (SPI) with X-ray Free Electron Lasers (XFELs) by estimating particle orientations and reciprocal space intensities from diffraction images only.</p><hr><h3>Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for  Imbalanced Medical Classification</h3>
<p>Jiahuan Yan,Haojun Gao,Zhang Kai,Weize Liu,Danny Chen,Jian Wu,Jintai Chen</p>
<p><a href='http://arxiv.org/abs/2311.16650v1'>http://arxiv.org/abs/2311.16650v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Text2Tree, a novel algorithm that uses internal label hierarchy in training deep learning models for medical text classification, improving performance on imbalanced and scarce data.</p><hr><h3>Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method  Perspective</h3>
<p>Ming-Yu Chung,Sheng-Yen Chou,Chia-Mu Yu,Pin-Yu Chen,Sy-Yen Kuo,Tsung-Yi Ho</p>
<p><a href='http://arxiv.org/abs/2311.16646v1'>http://arxiv.org/abs/2311.16646v1</a></p>
<p><b>Compressor summary</b>: The study presents new trigger pattern generation methods for dataset distillation, which enable effective and hard-to-detect backdoor attacks.</p><hr><h3>Scaling Political Texts with ChatGPT</h3>
<p>Gaël Le Mens,Aina Gallego</p>
<p><a href='http://arxiv.org/abs/2311.16639v1'>http://arxiv.org/abs/2311.16639v1</a></p>
<p><b>Compressor summary</b>: The text describes how GPT-4 can estimate the positions of political texts on various dimensions accurately, quickly, and cheaply, comparing its performance with other methods.</p><hr><h3>Parallax-Tolerant Image Stitching with Epipolar Displacement Field</h3>
<p>Jian Yu,Yi Yu,Feipeng Da</p>
<p><a href='http://arxiv.org/abs/2311.16637v1'>http://arxiv.org/abs/2311.16637v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new method for stitching large parallax images using epipolar geometry, which reduces alignment artifacts and maintains projectivity.</p><hr><h3>MotionZero:Exploiting Motion Priors for Zero-shot Text-to-Video  Generation</h3>
<p>Sitong Su,Litao Guo,Lianli Gao,Hengtao Shen,Jingkuan Song</p>
<p><a href='http://arxiv.org/abs/2311.16635v1'>http://arxiv.org/abs/2311.16635v1</a></p>
<p><b>Compressor summary</b>: MotionZero is a method for generating videos from text prompts without using motion information, exploiting the implied motion priors in the prompts to accurately and independently control the motion of different objects.</p><hr><h3>Outfit Completion via Conditional Set Transformation</h3>
<p>Takuma Nakamura,Yuki Saito,Ryosuke Goto</p>
<p><a href='http://arxiv.org/abs/2311.16630v1'>http://arxiv.org/abs/2311.16630v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new framework for outfit completion using deep neural networks and a conditional set transformation architecture that improves accuracy and scalability.</p><hr><h3>Gaussian Processes for Monitoring Air-Quality in Kampala</h3>
<p>Clara Stoddart,Lauren Shrack,Richard Sserunjogi,Usman Abdul-Ganiy,Engineer Bainomugisha,Deo Okure,Ruth Misener,Jose Pablo Folch,Ruby Sedgwick</p>
<p><a href='http://arxiv.org/abs/2311.16625v1'>http://arxiv.org/abs/2311.16625v1</a></p>
<p><b>Compressor summary</b>: The paper explores using Gaussian Processes to nowcast and forecast air pollution in Kampala, Uganda, where sensor coverage is limited.</p><hr><h3>On the Long Range Abilities of Transformers</h3>
<p>Itamar Zimerman,Lior Wolf</p>
<p><a href='http://arxiv.org/abs/2311.16620v1'>http://arxiv.org/abs/2311.16620v1</a></p>
<p><b>Compressor summary</b>: The authors propose modifications to the transformer architecture inspired by long-range layers, improving its performance on the Long Range Arena benchmark while maintaining simplicity and minimal additional computation.</p><hr><h3>Cross-level Attention with Overlapped Windows for Camouflaged Object  Detection</h3>
<p>Jiepan Li,Fangxiao Lu,Nan Xue,Zhuohong Li,Hongyan Zhang,Wei He</p>
<p><a href='http://arxiv.org/abs/2311.16618v1'>http://arxiv.org/abs/2311.16618v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new method called OWinCA that enhances low-level features for detecting camouflaged objects using cross-level attention and an overlapped window partition strategy, achieving better results than existing methods.</p><hr><h3>Adversarial Distribution Balancing for Counterfactual Reasoning</h3>
<p>Stefan Schrod,Fabian Sinz,Michael Altenbuchinger</p>
<p><a href='http://arxiv.org/abs/2311.16616v1'>http://arxiv.org/abs/2311.16616v1</a></p>
<p><b>Compressor summary</b>: ADBCR is a machine learning method for counterfactual reasoning that uses potential outcome estimates to remove spurious causal relations and performs well on benchmark datasets, especially when using unlabeled validation data.</p><hr><h3>LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning</h3>
<p>Jintang Li,Jiawang Dan,Ruofan Wu,Jing Zhou,Sheng Tian,Yunfei Liu,Baokun Wang,Changhua Meng,Weiqiang Wang,Yuchang Zhu,Liang Chen,Zibin Zheng</p>
<p><a href='http://arxiv.org/abs/2311.16605v1'>http://arxiv.org/abs/2311.16605v1</a></p>
<p><b>Compressor summary</b>: LasTGL is an industrial framework that integrates implementations of common temporal graph learning algorithms to facilitate research and application in this emerging field.</p><hr><h3>Improving Lane Detection Generalization: A Novel Framework using HD Maps  for Boosting Diversity</h3>
<p>Daeun Lee,Minhyeok Heo,Jiwon Kim</p>
<p><a href='http://arxiv.org/abs/2311.16589v1'>http://arxiv.org/abs/2311.16589v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new framework for improving lane detection algorithms by using HD maps and generative models to increase data diversity without expanding the data volume.</p><hr><h3>MedGen: A Python Natural Language Processing Toolkit for Medical Text  Processing</h3>
<p>Rui Yang,Qingcheng Zeng,Keen You,Yujie Qiao,Lucas Huang,Chia-Chun Hsieh,Benjamin Rosand,Jeremy Goldwasser,Amisha D Dave,Tiarnan D. L. Keenan,Emily Y Chew,Dragomir Radev,Zhiyong Lu,Hua Xu,Qingyu Chen,Irene Li</p>
<p><a href='http://arxiv.org/abs/2311.16588v1'>http://arxiv.org/abs/2311.16588v1</a></p>
<p><b>Compressor summary</b>: Summary:
The MedGen NLP toolkit offers easy-to-use generative and basic NLP functions for biomedical researchers and healthcare professionals, with fine-tuned domain models and public availability.</p><hr><h3>Clean Label Disentangling for Medical Image Segmentation with Noisy  Labels</h3>
<p>Zicheng Wang,Zhen Zhao,Erjian Guo,Luping Zhou</p>
<p><a href='http://arxiv.org/abs/2311.16580v1'>http://arxiv.org/abs/2311.16580v1</a></p>
<p><b>Compressor summary</b>: The authors propose a class-balanced sampling strategy and a noisy feature-aided clean label disentangling framework to address the noisy label issue in medical image segmentation, achieving state-of-the-art performance.</p><hr><h3>Recognizing Conditional Causal Relationships about Emotions and Their  Corresponding Conditions</h3>
<p>Xinhong Chen,Zongxi Li,Yaowei Wang,Haoran Xie,Jianping Wang,Qing Li</p>
<p><a href='http://arxiv.org/abs/2311.16579v1'>http://arxiv.org/abs/2311.16579v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new task that identifies valid causal relationships between emotions and causes in texts, taking into account specific context clauses, and proposes a multi-task framework to handle this task.</p><hr><h3>Efficient Key-Based Adversarial Defense for ImageNet by Using  Pre-trained Model</h3>
<p>AprilPyone MaungMaung,Isao Echizen,Hitoshi Kiya</p>
<p><a href='http://arxiv.org/abs/2311.16577v1'>http://arxiv.org/abs/2311.16577v1</a></p>
<p><b>Compressor summary</b>: The paper introduces key-based defense model proliferation using pre-trained models and efficient fine-tuning techniques for on-device image classification, improving accuracy by more than 10%.</p><hr><h3>MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices</h3>
<p>Yang Zhao,Yanwu Xu,Zhisheng Xiao,Tingbo Hou</p>
<p><a href='http://arxiv.org/abs/2311.16567v1'>http://arxiv.org/abs/2311.16567v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MobileDiffusion, an efficient text-to-image diffusion model with reduced size and fast inference speed, achieved through architecture optimization and sampling techniques.</p><hr><h3>DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D  Face Diffuser</h3>
<p>Peng Chen,Xiaobao Wei,Ming Lu,Yitong Zhu,Naiming Yao,Xingyu Xiao,Hui Chen</p>
<p><a href='http://arxiv.org/abs/2311.16565v1'>http://arxiv.org/abs/2311.16565v1</a></p>
<p><b>Compressor summary</b>: The proposed DiffusionTalker method uses contrastive learning and knowledge distillation to personalize and speed up 3D facial animation based on speech input, overcoming limitations of existing diffusion-based approaches.</p><hr><h3>Scalable Label Distribution Learning for Multi-Label Classification</h3>
<p>Xingyu Zhao,Yuexuan An,Lei Qi,Xin Geng</p>
<p><a href='http://arxiv.org/abs/2311.16556v1'>http://arxiv.org/abs/2311.16556v1</a></p>
<p><b>Compressor summary</b>: SLDL is a novel multi-label classification method that uses continuous distributions in a low-dimensional latent space to model asymmetric label correlations, reducing computational complexity and achieving competitive performance.</p><hr><h3>Enhancing Scene Text Detectors with Realistic Text Image Synthesis Using  Diffusion Models</h3>
<p>Ling Fu,Zijie Wu,Yingying Zhu,Yuliang Liu,Xiang Bai</p>
<p><a href='http://arxiv.org/abs/2311.16555v1'>http://arxiv.org/abs/2311.16555v1</a></p>
<p><b>Compressor summary</b>: DiffText is a new method that uses a diffusion model to create realistic synthetic text images with less spelling errors and better background integration, improving scene text detection performance.</p><hr><h3>HandyPriors: Physically Consistent Perception of Hand-Object  Interactions with Differentiable Priors</h3>
<p>Shutong Zhang,Yi-Ling Qiao,Guanglei Zhu,Eric Heiden,Dylan Turpin,Jingzhou Liu,Ming Lin,Miles Macklin,Animesh Garg</p>
<p><a href='http://arxiv.org/abs/2311.16552v1'>http://arxiv.org/abs/2311.16552v1</a></p>
<p><b>Compressor summary</b>: HandyPriors is a unified and general pipeline for pose estimation in human-object interaction scenes using differentiable physics and rendering priors, with two alternatives for hand and object pose estimation that achieve comparable or superior results and can be used for robotic manipulation and perception tasks.</p><hr><h3>Multi-Irreducible Spectral Synchronization for Robust Rotation Averaging</h3>
<p>Owen Howell,Haoen Huang,David Rosen</p>
<p><a href='http://arxiv.org/abs/2311.16544v1'>http://arxiv.org/abs/2311.16544v1</a></p>
<p><b>Compressor summary</b>: The authors propose a convex spectral relaxation method for estimating unknown orientations in robotics and computer vision, which has advantages over prior methods and provides performance guarantees under specific noise assumptions.</p><hr><h3>Exploring Straighter Trajectories of Flow Matching with Diffusion  Guidance</h3>
<p>Siyu Xing,Jie Cao,Huaibo Huang,Xiao-Yu Zhang,Ran He</p>
<p><a href='http://arxiv.org/abs/2311.16507v1'>http://arxiv.org/abs/2311.16507v1</a></p>
<p><b>Compressor summary</b>: StraightFM is a novel flow matching method that straightens trajectories using diffusion models and real data, resulting in higher quality images with fewer sampling steps.</p><hr><h3>Agents meet OKR: An Object and Key Results Driven Agent System with  Hierarchical Self-Collaboration and Self-Evaluation</h3>
<p>Yi Zheng,Chongyang Ma,Kanle Shi,Haibin Huang</p>
<p><a href='http://arxiv.org/abs/2311.16542v1'>http://arxiv.org/abs/2311.16542v1</a></p>
<p><b>Compressor summary</b>: The OKR-Agent framework enhances Large Language Models' task-solving abilities by using self-collaboration, self-correction, and hierarchical agents to improve domain knowledge, reasoning, and execution structure.</p><hr><h3>Personalized Predictions of Glioblastoma Infiltration: Mathematical  Models, Physics-Informed Neural Networks and Multimodal Scans</h3>
<p>Ray Zirui Zhang,Ivan Ezhov,Michal Balcerak,Andy Zhu,Benedikt Wiestler,Bjoern Menze,John Lowengrub</p>
<p><a href='http://arxiv.org/abs/2311.16536v1'>http://arxiv.org/abs/2311.16536v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a method that uses Physics-Informed Neural Networks to estimate patient-specific parameters of a model of Glioblastoma growth from a single MRI scan, which could help in designing personalized radiotherapy treatment plans.</p><hr><h3>Graph Prompt Learning: A Comprehensive Survey and Beyond</h3>
<p>Xiangguo Sun,Jiawen Zhang,Xixi Wu,Hong Cheng,Yun Xiong,Jia Li</p>
<p><a href='http://arxiv.org/abs/2311.16534v1'>http://arxiv.org/abs/2311.16534v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper surveys the emerging domain of graph prompts in AGI, addressing challenges and opportunities
- It proposes a unified framework for understanding graph prompt learning and categorizes over 100 works in this field
- It presents ProG, a Python library and website, to support research in graph prompting
- It discusses current challenges and future directions, offering a roadmap for research in graph prompting within AGI

Summary: The paper provides an overview of graph prompts in AGI, introducing a framework, a library, and a roadmap for this new domain.</p><hr><h3>On robust overfitting: adversarial training induced distribution matters</h3>
<p>Runzhi Tian,Yongyi Mao</p>
<p><a href='http://arxiv.org/abs/2311.16526v1'>http://arxiv.org/abs/2311.16526v1</a></p>
<p><b>Compressor summary</b>: Adversarial training causes robust overfitting and this paper investigates its correlation with perturbation-induced distributions and proposes a new upper bound for generalization error using local dispersion.</p><hr><h3>3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit  Functions</h3>
<p>Sihwa Park,Seongjun Kim,In-Seok Song,Seung Jun Baek</p>
<p><a href='http://arxiv.org/abs/2311.16524v1'>http://arxiv.org/abs/2311.16524v1</a></p>
<p><b>Compressor summary</b>: Occudent is a novel framework that uses neural implicit functions to reconstruct 3D teeth shapes from panoramic radiographs, outperforming existing methods.</p><hr><h3>Evaluation of dynamic characteristics of power grid based on GNN and  application on knowledge graph</h3>
<p>Hao Pei,Si Lin,Chuanfu Li,Che Wang,Haoming Chen,Sizhe Li</p>
<p><a href='http://arxiv.org/abs/2311.16522v1'>http://arxiv.org/abs/2311.16522v1</a></p>
<p><b>Compressor summary</b>: The text describes a new method using a graph neural network that can accurately detect and analyze faults in power grids with high accuracy and insightful results.</p><hr><h3>B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the  Response of Complex Dynamical Systems to Length-Variant Multiple Input  Functions</h3>
<p>Zhihao Kong,Amirhossein Mollaali,Christian Moya,Na Lu,Guang Lin</p>
<p><a href='http://arxiv.org/abs/2311.16519v1'>http://arxiv.org/abs/2311.16519v1</a></p>
<p><b>Compressor summary</b>: B-LSTM-MIONet is a redesigned framework that combines MIONet, LSTM, and Bayesian methods to learn neural operators from time-dependent data, handling variable-length real-time data and providing uncertainty quantification for complex systems modeling.</p><hr><h3>StyleCap: Automatic Speaking-Style Captioning from Speech Based on  Speech and Language Self-supervised Learning Models</h3>
<p>Kazuki Yamauchi,Yusuke Ijima,Yuki Saito</p>
<p><a href='http://arxiv.org/abs/2311.16509v1'>http://arxiv.org/abs/2311.16509v1</a></p>
<p><b>Compressor summary</b>: StyleCap is a method to generate natural language descriptions of speaking styles in speech using neural networks, paired data, and large language models.</p><hr><h3>Efficient Multimodal Diffusion Models Using Joint Data Infilling with  Partially Shared U-Net</h3>
<p>Zizhao Hu,Shaochong Jia,Mohammad Rostami</p>
<p><a href='http://arxiv.org/abs/2311.16488v1'>http://arxiv.org/abs/2311.16488v1</a></p>
<p><b>Compressor summary</b>: The paper introduces PS-U-Net, an efficient multimodal diffusion model that preserves modality-specific details and a new multimodal sampling method for conditional generation of text and image data with higher quality.</p><hr><h3>A Unified Framework for Multimodal, Multi-Part Human Motion Synthesis</h3>
<p>Zixiang Zhou,Yu Wan,Baoyuan Wang</p>
<p><a href='http://arxiv.org/abs/2311.16471v1'>http://arxiv.org/abs/2311.16471v1</a></p>
<p><b>Compressor summary</b>: The paper presents a scalable method to generate multimodal and multi-part human motion using codebooks and pre-trained models.</p><hr><h3>AvatarGPT: All-in-One Framework for Motion Understanding, Planning,  Generation and Beyond</h3>
<p>Zixiang Zhou,Yu Wan,Baoyuan Wang</p>
<p><a href='http://arxiv.org/abs/2311.16468v1'>http://arxiv.org/abs/2311.16468v1</a></p>
<p><b>Compressor summary</b>: AvatarGPT is an all-in-one framework that uses a large language model to perform various motion-related tasks, such as understanding, planning, and generating human motions, by treating each task as an instruction fine-tuned on the shared model.</p><hr><h3>TextDiffuser-2: Unleashing the Power of Language Models for Text  Rendering</h3>
<p>Jingye Chen,Yupan Huang,Tengchao Lv,Lei Cui,Qifeng Chen,Furu Wei</p>
<p><a href='http://arxiv.org/abs/2311.16465v1'>http://arxiv.org/abs/2311.16465v1</a></p>
<p><b>Compressor summary</b>: TextDiffuser-2 is a method that uses a large language model to improve the flexibility, automation, and style diversity of text rendering in diffusion models.</p><hr><h3>Bridging the Gap: A Unified Video Comprehension Framework for Moment  Retrieval and Highlight Detection</h3>
<p>Yicheng Xiao,Zhuoyan Luo,Yong Liu,Yue Ma,Hengwei Bian,Yatai Ji,Yujiu Yang,Xiu Li</p>
<p><a href='http://arxiv.org/abs/2311.16464v1'>http://arxiv.org/abs/2311.16464v1</a></p>
<p><b>Compressor summary</b>: UVCOM is a framework that effectively combines Video Moment Retrieval and Highlight Detection tasks by integrating multi-granularity, intra and inter-modality, and multi-aspect contrastive learning.</p><hr><h3>Viewport Prediction for Volumetric Video Streaming by Exploring Video  Saliency and Trajectory Information</h3>
<p>Jie Li,Zhixin Li,Zhi Liu,Pengyuan Zhou,Richang Hong,Qiyue Li,Han Hu</p>
<p><a href='http://arxiv.org/abs/2311.16462v1'>http://arxiv.org/abs/2311.16462v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method for improving viewport prediction in volumetric video streaming using saliency detection, trajectory information, and a new sampling technique.</p><hr><h3>Spiking Neural Networks with Dynamic Time Steps for Vision Transformers</h3>
<p>Gourav Datta,Zeyu Liu,Anni Li,Peter A. Beerel</p>
<p><a href='http://arxiv.org/abs/2311.16456v1'>http://arxiv.org/abs/2311.16456v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new training framework that adapts the number of time steps for each module in vision transformers, resulting in energy-efficient spiking neural networks for image recognition tasks.</p><hr><h3>Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case  Study in Medicine</h3>
<p>Harsha Nori,Yin Tat Lee,Sheng Zhang,Dean Carignan,Richard Edgar,Nicolo Fusi,Nicholas King,Jonathan Larson,Yuanzhi Li,Weishung Liu,Renqian Luo,Scott Mayer McKinney,Robert Osazuwa Ness,Hoifung Poon,Tao Qin,Naoto Usuyama,Chris White,Eric Horvitz</p>
<p><a href='http://arxiv.org/abs/2311.16452v1'>http://arxiv.org/abs/2311.16452v1</a></p>
<p><b>Compressor summary</b>: The authors explore prompt engineering techniques with GPT-4 to unlock its specialist capabilities in various domains, achieving state-of-the-art results on medical benchmarks and outperforming specialist models.</p><hr><h3>Typhoon Intensity Prediction with Vision Transformer</h3>
<p>Huanxin Chen,Pengshuai Yin,Huichou Huang,Qingyao Wu,Ruirui Liu,Xiatian Zhu</p>
<p><a href='http://arxiv.org/abs/2311.16450v1'>http://arxiv.org/abs/2311.16450v1</a></p>
<p><b>Compressor summary</b>: The Typhoon Intensity Transformer (Tint) uses self-attention mechanisms to capture local and global contextual relations in satellite images, improving typhoon intensity prediction accuracy.</p><hr><h3>Centre Stage: Centricity-based Audio-Visual Temporal Action Detection</h3>
<p>Hanyuan Wang,Majid Mirmehdi,Dima Damen,Toby Perrett</p>
<p><a href='http://arxiv.org/abs/2311.16446v1'>http://arxiv.org/abs/2311.16446v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method to improve one-stage action detection by fusing visual and audio modalities, using multi-scale cross-attention and a centricity score that estimates the proximity of timesteps to the action centre, achieving state-of-the-art performance on EPIC-Kitchens-100.</p><hr><h3>CLAP: Contrastive Learning with Augmented Prompts for Robustness on  Pretrained Vision-Language Models</h3>
<p>Yichao Cai,Yuhang Liu,Zhen Zhang,Javen Qinfeng Shi</p>
<p><a href='http://arxiv.org/abs/2311.16445v1'>http://arxiv.org/abs/2311.16445v1</a></p>
<p><b>Compressor summary</b>: The study proposes a method to improve vision-language models' resilience against perturbations by modifying text data's style while preserving its content, without retraining the image encoder on adversarial examples.</p><hr><h3>Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities  Using Web Instructional Videos</h3>
<p>Takehiko Ohkawa,Takuma Yagi,Taichi Nishimura,Ryosuke Furuta,Atsushi Hashimoto,Yoshitaka Ushiku,Yoichi Sato</p>
<p><a href='http://arxiv.org/abs/2311.16444v1'>http://arxiv.org/abs/2311.16444v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel benchmark for transferring knowledge from exocentric web videos to dense video captioning of egocentric videos using adversarial training, addressing the challenge of dynamic view changes between these two domains.</p><hr><h3>Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and  Asynchronous Dequantization</h3>
<p>Jinhao Li,Shiyao Li,Jiaming Xu,Shan Huang,Yaoxiu Lian,Jun Liu,Yu Wang,Guohao Dai</p>
<p><a href='http://arxiv.org/abs/2311.16442v1'>http://arxiv.org/abs/2311.16442v1</a></p>
<p><b>Compressor summary</b>: The paper proposes techniques to improve the accuracy and efficiency of large language models by adjusting the bit width of quantization and optimizing dequantization operations on GPUs.</p><hr><h3>Text-Driven Image Editing via Learnable Regions</h3>
<p>Yuanze Lin,Yi-Wen Chen,Yi-Hsuan Tsai,Lu Jiang,Ming-Hsuan Yang</p>
<p><a href='http://arxiv.org/abs/2311.16432v1'>http://arxiv.org/abs/2311.16432v1</a></p>
<p><b>Compressor summary</b>: The paper presents a text-to-image editing method that uses bounding boxes to find edit regions based on textual prompts, achieving high fidelity and realism with complex prompts.</p><hr><h3>Manifold Preserving Guided Diffusion</h3>
<p>Yutong He,Naoki Murata,Chieh-Hsin Lai,Yuhta Takida,Toshimitsu Uesaka,Dongjun Kim,Wei-Hsiang Liao,Yuki Mitsufuji,J. Zico Kolter,Ruslan Salakhutdinov,Stefano Ermon</p>
<p><a href='http://arxiv.org/abs/2311.16424v1'>http://arxiv.org/abs/2311.16424v1</a></p>
<p><b>Compressor summary</b>: MPGD is a training-free method for conditional image generation that uses diffusion models, neural networks, and pretrained autoencodters, achieving efficiency and effectiveness with speed-ups and high sample quality.</p><hr><h3>CDEval: A Benchmark for Measuring the Cultural Dimensions of Large  Language Models</h3>
<p>Yuhang Wang,Yanxu Zhu,Chao Kong,Shuyu Wei,Xiaoyuan Yi,Xing Xie,Jitao Sang</p>
<p><a href='http://arxiv.org/abs/2311.16421v1'>http://arxiv.org/abs/2311.16421v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces CDEval, a new benchmark to evaluate cultural dimensions of Large Language Models (LLMs), emphasizing the importance of cultural considerations in their development and applications.</p><hr><h3>Model-free Test Time Adaptation for Out-Of-Distribution Detection</h3>
<p>YiFan Zhang,Xue Wang,Tian Zhou,Kun Yuan,Zhang Zhang,Liang Wang,Rong Jin,Tieniu Tan</p>
<p><a href='http://arxiv.org/abs/2311.16420v1'>http://arxiv.org/abs/2311.16420v1</a></p>
<p><b>Compressor summary</b>: The Non-Parametric Test Time Adaptation framework for Out-Of-Distribution Detection (NPTTA) is a method that adapts to changing data distributions during testing and uses detected out-of-distribution samples to improve reliability, achieving better performance than existing methods.</p><hr><h3>Deep Learning for Time Series Classification of Parkinson's Disease Eye  Tracking Data</h3>
<p>Gonzalo Uribarri,Simon Ekman von Huth,Josefine Waldthaler,Per Svenningsson,Erik Fransén</p>
<p><a href='http://arxiv.org/abs/2311.16381v1'>http://arxiv.org/abs/2311.16381v1</a></p>
<p><b>Compressor summary</b>: The authors investigate using deep learning algorithms to classify Parkinson's disease from eye-tracking data during saccade experiments, achieving high accuracy with raw fixation interval inputs.</p>