
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-07-25</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-07-25 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View  Consistency</h3>
<p><a href='http://arxiv.org/abs/2407.17470v1'>http://arxiv.org/abs/2407.17470v1</a></p>
<p><b>Compressor summary</b>: SV4D is a latent video diffusion model that generates consistent novel views for dynamic 3D objects from a reference video and optimizes an implicit 4D representation without SDS optimization.</p><hr><h3>I Could've Asked That: Reformulating Unanswerable Questions</h3>
<p><a href='http://arxiv.org/abs/2407.17469v1'>http://arxiv.org/abs/2407.17469v1</a></p>
<p><b>Compressor summary</b>: The paper introduces CouldAsk, a benchmark for evaluating question reformulation, and shows that current language models struggle to improve unanswerable questions.</p><hr><h3>WildHallucinations: Evaluating Long-form Factuality in LLMs with  Real-World Entity Queries</h3>
<p><a href='http://arxiv.org/abs/2407.17468v1'>http://arxiv.org/abs/2407.17468v1</a></p>
<p><b>Compressor summary</b>: WildHallucinations is a benchmark that tests factuality of LLMs by generating and fact-checking information about real-world entities from user-chatbot conversations, revealing Hallucination patterns across domains.</p><hr><h3>CMR Scaling Law: Predicting Critical Mixture Ratios for Continual  Pre-training of Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.17467v1'>http://arxiv.org/abs/2407.17467v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a critical mixture ratio (CMR) to balance the general and domain-specific knowledge of large language models during continual pre-training, improving their efficiency and effectiveness in specialized domains.</p><hr><h3>Traversing Pareto Optimal Policies: Provably Efficient Multi-Objective  Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17466v1'>http://arxiv.org/abs/2407.17466v1</a></p>
<p><b>Compressor summary</b>: The paper studies multi-objective reinforcement learning (MORL) with multiple reward functions, analyzes different optimization targets for finding Pareto optimal policies, and proposes efficient algorithms using Tchebycheff scalarization.</p><hr><h3>u-$Î¼$P: The Unit-Scaled Maximal Update Parametrization</h3>
<p><a href='http://arxiv.org/abs/2407.17465v1'>http://arxiv.org/abs/2407.17465v1</a></p>
<p><b>Compressor summary</b>: u-$\mu$P combines $\mu$P and Unit Scaling to simplify and improve hyperparameter optimization for efficient training and low-precision computing.</p><hr><h3>Hidden or Inferred: Fair Learning-To-Rank with Unknown Demographics</h3>
<p><a href='http://arxiv.org/abs/2407.17459v1'>http://arxiv.org/abs/2407.17459v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how demographic inference errors affect the fairness performance of various learning-to-rank models and suggests that fair re-ranking strategies are more robust to these errors than LTR-based methods.</p><hr><h3>EuroCropsML: A Time Series Benchmark Dataset For Few-Shot Crop Type  Classification</h3>
<p><a href='http://arxiv.org/abs/2407.17458v1'>http://arxiv.org/abs/2407.17458v1</a></p>
<p><b>Compressor summary</b>: EuroCropsML is a new dataset for crop type classification in Europe using Sentinel-2 satellite images.</p><hr><h3>CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition</h3>
<p><a href='http://arxiv.org/abs/2407.17457v1'>http://arxiv.org/abs/2407.17457v1</a></p>
<p><b>Compressor summary</b>: CSCPR is a new algorithm for RGB-D indoor place recognition that uses global retrieval, reranking, and context clusters to handle noisy data and achieve better performance than existing models.</p><hr><h3>Automated Explanation Selection for Scientific Discovery</h3>
<p><a href='http://arxiv.org/abs/2407.17454v1'>http://arxiv.org/abs/2407.17454v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a machine learning-based cycle for generating and choosing explanations in Explainable AI, using a taxonomy of explanation selection criteria derived from sociology and cognitive science.</p><hr><h3>$VILA^2$: VILA Augmented VILA</h3>
<p><a href='http://arxiv.org/abs/2407.17453v1'>http://arxiv.org/abs/2407.17453v1</a></p>
<p><b>Compressor summary</b>: The authors propose VILA^2, a visual language model family that uses self-augmentation and specialist-augmentation to improve data quality and performance on various tasks.</p><hr><h3>Looking at Model Debiasing through the Lens of Anomaly Detection</h3>
<p><a href='http://arxiv.org/abs/2407.17449v1'>http://arxiv.org/abs/2407.17449v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to identify and reduce unwanted correlations in deep neural networks using anomaly detection and data augmentation.</p><hr><h3>Fluent Student-Teacher Redteaming</h3>
<p><a href='http://arxiv.org/abs/2407.17447v1'>http://arxiv.org/abs/2407.17447v1</a></p>
<p><b>Compressor summary</b>: The authors improve existing algorithms for jailbreaking safety-tuned language models by using a new distillation-based approach that makes the attacks more powerful and fluent, achieving high success rates on various models.</p><hr><h3>AHMF: Adaptive Hybrid-Memory-Fusion Model for Driver Attention  Prediction</h3>
<p><a href='http://arxiv.org/abs/2407.17442v1'>http://arxiv.org/abs/2407.17442v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an Adaptive Hybrid-Memory-Fusion (AHMF) model that incorporates working memory and long-term memory to predict driver attention more human-like, using domain adaptation techniques for better performance.</p><hr><h3>HumanVid: Demystifying Training Data for Camera-controllable Human Image  Animation</h3>
<p><a href='http://arxiv.org/abs/2407.17438v1'>http://arxiv.org/abs/2407.17438v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Human image animation generates videos from a photo of a character
- Existing approaches face challenges with training data, 2D motion, and camera motions
- HumanVid is a new dataset that combines real-world and synthetic data with rich annotations
- CamAnimate is a baseline model that shows state-of-the-art performance on HumanVid

Summary:
HumanVid introduces a large-scale dataset for human image animation, addressing the limitations of existing approaches by providing diverse and precise real-world and synthetic data with human and camera motion annotations.</p><hr><h3>Nerva: a Truly Sparse Implementation of Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2407.17437v1'>http://arxiv.org/abs/2407.17437v1</a></p>
<p><b>Compressor summary</b>: Nerva is a fast C++ neural network library that uses sparse matrix operations to reduce training time and memory usage while maintaining accuracy.</p><hr><h3>3D Gaussian Splatting: Survey, Technologies, Challenges, and  Opportunities</h3>
<p><a href='http://arxiv.org/abs/2407.17418v1'>http://arxiv.org/abs/2407.17418v1</a></p>
<p><b>Compressor summary</b>: 3D Gaussian Splatting is a technique that converts multi-view images into 3D representations for real-time rendering, and this survey reviews existing works, challenges, and opportunities in the field.</p><hr><h3>Can Watermarking Large Language Models Prevent Copyrighted Text  Generation and Hide Training Data?</h3>
<p><a href='http://arxiv.org/abs/2407.17417v1'>http://arxiv.org/abs/2407.17417v1</a></p>
<p><b>Compressor summary</b>: This paper investigates how watermarking large language models can deter copyright violations, while also considering the impact on membership inference attacks and proposing an adaptive technique to improve detection.</p><hr><h3>(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent  HyperNetwork</h3>
<p><a href='http://arxiv.org/abs/2407.17412v1'>http://arxiv.org/abs/2407.17412v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel algorithm, PASS, that leverages visual prompts to determine channel importance and achieve structural sparsity in neural networks, resulting in improved efficiency and performance.</p><hr><h3>Generation of Training Data from HD Maps in the Lanelet2 Framework</h3>
<p><a href='http://arxiv.org/abs/2407.17409v1'>http://arxiv.org/abs/2407.17409v1</a></p>
<p><b>Compressor summary</b>: The paper introduces lanelet2_ml_converter, an extension to the HD map framework Lanelet2 that supports machine learning tasks and training using map data.</p><hr><h3>Dependency Transformer Grammars: Integrating Dependency Structures into  Transformer Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.17406v1'>http://arxiv.org/abs/2407.17406v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Dependency Transformer Grammars (DTGs), a new type of Transformer model that uses dependency structures to improve generalization, and shows that it outperforms previous models based on constituency trees.</p><hr><h3>Grammar-based Game Description Generation using Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.17404v1'>http://arxiv.org/abs/2407.17404v1</a></p>
<p><b>Compressor summary</b>: The paper explores using large language models with game description grammar to improve automated game design with limited data.</p><hr><h3>Self-Calibrated Variance-Stabilizing Transformations for Real-World  Image Denoising</h3>
<p><a href='http://arxiv.org/abs/2407.17399v1'>http://arxiv.org/abs/2407.17399v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method called Noise2VST that uses an off-the-shelf Gaussian denoiser and a variance-stabilizing transform to efficiently remove noise from real-world images without additional training data.</p><hr><h3>Systematic Reasoning About Relational Domains With Graph Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2407.17396v1'>http://arxiv.org/abs/2407.17396v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a GNN architecture that treats node embeddings as epistemic states and shows it can achieve state-of-the-art results in reasoning with relational domains.</p><hr><h3>Five reasons against assuming a data-generating distribution in Machine  Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17395v1'>http://arxiv.org/abs/2407.17395v1</a></p>
<p><b>Compressor summary</b>: The authors challenge the common assumption of data-generating probability distributions in machine learning and propose an alternative framework that focuses on finite populations for better modeling and theory.</p><hr><h3>CovScore: Evaluation of Multi-Document Abstractive Title Set Generation</h3>
<p><a href='http://arxiv.org/abs/2407.17390v1'>http://arxiv.org/abs/2407.17390v1</a></p>
<p><b>Compressor summary</b>: CovScore is a new method for evaluating extracted thematic title sets from documents using five metrics, which simplifies and speeds up the evaluation process and can be applied to relevant datasets like Holocaust survivor testimonies.</p><hr><h3>PERSONA: A Reproducible Testbed for Pluralistic Alignment</h3>
<p><a href='http://arxiv.org/abs/2407.17387v1'>http://arxiv.org/abs/2407.17387v1</a></p>
<p><b>Compressor summary</b>: PERSONA is a test bed that evaluates and improves language models' ability to align with diverse user values by generating synthetic personas and feedback.</p><hr><h3>A Comprehensive Approach to Misspelling Correction with BERT and  Levenshtein Distance</h3>
<p><a href='http://arxiv.org/abs/2407.17383v1'>http://arxiv.org/abs/2407.17383v1</a></p>
<p><b>Compressor summary</b>: The research uses neural networks and BERT models to correct spelling errors in written text, especially in the Persian language.</p><hr><h3>MMRA: A Benchmark for Multi-granularity Multi-image Relational  Association</h3>
<p><a href='http://arxiv.org/abs/2407.17379v1'>http://arxiv.org/abs/2407.17379v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new multi-image relation association task (MMRA) to evaluate large visual language models' ability to perceive associative relations between multiple images and their details, finding that current models struggle with fine-grained tasks and spatial perception.</p><hr><h3>PrevPredMap: Exploring Temporal Modeling with Previous Predictions for  Online Vectorized HD Map Construction</h3>
<p><a href='http://arxiv.org/abs/2407.17378v1'>http://arxiv.org/abs/2407.17378v1</a></p>
<p><b>Compressor summary</b>: The paper introduces PrevPredMap, a framework that uses previous predictions to create online vectorized HD maps, with two essential modules and a dual-mode strategy for robust performance.</p><hr><h3>Entropy Reweighted Conformal Classification</h3>
<p><a href='http://arxiv.org/abs/2407.17377v1'>http://arxiv.org/abs/2407.17377v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>ViPer: Visual Personalization of Generative Models via Individual  Preference Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17365v1'>http://arxiv.org/abs/2407.17365v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>MuST: Multi-Scale Transformers for Surgical Phase Recognition</h3>
<p><a href='http://arxiv.org/abs/2407.17361v1'>http://arxiv.org/abs/2407.17361v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Gradient-based inference of abstract task representations for  generalization in neural networks</h3>
<p><a href='http://arxiv.org/abs/2407.17356v1'>http://arxiv.org/abs/2407.17356v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Scalify: scale propagation for efficient low-precision LLM training</h3>
<p><a href='http://arxiv.org/abs/2407.17353v1'>http://arxiv.org/abs/2407.17353v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Boosting Large Language Models with Socratic Method for Conversational  Mathematics Teaching</h3>
<p><a href='http://arxiv.org/abs/2407.17349v1'>http://arxiv.org/abs/2407.17349v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Label Alignment and Reassignment with Generalist Large Language Model  for Enhanced Cross-Domain Named Entity Recognition</h3>
<p><a href='http://arxiv.org/abs/2407.17344v1'>http://arxiv.org/abs/2407.17344v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Preliminary study on artificial intelligence methods for cybersecurity  threat detection in computer networks based on raw data packets</h3>
<p><a href='http://arxiv.org/abs/2407.17339v1'>http://arxiv.org/abs/2407.17339v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Cascaded Light Propagation Volumes using Spherical Radial Basis  Functions</h3>
<p><a href='http://arxiv.org/abs/2407.17336v1'>http://arxiv.org/abs/2407.17336v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Global and Local Confidence Based Fraud Detection Graph Neural Network</h3>
<p><a href='http://arxiv.org/abs/2407.17333v1'>http://arxiv.org/abs/2407.17333v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Multi-label Cluster Discrimination for Visual Representation Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17331v1'>http://arxiv.org/abs/2407.17331v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>DarSwin-Unet: Distortion Aware Encoder-Decoder Architecture</h3>
<p><a href='http://arxiv.org/abs/2407.17328v1'>http://arxiv.org/abs/2407.17328v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>LangOcc: Self-Supervised Open Vocabulary Occupancy Estimation via Volume  Rendering</h3>
<p><a href='http://arxiv.org/abs/2407.17310v1'>http://arxiv.org/abs/2407.17310v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>MoveLight: Enhancing Traffic Signal Control through Movement-Centric  Deep Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17303v1'>http://arxiv.org/abs/2407.17303v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>A Novel Two-Step Fine-Tuning Pipeline for Cold-Start Active Learning in  Text Classification Tasks</h3>
<p><a href='http://arxiv.org/abs/2407.17284v1'>http://arxiv.org/abs/2407.17284v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>DenseTrack: Drone-based Crowd Tracking via Density-aware  Motion-appearance Synergy</h3>
<p><a href='http://arxiv.org/abs/2407.17272v1'>http://arxiv.org/abs/2407.17272v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>M4: Multi-Proxy Multi-Gate Mixture of Experts Network for Multiple  Instance Learning in Histopathology Image Analysis</h3>
<p><a href='http://arxiv.org/abs/2407.17267v1'>http://arxiv.org/abs/2407.17267v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Channel-Aware Low-Rank Adaptation in Time Series Forecasting</h3>
<p><a href='http://arxiv.org/abs/2407.17246v1'>http://arxiv.org/abs/2407.17246v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Improving ICD coding using Chapter based Named Entities and Attentional  Models</h3>
<p><a href='http://arxiv.org/abs/2407.17230v1'>http://arxiv.org/abs/2407.17230v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>LPGen: Enhancing High-Fidelity Landscape Painting Generation through  Diffusion Model</h3>
<p><a href='http://arxiv.org/abs/2407.17229v1'>http://arxiv.org/abs/2407.17229v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>LEAN-GitHub: Compiling GitHub LEAN repositories for a versatile LEAN  prover</h3>
<p><a href='http://arxiv.org/abs/2407.17227v1'>http://arxiv.org/abs/2407.17227v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Sublinear Regret for An Actor-Critic Algorithm in Continuous-Time  Linear-Quadratic Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17226v1'>http://arxiv.org/abs/2407.17226v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Graph Neural Networks: A suitable Alternative to MLPs in Latent 3D  Medical Image Classification?</h3>
<p><a href='http://arxiv.org/abs/2407.17219v1'>http://arxiv.org/abs/2407.17219v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Spectrum-Informed Multistage Neural Networks: Multiscale Function  Approximators of Machine Precision</h3>
<p><a href='http://arxiv.org/abs/2407.17213v1'>http://arxiv.org/abs/2407.17213v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Nonverbal Immediacy Analysis in Education: A Multimodal Computational  Model</h3>
<p><a href='http://arxiv.org/abs/2407.17209v1'>http://arxiv.org/abs/2407.17209v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Take a Step and Reconsider: Sequence Decoding for Self-Improved Neural  Combinatorial Optimization</h3>
<p><a href='http://arxiv.org/abs/2407.17206v1'>http://arxiv.org/abs/2407.17206v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>ALPI: Auto-Labeller with Proxy Injection for 3D Object Detection using  2D Labels Only</h3>
<p><a href='http://arxiv.org/abs/2407.17197v1'>http://arxiv.org/abs/2407.17197v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Unpaired Photo-realistic Image Deraining with Energy-informed Diffusion  Model</h3>
<p><a href='http://arxiv.org/abs/2407.17193v1'>http://arxiv.org/abs/2407.17193v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Solving the Electrical Impedance Tomography Problem with a DeepONet Type  Neural Network: Theory and Application</h3>
<p><a href='http://arxiv.org/abs/2407.17182v1'>http://arxiv.org/abs/2407.17182v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>NarrationDep: Narratives on Social Media For Automatic Depression  Detection</h3>
<p><a href='http://arxiv.org/abs/2407.17174v1'>http://arxiv.org/abs/2407.17174v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Domain Generalized Recaptured Screen Image Identification Using SWIN  Transformer</h3>
<p><a href='http://arxiv.org/abs/2407.17170v1'>http://arxiv.org/abs/2407.17170v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Robust Deep Hawkes Process under Label Noise of Both Event and  Occurrence</h3>
<p><a href='http://arxiv.org/abs/2407.17164v1'>http://arxiv.org/abs/2407.17164v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Explainable Artificial Intelligence Techniques for Irregular Temporal  Classification of Multidrug Resistance Acquisition in Intensive Care Unit  Patients</h3>
<p><a href='http://arxiv.org/abs/2407.17165v1'>http://arxiv.org/abs/2407.17165v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>dlordinal: a Python package for deep ordinal classification</h3>
<p><a href='http://arxiv.org/abs/2407.17163v1'>http://arxiv.org/abs/2407.17163v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Context-aware Multi-task Learning for Pedestrian Intent and Trajectory  Prediction</h3>
<p><a href='http://arxiv.org/abs/2407.17162v1'>http://arxiv.org/abs/2407.17162v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for  Automatic Speech Recognition in Multilingual Oral History Archives</h3>
<p><a href='http://arxiv.org/abs/2407.17160v1'>http://arxiv.org/abs/2407.17160v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Establishing Truly Causal Relationship Between Whole Slide Image  Predictions and Diagnostic Evidence Subregions in Deep Learning</h3>
<p><a href='http://arxiv.org/abs/2407.17157v1'>http://arxiv.org/abs/2407.17157v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Path Following and Stabilisation of a Bicycle Model using a  Reinforcement Learning Approach</h3>
<p><a href='http://arxiv.org/abs/2407.17156v1'>http://arxiv.org/abs/2407.17156v1</a></p>
<p><b>Compressor summary</b>: </p>