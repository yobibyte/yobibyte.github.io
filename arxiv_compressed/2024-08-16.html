
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-08-16</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-08-16 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Can Large Language Models Understand Symbolic Graphics Programs?</h3>
<p><a href='http://arxiv.org/abs/2408.08313v1'>http://arxiv.org/abs/2408.08313v1</a></p>
<p><b>Compressor summary</b>: The authors create a benchmark to test large language models' understanding of symbolic graphics programs, which generate visual content, and find that existing models struggle with this task but finetuning improves their performance.</p><hr><h3>ScalingFilter: Assessing Data Quality through Inverse Utilization of  Scaling Laws</h3>
<p><a href='http://arxiv.org/abs/2408.08310v1'>http://arxiv.org/abs/2408.08310v1</a></p>
<p><b>Compressor summary</b>: ScalingFilter is a new method to evaluate text quality for pre-training large language models by comparing perplexities of two models on the same data, without relying on a reference dataset, and it improves zero-shot performance while preserving semantic diversity.</p><hr><h3>Understanding the Local Geometry of Generative Model Manifolds</h3>
<p><a href='http://arxiv.org/abs/2408.08307v1'>http://arxiv.org/abs/2408.08307v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how local geometric properties of generative models' manifolds relate to generation quality and proposes using reward models trained on these properties to control generation outcomes.</p><hr><h3>Benchmarking the Capabilities of Large Language Models in Transportation  System Engineering: Accuracy, Consistency, and Reasoning Behaviors</h3>
<p><a href='http://arxiv.org/abs/2408.08302v1'>http://arxiv.org/abs/2408.08302v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates large language models' abilities to solve transportation engineering problems using the new benchmark dataset TransportBench, revealing each model's strengths and limitations.</p><hr><h3>SLCA++: Unleash the Power of Sequential Fine-tuning for Continual  Learning with Pre-training</h3>
<p><a href='http://arxiv.org/abs/2408.08295v1'>http://arxiv.org/abs/2408.08295v1</a></p>
<p><b>Compressor summary</b>: SLCA++ is a framework that improves continual learning with pre-training by slowing down the learning rate and aligning classification layers, achieving state-of-the-art results on image classification benchmarks.</p><hr><h3>The ShareLM Collection and Plugin: Contributing Human-Model Chats for  the Benefit of the Community</h3>
<p><a href='http://arxiv.org/abs/2408.08291v1'>http://arxiv.org/abs/2408.08291v1</a></p>
<p><b>Compressor summary</b>: ShareLM is a collection of human-model conversations that can be shared using a Web extension plugin to improve open source language models.</p><hr><h3>Absence of Closed-Form Descriptions for Gradient Flow in Two-Layer  Narrow Networks</h3>
<p><a href='http://arxiv.org/abs/2408.08286v1'>http://arxiv.org/abs/2408.08286v1</a></p>
<p><b>Compressor summary</b>: The paper shows that the training dynamics of two-layer neural networks are non-integrable, meaning they are complex and hard to predict, which implies the need for numerical methods in optimizing neural networks.</p><hr><h3>BAM! Just Like That: Simple and Efficient Parameter Upcycling for  Mixture of Experts</h3>
<p><a href='http://arxiv.org/abs/2408.08274v1'>http://arxiv.org/abs/2408.08274v1</a></p>
<p><b>Compressor summary</b>: BAM is a method for improving large language models by using experts' attention parameters as well as their feed-forward networks to initialize Mixture of Experts (MoE) layers, achieving better performance than existing methods.</p><hr><h3>HeightLane: BEV Heightmap guided 3D Lane Detection</h3>
<p><a href='http://arxiv.org/abs/2408.08270v1'>http://arxiv.org/abs/2408.08270v1</a></p>
<p><b>Compressor summary</b>: HeightLane is a novel method for 3D lane detection from monocular images that uses a height map to improve spatial accuracy and recognition.</p><hr><h3>mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental  Health Text Analysis</h3>
<p><a href='http://arxiv.org/abs/2408.08261v1'>http://arxiv.org/abs/2408.08261v1</a></p>
<p><b>Compressor summary</b>: mhGPT is a small but powerful AI model that helps with mental health tasks using social media and PubMed data, and it works well even on low-end devices.</p><hr><h3>GSVD-NMF: Recovering Missing Features in Non-negative Matrix  Factorization</h3>
<p><a href='http://arxiv.org/abs/2408.08260v1'>http://arxiv.org/abs/2408.08260v1</a></p>
<p><b>Compressor summary</b>: GSVD-NMF is a method to improve non-negative matrix factorization by recovering missing components using generalized singular value decomposition.</p><hr><h3>Snuffy: Efficient Whole Slide Image Classifier</h3>
<p><a href='http://arxiv.org/abs/2408.08258v1'>http://arxiv.org/abs/2408.08258v1</a></p>
<p><b>Compressor summary</b>: Snuffy is a sparse transformer-based MIL-pooling method for WSI classification in digital pathology that requires limited pre-training and achieves superior performance on two datasets.</p><hr><h3>Derivative-Free Guidance in Continuous and Discrete Diffusion Models  with Soft Value-Based Decoding</h3>
<p><a href='http://arxiv.org/abs/2408.08252v1'>http://arxiv.org/abs/2408.08252v1</a></p>
<p><b>Compressor summary</b>: Our method improves naturalness while optimizing downstream rewards in diffusion models without differentiable proxies or fine-tuning, using soft value functions and iterative sampling.</p><hr><h3>Computer Vision Model Compression Techniques for Embedded Systems: A  Survey</h3>
<p><a href='http://arxiv.org/abs/2408.08250v1'>http://arxiv.org/abs/2408.08250v1</a></p>
<p><b>Compressor summary</b>: The paper reviews model compression techniques for computer vision tasks to enable the use of large deep neural networks in embedded systems, discusses different approaches and their performance variations on various devices, and provides codes and case studies.</p><hr><h3>Conformalized Answer Set Prediction for Knowledge Graph Embedding</h3>
<p><a href='http://arxiv.org/abs/2408.08248v1'>http://arxiv.org/abs/2408.08248v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using conformal prediction to generate answer sets with probabilistic guarantees for link prediction tasks in knowledge graph embeddings, addressing the issue of distinguishing plausible from implausible answers.</p><hr><h3>Explaining an Agent's Future Beliefs through Temporally Decomposing  Future Reward Estimators</h3>
<p><a href='http://arxiv.org/abs/2408.08230v1'>http://arxiv.org/abs/2408.08230v1</a></p>
<p><b>Compressor summary</b>: Temporal Reward Decomposition (TRD) is a method to predict and explain the future rewards of reinforcement learning agents, such as their expected reward timing, value, confidence, and input feature importance.</p><hr><h3>Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction</h3>
<p><a href='http://arxiv.org/abs/2408.08226v1'>http://arxiv.org/abs/2408.08226v1</a></p>
<p><b>Compressor summary</b>: The paper studies predictive multiplicity in link prediction for knowledge graphs and proposes using voting methods to reduce conflicting predictions.</p><hr><h3>Enhancing Sharpness-Aware Minimization by Learning Perturbation Radius</h3>
<p><a href='http://arxiv.org/abs/2408.08222v1'>http://arxiv.org/abs/2408.08222v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a bilevel optimization framework called LETS to learn the perturbation radius for sharpness-aware minimization algorithms, which improves model generalization by searching for flat minima in the loss landscape.</p><hr><h3>RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train  and Deploy Edge Classifiers for Computational Social Science</h3>
<p><a href='http://arxiv.org/abs/2408.08217v1'>http://arxiv.org/abs/2408.08217v1</a></p>
<p><b>Compressor summary</b>: This study proposes a systems design approach to improve classification performance using large language models as imperfect data annotators in various industries.</p><hr><h3>The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating  Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation</h3>
<p><a href='http://arxiv.org/abs/2408.08216v1'>http://arxiv.org/abs/2408.08216v1</a></p>
<p><b>Compressor summary</b>: The study proposes using Kolmogorov-Arnold Network (KAN) instead of Multi-layer Perceptron (MLP) to improve image-to-image translation in generative AI.</p><hr><h3>Moving Healthcare AI-Support Systems for Visually Detectable Diseases  onto Constrained Devices</h3>
<p><a href='http://arxiv.org/abs/2408.08215v1'>http://arxiv.org/abs/2408.08215v1</a></p>
<p><b>Compressor summary</b>: TinyML is explored as a solution for healthcare support in low connectivity areas by using low-spec devices to classify skin diseases from images without internet access.</p><hr><h3>Covert Bias: The Severity of Social Views' Unalignment Towards Implicit  and Explicit Opinion</h3>
<p><a href='http://arxiv.org/abs/2408.08212v1'>http://arxiv.org/abs/2408.08212v1</a></p>
<p><b>Compressor summary</b>: The study investigates how implicit language affects bias amplification in large language models and finds that biased models generate more cautious responses when aligned with conflicting opinions but are less reliable on socially nuanced topics.</p><hr><h3>Does Reasoning Emerge? Examining the Probabilities of Causation in Large  Language Models</h3>
<p><a href='http://arxiv.org/abs/2408.08210v1'>http://arxiv.org/abs/2408.08210v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework to assess how well large language models can reason using probability of necessity and sufficiency concepts, and demonstrates it with math examples.</p><hr><h3>WaterSplatting: Fast Underwater 3D Scene Reconstruction Using Gaussian  Splatting</h3>
<p><a href='http://arxiv.org/abs/2408.08206v1'>http://arxiv.org/abs/2408.08206v1</a></p>
<p><b>Compressor summary</b>: The proposed method fuses volumetric rendering with 3D Gaussian Splatting to effectively reconstruct underwater scenes, outperforming state-of-the-art NeRF-based methods in quality and efficiency.</p><hr><h3>Heavy Labels Out! Dataset Distillation with Label Space Lightening</h3>
<p><a href='http://arxiv.org/abs/2408.08201v1'>http://arxiv.org/abs/2408.08201v1</a></p>
<p><b>Compressor summary</b>: HeLlO is a framework that generates synthetic labels from images, reducing the storage and data requirements for dataset distillation while maintaining performance.</p><hr><h3>Stochastic Semi-Gradient Descent for Learning Mean Field Games with  Population-Aware Function Approximation</h3>
<p><a href='http://arxiv.org/abs/2408.08192v1'>http://arxiv.org/abs/2408.08192v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel online learning method called SemiSGD for large-population multi-agent systems, which combines value function and population distribution into one parameter, and shows its theoretical advantages over traditional fixed-point iteration methods.</p><hr><h3>Beyond Full Label: Single-Point Prompt for Infrared Small Target Label  Generation</h3>
<p><a href='http://arxiv.org/abs/2408.08191v1'>http://arxiv.org/abs/2408.08191v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a learning-based method to generate infrared small target labels using a single-point annotation paradigm that improves detection and reduces false alarms.</p><hr><h3>FancyVideo: Towards Dynamic and Consistent Video Generation via  Cross-frame Textual Guidance</h3>
<p><a href='http://arxiv.org/abs/2408.08189v1'>http://arxiv.org/abs/2408.08189v1</a></p>
<p><b>Compressor summary</b>: FancyVideo is a text-to-video generator that improves temporal coherence in video synthesis using a Cross-frame Textual Guidance Module with three components.</p><hr><h3>Not Every Image is Worth a Thousand Words: Quantifying Originality in  Stable Diffusion</h3>
<p><a href='http://arxiv.org/abs/2408.08184v1'>http://arxiv.org/abs/2408.08184v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to measure text-to-image model's originality based on the number of tokens needed to reconstruct an image, inspired by legal definitions of originality.</p><hr><h3>Machine learning empowered Modulation detection for OFDM-based signals</h3>
<p><a href='http://arxiv.org/abs/2408.08179v1'>http://arxiv.org/abs/2408.08179v1</a></p>
<p><b>Compressor summary</b>: The text proposes a blind modulation detection method for OFDM-based technologies using a ResNet network that can handle realistic environmental imperfections without prior knowledge of the transmitted signal.</p><hr><h3>Towards flexible perception with visual memory</h3>
<p><a href='http://arxiv.org/abs/2408.08172v1'>http://arxiv.org/abs/2408.08172v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The authors propose a new way of doing image classification using a database instead of a neural network
- Their approach has three main advantages: flexibility, unlearning, and interpretability
- They argue that this method could improve how knowledge is represented in deep vision models

Summary:
The authors introduce a flexible and interpretable image classification method that uses a database to store and search for embeddings, allowing them to add, remove, and intervene on data.</p><hr><h3>DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for  Reinforcement Learning and Monte-Carlo Tree Search</h3>
<p><a href='http://arxiv.org/abs/2408.08152v1'>http://arxiv.org/abs/2408.08152v1</a></p>
<p><b>Compressor summary</b>: DeepSeek-Prover-V1.5 is an open-source language model that improves theorem proving in Lean 4 by optimizing training, inference, and exploration strategies, achieving state-of-the-art results on miniF2F and ProofNet benchmarks.</p><hr><h3>Winning Snake: Design Choices in Multi-Shot ASP</h3>
<p><a href='http://arxiv.org/abs/2408.08150v1'>http://arxiv.org/abs/2408.08150v1</a></p>
<p><b>Compressor summary</b>: Answer set programming techniques are applied to solve the arcade game snake, with five implementations compared and visualized using clingraph.</p><hr><h3>Unsupervised Variational Translator for Bridging Image Restoration and  High-Level Vision Tasks</h3>
<p><a href='http://arxiv.org/abs/2408.08149v1'>http://arxiv.org/abs/2408.08149v1</a></p>
<p><b>Compressor summary</b>: VaT is an unsupervised learning method that bridges restoration and high-level vision networks without retraining them, enhancing image quality and performance on degraded environments.</p><hr><h3>KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft  Heads with Adversarial Learning</h3>
<p><a href='http://arxiv.org/abs/2408.08146v1'>http://arxiv.org/abs/2408.08146v1</a></p>
<p><b>Compressor summary</b>: KOALA improves speculative decoding by optimizing the draft head with multi-layer architecture and adversarial learning, achieving significant latency reduction.</p><hr><h3>Model-based Workflow for the Automated Generation of PDDL Descriptions</h3>
<p><a href='http://arxiv.org/abs/2408.08145v1'>http://arxiv.org/abs/2408.08145v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an automatic way to generate PDDL descriptions for planning from integrated system and product models using MBSE.</p><hr><h3>MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for  Multi-turn NLU</h3>
<p><a href='http://arxiv.org/abs/2408.08144v1'>http://arxiv.org/abs/2408.08144v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MIDAS, a novel approach using multi-level knowledge distillation to improve multi-turn Natural Language Understanding (NLU) in conversations.</p><hr><h3>Impact of Comprehensive Data Preprocessing on Predictive Modelling of  COVID-19 Mortality</h3>
<p><a href='http://arxiv.org/abs/2408.08142v1'>http://arxiv.org/abs/2408.08142v1</a></p>
<p><b>Compressor summary</b>: The study evaluates a custom data preprocessing pipeline that improves the accuracy of machine learning models predicting COVID-19 mortality using OWID data.</p><hr><h3>Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature  Attribution Explainability</h3>
<p><a href='http://arxiv.org/abs/2408.08137v1'>http://arxiv.org/abs/2408.08137v1</a></p>
<p><b>Compressor summary</b>: The text discusses the limitations of AOPC for evaluating feature attribution faithfulness in deep neural networks, proposing Normalized AOPC (NAOPC) as a more reliable and interpretable alternative.</p><hr><h3>CorrAdaptor: Adaptive Local Context Learning for Correspondence Pruning</h3>
<p><a href='http://arxiv.org/abs/2408.08134v1'>http://arxiv.org/abs/2408.08134v1</a></p>
<p><b>Compressor summary</b>: Key points:
- CorrAdaptor is a new architecture for pixel-level correspondences in computer vision and robotics
- It uses two branches to learn local contexts: explicit (KNN) and implicit (learnable matrix)
- It also has a motion injection module to improve robustness and adaptability
- It outperforms previous methods on various tasks

Summary:
CorrAdaptor is a novel architecture that learns pixel-level correspondences using two branches of local context learning and a motion injection module, achieving state-of-the-art results.</p><hr><h3>EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic</h3>
<p><a href='http://arxiv.org/abs/2408.08133v1'>http://arxiv.org/abs/2408.08133v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Neural probabilistic logic systems combine neural networks and probabilistic logic
- Optimize a sampling based objective instead of exact likelihood
- Error vanishes with more samples and sample diversity
- EXAL method explains, agrees, and learns from explanations
- Scales up to larger problems and outperforms previous methods

Summary:
The paper proposes a novel neural probabilistic logic system that uses sampling based optimization and a new method called EXAL that can explain, agree, and learn from explanations, achieving scalability and performance on complex problems.</p><hr><h3>Category-Prompt Refined Feature Learning for Long-Tailed Multi-Label  Image Classification</h3>
<p><a href='http://arxiv.org/abs/2408.08125v1'>http://arxiv.org/abs/2408.08125v1</a></p>
<p><b>Compressor summary</b>: CPRFL is a novel approach for long-tailed multi-label image classification that leverages semantic correlations between categories and refines prompts with contextual visual information to improve recognition performance.</p><hr><h3>The Unreasonable Effectiveness of Solving Inverse Problems with Neural  Networks</h3>
<p><a href='http://arxiv.org/abs/2408.08119v1'>http://arxiv.org/abs/2408.08119v1</a></p>
<p><b>Compressor summary</b>: Neural networks trained on inverse problems can achieve higher accuracy than classical optimizers even on their training data, challenging the assumption that faster inference sacrifices solution quality.</p><hr><h3>Hearing Your Blood Sugar: Non-Invasive Glucose Measurement Through  Simple Vocal Signals, Transforming any Speech into a Sensor with Machine  Learning</h3>
<p><a href='http://arxiv.org/abs/2408.08109v1'>http://arxiv.org/abs/2408.08109v1</a></p>
<p><b>Compressor summary</b>: The study proposes using voice analysis as a non-invasive way to monitor blood glucose levels in people with diabetes, potentially improving their quality of life.</p><hr><h3>Unsupervised Part Discovery via Dual Representation Alignment</h3>
<p><a href='http://arxiv.org/abs/2408.08108v1'>http://arxiv.org/abs/2408.08108v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method called PartFormer to learn unsupervised part-specific attention from paired images using geometric and semantic constraints, improving downstream tasks and part discovery performance.</p><hr><h3>Adaptation of uncertainty-penalized Bayesian information criterion for  parametric partial differential equation discovery</h3>
<p><a href='http://arxiv.org/abs/2408.08106v1'>http://arxiv.org/abs/2408.08106v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an extension of the uncertainty-penalized Bayesian information criterion (UBIC) for efficiently discovering parametric partial differential equations (PDEs) in noisy situations, using data transformation based on power spectral densities and confidence intervals.</p><hr><h3>Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language  Models to Infer Causal Links Between Siamese Images</h3>
<p><a href='http://arxiv.org/abs/2408.08105v1'>http://arxiv.org/abs/2408.08105v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MuCR, a new benchmark to test VLLMs' ability to infer cause-and-effect relationships from visual cues using image synthesis and tailored metrics.</p><hr><h3>When Video Coding Meets Multimodal Large Language Models: A Unified  Paradigm for Video Coding</h3>
<p><a href='http://arxiv.org/abs/2408.08093v1'>http://arxiv.org/abs/2408.08093v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new cross-modality approach to video compression using multimodal language models that separates videos into spatial content and motion components, optimizing quality for specific decoding requirements.</p><hr><h3>OC3D: Weakly Supervised Outdoor 3D Object Detection with Only Coarse  Click Annotation</h3>
<p><a href='http://arxiv.org/abs/2408.08092v1'>http://arxiv.org/abs/2408.08092v1</a></p>
<p><b>Compressor summary</b>: OC3D is a weakly supervised method for LiDAR-based 3D object detection that uses coarse clicks and achieves state-of-the-art performance with minimal annotation cost.</p><hr><h3>HAIR: Hypernetworks-based All-in-One Image Restoration</h3>
<p><a href='http://arxiv.org/abs/2408.08091v1'>http://arxiv.org/abs/2408.08091v1</a></p>
<p><b>Compressor summary</b>: HAIR is a plug-in-and-play method that generates parameters for image restoration models based on the contents of input images, improving their performance on various tasks.</p><hr><h3>AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents</h3>
<p><a href='http://arxiv.org/abs/2408.08089v1'>http://arxiv.org/abs/2408.08089v1</a></p>
<p><b>Compressor summary</b>: The paper introduces AgentCourt, a simulation system that uses large language models to train lawyer agents in legal skills through adversarial evolutionary processes and courtroom simulations.</p><hr><h3>ColorMamba: Towards High-quality NIR-to-RGB Spectral Translation with  Mamba</h3>
<p><a href='http://arxiv.org/abs/2408.08087v1'>http://arxiv.org/abs/2408.08087v1</a></p>
<p><b>Compressor summary</b>: ColorMamba is a novel model that uses Mamba, improved padding tokens, local convolutional enhancement, agent attention, and HSV color guidance to achieve better spectral translation in the visible spectrum.</p><hr><h3>Single-image coherent reconstruction of objects and humans</h3>
<p><a href='http://arxiv.org/abs/2408.08086v1'>http://arxiv.org/abs/2408.08086v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to reconstruct 3D scenes with interacting objects and people from a single image, reducing mesh collisions and improving performance.</p><hr><h3>An Efficient Replay for Class-Incremental Learning with Pre-trained  Models</h3>
<p><a href='http://arxiv.org/abs/2408.08084v1'>http://arxiv.org/abs/2408.08084v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to overcome catastrophic forgetting in class-incremental learning using pre-trained models, replay, and simple gradient constraints.</p><hr><h3>Treat Stillness with Movement: Remote Sensing Change Detection via  Coarse-grained Temporal Foregrounds Mining</h3>
<p><a href='http://arxiv.org/abs/2408.08078v1'>http://arxiv.org/abs/2408.08078v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel framework, CTMA, that incorporates motion cues and spatial features for remote sensing change detection using bi-temporal images.</p><hr><h3>Independent Policy Mirror Descent for Markov Potential Games: Scaling to  Large Number of Players</h3>
<p><a href='http://arxiv.org/abs/2408.08075v1'>http://arxiv.org/abs/2408.08075v1</a></p>
<p><b>Compressor summary</b>: The paper studies how to improve the efficiency of learning Nash equilibria in Markov Potential Games using policy gradient methods.</p><hr><h3>Extracting Sentence Embeddings from Pretrained Transformer Models</h3>
<p><a href='http://arxiv.org/abs/2408.08073v1'>http://arxiv.org/abs/2408.08073v1</a></p>
<p><b>Compressor summary</b>: The paper explores various methods to improve sentence embeddings for natural language processing tasks, achieving significant improvements for static token-based models and comparable results for BERT-derived representations.</p><hr><h3>I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative  Self-Enhancement Paradigm</h3>
<p><a href='http://arxiv.org/abs/2408.08072v1'>http://arxiv.org/abs/2408.08072v1</a></p>
<p><b>Compressor summary</b>: I-SHEEP is a self-alignment method for large language models that continuously improves their performance without human intervention.</p><hr><h3>Universality of Real Minimal Complexity Reservoir</h3>
<p><a href='http://arxiv.org/abs/2408.08071v1'>http://arxiv.org/abs/2408.08071v1</a></p>
<p><b>Compressor summary</b>: Reservoir Computing models can approximate dynamic filters with fading memory, and Simple Cycle Reservoirs, a specialized class with constrained architecture, are universally applicable and suitable for low-complexity hardware implementations.</p><hr><h3>MambaMIM: Pre-training Mamba with State Space Token-interpolation</h3>
<p><a href='http://arxiv.org/abs/2408.08070v1'>http://arxiv.org/abs/2408.08070v1</a></p>
<p><b>Compressor summary</b>: MambaMIM is a generative self-supervised learning method for selective state space models that improves long-range dependency representation and can be used for pre-training medical image tasks.</p><hr><h3>RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented  Generation</h3>
<p><a href='http://arxiv.org/abs/2408.08067v1'>http://arxiv.org/abs/2408.08067v1</a></p>
<p><b>Compressor summary</b>: RAGChecker is a framework to evaluate Retrieval-Augmented Generation (RAG) systems by measuring their retrieval and generation modules, which reveals patterns and trade-offs in RAG design choices and can help improve them.</p><hr><h3>Maximally Permissive Reward Machines</h3>
<p><a href='http://arxiv.org/abs/2408.08059v1'>http://arxiv.org/abs/2408.08059v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to generate reward machines from multiple plans, which leads to higher rewards for learning agents compared to methods based on a single plan.</p><hr><h3>Navigating Data Scarcity using Foundation Models: A Benchmark of  Few-Shot and Zero-Shot Learning Approaches in Medical Imaging</h3>
<p><a href='http://arxiv.org/abs/2408.08058v1'>http://arxiv.org/abs/2408.08058v1</a></p>
<p><b>Compressor summary</b>: The study compares different foundation models' performance in few-shot and zero-shot learning for medical image analysis tasks, finding that BiomedCLIP works best with very small training sets while CLIP models perform better with slightly more samples.</p><hr><h3>DATTA: Towards Diversity Adaptive Test-Time Adaptation in Dynamic Wild  World</h3>
<p><a href='http://arxiv.org/abs/2408.08056v1'>http://arxiv.org/abs/2408.08056v1</a></p>
<p><b>Compressor summary</b>: DATTA is a new method for test-time adaptation that adapts batch normalization and fine-tuning strategies based on the diversity score of input data, improving accuracy and Quality of Experience.</p><hr><h3>COTODE: COntinuous Trajectory neural Ordinary Differential Equations for  modelling event sequences</h3>
<p><a href='http://arxiv.org/abs/2408.08055v1'>http://arxiv.org/abs/2408.08055v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new model for event sequences that considers actor dynamics governed by a Gaussian Process and incorporates uncertainty estimation and negative feedback for improved performance.</p><hr><h3>Text2BIM: Generating Building Models Using a Large Language Model-based  Multi-Agent Framework</h3>
<p><a href='http://arxiv.org/abs/2408.08054v1'>http://arxiv.org/abs/2408.08054v1</a></p>
<p><b>Compressor summary</b>: Text2BIM is a framework that uses LLMs and multi-agent reasoning to generate high-quality 3D building models from natural language instructions, enhancing the design process in the AEC industry.</p><hr><h3>CamoTeacher: Dual-Rotation Consistency Learning for Semi-Supervised  Camouflaged Object Detection</h3>
<p><a href='http://arxiv.org/abs/2408.08050v1'>http://arxiv.org/abs/2408.08050v1</a></p>
<p><b>Compressor summary</b>: CamoTeacher is a novel semi-supervised object detection method that uses dual-rotation consistency learning to reduce noise and achieve state-of-the-art results.</p><hr><h3>An Efficient Continuous Control Perspective for  Reinforcement-Learning-based Sequential Recommendation</h3>
<p><a href='http://arxiv.org/abs/2408.08047v1'>http://arxiv.org/abs/2408.08047v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a continuous control framework for sequential recommendation using reinforcement learning that improves efficiency and long-term user engagement.</p><hr><h3>The Clever Hans Effect in Unsupervised Learning</h3>
<p><a href='http://arxiv.org/abs/2408.08041v1'>http://arxiv.org/abs/2408.08041v1</a></p>
<p><b>Compressor summary</b>: Unsupervised learning models may produce accurate predictions but with hidden biases that can lead to Clever Hans effects; using Explainable AI techniques, researchers found widespread CH effects and suggest ways to improve model robustness.</p><hr><h3>An Advanced Deep Learning Based Three-Stream Hybrid Model for Dynamic  Hand Gesture Recognition</h3>
<p><a href='http://arxiv.org/abs/2408.08035v1'>http://arxiv.org/abs/2408.08035v1</a></p>
<p><b>Compressor summary</b>: The text proposes a novel three-stream hybrid model that combines pixel and skeleton-based features to recognize hand gestures, addressing challenges like dataset limitations and varying lighting conditions.</p>