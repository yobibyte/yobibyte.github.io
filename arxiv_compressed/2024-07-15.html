
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2024-07-15</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-07-15 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>StyleSplat: 3D Object Style Transfer with Gaussian Splatting</h3>
<p><a href='http://arxiv.org/abs/2407.09473v1'>http://arxiv.org/abs/2407.09473v1</a></p>
<p><b>Compressor summary</b>: StyleSplat is a fast method for applying diverse artistic styles to 3D objects in scenes using 3D Gaussian splatting and feature matching, achieving localized stylization and photorealistic results.</p><hr><h3>Beyond Euclid: An Illustrated Guide to Modern Machine Learning with  Geometric, Topological, and Algebraic Structures</h3>
<p><a href='http://arxiv.org/abs/2407.09468v1'>http://arxiv.org/abs/2407.09468v1</a></p>
<p><b>Compressor summary</b>: The text discusses the need for a broader mathematical perspective in modern machine learning to handle non-Euclidean data with intricate geometric, topological, and algebraic structures.</p><hr><h3>FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3</h3>
<p><a href='http://arxiv.org/abs/2407.09467v1'>http://arxiv.org/abs/2407.09467v1</a></p>
<p><b>Compressor summary</b>: FairyLandAI is an AI-driven storytelling model that creates personalized fairytales for children, integrating text and image generation to enhance the storytelling experience and impart moral values.</p><hr><h3>Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators</h3>
<p><a href='http://arxiv.org/abs/2407.09453v1'>http://arxiv.org/abs/2407.09453v1</a></p>
<p><b>Compressor summary</b>: The text describes a method called weight block sparsity that reduces the size and computational cost of deep neural networks by zeroing some parameters in pre-trained models, leading to faster inference speeds and memory efficiency.</p><hr><h3>Human-like Episodic Memory for Infinite Context LLMs</h3>
<p><a href='http://arxiv.org/abs/2407.09450v1'>http://arxiv.org/abs/2407.09450v1</a></p>
<p><b>Compressor summary</b>: EM-LLM integrates human episodic memory into large language models, enabling them to handle infinite context lengths and outperforming state-of-the-art models in various tasks.</p><hr><h3>ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to  Identify Likely Toxic Prompts</h3>
<p><a href='http://arxiv.org/abs/2407.09447v1'>http://arxiv.org/abs/2407.09447v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a reinforcement learning approach to find prompts that can trigger toxic outputs from language models while maintaining intelligibility and realism.</p><hr><h3>MUSCLE: A Model Update Strategy for Compatible LLM Evolution</h3>
<p><a href='http://arxiv.org/abs/2407.09435v1'>http://arxiv.org/abs/2407.09435v1</a></p>
<p><b>Compressor summary</b>: The paper proposes compatibility metrics and a training strategy to minimize inconsistencies when updating large language models, aiming to improve user experience and satisfaction.</p><hr><h3>A Perspective on Foundation Models for the Electric Power Grid</h3>
<p><a href='http://arxiv.org/abs/2407.09434v1'>http://arxiv.org/abs/2407.09434v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using foundation models, advanced deep learning techniques, to enhance the management of complex and uncertain aspects of electric power grids in the context of climate change and energy transition.</p><hr><h3>Rethinking temporal self-similarity for repetitive action counting</h3>
<p><a href='http://arxiv.org/abs/2407.09431v1'>http://arxiv.org/abs/2407.09431v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new framework to count repetitive actions in videos by learning embeddings and predicting action start probabilities, instead of using a temporal self-similarity matrix as an intermediate representation.</p><hr><h3>Open (Clinical) LLMs are Sensitive to Instruction Phrasings</h3>
<p><a href='http://arxiv.org/abs/2407.09429v1'>http://arxiv.org/abs/2407.09429v1</a></p>
<p><b>Compressor summary</b>: The study examines how well instruction-tuned LLMs perform on clinical NLP tasks when given different natural language instructions, finding that domain-specific models can be more brittle than general ones and that phrasing differences affect fairness.</p><hr><h3>Mitigating Entity-Level Hallucination in Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.09417v1'>http://arxiv.org/abs/2407.09417v1</a></p>
<p><b>Compressor summary</b>: The paper proposes DRAD, a method to detect and correct hallucinations in LLMs by adapting the retrieval process based on real-time detection and using external knowledge.</p><hr><h3>A Benchmark Environment for Offline Reinforcement Learning in Racing  Games</h3>
<p><a href='http://arxiv.org/abs/2407.09415v1'>http://arxiv.org/abs/2407.09415v1</a></p>
<p><b>Compressor summary</b>: OfflineMania is a new environment for offline reinforcement learning research that simulates a single-agent racing game and provides datasets to test different algorithms.</p><hr><h3>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</h3>
<p><a href='http://arxiv.org/abs/2407.09413v1'>http://arxiv.org/abs/2407.09413v1</a></p>
<p><b>Compressor summary</b>: SPIQA is a large-scale QA dataset that tests multimodal models' ability to understand figures and tables in computer science research articles using multiple images and a Chain-of-Thought evaluation strategy.</p><hr><h3>Open-Canopy: A Country-Scale Benchmark for Canopy Height Estimation at  Very High Resolution</h3>
<p><a href='http://arxiv.org/abs/2407.09392v1'>http://arxiv.org/abs/2407.09392v1</a></p>
<p><b>Compressor summary</b>: Open-Canopy is an open-access benchmark for estimating very high resolution canopy height and detecting change using satellite and aerial data in France.</p><hr><h3>GAVEL: Generating Games Via Evolution and Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.09388v1'>http://arxiv.org/abs/2407.09388v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Automated game generation is complex and has challenges
- The work uses Ludii, a language that encodes rules of many board games
- The approach uses large language models and evolutionary computation to mutate and recombine games
- The generated games are new, interesting, and cover unseen regions of the rules space
- Some games can be played online through Ludii portal

Summary:
The work presents a novel approach to generate new and interesting board games using Ludii, a language that encodes many existing games, and combining large language models and evolutionary computation to create diverse and original game mechanics.</p><hr><h3>Radiance Fields from Photons</h3>
<p><a href='http://arxiv.org/abs/2407.09386v1'>http://arxiv.org/abs/2407.09386v1</a></p>
<p><b>Compressor summary</b>: Quanta radiance fields use single-photon cameras to train neural networks at the photon level, enabling high-quality view synthesis under challenging conditions like motion, low light, and dynamic range.</p><hr><h3>The Effectiveness of Curvature-Based Rewiring and the Role of  Hyperparameters in GNNs Revisited</h3>
<p><a href='http://arxiv.org/abs/2407.09381v1'>http://arxiv.org/abs/2407.09381v1</a></p>
<p><b>Compressor summary</b>: Curvature-based rewiring may not improve message passing efficiency in real-world graphs because it does not always target oversquashed edges, and performance gains are due to hyperparameter sweeps.</p><hr><h3>FANet: Feature Amplification Network for Semantic Segmentation in  Cluttered Background</h3>
<p><a href='http://arxiv.org/abs/2407.09379v1'>http://arxiv.org/abs/2407.09379v1</a></p>
<p><b>Compressor summary</b>: The paper proposes FANet, a network that uses AFE blocks to incorporate semantic information for better semantic segmentation in complex scenes with cluttered backgrounds and translucent objects.</p><hr><h3>Graph Neural Network Causal Explanation via Neural Causal Models</h3>
<p><a href='http://arxiv.org/abs/2407.09378v1'>http://arxiv.org/abs/2407.09378v1</a></p>
<p><b>Compressor summary</b>: {
ame} is a causal graph neural network explainer that identifies important subgraphs by training neural causal models on the input graph.</p><hr><h3>HiPPO-Prophecy: State-Space Models can Provably Learn Dynamical Systems  in Context</h3>
<p><a href='http://arxiv.org/abs/2407.09375v1'>http://arxiv.org/abs/2407.09375v1</a></p>
<p><b>Compressor summary</b>: This paper investigates how State Space Models can learn from past observations and make predictions without retraining, by using a new weight construction method that approximates input signal derivatives.</p><hr><h3>Towards Personalised Patient Risk Prediction Using Temporal Hospital  Data Trajectories</h3>
<p><a href='http://arxiv.org/abs/2407.09373v1'>http://arxiv.org/abs/2407.09373v1</a></p>
<p><b>Compressor summary</b>: The text proposes a method to group ICU patients based on their observation trajectories and develop personalized risk predictions, improving clinical decision making.</p><hr><h3>ConRebSeg: A Segmentation Dataset for Reinforced Concrete Construction</h3>
<p><a href='http://arxiv.org/abs/2407.09372v1'>http://arxiv.org/abs/2407.09372v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new dataset of images for autonomous robots in construction and analyzes their performance, suggesting more data and consistent labels are needed.</p><hr><h3>Learning High-Frequency Functions Made Easy with Sinusoidal Positional  Encoding</h3>
<p><a href='http://arxiv.org/abs/2407.09370v1'>http://arxiv.org/abs/2407.09370v1</a></p>
<p><b>Compressor summary</b>: Sinusoidal positional encoding (SPE) is a new method that adapts to different tasks without hyperparameter tuning, improving performance in various tasks like 3D view synthesis, Text-to-Speech generation, and 1D regression.</p><hr><h3>Reshaping the Online Data Buffering and Organizing Mechanism for  Continual Test-Time Adaptation</h3>
<p><a href='http://arxiv.org/abs/2407.09367v1'>http://arxiv.org/abs/2407.09367v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new approach to adapt pre-trained models to unsupervised domain shifts by using uncertainty-aware data buffering, graph-based class relation preservation, and pseudo-target replay.</p><hr><h3>Is Contrasting All You Need? Contrastive Learning for the Detection and  Attribution of AI-generated Text</h3>
<p><a href='http://arxiv.org/abs/2407.09364v1'>http://arxiv.org/abs/2407.09364v1</a></p>
<p><b>Compressor summary</b>: WhosAI is a new framework that can detect and reveal whether text was written by humans or AI, using contrastive learning to learn semantic similarity representations from multiple generators.</p><hr><h3>A Unified Anomaly Synthesis Strategy with Gradient Ascent for Industrial  Anomaly Detection and Localization</h3>
<p><a href='http://arxiv.org/abs/2407.09359v1'>http://arxiv.org/abs/2407.09359v1</a></p>
<p><b>Compressor summary</b>: GLASS is a novel anomaly synthesis strategy that enhances unsupervised anomaly detection by combining global and local synthesis methods, achieving state-of-the-art results in weak defect detection and industrial applications.</p><hr><h3>Any-Property-Conditional Molecule Generation with Self-Criticism using  Spanning Trees</h3>
<p><a href='http://arxiv.org/abs/2407.09357v1'>http://arxiv.org/abs/2407.09357v1</a></p>
<p><b>Compressor summary</b>: STGG+ is a Transformer-based method for generating molecules with desired properties by incorporating random masking, property prediction loss, and other improvements, achieving state-of-the-art results on various tasks.</p><hr><h3>Imaging Interiors: An Implicit Solution to Electromagnetic Inverse  Scattering Problems</h3>
<p><a href='http://arxiv.org/abs/2407.09352v1'>http://arxiv.org/abs/2407.09352v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an implicit method for solving Electromagnetic Inverse Scattering Problems, which improves the accuracy of non-invasively determining the internal relative permittivity of a scatterer using electromagnetic fields.</p><hr><h3>Pre-training Point Cloud Compact Model with Partial-aware Reconstruction</h3>
<p><a href='http://arxiv.org/abs/2407.09344v1'>http://arxiv.org/abs/2407.09344v1</a></p>
<p><b>Compressor summary</b>: Point-CPR is a compact point cloud model that uses partial-aware prediction and a local aggregation encoder to improve 3D representation and reduce model size compared to existing Masked Point Modeling methods.</p><hr><h3>Guidelines for Augmentation Selection in Contrastive Learning for Time  Series Classification</h3>
<p><a href='http://arxiv.org/abs/2407.09336v1'>http://arxiv.org/abs/2407.09336v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Contrastive learning is a key technique for unsupervised time series representation learning
- Augmentation choice affects performance significantly, but is often empirical or grid searching
- The paper proposes a framework to select augmentations based on trend and seasonality of datasets
- The framework is evaluated on synthetic and real-world datasets, showing better results than baselines

Summary:
The paper presents a principled method to recommend augmentations for contrastive learning in time series analysis, based on dataset characteristics such as trend and seasonality, and shows its effectiveness on diverse datasets.</p><hr><h3>Sina at FigNews 2024: Multilingual Datasets Annotated with Bias and  Propaganda</h3>
<p><a href='http://arxiv.org/abs/2407.09327v1'>http://arxiv.org/abs/2407.09327v1</a></p>
<p><b>Compressor summary</b>: The article presents a multilingual bias and propaganda annotated corpus from Facebook posts about the Israeli War on Gaza, created for a shared task and used to evaluate performance of detection techniques.</p><hr><h3>Scalability of Bayesian Network Structure Elicitation with Large  Language Models: a Novel Methodology and Comparative Analysis</h3>
<p><a href='http://arxiv.org/abs/2407.09311v1'>http://arxiv.org/abs/2407.09311v1</a></p>
<p><b>Compressor summary</b>: The authors present a new method for finding Bayesian Network structures using multiple LLMs and majority voting, compare it to an alternative method, and discuss its scalability and applicability.</p><hr><h3>ProDepth: Boosting Self-Supervised Multi-Frame Monocular Depth with  Probabilistic Fusion</h3>
<p><a href='http://arxiv.org/abs/2407.09303v1'>http://arxiv.org/abs/2407.09303v1</a></p>
<p><b>Compressor summary</b>: ProDepth is a novel framework that uses a probabilistic approach to address inconsistencies caused by dynamic objects in multi-frame monocular depth estimation, improving performance on various datasets.</p><hr><h3>PID: Physics-Informed Diffusion Model for Infrared Image Generation</h3>
<p><a href='http://arxiv.org/abs/2407.09299v1'>http://arxiv.org/abs/2407.09299v1</a></p>
<p><b>Compressor summary</b>: The Physics-Informed Diffusion model translates RGB images to infrared images while adhering to physical laws, achieving better results than existing methods.</p><hr><h3>Transformer Layers as Painters</h3>
<p><a href='http://arxiv.org/abs/2407.09298v1'>http://arxiv.org/abs/2407.09298v1</a></p>
<p><b>Compressor summary</b>: The study investigates how transformer layers work and how to use them more efficiently for different problems.</p><hr><h3>Learning Distances from Data with Normalizing Flows and Score Matching</h3>
<p><a href='http://arxiv.org/abs/2407.09297v1'>http://arxiv.org/abs/2407.09297v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to estimate density-based distances in high-dimensional data using normalizing flows and a dimension-adapted Fermat distance.</p><hr><h3>SS-SfP:Neural Inverse Rendering for Self Supervised Shape from (Mixed)  Polarization</h3>
<p><a href='http://arxiv.org/abs/2407.09294v1'>http://arxiv.org/abs/2407.09294v1</a></p>
<p><b>Compressor summary</b>: The text presents a novel method to estimate 3D shapes and refractive index from single-view polarization images using a modified polarization reflection model, reflectance cues, and an inverse rendering-based deep learning framework.</p><hr><h3>WSESeg: Introducing a Dataset for the Segmentation of Winter Sports  Equipment with a Baseline for Interactive Segmentation</h3>
<p><a href='http://arxiv.org/abs/2407.09288v1'>http://arxiv.org/abs/2407.09288v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new dataset for winter sports equipment segmentation and tests interactive segmentation models with online adaptation methods to improve efficiency and accuracy.</p><hr><h3>Instruction Following with Goal-Conditioned Reinforcement Learning in  Virtual Environments</h3>
<p><a href='http://arxiv.org/abs/2407.09287v1'>http://arxiv.org/abs/2407.09287v1</a></p>
<p><b>Compressor summary</b>: The study proposes a hierarchical framework that combines language understanding and reinforcement learning to enable AI agents to execute complex language instructions in virtual environments.</p><hr><h3>MetaFood CVPR 2024 Challenge on Physically Informed 3D Food  Reconstruction: Methods and Results</h3>
<p><a href='http://arxiv.org/abs/2407.09285v1'>http://arxiv.org/abs/2407.09285v1</a></p>
<p><b>Compressor summary</b>: The MetaFood Workshop and its challenge aim to improve 3D food reconstruction for nutrition monitoring using a visible checkerboard as a size reference, with 16 teams submitting results on varying difficulty levels.</p><hr><h3>DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection</h3>
<p><a href='http://arxiv.org/abs/2407.09283v1'>http://arxiv.org/abs/2407.09283v1</a></p>
<p><b>Compressor summary</b>: DAHRS improves multilingual SRL projection accuracy by addressing spurious role labels caused by naturally occurring divergences and using linguistically-informed alignment remediation followed by FCFA projection.</p><hr><h3>Predicting and Understanding Human Action Decisions: Insights from Large  Language Models and Cognitive Instance-Based Learning</h3>
<p><a href='http://arxiv.org/abs/2407.09281v1'>http://arxiv.org/abs/2407.09281v1</a></p>
<p><b>Compressor summary</b>: The paper compares large language models and a cognitive instance-based learning model in predicting human behavior in sequential decision-making tasks, finding that LLMs are better at incorporating feedback while the cognitive IBL model captures loss aversion bias.</p><hr><h3>H2O-Danube3 Technical Report</h3>
<p><a href='http://arxiv.org/abs/2407.09276v1'>http://arxiv.org/abs/2407.09276v1</a></p>
<p><b>Compressor summary</b>: H2O-Danube3 is a small language model pre-trained on Web data, with high performance and portability for various tasks and devices.</p><hr><h3>Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein  Generation with the Large Multimodal Model HelixProtX</h3>
<p><a href='http://arxiv.org/abs/2407.09274v1'>http://arxiv.org/abs/2407.09274v1</a></p>
<p><b>Compressor summary</b>: HelixProtX is a system that uses a large multimodal model to transform any input protein modality into any desired protein modality, enabling better understanding and generation of protein data and outperforming existing models in various tasks.</p><hr><h3>iNeMo: Incremental Neural Mesh Models for Robust Class-Incremental  Learning</h3>
<p><a href='http://arxiv.org/abs/2407.09271v1'>http://arxiv.org/abs/2407.09271v1</a></p>
<p><b>Compressor summary</b>: Our method improves continual learning for vision tasks by using incremental neural mesh models, latent space initialization, and positional regularization, achieving better performance in both in-domain and out-of-distribution scenarios.</p><hr><h3>Context Embeddings for Efficient Answer Generation in RAG</h3>
<p><a href='http://arxiv.org/abs/2407.09252v1'>http://arxiv.org/abs/2407.09252v1</a></p>
<p><b>Compressor summary</b>: COCOM compresses long contexts for Retrieval-Augmented Generation, speeding up decoding time and improving answer quality.</p><hr><h3>Semantic UV mapping to improve texture inpainting for indoor scenes</h3>
<p><a href='http://arxiv.org/abs/2407.09248v1'>http://arxiv.org/abs/2407.09248v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method that uses semantic information to improve UV mapping and 3D reconstruction of indoor scenes after clutter removal.</p><hr><h3>Constrained Intrinsic Motivation for Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2407.09247v1'>http://arxiv.org/abs/2407.09247v1</a></p>
<p><b>Compressor summary</b>: Constrained Intrinsic Motivation (CIM) improves unsupervised skill discovery and exploration with intrinsic motivation in reinforcement learning tasks by addressing challenges like static skills, limited state coverage, and suboptimality.</p><hr><h3>The Sociolinguistic Foundations of Language Modeling</h3>
<p><a href='http://arxiv.org/abs/2407.09241v1'>http://arxiv.org/abs/2407.09241v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a sociolinguistic approach to language modeling, considering how different language varieties affect various challenges and emphasizing the importance of accurate representation in training data.</p><hr><h3>Modelling the Human Intuition to Complete the Missing Information in  Images for Convolutional Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2407.09236v1'>http://arxiv.org/abs/2407.09236v1</a></p>
<p><b>Compressor summary</b>: The study proposes a visual intuition model based on Gestalt theory to improve CNN performance by completing missing information in images, and tests it on MNIST data set.</p><hr><h3>Surgical Text-to-Image Generation</h3>
<p><a href='http://arxiv.org/abs/2407.09230v1'>http://arxiv.org/abs/2407.09230v1</a></p>
<p><b>Compressor summary</b>: The authors propose Surgical Imagen, a text-to-image generative model that can create realistic surgical images from textual descriptions, addressing challenges like high annotation costs and ethical constraints in acquiring surgical data for research and development.</p><hr><h3>Evaluating AI Evaluation: Perils and Prospects</h3>
<p><a href='http://arxiv.org/abs/2407.09221v1'>http://arxiv.org/abs/2407.09221v1</a></p>
<p><b>Compressor summary</b>: The paper argues for a reform in AI evaluation methods using cognitive sciences and identifies challenges and promising research directions.</p><hr><h3>A Fair Ranking and New Model for Panoptic Scene Graph Generation</h3>
<p><a href='http://arxiv.org/abs/2407.09216v1'>http://arxiv.org/abs/2407.09216v1</a></p>
<p><b>Compressor summary</b>: The paper corrects an error in panoptic scene graph generation evaluations, shows that two-stage models are competitive to one-stage models, and introduces a new two-stage model (DSFormer) that outperforms existing models.</p><hr><h3>HUP-3D: A 3D multi-view synthetic dataset for assisted-egocentric  hand-ultrasound pose estimation</h3>
<p><a href='http://arxiv.org/abs/2407.09215v1'>http://arxiv.org/abs/2407.09215v1</a></p>
<p><b>Compressor summary</b>: HUP-3D is a large, diverse, and realistic synthetic dataset for estimating hand-ultrasound probe pose in obstetric ultrasound using markerless 3D joint pose estimation with potential applications in medical education and guidance.</p><hr><h3>Generating SROI^{-} Ontologies via Knowledge Graph Query Embedding  Learning</h3>
<p><a href='http://arxiv.org/abs/2407.09212v1'>http://arxiv.org/abs/2407.09212v1</a></p>
<p><b>Compressor summary</b>: AConE is a novel query embedding method that explains knowledge in SROI^{-} description logic and outperforms previous models with fewer parameters.</p><hr><h3>Pronunciation Assessment with Multi-modal Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.09209v1'>http://arxiv.org/abs/2407.09209v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a LLM-based scoring system for automated language learning assessment that uses speech encoder and modality adapter layer to generate accuracy and fluency scores.</p><hr><h3>A Chatbot for Asylum-Seeking Migrants in Europe</h3>
<p><a href='http://arxiv.org/abs/2407.09197v1'>http://arxiv.org/abs/2407.09197v1</a></p>
<p><b>Compressor summary</b>: ACME is a chatbot that helps migrants in Europe find the best protection option using computational argumentation.</p><hr><h3>Salt & Pepper Heatmaps: Diffusion-informed Landmark Detection Strategy</h3>
<p><a href='http://arxiv.org/abs/2407.09192v1'>http://arxiv.org/abs/2407.09192v1</a></p>
<p><b>Compressor summary</b>: The text describes a method for accurate anatomical landmark detection using diffusion models that generate probability regions as heatmaps, achieving high quality results in medical image processing.</p><hr><h3>From Easy to Hard: Learning Curricular Shape-aware Features for Robust  Panoptic Scene Graph Generation</h3>
<p><a href='http://arxiv.org/abs/2407.09191v1'>http://arxiv.org/abs/2407.09191v1</a></p>
<p><b>Compressor summary</b>: CAFE is a model-agnostic learning strategy for panoptic scene graph generation that incorporates shape-aware features in an easy-to-hard manner and outperforms existing methods.</p><hr><h3>Enhancing Depressive Post Detection in Bangla: A Comparative Study of  TF-IDF, BERT and FastText Embeddings</h3>
<p><a href='http://arxiv.org/abs/2407.09187v1'>http://arxiv.org/abs/2407.09187v1</a></p>
<p><b>Compressor summary</b>: The study proposes a method to detect depression in Bangla social media posts using advanced natural language processing and deep learning techniques, achieving better results than existing approaches.</p><hr><h3>Variational Inference via Smoothed Particle Hydrodynamics</h3>
<p><a href='http://arxiv.org/abs/2407.09186v1'>http://arxiv.org/abs/2407.09186v1</a></p>
<p><b>Compressor summary</b>: SPH-ParVI is a new variational inference method that uses smoothed particle hydrodynamics to simulate fluid flow and sample probabilistic models efficiently.</p><hr><h3>Does Incomplete Syntax Influence Korean Language Model? Focusing on Word  Order and Case Markers</h3>
<p><a href='http://arxiv.org/abs/2407.09184v1'>http://arxiv.org/abs/2407.09184v1</a></p>
<p><b>Compressor summary</b>: The study introduces a new dataset (SIKO) for Korean language models to improve their handling of incomplete syntax in natural language processing.</p><hr><h3>Exploring the Effectiveness of Methods for Persona Extraction</h3>
<p><a href='http://arxiv.org/abs/2407.09181v1'>http://arxiv.org/abs/2407.09181v1</a></p>
<p><b>Compressor summary</b>: The paper studies how to extract dialogue participant information and evaluate their performance in Russian using Multi-Session Chat dataset, F-score metric, and various models, finding that all models have low recall and larger models improve extraction.</p><hr><h3>DART: An Automated End-to-End Object Detection Pipeline with Data  Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label  Review, and Model Training</h3>
<p><a href='http://arxiv.org/abs/2407.09174v1'>http://arxiv.org/abs/2407.09174v1</a></p>
<p><b>Compressor summary</b>: DART is an automated pipeline for object detection in industrial applications that uses image generation, open-vocabulary annotation, and multimodal review to streamline the workflow and improve performance.</p><hr><h3>Conformal Inductive Graph Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2407.09173v1'>http://arxiv.org/abs/2407.09173v1</a></p>
<p><b>Compressor summary</b>: Conformal prediction can be applied to transductive node-classification using exchangeable graphs, preserving coverage and statistical efficiency.</p><hr><h3>Machine Apophenia: The Kaleidoscopic Generation of Architectural Images</h3>
<p><a href='http://arxiv.org/abs/2407.09172v1'>http://arxiv.org/abs/2407.09172v1</a></p>
<p><b>Compressor summary</b>: The study applies generative AI to create unique architectural designs using neural networks trained on human data, producing coherent images with captions shared online.</p><hr><h3>SE(3)-bi-equivariant Transformers for Point Cloud Assembly</h3>
<p><a href='http://arxiv.org/abs/2407.09167v1'>http://arxiv.org/abs/2407.09167v1</a></p>
<p><b>Compressor summary</b>: SE(3)-bi-equivariant transformer (BITR) is a method to align non-overlapped point clouds by exploiting SE(3)-bi-equivariance prior, which ensures robustness against rigid perturbations and initial positions.</p><hr><h3>Robust Yet Efficient Conformal Prediction Sets</h3>
<p><a href='http://arxiv.org/abs/2407.09165v1'>http://arxiv.org/abs/2407.09165v1</a></p>
<p><b>Compressor summary</b>: Conformal prediction can produce robust prediction sets against adversarial examples, by bounding the change in conformity scores with efficient algorithms.</p><hr><h3>Exploring State Space and Reasoning by Elimination in Tsetlin Machine</h3>
<p><a href='http://arxiv.org/abs/2407.09162v1'>http://arxiv.org/abs/2407.09162v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve the Tsetlin Machine's word embedding by incorporating feature negations and optimizing its parameters, achieving high accuracy in pattern classification tasks.</p><hr><h3>Weakly-supervised Autism Severity Assessment in Long Videos</h3>
<p><a href='http://arxiv.org/abs/2407.09159v1'>http://arxiv.org/abs/2407.09159v1</a></p>
<p><b>Compressor summary</b>: The paper presents a video-based method to detect and categorize severity of autism using spatio-temporal features and a shallow TCN-MLP network, which can aid clinicians in autism spectrum analysis.</p><hr><h3>The Two Sides of the Coin: Hallucination Generation and Detection with  LLMs as Evaluators for LLMs</h3>
<p><a href='http://arxiv.org/abs/2407.09152v1'>http://arxiv.org/abs/2407.09152v1</a></p>
<p><b>Compressor summary</b>: The study examined four large language models' abilities to generate and detect hallucinations, using ensemble voting for detection, in the CLEF ELOQUENT HalluciGen shared task.</p><hr><h3>Evaluating the Adversarial Robustness of Semantic Segmentation: Trying  Harder Pays Off</h3>
<p><a href='http://arxiv.org/abs/2407.09150v1'>http://arxiv.org/abs/2407.09150v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Machine learning models can be fooled by small adversarial perturbations
- Semantic segmentation models are more sensitive than image classification models
- New attacks and detailed analysis reveal the extent of the problem
- Size-bias and diversity of attacks make evaluation challenging

Summary:
The paper shows that semantic segmentation models are highly vulnerable to adversarial perturbations, which can fool them by altering small parts of images. The authors propose new attacks and analyze the models in detail, finding size-bias and diversity issues that complicate evaluation.</p><hr><h3>Accuracy is Not All You Need</h3>
<p><a href='http://arxiv.org/abs/2407.09141v1'>http://arxiv.org/abs/2407.09141v1</a></p>
<p><b>Compressor summary</b>: Summary: The paper studies how compression techniques affect LLMs' quality and suggests using KL-Divergence and flips as better evaluation metrics than accuracy.</p><hr><h3>Stepwise Verification and Remediation of Student Reasoning Errors with  Large Language Model Tutors</h3>
<p><a href='http://arxiv.org/abs/2407.09136v1'>http://arxiv.org/abs/2407.09136v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to improve dialog tutoring models by detecting student errors in math reasoning problems and generating targeted feedback based on the errors.</p><hr><h3>Robustness of Explainable Artificial Intelligence in Industrial Process  Modelling</h3>
<p><a href='http://arxiv.org/abs/2407.09127v1'>http://arxiv.org/abs/2407.09127v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates XAI methods using an EAF model and a novel scoring method based on ground truth simulations and sensitivity analysis, showing how well they explain the data-generating process.</p><hr><h3>Decentralized multi-agent reinforcement learning algorithm using a  cluster-synchronized laser network</h3>
<p><a href='http://arxiv.org/abs/2407.09124v1'>http://arxiv.org/abs/2407.09124v1</a></p>
<p><b>Compressor summary</b>: The text proposes a photonic-based algorithm for multi-agent decision-making that balances exploration and exploitation without explicit information sharing, using chaotic lasers and decentralized coupling adjustment.</p><hr><h3>Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled  Refusal Training</h3>
<p><a href='http://arxiv.org/abs/2407.09121v1'>http://arxiv.org/abs/2407.09121v1</a></p>
<p><b>Compressor summary</b>: This study proposes a new method, DeRTa, to improve the safety of Large Language Models by training them to recognize and refuse harmful content at any position in a response.</p><hr><h3>URRL-IMVC: Unified and Robust Representation Learning for Incomplete  Multi-View Clustering</h3>
<p><a href='http://arxiv.org/abs/2407.09120v1'>http://arxiv.org/abs/2407.09120v1</a></p>
<p><b>Compressor summary</b>: URRL-IMVC is a novel method for incomplete multi-view clustering that leverages multi-view information and neighboring samples to generate robust embeddings without relying on cross-view contrastive learning or missing view recovery.</p><hr><h3>Layer-Wise Relevance Propagation with Conservation Property for ResNet</h3>
<p><a href='http://arxiv.org/abs/2407.09115v1'>http://arxiv.org/abs/2407.09115v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to explain ResNet neural networks by extending Layer-wise Relevance Propagation with Relevance Splitting to handle skip connections, and shows its effectiveness on ImageNet and Caltech-UCSD Birds datasets.</p><hr><h3>Inference Optimization of Foundation Models on AI Accelerators</h3>
<p><a href='http://arxiv.org/abs/2407.09111v1'>http://arxiv.org/abs/2407.09111v1</a></p>
<p><b>Compressor summary</b>: The tutorial discusses optimization techniques for fast and efficient inference using AI accelerators with Transformer-based foundation models in various applications.</p><hr><h3>Enhancing Training Efficiency Using Packing with Flash Attention</h3>
<p><a href='http://arxiv.org/abs/2407.09105v1'>http://arxiv.org/abs/2407.09105v1</a></p>
<p><b>Compressor summary</b>: Packing and Flash Attention with proper masking improve LLM training efficiency and accuracy by combining multiple examples up to the maximum sequence length without wasting GPU resources or affecting attention computation.</p><hr><h3>DANIEL: A fast Document Attention Network for Information Extraction and  Labelling of handwritten documents</h3>
<p><a href='http://arxiv.org/abs/2407.09103v1'>http://arxiv.org/abs/2407.09103v1</a></p>
<p><b>Compressor summary</b>: DANIEL is a fast, end-to-end architecture for handwritten document understanding that integrates language modeling, layout analysis, text recognition, and named entity recognition across multiple languages, layouts, and tasks.</p><hr><h3>STD-LLM: Understanding Both Spatial and Temporal Properties of  Spatial-Temporal Data with LLMs</h3>
<p><a href='http://arxiv.org/abs/2407.09096v1'>http://arxiv.org/abs/2407.09096v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes STD-LLM, a model that can do spatial-temporal forecasting and imputation tasks using LLMs
- STD-LLM uses tokenizers, virtual nodes, node embeddings, and hypergraph learning to understand spatial-temporal data
- STD-LLM performs well on various datasets and few-shot/zero-shot learning tasks

Summary:
The paper introduces STD-LLM, a model that leverages LLMs to handle both forecasting and imputation for spatial-temporal data using special tokens, embeddings, and hypergraph learning, achieving strong results on different datasets and few-shot/zero-shot scenarios.</p><hr><h3>On Exact Bit-level Reversible Transformers Without Changing  Architectures</h3>
<p><a href='http://arxiv.org/abs/2407.09093v1'>http://arxiv.org/abs/2407.09093v1</a></p>
<p><b>Compressor summary</b>: The paper proposes bit-level reversible transformers by treating each block as an Euler integration approximation and using bidirectional integration approximation, which improves accuracy and data-throughput in training.</p><hr><h3>On the Role of Discrete Tokenization in Visual Representation Learning</h3>
<p><a href='http://arxiv.org/abs/2407.09087v1'>http://arxiv.org/abs/2407.09087v1</a></p>
<p><b>Compressor summary</b>: The paper explores the impact of discrete tokens in masked image modeling, proposes a new metric to measure their effectiveness, and introduces ClusterMIM, a method that outperforms existing approaches on various datasets and models.</p><hr><h3>Open Vocabulary Multi-Label Video Classification</h3>
<p><a href='http://arxiv.org/abs/2407.09073v1'>http://arxiv.org/abs/2407.09073v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to adapt a pre-trained vision-language model (VLM) for open vocabulary multilabel video classification by using large language models (LLMs) to provide semantic guidance and integrating temporal modeling into the VLM's encoder.</p><hr><h3>New Desiderata for Direct Preference Optimization</h3>
<p><a href='http://arxiv.org/abs/2407.09072v1'>http://arxiv.org/abs/2407.09072v1</a></p>
<p><b>Compressor summary</b>: The text discusses the challenges of using direct preference optimization (DPO) methods for fine-tuning language models based on human feedback, and proposes a new loss function to address these issues.</p><hr><h3>Spectral Self-supervised Feature Selection</h3>
<p><a href='http://arxiv.org/abs/2407.09061v1'>http://arxiv.org/abs/2407.09061v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Unsupervised feature selection for high-dimensional data
- Self-supervised graph-based approach using pseudo-labels from graph Laplacian eigenvectors
- Robust to outliers and complex substructures
- Effective on real-world datasets, especially biological ones

Summary:
The paper presents a robust and effective self-supervised graph-based method for unsupervised feature selection from high-dimensional data, using pseudo-labels from graph Laplacian eigenvectors.</p><hr><h3>Domain-adaptive Video Deblurring via Test-time Blurring</h3>
<p><a href='http://arxiv.org/abs/2407.09059v1'>http://arxiv.org/abs/2407.09059v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a domain adaptation scheme that uses a blurring model to generate training pairs for fine-tuning a video deblurring model in unseen domains, improving performance on real-world videos.</p><hr><h3>PersonificationNet: Making customized subject act like a person</h3>
<p><a href='http://arxiv.org/abs/2407.09057v1'>http://arxiv.org/abs/2407.09057v1</a></p>
<p><b>Compressor summary</b>: PersonificationNet is a model that can make a cartoon or toy act like a person by copying their pose and appearance from few images.</p><hr><h3>From MIDI to Rich Tablatures: an Automatic Generative System  incorporating Lead Guitarists' Fingering and Stylistic choices</h3>
<p><a href='http://arxiv.org/abs/2407.09052v1'>http://arxiv.org/abs/2407.09052v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The system generates tablatures for lead electric guitar from MIDI melodies
- It solves a multi-attribute optimization problem to find the best fingering
- It incorporates common clich√©s, biomechanical feasibility, articulations, and expressive techniques
- It converts the output into MusicXML format for easy use

Summary:
The system creates tablatures for lead electric guitar from MIDI melodies by optimizing fingering, incorporating musical aspects, and converting to MusicXML.</p><hr><h3>KUNPENG: An Embodied Large Model for Intelligent Maritime</h3>
<p><a href='http://arxiv.org/abs/2407.09048v1'>http://arxiv.org/abs/2407.09048v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Intelligent maritime is a part of smart ocean construction that uses AI and data analysis to improve efficiency and intelligence of ocean transportation
- It faces challenges from complex and dynamic maritime environment and diverse data sources
- KUNPENG is a model for intelligent maritime that perceives heterogeneous data, makes decisions, and optimizes power for safe and efficient navigation

Summary:
KUNPENG is an AI model that enhances the efficiency and intelligence of ocean transportation by navigating vessels safely and optimally in complex maritime environments using diverse data sources.</p><hr><h3>Cs2K: Class-specific and Class-shared Knowledge Guidance for Incremental  Semantic Segmentation</h3>
<p><a href='http://arxiv.org/abs/2407.09047v1'>http://arxiv.org/abs/2407.09047v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for incremental semantic segmentation that balances learning from old and new classes using prototype-guided techniques and weight-guided consolidation.</p><hr><h3>Molecule Language Model with Augmented Pairs and Expertise Transfer</h3>
<p><a href='http://arxiv.org/abs/2407.09043v1'>http://arxiv.org/abs/2407.09043v1</a></p>
<p><b>Compressor summary</b>: AMOLE is a model that enhances the understanding of molecules and their texts by preserving structural similarity and transferring expertise.</p><hr><h3>Overcoming Catastrophic Forgetting in Tabular Data Classification: A  Pseudorehearsal-based approach</h3>
<p><a href='http://arxiv.org/abs/2407.09039v1'>http://arxiv.org/abs/2407.09039v1</a></p>
<p><b>Compressor summary</b>: TRIL3 is a new method for continuous learning in tabular data classification that uses synthetic data to prevent forgetting and achieves superior performance with minimal synthetic data.</p><hr><h3>Textual Query-Driven Mask Transformer for Domain Generalized  Segmentation</h3>
<p><a href='http://arxiv.org/abs/2407.09033v1'>http://arxiv.org/abs/2407.09033v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a text-based semantic segmentation method that leverages vision-language models and transformers to improve generalization across domains, achieving state-of-the-art results on GTA5$->$Cityscapes.</p><hr><h3>HPC: Hierarchical Progressive Coding Framework for Volumetric Video</h3>
<p><a href='http://arxiv.org/abs/2407.09026v1'>http://arxiv.org/abs/2407.09026v1</a></p>
<p><b>Compressor summary</b>: The paper proposes HPC, a framework for compressing volumetric videos based on NeRF that enables variable bitrate and quality using a single model, reducing temporal redundancy and optimizing compression with multi-rate-distortion loss function.</p><hr><h3>SpreadsheetLLM: Encoding Spreadsheets for Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.09025v1'>http://arxiv.org/abs/2407.09025v1</a></p>
<p><b>Compressor summary</b>: SpreadsheetLLM introduces an efficient encoding framework for large language models to effectively understand and reason with spreadsheets using SheetCompressor and Chain of Spreadsheet.</p><hr><h3>Aligning Diffusion Behaviors with Q-functions for Efficient Continuous  Control</h3>
<p><a href='http://arxiv.org/abs/2407.09024v1'>http://arxiv.org/abs/2407.09024v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a two-stage optimization method for offline Reinforcement Learning using language model alignment, introduces Efficient Diffusion Alignment (EDA) for continuous control problems, and shows its superior performance on the D4RL benchmark.</p><hr><h3>3M-Health: Multimodal Multi-Teacher Knowledge Distillation for Mental  Health Detection</h3>
<p><a href='http://arxiv.org/abs/2407.09020v1'>http://arxiv.org/abs/2407.09020v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a multimodal and multi-teacher approach to improve mental health classification using social media data, which integrates diverse features like text and sound, and distributes learning across specialized teachers.</p><hr><h3>AI-Driven Guided Response for Security Operation Centers with Microsoft  Copilot for Security</h3>
<p><a href='http://arxiv.org/abs/2407.09017v1'>http://arxiv.org/abs/2407.09017v1</a></p>
<p><b>Compressor summary</b>: Copilot Guided Response (CGR) is an ML system that helps security analysts investigate, triage, and remediate security incidents by providing historical context, determining the nature of the incident, and suggesting containment actions.</p><hr><h3>CompAct: Compressing Retrieved Documents Actively for Question Answering</h3>
<p><a href='http://arxiv.org/abs/2407.09014v1'>http://arxiv.org/abs/2407.09014v1</a></p>
<p><b>Compressor summary</b>: CompAct is a framework that compresses extensive documents for language models to improve multi-hop question-answering without losing key information.</p><hr><h3>Procedural Content Generation via Generative Artificial Intelligence</h3>
<p><a href='http://arxiv.org/abs/2407.09013v1'>http://arxiv.org/abs/2407.09013v1</a></p>
<p><b>Compressor summary</b>: This paper surveys how generative AI is used for creating various types of content in PCG and discusses the challenges of limited domain-specific training data.</p><hr><h3>TCAN: Animating Human Images with Temporally Consistent Pose Guidance  using Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2407.09012v1'>http://arxiv.org/abs/2407.09012v1</a></p>
<p><b>Compressor summary</b>: TCAN is a pose-driven human image animation method that uses ControlNet and LoRA to create realistic videos with robustness to erroneous poses and consistent over time, while also allowing for a more static background.</p><hr><h3>One Stone, Four Birds: A Comprehensive Solution for QA System Using  Supervised Contrastive Learning</h3>
<p><a href='http://arxiv.org/abs/2407.09011v1'>http://arxiv.org/abs/2407.09011v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve question answering systems by using supervised contrastive learning, which enhances robustness and efficiency in handling various user inputs.</p><hr><h3>Benchmarking Language Model Creativity: A Case Study on Code Generation</h3>
<p><a href='http://arxiv.org/abs/2407.09007v1'>http://arxiv.org/abs/2407.09007v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a framework to measure the creativity of large language models using two characteristics: convergent and divergent thinking, and applies it to Codeforces problems.</p><hr><h3>Introducing VaDA: Novel Image Segmentation Model for Maritime Object  Segmentation Using New Dataset</h3>
<p><a href='http://arxiv.org/abs/2407.09005v1'>http://arxiv.org/abs/2407.09005v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new AI model for recognizing objects in maritime scenes, introduces a benchmark dataset, and develops a performance evaluation method to standardize and improve autonomous navigation systems.</p><hr><h3>Enhancing Few-Shot Stock Trend Prediction with Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.09003v1'>http://arxiv.org/abs/2407.09003v1</a></p>
<p><b>Compressor summary</b>: The summary: The authors propose a 'denoising-then-voting' method using large language models to predict stock trends from individual news instead of merged news, overcoming noise and input length limits and achieving comparable performance to supervised methods.</p><hr><h3>Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs</h3>
<p><a href='http://arxiv.org/abs/2407.08995v1'>http://arxiv.org/abs/2407.08995v1</a></p>
<p><b>Compressor summary</b>: The study proposes a method for LLMs to generate their own role-play prompts through fine-tuning, improving their performance in various domains and automating complex prompting strategies.</p><hr><h3>Global Attention-Guided Dual-Domain Point Cloud Feature Learning for  Classification and Segmentation</h3>
<p><a href='http://arxiv.org/abs/2407.08994v1'>http://arxiv.org/abs/2407.08994v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Point-based neural models are effective for point cloud analysis but have issues with input embedding and neighboring aggregations
- The paper proposes GAD, a network with CPT and DKFF modules to address these issues
- Experiments show the superior performance of GAD on various tasks

Summary:
The paper introduces GAD, a network that improves point cloud analysis by using global attention and dual-domain feature learning to enhance input embedding and neighboring aggregations.</p><hr><h3>Task-driven single-image super-resolution reconstruction of document  scans</h3>
<p><a href='http://arxiv.org/abs/2407.08993v1'>http://arxiv.org/abs/2407.08993v1</a></p>
<p><b>Compressor summary</b>: The paper explores using deep learning for super-resolution to improve optical character recognition from document scans, introducing a multi-task loss function to address the ill-posedness of the problem.</p><hr><h3>Emotion Talk: Emotional Support via Audio Messages for Psychological  Assistance</h3>
<p><a href='http://arxiv.org/abs/2407.08992v1'>http://arxiv.org/abs/2407.08992v1</a></p>
<p><b>Compressor summary</b>: Emotion Talk is a system that provides emotional support through audio messages in Portuguese, analyzing and responding to users' emotions outside therapy sessions.</p><hr><h3>Robustness of LLMs to Perturbations in Text</h3>
<p><a href='http://arxiv.org/abs/2407.08989v1'>http://arxiv.org/abs/2407.08989v1</a></p>
<p><b>Compressor summary</b>: This study evaluates large language models' robustness against morphological variations in text and finds that they perform better than previous pre-trained models on real-world benchmarks like GEC and LSC.</p><hr><h3>Towards Chapter-to-Chapter Context-Aware Literary Translation via Large  Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.08978v1'>http://arxiv.org/abs/2407.08978v1</a></p>
<p><b>Compressor summary</b>: The text describes a new dataset of Chinese-English literature with complex discourse structures, proposes chapter-to-chapter translation as a pragmatic context-aware translation task, and explores the performance of machine translation models and large language models on this setting.</p><hr><h3>Integrating White and Black Box Techniques for Interpretable Machine  Learning</h3>
<p><a href='http://arxiv.org/abs/2407.08973v1'>http://arxiv.org/abs/2407.08973v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an ensembling method that uses transparent and opaque models for easy and hard inputs respectively to balance interpretability and performance.</p><hr><h3>Revealing the Dark Secrets of Extremely Large Kernel ConvNets on  Robustness</h3>
<p><a href='http://arxiv.org/abs/2407.08972v1'>http://arxiv.org/abs/2407.08972v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates the robustness of large kernel convolutional neural networks (CNNs) and compares their performance to transformers (ViTs) on six benchmark datasets, revealing novel insights into their properties.</p><hr><h3>Full-Stage Pseudo Label Quality Enhancement for Weakly-supervised  Temporal Action Localization</h3>
<p><a href='http://arxiv.org/abs/2407.08971v1'>http://arxiv.org/abs/2407.08971v1</a></p>
<p><b>Compressor summary</b>: FuSTAL improves pseudo label quality for action localization in untrimmed videos using cross-video contrastive learning, prior-based filtering, and EMA-based distillation, achieving state-of-the-art results.</p><hr><h3>SlideGCD: Slide-based Graph Collaborative Training with Knowledge  Distillation for Whole Slide Image Classification</h3>
<p><a href='http://arxiv.org/abs/2407.08968v1'>http://arxiv.org/abs/2407.08968v1</a></p>
<p><b>Compressor summary</b>: SlideGCD is a WSI analysis pipeline that uses slide-based graph construction and graph learning to explore inter-correlations between slides for cancer diagnostics, improving the performance of existing multi-instance learning methods on TCGA datasets.</p><hr><h3>Empowering Few-Shot Relation Extraction with The Integration of  Traditional RE Methods and Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.08967v1'>http://arxiv.org/abs/2407.08967v1</a></p>
<p><b>Compressor summary</b>: The text proposes a Dual-System Augmented Relation Extractor (DSARE) that combines traditional RE models with LLMs to address their limitations in few-shot relation extraction tasks.</p><hr><h3>LAPT: Label-driven Automated Prompt Tuning for OOD Detection with  Vision-Language Models</h3>
<p><a href='http://arxiv.org/abs/2407.08966v1'>http://arxiv.org/abs/2407.08966v1</a></p>
<p><b>Compressor summary</b>: LAPT is a novel approach for OOD detection that automatically generates prompts with class names and negative labels, improving reliability and reducing manual intervention.</p><hr><h3>Lite-SAM Is Actually What You Need for Segment Everything</h3>
<p><a href='http://arxiv.org/abs/2407.08965v1'>http://arxiv.org/abs/2407.08965v1</a></p>
<p><b>Compressor summary</b>: Lite-SAM is an efficient end-to-end solution for SegEvery with a streamlined CNN-Transformer hybrid encoder, an automated prompt proposal network, and a mask decoder that achieves state-of-the-art performance while reducing computational costs.</p><hr><h3>Communication-Aware Reinforcement Learning for Cooperative Adaptive  Cruise Control</h3>
<p><a href='http://arxiv.org/abs/2407.08964v1'>http://arxiv.org/abs/2407.08964v1</a></p>
<p><b>Compressor summary</b>: CA-RL improves traffic efficiency and safety by using communication-aware Reinforcement Learning to optimize CACC in Connected and Autonomous Vehicles.</p><hr><h3>Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for  Few-shot Hierarchical Text Classification</h3>
<p><a href='http://arxiv.org/abs/2407.08959v1'>http://arxiv.org/abs/2407.08959v1</a></p>
<p><b>Compressor summary</b>: The paper proposes HierICRF, a method that improves few-shot hierarchical text classification by adapting unstructured semantic spaces in pre-trained language models to the downstream domain hierarchy using iterative language modeling and hierarchical consistency correction.</p><hr><h3>Detect, Investigate, Judge and Determine: A Novel LLM-based Framework  for Few-shot Fake News Detection</h3>
<p><a href='http://arxiv.org/abs/2407.08952v1'>http://arxiv.org/abs/2407.08952v1</a></p>
<p><b>Compressor summary</b>: DAFND is a model that improves fake news detection by enhancing large language models with a Detection, Investigation, Judge, and Determination module that utilizes both inside and outside information.</p><hr><h3>Exploring Richer and More Accurate Information via Frequency Selection  for Image Restoration</h3>
<p><a href='http://arxiv.org/abs/2407.08950v1'>http://arxiv.org/abs/2407.08950v1</a></p>
<p><b>Compressor summary</b>: MSFSNet is a network that improves image restoration by selectively recovering information using spatial and frequency domain knowledge, dynamic filter selection, and skip feature fusion.</p><hr><h3>One-Shot Pose-Driving Face Animation Platform</h3>
<p><a href='http://arxiv.org/abs/2407.08949v1'>http://arxiv.org/abs/2407.08949v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to generate dynamic and expressive talking head videos from a single face image, improving the existing Image2Video model with a Face Locator and Motion Frame mechanism, and provide a demo platform for easy use.</p><hr><h3>Constructing Concept-based Models to Mitigate Spurious Correlations with  Minimal Human Effort</h3>
<p><a href='http://arxiv.org/abs/2407.08947v1'>http://arxiv.org/abs/2407.08947v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes a method to build interpretable models (CBMs) using foundation models with minimal human effort
- The method reduces biases and vulnerability to spurious correlations in CBMs
- The method is evaluated on multiple datasets and shows effectiveness

Summary:
The paper presents a novel framework that leverages foundation models to construct interpretable models with low bias and high robustness, and evaluates it on various datasets.</p><hr><h3>Your Diffusion Model is Secretly a Noise Classifier and Benefits from  Contrastive Training</h3>
<p><a href='http://arxiv.org/abs/2407.08946v1'>http://arxiv.org/abs/2407.08946v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new self-supervised training objective for diffusion models to improve denoising in regions outside the standard training distribution, leading to better sampling quality and performance.</p><hr><h3>Bora: Biomedical Generalist Video Generation Model</h3>
<p><a href='http://arxiv.org/abs/2407.08944v1'>http://arxiv.org/abs/2407.08944v1</a></p>
<p><b>Compressor summary</b>: Bora is a new spatio-temporal diffusion probabilistic model that can generate realistic and diverse biomedical videos from text prompts, potentially improving medical education, decision-making, and training.</p><hr><h3>Large Language Models as Biomedical Hypothesis Generators: A  Comprehensive Evaluation</h3>
<p><a href='http://arxiv.org/abs/2407.08940v1'>http://arxiv.org/abs/2407.08940v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates large language models' ability to generate novel hypotheses from biomedical literature, using various settings and metrics, and finds that they can produce valid and diverse hypotheses with some limitations.</p><hr><h3>LightenDiffusion: Unsupervised Low-Light Image Enhancement with  Latent-Retinex Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2407.08939v1'>http://arxiv.org/abs/2407.08939v1</a></p>
<p><b>Compressor summary</b>: The paper introduces LightenDiffusion, a diffusion-based unsupervised framework that enhances low-light images using Retinex theory and physically explainable diffusion models, improving visual quality over existing methods.</p><hr><h3>Self-Evolving GPT: A Lifelong Autonomous Experiential Learner</h3>
<p><a href='http://arxiv.org/abs/2407.08937v1'>http://arxiv.org/abs/2407.08937v1</a></p>
<p><b>Compressor summary</b>: The text describes a framework that enables large language models to learn from experience and improve their performance on various tasks, demonstrating the feasibility of using LLMs to mimic human experiential learning.</p><hr><h3>Compositional Structures in Neural Embedding and Interaction  Decompositions</h3>
<p><a href='http://arxiv.org/abs/2407.08934v1'>http://arxiv.org/abs/2407.08934v1</a></p>
<p><b>Compressor summary</b>: The text explores how vector embeddings in neural networks relate to conditional independence constraints and helps explain structural patterns in data representations.</p><hr><h3>Machine Learning in High Volume Media Manufacturing</h3>
<p><a href='http://arxiv.org/abs/2407.08933v1'>http://arxiv.org/abs/2407.08933v1</a></p>
<p><b>Compressor summary</b>: The authors develop a novel program that combines rule-based and machine learning approaches to identify and adapt to errors or failures in high-volume manufacturing environments.</p><hr><h3>Deep Attention Driven Reinforcement Learning (DAD-RL) for Autonomous  Vehicle Decision-Making in Dynamic Environment</h3>
<p><a href='http://arxiv.org/abs/2407.08932v1'>http://arxiv.org/abs/2407.08932v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a simple framework for autonomous vehicles to make decisions in urban environments by incorporating the significance of surrounding vehicles and contextual information using deep attention, reinforcement learning, and an encoder.</p><hr><h3>Global-Local Collaborative Inference with LLM for Lidar-Based  Open-Vocabulary Detection</h3>
<p><a href='http://arxiv.org/abs/2407.08931v1'>http://arxiv.org/abs/2407.08931v1</a></p>
<p><b>Compressor summary</b>: Key points:
- OVD is detecting objects in a scene without predefined classes
- The paper proposes GLIS, a method that uses both object-level and scene-level features from lidar point clouds
- GLIS also uses LLM for inference and RPLG and BAOL for refinement
- Experiments show the effectiveness of GLIS on two datasets

Summary:
The paper introduces GLIS, a lidar-based OVD method that leverages object-level and scene-level features, as well as LLM inference, RPLG, and BAOL for refinement.</p><hr><h3>Leveraging large language models for nano synthesis mechanism  explanation: solid foundations or mere conjectures?</h3>
<p><a href='http://arxiv.org/abs/2407.08922v1'>http://arxiv.org/abs/2407.08922v1</a></p>
<p><b>Compressor summary</b>: This paper introduces a benchmark and a novel evaluation metric (c-score) to assess whether large language models understand the underlying physicochemical mechanisms of gold nanoparticle synthesis, suggesting their potential for advancing scientific discovery.</p><hr><h3>Exploring Knowledge Transfer in Evolutionary Many-task Optimization: A  Complex Network Perspective</h3>
<p><a href='http://arxiv.org/abs/2407.08918v1'>http://arxiv.org/abs/2407.08918v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a new framework using complex networks to analyze and improve knowledge transfer in evolutionary many-task optimization (EMaTO).</p><hr><h3>Transforming Movie Recommendations with Advanced Machine Learning: A  Study of NMF, SVD,and K-Means Clustering</h3>
<p><a href='http://arxiv.org/abs/2407.08916v1'>http://arxiv.org/abs/2407.08916v1</a></p>
<p><b>Compressor summary</b>: The study creates a movie recommendation system using machine learning methods like NMF, SVD, and K-Means clustering to improve user experience.</p><hr><h3>PAIL: Performance based Adversarial Imitation Learning Engine for Carbon  Neutral Optimization</h3>
<p><a href='http://arxiv.org/abs/2407.08910v1'>http://arxiv.org/abs/2407.08910v1</a></p>
<p><b>Compressor summary</b>: PAIL is a novel method that uses imitation learning and adversarial training to optimize industrial operations for carbon neutrality without predefined rewards.</p><hr><h3>KGpose: Keypoint-Graph Driven End-to-End Multi-Object 6D Pose Estimation  via Point-Wise Pose Voting</h3>
<p><a href='http://arxiv.org/abs/2407.08909v1'>http://arxiv.org/abs/2407.08909v1</a></p>
<p><b>Compressor summary</b>: KGpose is a novel framework that uses keypoint graphs to estimate 6D poses of multiple objects from RGB and point cloud features, achieving competitive results for robotic applications.</p><hr><h3>Are They the Same Picture? Adapting Concept Bottleneck Models for  Human-AI Collaboration in Image Retrieval</h3>
<p><a href='http://arxiv.org/abs/2407.08908v1'>http://arxiv.org/abs/2407.08908v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Image retrieval is important for various applications and requires human expertise
- CHAIR is a model that allows humans to correct intermediate concepts and improves embedding generation
- CHAIR outperforms similar models without intervention and benefits from human guidance

Summary:
CHAIR is a human-in-the-loop image retrieval model that enables better performance by letting humans correct intermediate concepts.</p><hr><h3>AirSketch: Generative Motion to Sketch</h3>
<p><a href='http://arxiv.org/abs/2407.08906v1'>http://arxiv.org/abs/2407.08906v1</a></p>
<p><b>Compressor summary</b>: AirSketch is a method for generating sketches from hand motions without needing expensive hardware or markers, using controllable image diffusion models.</p><hr><h3>Application of Artificial Intelligence in Supporting Healthcare  Professionals and Caregivers in Treatment of Autistic Children</h3>
<p><a href='http://arxiv.org/abs/2407.08902v1'>http://arxiv.org/abs/2407.08902v1</a></p>
<p><b>Compressor summary</b>: The paper presents an AI algorithm that can accurately detect Autism Spectrum Disorder by analyzing facial and bodily expressions of children during daily activities.</p><hr><h3>IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating  Interactive Task-Solving Agents</h3>
<p><a href='http://arxiv.org/abs/2407.08898v1'>http://arxiv.org/abs/2407.08898v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a toolkit for creating interactive AI agents that understand natural language and execute grounded instructions in a Minecraft-like environment, as well as an evaluation platform with human annotators to assess their performance.</p>