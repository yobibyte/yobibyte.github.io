
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-07-02</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-07-02 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Odd-One-Out: Anomaly Detection by Comparing with Neighbors</h3>
<p><a href='http://arxiv.org/abs/2406.20099v1'>http://arxiv.org/abs/2406.20099v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new anomaly detection problem that focuses on identifying odd-looking objects in a scene using multiple views, introduces two benchmarks, and presents a novel method to detect them with 3D object-centric representations.</p><hr><h3>Backdoor Attack in Prompt-Based Continual Learning</h3>
<p><a href='http://arxiv.org/abs/2406.19753v1'>http://arxiv.org/abs/2406.19753v1</a></p>
<p><b>Compressor summary</b>: Prompt-based continual learning faces backdoor attacks that manipulate prompts to make models follow a desired target when triggered, and the paper proposes solutions for transferability, resiliency, and authenticity challenges.</p><hr><h3>MM-Instruct: Generated Visual Instructions for Large Multimodal Model  Alignment</h3>
<p><a href='http://arxiv.org/abs/2406.19736v1'>http://arxiv.org/abs/2406.19736v1</a></p>
<p><b>Compressor summary</b>: MM-Instruct is a new visual instruction dataset that enhances the capabilities of large multimodal models for various tasks by generating diverse and high-quality data from conventional image captioning datasets.</p><hr><h3>Message du troisi{è}me type : irruption d'un tiers dans un dialogue en  ligne</h3>
<p><a href='http://arxiv.org/abs/2406.19731v1'>http://arxiv.org/abs/2406.19731v1</a></p>
<p><b>Compressor summary</b>: The study analyzes Wikipedia talk pages in French, focusing on multiparty conversations and the role of a third participant's intervention in these discussions.</p><hr><h3>Le sens de la famille : analyse du vocabulaire de la parent{é} par les  plongements de mots</h3>
<p><a href='http://arxiv.org/abs/2406.19729v1'>http://arxiv.org/abs/2406.19729v1</a></p>
<p><b>Compressor summary</b>: The study analyzes how the structure and meaning of family relationship terms in French are revealed by their distribution in various corpora.</p><hr><h3>EPOCH: Jointly Estimating the 3D Pose of Cameras and Humans</h3>
<p><a href='http://arxiv.org/abs/2406.19726v1'>http://arxiv.org/abs/2406.19726v1</a></p>
<p><b>Compressor summary</b>: The study proposes EPOCH, a framework that uses the full perspective camera model to estimate 3D human joint positions from single 2D images with weak supervision, achieving state-of-the-art results.</p><hr><h3>Uncertainty Quantification in Large Language Models Through Convex Hull  Analysis</h3>
<p><a href='http://arxiv.org/abs/2406.19712v1'>http://arxiv.org/abs/2406.19712v1</a></p>
<p><b>Compressor summary</b>: The study proposes a new geometric method to measure uncertainty in large language models using convex hull analysis of response embeddings based on prompt complexity, model, and temperature setting.</p><hr><h3>CHASE: A Causal Heterogeneous Graph based Framework for Root Cause  Analysis in Multimodal Microservice Systems</h3>
<p><a href='http://arxiv.org/abs/2406.19711v1'>http://arxiv.org/abs/2406.19711v1</a></p>
<p><b>Compressor summary</b>: CHASE is a framework for detecting anomalies and finding root causes in microservice systems using multimodal data and causality-based hypergraphs, outperforming existing methods.</p><hr><h3>InfiniGen: Efficient Generative Inference of Large Language Models with  Dynamic KV Cache Management</h3>
<p><a href='http://arxiv.org/abs/2406.19707v1'>http://arxiv.org/abs/2406.19707v1</a></p>
<p><b>Compressor summary</b>: InfiniGen is a framework that efficiently manages the key-value cache for long-text generation in large language models, improving performance and accuracy.</p><hr><h3>DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial  Optimization Problems</h3>
<p><a href='http://arxiv.org/abs/2406.19705v1'>http://arxiv.org/abs/2406.19705v1</a></p>
<p><b>Compressor summary</b>: DISCO is an efficient diffusion solver for combinatorial optimization problems that improves solution quality and speed by denoising solutions quickly and sampling from a more meaningful domain.</p><hr><h3>Vision Transformer with Key-select Routing Attention for Single Image  Dehazing</h3>
<p><a href='http://arxiv.org/abs/2406.19703v1'>http://arxiv.org/abs/2406.19703v1</a></p>
<p><b>Compressor summary</b>: Ksformer is a new dehazing method that uses MKRA for selective key area extraction and LFPM for enhancing high-frequency features, achieving better results than previous methods.</p><hr><h3>Deep Fusion Model for Brain Tumor Classification Using Fine-Grained  Gradient Preservation</h3>
<p><a href='http://arxiv.org/abs/2406.19690v1'>http://arxiv.org/abs/2406.19690v1</a></p>
<p><b>Compressor summary</b>: The research proposes a novel computer vision-based architecture that accurately and quickly classifies brain tumors, making it suitable for deployment in resource-limited areas.</p><hr><h3>MimicMotion: High-Quality Human Motion Video Generation with  Confidence-aware Pose Guidance</h3>
<p><a href='http://arxiv.org/abs/2406.19680v1'>http://arxiv.org/abs/2406.19680v1</a></p>
<p><b>Compressor summary</b>: MimicMotion is a framework for generating high-quality, controllable videos of any length by mimicking specific motion guidance with improved pose confidence and reduced image distortion.</p><hr><h3>Deep Learning-based Depth Estimation Methods from Monocular Image and  Videos: A Comprehensive Survey</h3>
<p><a href='http://arxiv.org/abs/2406.19675v1'>http://arxiv.org/abs/2406.19675v1</a></p>
<p><b>Compressor summary</b>: This paper surveys deep learning-based methods for estimating depth from single RGB images and videos, categorizing them by input/output modalities, network architectures, and learning methods, and discussing milestones, pipelines, datasets, and metrics.</p><hr><h3>Less is More: Accurate Speech Recognition & Translation without  Web-Scale Data</h3>
<p><a href='http://arxiv.org/abs/2406.19674v1'>http://arxiv.org/abs/2406.19674v1</a></p>
<p><b>Compressor summary</b>: Canary is a multilingual speech recognition and translation model that performs better than current models on four languages using much less data and advanced techniques.</p><hr><h3>Beyond First-Order: A Multi-Scale Approach to Finger Knuckle Print  Biometrics</h3>
<p><a href='http://arxiv.org/abs/2406.19672v1'>http://arxiv.org/abs/2406.19672v1</a></p>
<p><b>Compressor summary</b>: The paper proposes DOTCNet, a novel finger knuckle print recognition approach that captures both first and second order textures using learnable Gabor filters and an attention mechanism.</p><hr><h3>PopAlign: Population-Level Alignment for Fair Text-to-Image Generation</h3>
<p><a href='http://arxiv.org/abs/2406.19668v1'>http://arxiv.org/abs/2406.19668v1</a></p>
<p><b>Compressor summary</b>: PopAlign is a method to reduce biases in text-to-image models by optimizing for population-level preferences during training.</p><hr><h3>CSAKD: Knowledge Distillation with Cross Self-Attention for  Hyperspectral and Multispectral Image Fusion</h3>
<p><a href='http://arxiv.org/abs/2406.19666v1'>http://arxiv.org/abs/2406.19666v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel knowledge distillation framework for hyperspectral image fusion and super-resolution, using a Cross-Layer Residual Aggregation block and a Cross Self-Attention fusion module to enhance efficiency and quality.</p><hr><h3>PM-VIS+: High-Performance Video Instance Segmentation without Video  Annotation</h3>
<p><a href='http://arxiv.org/abs/2406.19665v1'>http://arxiv.org/abs/2406.19665v1</a></p>
<p><b>Compressor summary</b>: The paper presents PM-VIS+, a method that achieves high video instance segmentation performance without manual video annotations, using image datasets and adapting supervision based on annotation types.</p><hr><h3>Finite basis Kolmogorov-Arnold networks: domain decomposition for  data-driven and physics-informed problems</h3>
<p><a href='http://arxiv.org/abs/2406.19662v1'>http://arxiv.org/abs/2406.19662v1</a></p>
<p><b>Compressor summary</b>: The authors propose a domain decomposition method for training KANs in parallel, called FBKANs, which can handle multiscale problems and noisy data using physics-informed training.</p><hr><h3>LLMEasyQuant -- An Easy to Use Toolkit for LLM Quantization</h3>
<p><a href='http://arxiv.org/abs/2406.19657v1'>http://arxiv.org/abs/2406.19657v1</a></p>
<p><b>Compressor summary</b>: LLMEasyQuant is a user-friendly and beginner-friendly package for LLM quantization that simplifies deployment and learning.</p><hr><h3>Basketball-SORT: An Association Method for Complex Multi-object  Occlusion Problems in Basketball Multi-object Tracking</h3>
<p><a href='http://arxiv.org/abs/2406.19655v1'>http://arxiv.org/abs/2406.19655v1</a></p>
<p><b>Compressor summary</b>: The text describes a new method for tracking multiple objects in basketball videos, called Basketball-SORT, which handles occlusions and complex motions better than existing methods.</p><hr><h3>ACES: Automatic Cohort Extraction System for Event-Stream Datasets</h3>
<p><a href='http://arxiv.org/abs/2406.19653v1'>http://arxiv.org/abs/2406.19653v1</a></p>
<p><b>Compressor summary</b>: ACES is a tool that simplifies defining and extracting cohorts for machine learning tasks using event-stream datasets, improving reproducibility in healthcare studies.</p><hr><h3>DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark  for Incoherence Detection, Reasoning, and Rewriting</h3>
<p><a href='http://arxiv.org/abs/2406.19650v1'>http://arxiv.org/abs/2406.19650v1</a></p>
<p><b>Compressor summary</b>: DECOR is a benchmark dataset to improve L2 English writing by detecting and rewriting incoherent sentences using expert annotations and fine-tuned models.</p><hr><h3>Beyond Human Preferences: Exploring Reinforcement Learning Trajectory  Evaluation and Improvement through LLMs</h3>
<p><a href='http://arxiv.org/abs/2406.19644v1'>http://arxiv.org/abs/2406.19644v1</a></p>
<p><b>Compressor summary</b>: LLM4PG uses large language models to generate preferences for reinforcement learning, enabling faster convergence and better performance in complex game tasks with diverse constraints.</p><hr><h3>Unlocking Varied Perspectives: A Persona-Based Multi-Agent Framework  with Debate-Driven Text Planning for Argument Generation</h3>
<p><a href='http://arxiv.org/abs/2406.19643v1'>http://arxiv.org/abs/2406.19643v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Argument writing is challenging for humans and machines
- Current language models lack coherence and diversity in output
- Proposed persona-based multi-agent framework inspired by human debate
- Framework enables fluid and nonlinear development of ideas
- Framework improves argument quality in essay writing

Summary:
The authors propose a novel framework that simulates human debate to generate more diverse and persuasive arguments for essay writing, using multiple agents with different personas.</p><hr><h3>IDT: Dual-Task Adversarial Attacks for Privacy Protection</h3>
<p><a href='http://arxiv.org/abs/2406.19642v1'>http://arxiv.org/abs/2406.19642v1</a></p>
<p><b>Compressor summary</b>: IDT is a method that uses adversarial techniques to modify texts to protect privacy without losing utility, by identifying and changing sensitive tokens based on auxiliary models' predictions.</p><hr><h3>Efficient Event Stream Super-Resolution with Recursive Multi-Branch  Fusion</h3>
<p><a href='http://arxiv.org/abs/2406.19640v1'>http://arxiv.org/abs/2406.19640v1</a></p>
<p><b>Compressor summary</b>: RMFNet is a network that uses Feature Fusion Modules and Feature Exchange Modules to improve super-resolution of event streams by separating positive and negative events, fusing contextual information, and exchanging information between branches.</p><hr><h3>Precision matters: Precision-aware ensemble for weakly supervised  semantic segmentation</h3>
<p><a href='http://arxiv.org/abs/2406.19638v1'>http://arxiv.org/abs/2406.19638v1</a></p>
<p><b>Compressor summary</b>: ORANDNet is an ensemble method that improves semantic segmentation using CAMs from different classifiers and curriculum learning to increase precision and reduce noise.</p><hr><h3>Model Predictive Simulation Using Structured Graphical Models and  Transformers</h3>
<p><a href='http://arxiv.org/abs/2406.19635v1'>http://arxiv.org/abs/2406.19635v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Model Predictive Simulation (MPS) method that uses transformers and probabilistic graphical models to improve safety and realism of trajectories for multiple interacting agents in a simulation.</p><hr><h3>PPTFormer: Pseudo Multi-Perspective Transformer for UAV Segmentation</h3>
<p><a href='http://arxiv.org/abs/2406.19632v1'>http://arxiv.org/abs/2406.19632v1</a></p>
<p><b>Compressor summary</b>: The PPTFormer is a novel network that enhances UAV image segmentation by creating pseudo perspectives without needing multi-perspective labeled datasets, achieving state-of-the-art results.</p><hr><h3>Optimal Video Compression using Pixel Shift Tracking</h3>
<p><a href='http://arxiv.org/abs/2406.19630v1'>http://arxiv.org/abs/2406.19630v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Redundancy Removal using Shift (R²S), a video compression method that removes redundant pixels across various ML models, improving storage efficiency and adaptability.</p><hr><h3>Safety through feedback in Constrained RL</h3>
<p><a href='http://arxiv.org/abs/2406.19626v1'>http://arxiv.org/abs/2406.19626v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an approach to learn a cost function for safe reinforcement learning from trajectory-level feedback, using a surrogate objective and novelty-based sampling to reduce the burden on human evaluators.</p><hr><h3>Stochastic Zeroth-Order Optimization under Strongly Convexity and  Lipschitz Hessian: Minimax Sample Complexity</h3>
<p><a href='http://arxiv.org/abs/2406.19617v1'>http://arxiv.org/abs/2406.19617v1</a></p>
<p><b>Compressor summary</b>: This paper develops an algorithm that optimizes second-order smooth and strongly convex functions under noisy evaluations by combining bootstrapping and mirror-descent stages with a novel gradient estimator.</p><hr><h3>VarteX: Enhancing Weather Forecast through Distributed Variable  Representation</h3>
<p><a href='http://arxiv.org/abs/2406.19615v1'>http://arxiv.org/abs/2406.19615v1</a></p>
<p><b>Compressor summary</b>: VarteX is a new framework for deep learning-based weather forecasting that efficiently handles multiple variables and outperforms conventional models with fewer parameters and resources.</p><hr><h3>A Survey on Data Quality Dimensions and Tools for Machine Learning</h3>
<p><a href='http://arxiv.org/abs/2406.19614v1'>http://arxiv.org/abs/2406.19614v1</a></p>
<p><b>Compressor summary</b>: This paper surveys 17 data quality evaluation and improvement tools for machine learning, discussing their strengths, limitations, and potential applications of large language models and generative AI in this field.</p><hr><h3>A Survey on Deep Clustering: From the Prior Perspective</h3>
<p><a href='http://arxiv.org/abs/2406.19602v1'>http://arxiv.org/abs/2406.19602v1</a></p>
<p><b>Compressor summary</b>: 
Key points:
- Deep clustering is a powerful method for analyzing complex data using neural networks and prior knowledge.
- The survey reviews different types of prior knowledge used in deep clustering methods and their evolution.
- The survey provides a benchmark on five datasets and analyzes the performance of methods with diverse priors.

Summary:
The survey presents a comprehensive overview of deep clustering methods that use neural networks and prior knowledge to analyze complex data, categorizes them into six types of prior knowledge, and evaluates their performance on five datasets.</p><hr><h3>Mixture of In-Context Experts Enhance LLMs' Long Context Awareness</h3>
<p><a href='http://arxiv.org/abs/2406.19598v1'>http://arxiv.org/abs/2406.19598v1</a></p>
<p><b>Compressor summary</b>: MoICE is a novel method that enhances large language models' context awareness by using routers to select the best RoPE angles for each attention head, improving performance and efficiency on various tasks.</p><hr><h3>SK-VQA: Synthetic Knowledge Generation at Scale for Training  Context-Augmented Multimodal LLMs</h3>
<p><a href='http://arxiv.org/abs/2406.19593v1'>http://arxiv.org/abs/2406.19593v1</a></p>
<p><b>Compressor summary</b>: Synthetic data helps train large vision and language models in context-augmented generation systems by providing diverse and challenging multimodal questions.</p>