
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2024-08-06</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-08-06 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Latent-INR: A Flexible Framework for Implicit Representations of Videos  with Discriminative Semantics</h3>
<p><a href='http://arxiv.org/abs/2408.02672v1'>http://arxiv.org/abs/2408.02672v1</a></p>
<p><b>Compressor summary</b>: Implicit Neural Networks can compress videos efficiently while preserving semantic meaning, enabling various downstream applications like retrieval and chat.</p><hr><h3>Self-Taught Evaluators</h3>
<p><a href='http://arxiv.org/abs/2408.02666v1'>http://arxiv.org/abs/2408.02666v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a self-improving evaluator that uses synthetic data to train an LLM without human annotations, achieving performance comparable to top reward models.</p><hr><h3>On Using Quasirandom Sequences in Machine Learning for Model Weight  Initialization</h3>
<p><a href='http://arxiv.org/abs/2408.02654v1'>http://arxiv.org/abs/2408.02654v1</a></p>
<p><b>Compressor summary</b>: Using quasirandom number generators (QRNGs) for neural network weight initialization improves model performance and training speed compared to pseudorandom number generators (PRNGs).</p><hr><h3>Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large  Language Models?</h3>
<p><a href='http://arxiv.org/abs/2408.02651v1'>http://arxiv.org/abs/2408.02651v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a reinforcement learning method to optimize adversarial triggers for jailbreaking large language models, enhancing their effectiveness and transferability.</p><hr><h3>SEAS: Self-Evolving Adversarial Safety Optimization for Large Language  Models</h3>
<p><a href='http://arxiv.org/abs/2408.02632v1'>http://arxiv.org/abs/2408.02632v1</a></p>
<p><b>Compressor summary</b>: SEAS is a novel optimization framework that enhances the security of large language models by leveraging data generated by the model itself and refining both red team and target models through three iterative stages.</p><hr><h3>VidGen-1M: A Large-Scale Dataset for Text-to-video Generation</h3>
<p><a href='http://arxiv.org/abs/2408.02629v1'>http://arxiv.org/abs/2408.02629v1</a></p>
<p><b>Compressor summary</b>: VidGen-1M is a high-quality text-to-video training dataset created by curating videos and captions using a coarse-to-fine strategy.</p><hr><h3>DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for  Long Time-Series Forecasting</h3>
<p><a href='http://arxiv.org/abs/2408.02279v1'>http://arxiv.org/abs/2408.02279v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a dynamic tokenizer and multi-scale Transformer model for long-term time series forecasting, addressing challenges in capturing diverse characteristics and features across different temporal scales.</p><hr><h3>Geometric Algebra Meets Large Language Models: Instruction-Based  Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes</h3>
<p><a href='http://arxiv.org/abs/2408.02275v1'>http://arxiv.org/abs/2408.02275v1</a></p>
<p><b>Compressor summary</b>: The paper presents shenlong, a system that uses Large Language Models and Conformal Geometric Algebra to enable precise 3D scene editing with natural language instructions, outperforming traditional methods in accuracy and latency.</p><hr><h3>COM Kitchens: An Unedited Overhead-view Video Dataset as a  Vision-Language Benchmark</h3>
<p><a href='http://arxiv.org/abs/2408.02272v1'>http://arxiv.org/abs/2408.02272v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper introduces COM Kitchens, a dataset for procedural video understanding
- The dataset is collected using smartphones with wide-angle lenses to capture overhead-view videos of food preparation
- The paper proposes two new tasks: Online Recipe Retrieval and Dense Video Captioning on unedited Overhead-View videos

Summary:
The paper presents COM Kitchens, a novel dataset for procedural video understanding using smartphone-captured overhead-view videos of cooking activities, and introduces two new tasks based on it.</p><hr><h3>StyEmp: Stylizing Empathetic Response Generation via Multi-Grained  Prefix Encoder and Personality Reinforcement</h3>
<p><a href='http://arxiv.org/abs/2408.02271v1'>http://arxiv.org/abs/2408.02271v1</a></p>
<p><b>Compressor summary</b>: StyEmp is a system that generates empathetic responses with consistent personality using prefix mechanisms and contrastive learning.</p><hr><h3>One-Shot Collaborative Data Distillation</h3>
<p><a href='http://arxiv.org/abs/2408.02266v1'>http://arxiv.org/abs/2408.02266v1</a></p>
<p><b>Compressor summary</b>: The authors propose CollabDM, a collaborative data distillation technique that creates high-quality synthetic datasets from large machine learning training datasets in distributed environments with minimal communication cost and outperforms existing methods on skewed data and attack detection in 5G networks.</p><hr><h3>Explain via Any Concept: Concept Bottleneck Model with Open Vocabulary  Concepts</h3>
<p><a href='http://arxiv.org/abs/2408.02265v1'>http://arxiv.org/abs/2408.02265v1</a></p>
<p><b>Compressor summary</b>: The OpenCBM model allows users to add or remove concepts from a bottleneck framework, making it more interpretable and achieving better classification results than previous models.</p><hr><h3>VoxelTrack: Exploring Voxel Representation for 3D Point Cloud Object  Tracking</h3>
<p><a href='http://arxiv.org/abs/2408.02263v1'>http://arxiv.org/abs/2408.02263v1</a></p>
<p><b>Compressor summary</b>: VoxelTrack is a novel 3D object tracking framework that uses voxelization to effectively capture and model 3D spatial information for accurate position prediction.</p><hr><h3>To Aggregate or Not to Aggregate. That is the Question: A Case Study on  Annotation Subjectivity in Span Prediction</h3>
<p><a href='http://arxiv.org/abs/2408.02257v1'>http://arxiv.org/abs/2408.02257v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how to automatically predict text spans from legal problem descriptions that indicate a legal area, using a corpus of laypeople's texts annotated by lawyers, and shows that majority-voted spans perform better than disaggregated ones.</p><hr><h3>Advancing Post-OCR Correction: A Comparative Study of Synthetic Data</h3>
<p><a href='http://arxiv.org/abs/2408.02253v1'>http://arxiv.org/abs/2408.02253v1</a></p>
<p><b>Compressor summary</b>: The paper studies how synthetic data helps improve post-OCR models' performance across various languages, especially low-resource ones, by testing different data aspects and introducing a glyph similarity algorithm.</p><hr><h3>ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems</h3>
<p><a href='http://arxiv.org/abs/2408.02248v1'>http://arxiv.org/abs/2408.02248v1</a></p>
<p><b>Compressor summary</b>: ReDel is a toolkit for creating recursive multi-agent systems with flexible delegation and tool-use, which can improve performance on agentic tasks and be easily visualized and debugged.</p><hr><h3>Contrastive Learning and Abstract Concepts: The Case of Natural Numbers</h3>
<p><a href='http://arxiv.org/abs/2408.02247v1'>http://arxiv.org/abs/2408.02247v1</a></p>
<p><b>Compressor summary</b>: The authors apply contrastive learning to train a neural network to estimate discrete quantities, showing its advantages over supervised learning in certain generalization scenarios.</p><hr><h3>Evaluating Vision-Language Models for Zero-Shot Detection,  Classification, and Association of Motorcycles, Passengers, and Helmets</h3>
<p><a href='http://arxiv.org/abs/2408.02244v1'>http://arxiv.org/abs/2408.02244v1</a></p>
<p><b>Compressor summary</b>: The study uses a vision-language model to detect and classify helmet usage in motorcycle videos, achieving good results for safety and traffic enforcement.</p><hr><h3>Methods to improve run time of hydrologic models: opportunities and  challenges in the machine learning era</h3>
<p><a href='http://arxiv.org/abs/2408.02242v1'>http://arxiv.org/abs/2408.02242v1</a></p>
<p><b>Compressor summary</b>: This paper discusses the use of machine learning in hydrologic modeling, its advantages over physics-based models, and the challenges and opportunities for improving simulation speed and addressing future research needs.</p><hr><h3>BOTS-LM: Training Large Language Models for Setswana</h3>
<p><a href='http://arxiv.org/abs/2408.02239v1'>http://arxiv.org/abs/2408.02239v1</a></p>
<p><b>Compressor summary</b>: BOTS-LM is a bilingual language model for Setswana and English that performs well on translation and reasoning tasks while being computationally efficient.</p><hr><h3>Do Large Language Models Speak All Languages Equally? A Comparative  Study in Low-Resource Settings</h3>
<p><a href='http://arxiv.org/abs/2408.02237v1'>http://arxiv.org/abs/2408.02237v1</a></p>
<p><b>Compressor summary</b>: This study evaluates LLMs' performance in sentiment and hate speech tasks in low-resource South Asian languages, finding English outperforms other languages and NLI is the strongest task for GPT-4.</p><hr><h3>A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method  for Legal Charge Prediction</h3>
<p><a href='http://arxiv.org/abs/2408.02233v1'>http://arxiv.org/abs/2408.02233v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Legal charge prediction is an important task in legal AI that assigns accurate labels to case descriptions
- Existing methods use neural networks but do not leverage multi-source external knowledge effectively
- The proposed method uses a prompt learning framework to integrate knowledge from a legal knowledge base, a conversational LLM, and related legal articles
- The method achieved state-of-the-art results on CAIL-2018 and has low data dependency
- The method is also interpretable

Summary:
The paper proposes a prompt learning framework that leverages multi-source external knowledge to improve legal charge prediction, achieving better performance and interpretability than existing methods.</p><hr><h3>REVISION: Rendering Tools Enable Spatial Fidelity in Vision-Language  Models</h3>
<p><a href='http://arxiv.org/abs/2408.02231v1'>http://arxiv.org/abs/2408.02231v1</a></p>
<p><b>Compressor summary</b>: REVISION improves spatial fidelity in vision-language models by generating accurate images from text, and evaluates spatial reasoning with RevQA benchmark.</p><hr><h3>ProCreate, Dont Reproduce! Propulsive Energy Diffusion for Creative  Generation</h3>
<p><a href='http://arxiv.org/abs/2408.02226v1'>http://arxiv.org/abs/2408.02226v1</a></p>
<p><b>Compressor summary</b>: ProCreate enhances the diversity and creativity of diffusion-based image generative models by moving generated images away from reference images, and demonstrates its effectiveness on a new few-shot creative generation dataset called FSCG-8.</p><hr><h3>Large Language Model Aided QoS Prediction for Service Recommendation</h3>
<p><a href='http://arxiv.org/abs/2408.02223v1'>http://arxiv.org/abs/2408.02223v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new model (llmQoS) that uses large language models to extract information from natural language sentences describing web users and services, and predicts their quality of service.</p><hr><h3>Cross-modulated Attention Transformer for RGBT Tracking</h3>
<p><a href='http://arxiv.org/abs/2408.02222v1'>http://arxiv.org/abs/2408.02222v1</a></p>
<p><b>Compressor summary</b>: CAFormer is a novel attention model for RGBT tracking that performs self-correlation, inter-modality interaction, and search-template correlation in a unified way to improve robustness and efficiency.</p><hr><h3>Climate-Driven Doubling of Maize Loss Probability in U.S. Crop  Insurance: Spatiotemporal Prediction and Possible Policy Responses</h3>
<p><a href='http://arxiv.org/abs/2408.02217v1'>http://arxiv.org/abs/2408.02217v1</a></p>
<p><b>Compressor summary</b>: The paper uses machine learning to predict increased frequency and severity of crop losses due to climate change, suggesting changes in crop insurance policies to support growers' adaptation to the changing environment.</p><hr><h3>More Than Positive and Negative: Communicating Fine Granularity in  Medical Diagnosis</h3>
<p><a href='http://arxiv.org/abs/2408.02214v1'>http://arxiv.org/abs/2408.02214v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a fine-grained benchmark for chest X-ray analysis and presents a simple but effective method to improve AI diagnostic systems by using coarse labels in training.</p><hr><h3>ExoViP: Step-by-step Verification and Exploration with Exoskeleton  Modules for Compositional Visual Reasoning</h3>
<p><a href='http://arxiv.org/abs/2408.02210v1'>http://arxiv.org/abs/2408.02210v1</a></p>
<p><b>Compressor summary</b>: ExoViP is a "plug-and-play" method to improve visual-language programming by correcting errors in planning and execution with introspective verification.</p><hr><h3>Source-Free Domain-Invariant Performance Prediction</h3>
<p><a href='http://arxiv.org/abs/2408.02209v1'>http://arxiv.org/abs/2408.02209v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new method for estimating model performance without using source data, based on uncertainty and calibration with a generative model, and shows its superiority over existing approaches.</p><hr><h3>Evaluating the Performance of Large Language Models for SDG Mapping  (Technical Report)</h3>
<p><a href='http://arxiv.org/abs/2408.02201v1'>http://arxiv.org/abs/2408.02201v1</a></p>
<p><b>Compressor summary</b>: The study compares open-source language models' performance on the SDG mapping task, finding no significant differences among four of them and room for improvement in LLaMA 2 and Gemma.</p><hr><h3>Synergistic Learning with Multi-Task DeepONet for Efficient PDE Problem  Solving</h3>
<p><a href='http://arxiv.org/abs/2408.02198v1'>http://arxiv.org/abs/2408.02198v1</a></p>
<p><b>Compressor summary</b>: The text introduces a multi-task deep operator network (MT-DeepONet) for solving partial differential equations (PDEs) with different functional forms and geometries, improving generalization and reducing training cost.</p><hr><h3>CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs</h3>
<p><a href='http://arxiv.org/abs/2408.02193v1'>http://arxiv.org/abs/2408.02193v1</a></p>
<p><b>Compressor summary</b>: CodeACT framework improves open-source large language models' performance and efficiency in code-related tasks by selectively using high-quality data and reducing computational resources.</p><hr><h3>Unsupervised Domain Adaption Harnessing Vision-Language Pre-training</h3>
<p><a href='http://arxiv.org/abs/2408.02192v1'>http://arxiv.org/abs/2408.02192v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method called CMKD that uses VLP models to guide UDA tasks, and introduces RST to reduce storage overhead for model deployment, achieving state-of-the-art performance on standard benchmarks.</p><hr><h3>Dense Feature Interaction Network for Image Inpainting Localization</h3>
<p><a href='http://arxiv.org/abs/2408.02191v1'>http://arxiv.org/abs/2408.02191v1</a></p>
<p><b>Compressor summary</b>: DeFI-Net is a novel method for detecting image inpainting that uses a feature pyramid architecture and adaptive feature refinement to improve accuracy and edge localization.</p><hr><h3>AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing  Pipelines</h3>
<p><a href='http://arxiv.org/abs/2408.02181v1'>http://arxiv.org/abs/2408.02181v1</a></p>
<p><b>Compressor summary</b>: AssemAI is an interpretable image-based anomaly detection system for smart manufacturing pipelines, using a custom object detection model and a tailored image dataset.</p>