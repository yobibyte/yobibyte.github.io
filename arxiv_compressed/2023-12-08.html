
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2023-12-08</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2023-12-08 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Scaling Laws of Synthetic Images for Model Training ... for Now</h3>
<p>Lijie Fan,Kaifeng Chen,Dilip Krishnan,Dina Katabi,Phillip Isola,Yonglong Tian</p>
<p><a href='http://arxiv.org/abs/2312.04567v1'>http://arxiv.org/abs/2312.04567v1</a></p>
<p><b>Compressor summary</b>: This paper investigates how text-to-image models scale when training vision systems using synthetic data and identifies factors that affect this behavior, finding that synthetic images can be effective in certain scenarios but struggle with generating some concepts, limiting their usefulness for supervised image classifiers.</p><hr><h3>Gen2Det: Generate to Detect</h3>
<p>Saksham Suri,Fanyi Xiao,Animesh Sinha,Sean Chang Culatana,Raghuraman Krishnamoorthi,Chenchen Zhu,Abhinav Shrivastava</p>
<p><a href='http://arxiv.org/abs/2312.04566v1'>http://arxiv.org/abs/2312.04566v1</a></p>
<p><b>Compressor summary</b>: Gen2Det is a simple pipeline that uses state-of-the-art image generation methods to create synthetic training data for object detection, improving performance on various settings and tasks.</p><hr><h3>MuRF: Multi-Baseline Radiance Fields</h3>
<p>Haofei Xu,Anpei Chen,Yuedong Chen,Christos Sakaridis,Yulun Zhang,Marc Pollefeys,Andreas Geiger,Fisher Yu</p>
<p><a href='http://arxiv.org/abs/2312.04565v1'>http://arxiv.org/abs/2312.04565v1</a></p>
<p><b>Compressor summary</b>: MuRF is a method for sparse view synthesis that uses discretized volumes and convolutional networks to produce high-quality images across various baseline settings and scenes.</p><hr><h3>EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS</h3>
<p>Sharath Girish,Kamal Gupta,Abhinav Shrivastava</p>
<p><a href='http://arxiv.org/abs/2312.04564v1'>http://arxiv.org/abs/2312.04564v1</a></p>
<p><b>Compressor summary</b>: The authors propose a technique to reduce memory storage requirements for 3D Gaussian splatting in novel-view scene synthesis, achieving faster training and rendering speeds while maintaining visual quality.</p><hr><h3>Visual Geometry Grounded Deep Structure From Motion</h3>
<p>Jianyuan Wang,Nikita Karaev,Christian Rupprecht,David Novotny</p>
<p><a href='http://arxiv.org/abs/2312.04563v1'>http://arxiv.org/abs/2312.04563v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new deep learning pipeline called VGGSfM that reconstructs the camera poses and 3D structure of a scene from unconstrained images in an end-to-end differentiable manner, improving performance on three datasets.</p><hr><h3>NeRFiller: Completing Scenes via Generative 3D Inpainting</h3>
<p>Ethan Weber,Aleksander Hołyński,Varun Jampani,Saurabh Saxena,Noah Snavely,Abhishek Kar,Angjoo Kanazawa</p>
<p><a href='http://arxiv.org/abs/2312.04560v1'>http://arxiv.org/abs/2312.04560v1</a></p>
<p><b>Compressor summary</b>: NeRFiller uses 2D visual generative models to complete missing parts of 3D scenes or objects, achieving the most 3D consistent and plausible scene completions.</p><hr><h3>GenDeF: Learning Generative Deformation Field for Video Generation</h3>
<p>Wen Wang,Kecheng Zheng,Qiuyu Wang,Hao Chen,Zifan Shi,Ceyuan Yang,Yujun Shen,Chunhua Shen</p>
<p><a href='http://arxiv.org/abs/2312.04561v1'>http://arxiv.org/abs/2312.04561v1</a></p>
<p><b>Compressor summary</b>: The GenDeF method generates videos by warping a static image with a generative deformation field, which improves visual quality, allows for motion modeling, and enables easy video editing and processing.</p><hr><h3>PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation</h3>
<p>Zhaoxi Chen,Fangzhou Hong,Haiyi Mei,Guangcong Wang,Lei Yang,Ziwei Liu</p>
<p><a href='http://arxiv.org/abs/2312.04559v1'>http://arxiv.org/abs/2312.04559v1</a></p>
<p><b>Compressor summary</b>: PrimDiffusion is a diffusion-based framework that generates high-quality 3D human models by operating on volumetric primitives, enabling efficient rendering and flexible conditional generation.</p><hr><h3>MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar</h3>
<p>Yufan Chen,Lizhen Wang,Qijing Li,Hongjiang Xiao,Shengping Zhang,Hongxun Yao,Yebin Liu</p>
<p><a href='http://arxiv.org/abs/2312.04558v1'>http://arxiv.org/abs/2312.04558v1</a></p>
<p><b>Compressor summary</b>: MonoGaussianAvatar is a novel approach that uses 3D Gaussian points and a deformation field to create realistic head avatars from monocular portrait videos, overcoming the limitations of existing methods.</p><hr><h3>GenTron: Delving Deep into Diffusion Transformers for Image and Video  Generation</h3>
<p>Shoufa Chen,Mengmeng Xu,Jiawei Ren,Yuren Cong,Sen He,Yanping Xie,Animesh Sinha,Ping Luo,Tao Xiang,Juan-Manuel Perez-Rua</p>
<p><a href='http://arxiv.org/abs/2312.04557v1'>http://arxiv.org/abs/2312.04557v1</a></p>
<p><b>Compressor summary</b>: GenTron is a family of generative models using Transformer-based diffusion that improves visual quality and can generate videos from text, achieving high win rates in human evaluations.</p><hr><h3>Large Language Models for Mathematicians</h3>
<p>Simon Frieder,Julius Berner,Philipp Petersen,Thomas Lukasiewicz</p>
<p><a href='http://arxiv.org/abs/2312.04556v1'>http://arxiv.org/abs/2312.04556v1</a></p>
<p><b>Compressor summary</b>: The note discusses how large language models can help professional mathematicians by explaining their structure, assessing their mathematical skills, and exploring their impact on the field.</p><hr><h3>Improved Visual Grounding through Self-Consistent Explanations</h3>
<p>Ruozhen He,Paola Cascante-Bonilla,Ziyan Yang,Alexander C. Berg,Vicente Ordonez</p>
<p><a href='http://arxiv.org/abs/2312.04554v1'>http://arxiv.org/abs/2312.04554v1</a></p>
<p><b>Compressor summary</b>: The authors propose SelfEQ, a method that improves object localization in vision-and-language models by generating paraphrases and finetuning for self-consistent visual explanations.</p><hr><h3>SPIDeRS: Structured Polarization for Invisible Depth and Reflectance  Sensing</h3>
<p>Tomoki Ichikawa,Shohei Nobuhara,Ko Nishino</p>
<p><a href='http://arxiv.org/abs/2312.04553v1'>http://arxiv.org/abs/2312.04553v1</a></p>
<p><b>Compressor summary</b>: SPIDeRS uses polarized patterns of light to capture depth, surface normals, and reflectance of objects invisibly for applications in vision, xR, robotics, and HCI.</p><hr><h3>Generating Illustrated Instructions</h3>
<p>Sachit Menon,Ishan Misra,Rohit Girdhar</p>
<p><a href='http://arxiv.org/abs/2312.04552v1'>http://arxiv.org/abs/2312.04552v1</a></p>
<p><b>Compressor summary</b>: The authors introduce a task called Illustrated Instructions, which generates custom visual instructions based on text input, and propose a new model called StackedDiffusion that outperforms existing methods and enables personalized applications.</p><hr><h3>Free3D: Consistent Novel View Synthesis without 3D Representation</h3>
<p>Chuanxia Zheng,Andrea Vedaldi</p>
<p><a href='http://arxiv.org/abs/2312.04551v1'>http://arxiv.org/abs/2312.04551v1</a></p>
<p><b>Compressor summary</b>: Free3D is a novel view synthesis method that uses a 2D image generator fine-tuned with ray conditioning normalization and multi-view attention to achieve better pose encoding and consistency without needing a 3D representation.</p><hr><h3>Multiview Aerial Visual Recognition (MAVREC): Can Multi-view Improve  Aerial Visual Perception?</h3>
<p>Aritra Dutta,Srijan Das,Jacob Nielsen,Rajatsubhra Chakraborty,Mubarak Shah</p>
<p><a href='http://arxiv.org/abs/2312.04548v1'>http://arxiv.org/abs/2312.04548v1</a></p>
<p><b>Compressor summary</b>: MAVREC is a large, diverse video dataset with ground and aerial views for improving object detection in aerial images.</p><hr><h3>Digital Life Project: Autonomous 3D Characters with Social Intelligence</h3>
<p>Zhongang Cai,Jianping Jiang,Zhongfei Qing,Xinying Guo,Mingyuan Zhang,Zhengyu Lin,Haiyi Mei,Chen Wei,Ruisi Wang,Wanqi Yin,Xiangyu Fan,Han Du,Liang Pan,Peng Gao,Zhitao Yang,Yang Gao,Jiaqi Li,Tianxiang Ren,Yukun Wei,Xiaogang Wang,Chen Change Loy,Lei Yang,Ziwei Liu</p>
<p><a href='http://arxiv.org/abs/2312.04547v1'>http://arxiv.org/abs/2312.04547v1</a></p>
<p><b>Compressor summary</b>: The Digital Life Project is a framework that creates autonomous 3D characters with realistic social interactions and body movements using language and motion synthesis techniques.</p><hr><h3>Adversarial Learning for Feature Shift Detection and Correction</h3>
<p>Miriam Barrabes,Daniel Mas Montserrat,Margarita Geleta,Xavier Giro-i-Nieto,Alexander G. Ioannidis</p>
<p><a href='http://arxiv.org/abs/2312.04546v1'>http://arxiv.org/abs/2312.04546v1</a></p>
<p><b>Compressor summary</b>: The text describes a method for detecting and fixing data shifts using adversarial learning with supervised classifiers and iterative heuristics, which outperforms existing techniques.</p><hr><h3>HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a  Single Image</h3>
<p>Tong Wu,Zhibing Li,Shuai Yang,Pan Zhang,Xinggang Pan,Jiaqi Wang,Dahua Lin,Ziwei Liu</p>
<p><a href='http://arxiv.org/abs/2312.04543v1'>http://arxiv.org/abs/2312.04543v1</a></p>
<p><b>Compressor summary</b>: HyperDreamer is a new method for creating realistic and editable 3D models from a single image using advanced techniques for viewing, rendering, and editing.</p><hr><h3>Sim-to-Real Causal Transfer: A Metric Learning Approach to  Causally-Aware Interaction Representations</h3>
<p>Yuejiang Liu,Ahmad Rahimi,Po-Chien Luan,Frano Rajič,Alexandre Alahi</p>
<p><a href='http://arxiv.org/abs/2312.04540v1'>http://arxiv.org/abs/2312.04540v1</a></p>
<p><b>Compressor summary</b>: The authors study how to represent causal relationships in multi-agent systems, propose a metric learning approach for causal awareness, and demonstrate its effectiveness on pedestrian datasets.</p><hr><h3>Self-Guided Open-Vocabulary Semantic Segmentation</h3>
<p>Osman Ülger,Maksymilian Kulicki,Yuki Asano,Martin R. Oswald</p>
<p><a href='http://arxiv.org/abs/2312.04539v1'>http://arxiv.org/abs/2312.04539v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel framework called Self-Seg that uses VLMs to perform open-vocabulary image segmentation without textual input, achieving state-of-the-art results on several datasets.</p><hr><h3>Trajeglish: Learning the Language of Driving Scenarios</h3>
<p>Jonah Philion,Xue Bin Peng,Sanja Fidler</p>
<p><a href='http://arxiv.org/abs/2312.04535v1'>http://arxiv.org/abs/2312.04535v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes a method to simulate dynamic driving scenarios using discrete sequence modeling
- The method discretizes trajectories to centimeter-level resolution and models multi-agent interactions with an encoder-decoder
- The method achieves state-of-the-art realism and outperforms prior work on benchmarks
- The method can be adapted to improve performance on other datasets and evaluated for scalability and saliency

Summary:
The paper presents a data-driven, tokenized, and encoder-decoder based method to simulate realistic and interactive driving scenarios, which improves self-driving development and can be applied to different tasks.</p><hr><h3>PICTURE: PhotorealistIC virtual Try-on from UnconstRained dEsigns</h3>
<p>Shuliang Ning,Duomin Wang,Yipeng Qin,Zirong Jin,Baoyuan Wang,Xiaoguang Han</p>
<p><a href='http://arxiv.org/abs/2312.04534v1'>http://arxiv.org/abs/2312.04534v1</a></p>
<p><b>Compressor summary</b>: The paper introduces ucVTON, a novel method for realistic synthesis of personalized clothing on human images, allowing flexible specification of style and texture conditions, and enabling superior quality and user experience in virtual try-on applications.</p><hr><h3>Camera Height Doesn't Change: Unsupervised Monocular Scale-Aware  Road-Scene Depth Estimation</h3>
<p>Genki Kinoshita,Ko Nishino</p>
<p><a href='http://arxiv.org/abs/2312.04530v1'>http://arxiv.org/abs/2312.04530v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Monocular depth estimators need scale supervision or suffer from ambiguity
- StableCamH is a novel scale-aware method that uses object heights and camera height
- StableCamH does not require auxiliary sensors or supervision
- StableCamH has a learning-based size prior for car appearance
- StableCamH achieves state-of-the-art accuracy and generalizability

Summary:
StableCamH is a scale-aware monocular depth estimation method that uses object heights and camera height without auxiliary sensors or supervision. It has a learning-based size prior for cars and outperforms related methods.</p><hr><h3>Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of  Illumination and Reflectance</h3>
<p>Yuto Enyo,Ko Nishino</p>
<p><a href='http://arxiv.org/abs/2312.04529v1'>http://arxiv.org/abs/2312.04529v1</a></p>
<p><b>Compressor summary</b>: The paper introduces DRMNet, a stochastic inverse rendering method that recovers the full frequency spectrum of illumination and object reflectance from a single image using a diffusion model.</p><hr><h3>Using Large Language Models for Hyperparameter Optimization</h3>
<p>Michael R. Zhang,Nishkrit Desai,Juhan Bae,Jonathan Lorraine,Jimmy Ba</p>
<p><a href='http://arxiv.org/abs/2312.04528v1'>http://arxiv.org/abs/2312.04528v1</a></p>
<p><b>Compressor summary</b>: The paper shows how large language models can help improve hyperparameter optimization efficiency by generating code and making better decisions with limited search budgets.</p><hr><h3>Correspondences of the Third Kind: Camera Pose Estimation from Object  Reflection</h3>
<p>Kohei Yamashita,Vincent Lepetit,Ko Nishino</p>
<p><a href='http://arxiv.org/abs/2312.04527v1'>http://arxiv.org/abs/2312.04527v1</a></p>
<p><b>Compressor summary</b>: The paper introduces reflection correspondences, a new type of correspondence that helps estimate camera pose without relying on the background, and proposes methods for using all three kinds of correspondences for robust object shape estimation.</p><hr><h3>RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing  with Diffusion Models</h3>
<p>Ozgur Kara,Bariscan Kurtkaya,Hidir Yesiltepe,James M. Rehg,Pinar Yanardag</p>
<p><a href='http://arxiv.org/abs/2312.04524v1'>http://arxiv.org/abs/2312.04524v1</a></p>
<p><b>Compressor summary</b>: RAVE is a zero-shot video editing method that uses text-to-image diffusion models to create high-quality, temporally consistent, and semantically preserved videos with various edits and efficient memory requirements.</p><hr><h3>Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping</h3>
<p>Alex Costanzino,Pierluigi Zama Ramirez,Giuseppe Lisanti,Luigi Di Stefano</p>
<p><a href='http://arxiv.org/abs/2312.04521v1'>http://arxiv.org/abs/2312.04521v1</a></p>
<p><b>Compressor summary</b>: The paper presents a fast framework for anomaly detection using point clouds and RGB images by learning feature mapping between modalities and detecting inconsistencies, achieving state-of-the-art results and improving efficiency with layer pruning.</p><hr><h3>Bootstrapping Autonomous Radars with Self-Supervised Learning</h3>
<p>Yiduo Hao,Sohrab Madani,Junfeng Guan,Mohammed Alloulah,Saurabh Gupta,Haitham Hassanieh</p>
<p><a href='http://arxiv.org/abs/2312.04519v1'>http://arxiv.org/abs/2312.04519v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a self-supervised learning method to train radar models for autonomous vehicles using unlabeled data, improving object detection accuracy.</p><hr><h3>Efficient Monotonic Multihead Attention</h3>
<p>Xutai Ma,Anna Sun,Siqi Ouyang,Hirofumi Inaguma,Paden Tomasello</p>
<p><a href='http://arxiv.org/abs/2312.04515v1'>http://arxiv.org/abs/2312.04515v1</a></p>
<p><b>Compressor summary</b>: EMMA is a new translation model that improves monotonic alignment estimation, training, and inference, achieving top performance in speech-to-text translation for Spanish and English.</p><hr><h3>An LLM Compiler for Parallel Function Calling</h3>
<p>Sehoon Kim,Suhong Moon,Ryan Tabrizi,Nicholas Lee,Michael W. Mahoney,Kurt Keutzer,Amir Gholami</p>
<p><a href='http://arxiv.org/abs/2312.04511v1'>http://arxiv.org/abs/2312.04511v1</a></p>
<p><b>Compressor summary</b>: LLMCompiler is a tool that improves the efficiency and accuracy of multi-function calling in large language models by executing functions in parallel using classical compiler principles.</p><hr><h3>A Block Metropolis-Hastings Sampler for Controllable Energy-based Text  Generation</h3>
<p>Jarad Forristal,Niloofar Mireshghallah,Greg Durrett,Taylor Berg-Kirkpatrick</p>
<p><a href='http://arxiv.org/abs/2312.04510v1'>http://arxiv.org/abs/2312.04510v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new Markov Chain (MC) sampler for energy-based language models that can generate longer texts by iteratively prompting a large language model, improving both efficiency and accuracy in controlled text generation tasks.</p><hr><h3>Graph Metanetworks for Processing Diverse Neural Architectures</h3>
<p>Derek Lim,Haggai Maron,Marc T. Law,Jonathan Lorraine,James Lucas</p>
<p><a href='http://arxiv.org/abs/2312.04501v1'>http://arxiv.org/abs/2312.04501v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Graph Metanetworks (GMNs), a generalizable method for processing graphs representing input neural networks, which can handle various neural architectures and are expressive and equivariant to parameter permutation symmetries.</p><hr><h3>FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation</h3>
<p>Xiang Xu,Lingdong Kong,Hui Shuai,Qingshan Liu</p>
<p><a href='http://arxiv.org/abs/2312.04484v1'>http://arxiv.org/abs/2312.04484v1</a></p>
<p><b>Compressor summary</b>: FRNet restores contextual information in range-view LiDAR segmentation using frustum-based feature extraction and fusion, achieving competitive performance with high efficiency.</p><hr><h3>Hierarchical Spatio-temporal Decoupling for Text-to-Video Generation</h3>
<p>Zhiwu Qing,Shiwei Zhang,Jiayu Wang,Xiang Wang,Yujie Wei,Yingya Zhang,Changxin Gao,Nong Sang</p>
<p><a href='http://arxiv.org/abs/2312.04483v1'>http://arxiv.org/abs/2312.04483v1</a></p>
<p><b>Compressor summary</b>: HiGen is a diffusion model-based method that improves text-to-video generation by decoupling spatial and temporal factors, leading to more realistic and diverse videos with semantics accuracy and motion stability.</p><hr><h3>GSGFormer: Generative Social Graph Transformer for Multimodal Pedestrian  Trajectory Prediction</h3>
<p>Zhongchang Luo,Marion Robin,Pavan Vasishta</p>
<p><a href='http://arxiv.org/abs/2312.04479v1'>http://arxiv.org/abs/2312.04479v1</a></p>
<p><b>Compressor summary</b>: GSGFormer is a new generative model that predicts pedestrian trajectories by considering complex interactions between pedestrians and their environment, offering diverse behavioral modalities and performing well even with limited data.</p><hr><h3>Chain of Code: Reasoning with a Language Model-Augmented Code Emulator</h3>
<p>Chengshu Li,Jacky Liang,Andy Zeng,Xinyun Chen,Karol Hausman,Dorsa Sadigh,Sergey Levine,Li Fei-Fei,Fei Xia,Brian Ichter</p>
<p><a href='http://arxiv.org/abs/2312.04474v1'>http://arxiv.org/abs/2312.04474v1</a></p>
<p><b>Compressor summary</b>: Chain of Code is a method to improve language models' ability to reason by having them write and emulate code for various linguistic tasks, leading to better performance on reasoning benchmarks.</p><hr><h3>On the Learnability of Watermarks for Language Models</h3>
<p>Chenchen Gu,Xiang Lisa Li,Percy Liang,Tatsunori Hashimoto</p>
<p><a href='http://arxiv.org/abs/2312.04469v1'>http://arxiv.org/abs/2312.04469v1</a></p>
<p><b>Compressor summary</b>: The paper proposes watermark distillation, a method for teaching models to generate watermarked text with high detectability, and explores its limitations.</p><hr><h3>Emotional Speech-driven 3D Body Animation via Disentangled Latent  Diffusion</h3>
<p>Kiran Chhatre,Radek Daněček,Nikos Athanasiou,Giorgio Becherini,Christopher Peters,Michael J. Black,Timo Bolkart</p>
<p><a href='http://arxiv.org/abs/2312.04466v1'>http://arxiv.org/abs/2312.04466v1</a></p>
<p><b>Compressor summary</b>: AMUSE is a model that generates realistic 3D human gestures from speech, controlling for content, emotion, and style.</p><hr><h3>FitDiff: Robust monocular 3D facial shape and reflectance estimation  using Diffusion Models</h3>
<p>Stathis Galanakis,Alexandros Lattas,Stylianos Moschoglou,Stefanos Zafeiriou</p>
<p><a href='http://arxiv.org/abs/2312.04465v1'>http://arxiv.org/abs/2312.04465v1</a></p>
<p><b>Compressor summary</b>: FitDiff is a diffusion-based 3D face model that uses a 2D image to generate realistic and relightable avatars with high performance.</p><hr><h3>Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement  Learning with General Function Approximation</h3>
<p>Jiayi Huang,Han Zhong,Liwei Wang,Lin F. Yang</p>
<p><a href='http://arxiv.org/abs/2312.04464v1'>http://arxiv.org/abs/2312.04464v1</a></p>
<p><b>Compressor summary</b>: UCRL-WVTR is an algorithm for reinforcement learning that eliminates the planning horizon, achieves sharp regret bounds, and is computationally efficient.</p><hr><h3>PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</h3>
<p>Zhen Li,Mingdeng Cao,Xintao Wang,Zhongang Qi,Ming-Ming Cheng,Ying Shan</p>
<p><a href='http://arxiv.org/abs/2312.04461v1'>http://arxiv.org/abs/2312.04461v1</a></p>
<p><b>Compressor summary</b>: PhotoMaker is a fast text-to-image generation method that preserves identity information by encoding multiple input images into a unified ID representation, enabling various applications.</p><hr><h3>Fortify the Shortest Stave in Attention: Enhancing Context Awareness of  Large Language Models for Effective Tool Use</h3>
<p>Yuhan Chen,Ang Lv,Ting-En Lin,Changyu Chen,Yuchuan Wu,Fei Huang,Yongbin Li,Rui Yan</p>
<p><a href='http://arxiv.org/abs/2312.04455v1'>http://arxiv.org/abs/2312.04455v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Attention Buckets, a method that improves large language models' tool use performance by shaping their attention waveform with multiple processes and angles.</p><hr><h3>OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization</h3>
<p>Shmuel Amar,Liat Schiff,Ori Ernst,Asi Shefer,Ori Shapira,Ido Dagan</p>
<p><a href='http://arxiv.org/abs/2312.04440v1'>http://arxiv.org/abs/2312.04440v1</a></p>
<p><b>Compressor summary</b>: The paper introduces OpenAsp, a benchmark dataset for multi-document aspect-based summarization, created from existing datasets using a novel annotation protocol.</p><hr><h3>DreamVideo: Composing Your Dream Videos with Customized Subject and  Motion</h3>
<p>Yujie Wei,Shiwei Zhang,Zhiwu Qing,Hangjie Yuan,Zhiheng Liu,Yu Liu,Yingya Zhang,Jingren Zhou,Hongming Shan</p>
<p><a href='http://arxiv.org/abs/2312.04433v1'>http://arxiv.org/abs/2312.04433v1</a></p>
<p><b>Compressor summary</b>: DreamVideo is a method to generate personalized videos from static images and motion videos by learning subject appearance and target motion patterns using textual inversion, fine-tuning, and adapters.</p><hr><h3>Approximate Caching for Efficiently Serving Diffusion Models</h3>
<p>Shubham Agarwal,Subrata Mitra,Sarthak Chakraborty,Srikrishna Karanam,Koyel Mukherjee,Shiv Saini</p>
<p><a href='http://arxiv.org/abs/2312.04429v1'>http://arxiv.org/abs/2312.04429v1</a></p>
<p><b>Compressor summary</b>: The paper introduces approximate-caching, a technique that reduces resource consumption and latency in text-to-image generation using diffusion models by reusing intermediate noise states for similar prompts.</p><hr><h3>Cascade-Zero123: One Image to Highly Consistent 3D with Self-Prompted  Nearby Views</h3>
<p>Yabo Chen,Jiemin Fang,Yuyang Huang,Taoran Yi,Xiaopeng Zhang,Lingxi Xie,Xinggang Wang,Wenrui Dai,Hongkai Xiong,Qi Tian</p>
<p><a href='http://arxiv.org/abs/2312.04424v1'>http://arxiv.org/abs/2312.04424v1</a></p>
<p><b>Compressor summary</b>: The authors propose a cascade generation framework called Cascade-Zero123 that uses two Zero-1-to-3 models to generate multi-view 3D images from one single image, addressing the challenges of geometric and visual consistency across views for complex objects.</p><hr><h3>Scalable Knowledge Graph Construction and Inference on Human Genome  Variants</h3>
<p>Shivika Prasanna,Deepthi Rao,Eduardo Simoes,Praveen Rao</p>
<p><a href='http://arxiv.org/abs/2312.04423v1'>http://arxiv.org/abs/2312.04423v1</a></p>
<p><b>Compressor summary</b>: The text describes how variant-level information from RNA-sequences of COVID-19 patients was represented as a large, scalable knowledge graph, which was used for analysis and inference tasks.</p><hr><h3>Monitoring Sustainable Global Development Along Shared Socioeconomic  Pathways</h3>
<p>Michelle W. L. Wan,Jeffrey N. Clark,Edward A. Small,Elena Fillola Mayoral,Raúl Santos-Rodríguez</p>
<p><a href='http://arxiv.org/abs/2312.04416v1'>http://arxiv.org/abs/2312.04416v1</a></p>
<p><b>Compressor summary</b>: The authors propose methods to measure and track sustainable development using data integration and machine learning.</p><hr><h3>Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models</h3>
<p>Jiayi Guo,Xingqian Xu,Yifan Pu,Zanlin Ni,Chaofei Wang,Manushree Vasu,Shiji Song,Gao Huang,Humphrey Shi</p>
<p><a href='http://arxiv.org/abs/2312.04410v1'>http://arxiv.org/abs/2312.04410v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Smooth Diffusion, a new category of diffusion models that improve latent space smoothness for better text-to-image generation and other downstream tasks.</p><hr><h3>On the Impact of Multi-dimensional Local Differential Privacy on  Fairness</h3>
<p>karima Makhlouf,Heber H. Arcolezi,Sami Zhioua,Ghassen Ben Brahim,Catuscia Palamidessi</p>
<p><a href='http://arxiv.org/abs/2312.04404v1'>http://arxiv.org/abs/2312.04404v1</a></p>
<p><b>Compressor summary</b>: This paper studies how local differential privacy (LDP) affects fairness when multiple sensitive attributes are used, and provides recommendations for balancing privacy, fairness, and utility in machine learning applications.</p><hr><h3>OT-Attack: Enhancing Adversarial Transferability of Vision-Language  Models via Optimal Transport Optimization</h3>
<p>Dongchen Han,Xiaojun Jia,Yang Bai,Jindong Gu,Yang Liu,Xiaochun Cao</p>
<p><a href='http://arxiv.org/abs/2312.04403v1'>http://arxiv.org/abs/2312.04403v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method, OT-Attack, to generate high-transferability adversarial examples for VLP models by optimizing the alignment between data-augmented image and text pairs using optimal transport theory.</p><hr><h3>Intelligent Anomaly Detection for Lane Rendering Using Transformer with  Self-Supervised Pre-Training and Customized Fine-Tuning</h3>
<p>Yongqi Dong,Xingmin Lu,Ruohan Li,Wei Song,Bart van Arem,Haneen Farah</p>
<p><a href='http://arxiv.org/abs/2312.04398v1'>http://arxiv.org/abs/2312.04398v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a four-phase pipeline to detect anomalies in lane rendering maps using self-supervised pre-training with MiM, customized fine-tuning, and post-processing, improving accuracy and efficiency.</p><hr><h3>PhysHOI: Physics-Based Imitation of Dynamic Human-Object Interaction</h3>
<p>Yinhuai Wang,Jing Lin,Ailing Zeng,Zhengyi Luo,Jian Zhang,Lei Zhang</p>
<p><a href='http://arxiv.org/abs/2312.04393v1'>http://arxiv.org/abs/2312.04393v1</a></p>
<p><b>Compressor summary</b>: The text describes a new approach called PhysHOI for teaching humanoid robots to imitate human-object interaction using physics-based models and contact graph rewards without task-specific rewards, as well as introducing a dataset of basketball skills for testing the approach.</p><hr><h3>Model-Based Epistemic Variance of Values for Risk-Aware Policy  Optimization</h3>
<p>Carlos E. Luis,Alessandro G. Bottero,Julia Vinogradska,Felix Berkenkamp,Jan Peters</p>
<p><a href='http://arxiv.org/abs/2312.04386v1'>http://arxiv.org/abs/2312.04386v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new uncertainty Bellman equation for model-based reinforcement learning that improves exploration and policy optimization, and introduces QU-SAC, an algorithm that can handle risk-seeking or risk-averse objectives.</p><hr><h3>How much informative is your XAI? A decision-making assessment task to  objectively measure the goodness of explanations</h3>
<p>Marco Matarese,Francesco Rea,Alessandra Sciutti</p>
<p><a href='http://arxiv.org/abs/2312.04379v1'>http://arxiv.org/abs/2312.04379v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an assessment task to measure and compare the information power of XAI systems in user-centred approaches, which could improve interaction between users and systems.</p><hr><h3>LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language  Model Programs</h3>
<p>Yunsheng Ma,Can Cui,Xu Cao,Wenqian Ye,Peiran Liu,Juanwu Lu,Amr Abdelraouf,Rohit Gupta,Kyungtae Han,Aniket Bera,James M. Rehg,Ziran Wang</p>
<p><a href='http://arxiv.org/abs/2312.04372v1'>http://arxiv.org/abs/2312.04372v1</a></p>
<p><b>Compressor summary</b>: LaMPilot is a framework for autonomous driving that uses code generation with behavioral primitives to handle user instructions, and evaluates LLMs on a custom benchmark with GPT-4 achieving high performance.</p><hr><h3>SingingHead: A Large-scale 4D Dataset for Singing Head Animation</h3>
<p>Sijing Wu,Yunhao Li,Weitian Zhang,Jun Jia,Yucheng Zhu,Yichao Yan,Guangtao Zhai</p>
<p><a href='http://arxiv.org/abs/2312.04369v1'>http://arxiv.org/abs/2312.04369v1</a></p>
<p><b>Compressor summary</b>: The paper introduces SingingHead, a large dataset for singing head animation, and UniSinger, a framework that uses it to achieve both 3D and 2D facial animation for singing.</p><hr><h3>DemoCaricature: Democratising Caricature Generation with a Rough Sketch</h3>
<p>Dar-Yen Chen,Subhadeep Koley,Aneeshan Sain,Pinaki Nath Chowdhury,Tao Xiang,Ayan Kumar Bhunia,Yi-Zhe Song</p>
<p><a href='http://arxiv.org/abs/2312.04364v1'>http://arxiv.org/abs/2312.04364v1</a></p>
<p><b>Compressor summary</b>: The paper introduces methods for generating personalized caricatures from photos and sketches, balancing abstraction and identity while preserving creativity.</p><hr><h3>PCoQA: Persian Conversational Question Answering Dataset</h3>
<p>Hamed Hematian Hemati,Atousa Toghyani,Atena Souri,Sayed Hesam Alavian,Hossein Sameti,Hamid Beigy</p>
<p><a href='http://arxiv.org/abs/2312.04362v1'>http://arxiv.org/abs/2312.04362v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces PCoQA, a Persian conversational question answering dataset with challenges like open-ended non-factual answers and longer answers.</p><hr><h3>CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language  Models</h3>
<p>Zhijing Jin,Yuen Chen,Felix Leeb,Luigi Gresele,Ojasv Kamal,Zhiheng Lyu,Kevin Blin,Fernando Gonzalez Adauto,Max Kleiman-Weiner,Mrinmaya Sachan,Bernhard Schölkopf</p>
<p><a href='http://arxiv.org/abs/2312.04350v1'>http://arxiv.org/abs/2312.04350v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new natural language processing task to evaluate whether large language models can perform causal inference using formal rules, and present a challenging dataset and prompting strategy for this purpose.</p><hr><h3>Improved Efficient Two-Stage Denoising Diffusion Power System  Measurement Recovery Against False Data Injection Attacks and Data Losses</h3>
<p>Jianhua Pei,Jingyu Wang,Dongyuan Shi,Ping Wang</p>
<p><a href='http://arxiv.org/abs/2312.04346v1'>http://arxiv.org/abs/2312.04346v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a two-stage denoising diffusion model for accurate power system measurement recovery despite various uncertainties and complex dynamics, with improved efficiency and robustness.</p><hr><h3>Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on  Prompt Engineering Strategies</h3>
<p>Pengcheng Chen,Ziyan Huang,Zhongying Deng,Tianbin Li,Yanzhou Su,Haoyu Wang,Jin Ye,Yu Qiao,Junjun He</p>
<p><a href='http://arxiv.org/abs/2312.04344v1'>http://arxiv.org/abs/2312.04344v1</a></p>
<p><b>Compressor summary</b>: The paper examines how to improve GPT-4V's medical imaging interpretation skills using prompt engineering techniques, leading to more reliable and valuable insights for healthcare.</p><hr><h3>Causality and Explainability for Trustworthy Integrated Pest Management</h3>
<p>Ilias Tsoumas,Vasileios Sitokonstantinou,Georgios Giannarakis,Evagelia Lampiri,Christos Athanassiou,Gustau Camps-Valls,Charalampos Kontoes,Ioannis Athanasiadis</p>
<p><a href='http://arxiv.org/abs/2312.04343v1'>http://arxiv.org/abs/2312.04343v1</a></p>
<p><b>Compressor summary</b>: The authors propose an advanced data analysis framework to help farmers adopt Integrated Pest Management (IPM) practices by providing accurate pest predictions, interpretable advice, and effective assessments.</p><hr><h3>Merging by Matching Models in Task Subspaces</h3>
<p>Derek Tam,Mohit Bansal,Colin Raffel</p>
<p><a href='http://arxiv.org/abs/2312.04339v1'>http://arxiv.org/abs/2312.04339v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new method called MaTS for merging models by matching them based on their task subspace, which improves performance and allows solving intractable problems with various initializations and estimates.</p><hr><h3>Multi-View Unsupervised Image Generation with Cross Attention Guidance</h3>
<p>Llukman Cerkezi,Aram Davtyan,Sepehr Sameni,Paolo Favaro</p>
<p><a href='http://arxiv.org/abs/2312.04337v1'>http://arxiv.org/abs/2312.04337v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new method for unsupervised training of a diffusion model that can synthesize novel views from single-category datasets using object poses identified by clustering and cross-view consistency ensured by hard-attention guidance, achieving state-of-the-art results on real and synthetic images.</p><hr><h3>Towards a Perceptual Evaluation Framework for Lighting Estimation</h3>
<p>Justine Giroux,Mohammad Reza Karimi Dastjerdi,Yannick Hold-Geoffroy,Javier Vazquez-Corral,Jean-François Lalonde</p>
<p><a href='http://arxiv.org/abs/2312.04334v1'>http://arxiv.org/abs/2312.04334v1</a></p>
<p><b>Compressor summary</b>: The authors propose a psychophysical experiment to measure human preference for relit virtual scenes and show that existing image quality assessment metrics do not capture human perception, but a combination of them can improve the evaluation of lighting estimation algorithms.</p><hr><h3>Beyond Surface: Probing LLaMA Across Scales and Layers</h3>
<p>Nuo Chen,Ning Wu,Shining Liang,Ming Gong,Linjun Shou,Dongmei Zhang,Jia Li</p>
<p><a href='http://arxiv.org/abs/2312.04333v1'>http://arxiv.org/abs/2312.04333v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes LLaMA, a natural language processing model, using multiple-choice tasks to measure its understanding in reasoning and computation, finding that larger sizes improve reasoning but not knowledge, and lower layers lack arithmetic and facts while upper layers have more computational power and real-world knowledge.</p><hr><h3>Surrogate Modelling for Sea Ice Concentration using Lightweight Neural  Ensemble</h3>
<p>Julia Borisova,Nikolay O. Nikitin</p>
<p><a href='http://arxiv.org/abs/2312.04330v1'>http://arxiv.org/abs/2312.04330v1</a></p>
<p><b>Compressor summary</b>: LANE-SI is an adaptive deep learning model that forecasts sea ice concentration in the Arctic, achieving comparable or better results than existing physical models.</p><hr><h3>A Multi-scale Information Integration Framework for Infrared and Visible  Image Fusion</h3>
<p>Guang Yang,Jie Li,Hanxiao Lei,Xinbo Gao</p>
<p><a href='http://arxiv.org/abs/2312.04328v1'>http://arxiv.org/abs/2312.04328v1</a></p>
<p><b>Compressor summary</b>: The authors propose a multi-scale dual attention framework for fusing infrared and visible images, which measures and integrates complementary information at different scales using structure and loss function, and achieves robust and informative results across scenarios.</p><hr><h3>Learning to sample in Cartesian MRI</h3>
<p>Thomas Sanchez</p>
<p><a href='http://arxiv.org/abs/2312.04327v1'>http://arxiv.org/abs/2312.04327v1</a></p>
<p><b>Compressor summary</b>: The thesis proposes two algorithms for accelerating MRI acquisition and improving image quality, focusing on Cartesian MRI techniques and comparing them with deep learning methods.</p><hr><h3>iDesigner: A High-Resolution and Complex-Prompt Following Text-to-Image  Diffusion Model for Interior Design</h3>
<p>Ruyi Gan,Xiaojun Wu,Junyu Lu,Yuanhe Tian,Dixiang Zhang,Ziwei Wu,Renliang Sun,Chang Liu,Jiaxing Zhang,Pingjian Zhang,Yan Song</p>
<p><a href='http://arxiv.org/abs/2312.04326v1'>http://arxiv.org/abs/2312.04326v1</a></p>
<p><b>Compressor summary</b>: The paper presents a text-to-image model for interior design that uses curriculum learning and reinforcement learning to improve prompt-following capabilities and generate high-quality images based on textual descriptions.</p><hr><h3>MIMo: A Multi-Modal Infant Model for Studying Cognitive Development</h3>
<p>Dominik Mattern,Pierre Schumacher,Francisco M. López,Marcel C. Raabe,Markus R. Ernst,Arthur Aubret,Jochen Triesch</p>
<p><a href='http://arxiv.org/abs/2312.04318v1'>http://arxiv.org/abs/2312.04318v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses an open-source multi-modal infant model called MIMo, which simulates early human cognitive development through embodied interactions with the physical and social environment.</p><hr><h3>GPT4SGG: Synthesizing Scene Graphs from Holistic and Region-specific  Narratives</h3>
<p>Zuyao Chen,Jinlin Wu,Zhen Lei,Zhaoxiang Zhang,Changwen Chen</p>
<p><a href='http://arxiv.org/abs/2312.04314v1'>http://arxiv.org/abs/2312.04314v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new method, GPT4SGG, to generate scene graphs from detailed narratives based on images, which improves upon traditional language parsing and localization methods for scene graph generation.</p><hr><h3>Finding Interpretable Class-Specific Patterns through Efficient Neural  Search</h3>
<p>Nils Philipp Walter,Jonas Fischer,Jilles Vreeken</p>
<p><a href='http://arxiv.org/abs/2312.04311v1'>http://arxiv.org/abs/2312.04311v1</a></p>
<p><b>Compressor summary</b>: The proposed binary neural network architecture DIFFNAPS can extract differential patterns from high-dimensional data in a scalable and interpretable way, improving the understanding of cellular processes and potentially leading to novel treatments.</p><hr><h3>A Structural-Clustering Based Active Learning for Graph Neural Networks</h3>
<p>Ricky Maulana Fajri,Yulong Pei,Lu Yin,Mykola Pechenizkiy</p>
<p><a href='http://arxiv.org/abs/2312.04307v1'>http://arxiv.org/abs/2312.04307v1</a></p>
<p><b>Compressor summary</b>: The Structural-Clustering PageRank method for improved Active learning (SPA) is a simple and effective approach to select informative and central nodes from graph-structured data using community detection and PageRank scoring.</p><hr><h3>nerblackbox: A High-level Library for Named Entity Recognition in Python</h3>
<p>Felix Stollenwerk</p>
<p><a href='http://arxiv.org/abs/2312.04306v1'>http://arxiv.org/abs/2312.04306v1</a></p>
<p><b>Compressor summary</b>: nerblackbox is a python library that simplifies using transformer-based models for named entity recognition, offering various options for training, evaluation, and inference.</p><hr><h3>Prompt Highlighter: Interactive Control for Multi-Modal LLMs</h3>
<p>Yuechen Zhang,Shengju Qian,Bohao Peng,Shu Liu,Jiaya Jia</p>
<p><a href='http://arxiv.org/abs/2312.04302v1'>http://arxiv.org/abs/2312.04302v1</a></p>
<p><b>Compressor summary</b>: The study introduces Prompt Highlighter, a method to control text generation from multi-modal LLMs by highlighting specific prompt spans for focused and customized output.</p><hr><h3>Cross-codex Learning for Reliable Scribe Identification in Medieval  Manuscripts</h3>
<p>Julius Weißmann,Markus Seidl,Anya Dietrich,Martin Haltrich</p>
<p><a href='http://arxiv.org/abs/2312.04296v1'>http://arxiv.org/abs/2312.04296v1</a></p>
<p><b>Compressor summary</b>: The paper shows how using cross-codex training data and neural networks can improve scribe identification from historic manuscripts, allowing for more accurate and efficient paleographic analysis.</p><hr><h3>Estimating Countries with Similar Maternal Mortality Rate using Cluster  Analysis and Pairing Countries with Identical MMR</h3>
<p>S. Nandini,Sanjjushri Varshini R</p>
<p><a href='http://arxiv.org/abs/2312.04275v1'>http://arxiv.org/abs/2312.04275v1</a></p>
<p><b>Compressor summary</b>: The text discusses how machine learning can be used to analyze maternal mortality rates in different countries and identify similarities and differences in their factors affecting these rates.</p><hr><h3>Invariant Random Forest: Tree-Based Model Solution for OOD  Generalization</h3>
<p>Yufan Liao,Qi Wu,Xing Yan</p>
<p><a href='http://arxiv.org/abs/2312.04273v1'>http://arxiv.org/abs/2312.04273v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Invariant Decision Tree (IDT) and Invariant Random Forest (IRF), novel methods for out-of-distribution generalization in decision tree models, motivated by theory and validated by experiments.</p><hr><h3>Activity Grammars for Temporal Action Segmentation</h3>
<p>Dayoung Gong,Joonseok Lee,Deunsol Jung,Suha Kwak,Minsu Cho</p>
<p><a href='http://arxiv.org/abs/2312.04266v1'>http://arxiv.org/abs/2312.04266v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an activity grammar to help neural networks predict actions from videos more accurately and understandably.</p><hr><h3>Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for  Domain Generalized Semantic Segmentation</h3>
<p>Zhixiang Wei,Lin Chen,Yi Jin,Xiaoxiao Ma,Tianle Liu,Pengyang Lin,Ben Wang,Huaian Chen,Jinjin Zheng</p>
<p><a href='http://arxiv.org/abs/2312.04265v1'>http://arxiv.org/abs/2312.04265v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Rein, a robust fine-tuning method that uses fewer trainable parameters to improve semantic segmentation with pre-trained vision models, achieving state-of-the-art results.</p><hr><h3>PsyChat: A Client-Centric Dialogue System for Mental Health Support</h3>
<p>Huachuan Qiu,Anqi Li,Lizhi Ma,Zhenzhong Lan</p>
<p><a href='http://arxiv.org/abs/2312.04262v1'>http://arxiv.org/abs/2312.04262v1</a></p>
<p><b>Compressor summary</b>: PsyChat is a client-centric dialogue system that provides psychological support through online chat by recognizing client behaviors and generating appropriate responses.</p><hr><h3>Extending Answer Set Programming with Rational Numbers</h3>
<p>Francesco Pacenza,Jessica Zangari</p>
<p><a href='http://arxiv.org/abs/2312.04249v1'>http://arxiv.org/abs/2312.04249v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an extension to Answer Set Programming (ASP) that approximates non-integers with rational numbers, improving its ability to model real-world data and information while preserving declarativity and reproducibility.</p><hr><h3>TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes</h3>
<p>Xuying Zhang,Bo-Wen Yin,Yuming Chen,Zheng Lin,Yunheng Li,Qibin Hou,Ming-Ming Cheng</p>
<p><a href='http://arxiv.org/abs/2312.04248v1'>http://arxiv.org/abs/2312.04248v1</a></p>
<p><b>Compressor summary</b>: TeMO is a novel framework that uses Decoupled Graph Attention and Cross-Grained Contrast supervision to style multiple objects in 3D scenes.</p><hr><h3>Detecting and Restoring Non-Standard Hands in Stable Diffusion Generated  Images</h3>
<p>Yiqun Zhang,Zhenyue Qin,Yang Liu,Dylan Campbell</p>
<p><a href='http://arxiv.org/abs/2312.04236v1'>http://arxiv.org/abs/2312.04236v1</a></p>
<p><b>Compressor summary</b>: The authors present a method to correct anatomical errors in hand images generated by Stable Diffusion using a specialized dataset, detection, pose estimation, ControlNet, and InstructPix2Pix.</p><hr><h3>Graph Convolutions Enrich the Self-Attention in Transformers!</h3>
<p>Jeongwhan Choi,Hyowon Wi,Jayoung Kim,Yehjin Shin,Kookjin Lee,Nathaniel Trask,Noseong Park</p>
<p><a href='http://arxiv.org/abs/2312.04234v1'>http://arxiv.org/abs/2312.04234v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new self-attention mechanism called graph-filter-based self-attention (GFSA) that improves Transformer performance across different tasks by addressing the oversmoothing problem.</p><hr><h3>Fine-tune vision foundation model for crack segmentation in civil  infrastructures</h3>
<p>Kang Ge,Chen Wang,Yutao Guo</p>
<p><a href='http://arxiv.org/abs/2312.04233v1'>http://arxiv.org/abs/2312.04233v1</a></p>
<p><b>Compressor summary</b>: The authors propose CrackSAM, a large foundation model fine-tuned for crack segmentation using two efficient methods, and show its excellent performance on two unique datasets and challenging conditions.</p><hr><h3>Adventures of Trustworthy Vision-Language Models: A Survey</h3>
<p>Mayank Vatsa,Anubhooti Jain,Richa Singh</p>
<p><a href='http://arxiv.org/abs/2312.04231v1'>http://arxiv.org/abs/2312.04231v1</a></p>
<p><b>Compressor summary</b>: This paper examines vision-language transformers using BRI principles to improve their trustworthiness and accountability in various applications.</p><hr><h3>TLCE: Transfer-Learning Based Classifier Ensembles for Few-Shot  Class-Incremental Learning</h3>
<p>Shuangmei Wang,Yang Cao,Tieru Wu</p>
<p><a href='http://arxiv.org/abs/2312.04225v1'>http://arxiv.org/abs/2312.04225v1</a></p>
<p><b>Compressor summary</b>: TLCE is a method that uses multiple pre-trained models and episodic training to recognize new classes without forgetting old ones or overfitting, achieving better results than existing few-shot class-incremental learning approaches.</p><hr><h3>Swap distance minimization in SOV languages. Cognitive and mathematical  foundations</h3>
<p>Ramon Ferrer-i-Cancho,Savithry Namboodiripad</p>
<p><a href='http://arxiv.org/abs/2312.04219v1'>http://arxiv.org/abs/2312.04219v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses the principle of swap distance minimization in word order variations and its cognitive underpinning, and tests it on three flexible order SOV languages.</p><hr><h3>CODEX: A Cluster-Based Method for Explainable Reinforcement Learning</h3>
<p>Timothy K. Mathes,Jessica Inman,Andrés Colón,Simon Khan</p>
<p><a href='http://arxiv.org/abs/2312.04216v1'>http://arxiv.org/abs/2312.04216v1</a></p>
<p><b>Compressor summary</b>: The paper introduces CODEX, a method that uses semantic clustering to summarize RL agent behavior in state-action space, making it easier to explain and build trust in high-risk applications.</p><hr><h3>Constraint Model for the Satellite Image Mosaic Selection Problem</h3>
<p>Manuel Combarro Simón,Pierre Talbot,Grégoire Danoy,Jedrzej Musial,Mohammed Alswaitti,Pascal Bouvry</p>
<p><a href='http://arxiv.org/abs/2312.04210v1'>http://arxiv.org/abs/2312.04210v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Satellite image mosaic selection problem is a challenge when optimizing multiple parameters
- The input includes area of interest, satellite images, requirements, and objectives
- The authors propose a new dataset and two models to solve the problem

Summary:
The paper presents a new problem of selecting satellite images to create mosaics that meet various criteria, and proposes two models and a realistic dataset to address it.</p><hr><h3>Constrained Hierarchical Clustering via Graph Coarsening and Optimal  Cuts</h3>
<p>Eliabelle Mauduit,Andrea Simonetto</p>
<p><a href='http://arxiv.org/abs/2312.04209v1'>http://arxiv.org/abs/2312.04209v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses a method for clustering words with both horizontal and vertical constraints using a two-step algorithm that combines soft constraints, graph coarsening, and optimal cut heights.</p><hr><h3>SAMBA: A Trainable Segmentation Web-App with Smart Labelling</h3>
<p>Ronan Docherty,Isaac Squires,Antonis Vamvakeros,Samuel J. Cooper</p>
<p><a href='http://arxiv.org/abs/2312.04197v1'>http://arxiv.org/abs/2312.04197v1</a></p>
<p><b>Compressor summary</b>: SAMBA is a web-based trainable segmentation tool for materials science images that uses SAM for label suggestions and a random forest classifier for robust segmentations.</p><hr><h3>Language Model Knowledge Distillation for Efficient Question Answering  in Spanish</h3>
<p>Adrián Bazaga,Pietro Liò,Gos Micklem</p>
<p><a href='http://arxiv.org/abs/2312.04193v1'>http://arxiv.org/abs/2312.04193v1</a></p>
<p><b>Compressor summary</b>: The authors develop a smaller, efficient Spanish language model for question answering based on knowledge distillation from a larger model.</p><hr><h3>Joint-Individual Fusion Structure with Fusion Attention Module for  Multi-Modal Skin Cancer Classification</h3>
<p>Peng Tang,Xintong Yan,Yang Nan,Xiaobin Hu,Xiaobin Hu,Bjoern H Menzee. Sebastian Krammer,Tobias Lasser</p>
<p><a href='http://arxiv.org/abs/2312.04189v1'>http://arxiv.org/abs/2312.04189v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new fusion method combining dermatological images and patient metadata for skin cancer classification using a joint-individual fusion structure and a fusion attention module, which improves accuracy over existing methods.</p><hr><h3>AI and Jobs: Has the Inflection Point Arrived? Evidence from an Online  Labor Platform</h3>
<p>Dandan Qiao,Huaxia Rui,Qian Xiong</p>
<p><a href='http://arxiv.org/abs/2312.04180v1'>http://arxiv.org/abs/2312.04180v1</a></p>
<p><b>Compressor summary</b>: The text discusses how artificial intelligence performance affects human workers' jobs in different occupations and proposes a framework to analyze the impact of AI on employment.</p><hr><h3>A novel feature selection framework for incomplete data</h3>
<p>Cong Guo</p>
<p><a href='http://arxiv.org/abs/2312.04171v1'>http://arxiv.org/abs/2312.04171v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new framework for selecting features on incomplete datasets that considers feature importance in the imputation process and uses an improved reliefF algorithm to learn the feature importance vector.</p><hr><h3>Augmentation-Free Dense Contrastive Knowledge Distillation for Efficient  Semantic Segmentation</h3>
<p>Jiawei Fan,Chao Li,Xiaolong Liu,Meina Song,Anbang Yao</p>
<p><a href='http://arxiv.org/abs/2312.04168v1'>http://arxiv.org/abs/2312.04168v1</a></p>
<p><b>Compressor summary</b>: Af-DCD is a new contrastive learning method for semantic segmentation that improves efficiency and accuracy by using masked features and feature partitions without data augmentation or memory buffer.</p><hr><h3>Mixture of Dynamical Variational Autoencoders for Multi-Source  Trajectory Modeling and Separation</h3>
<p>Xiaoyu Lin,Laurent Girin,Xavier Alameda-Pineda</p>
<p><a href='http://arxiv.org/abs/2312.04167v1'>http://arxiv.org/abs/2312.04167v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MixDVAE, a latent-variable generative model for multi-source dynamics estimation, and demonstrates its effectiveness on computer vision and audio processing tasks.</p><hr><h3>Text as Image: Learning Transferable Adapter for Multi-Label  Classification</h3>
<p>Xuelin Zhu,Jiuxin Cao,Jian liu,Dongqi Tang,Furong Xu,Weijia Liu,Jiawei Ge,Bo Liu,Qingpei Guo,Tianyi Zhang</p>
<p><a href='http://arxiv.org/abs/2312.04160v1'>http://arxiv.org/abs/2312.04160v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to improve vision-language pre-trained models for multi-label image classification by using an adapter network with random perturbation and large language models for text generation, enabling automated visual label recognition.</p><hr><h3>EulerMormer: Robust Eulerian Motion Magnification via Dynamic Filtering  within Transformer</h3>
<p>Fei Wang,Dan Guo,Kun Li,Meng Wang</p>
<p><a href='http://arxiv.org/abs/2312.04152v1'>http://arxiv.org/abs/2312.04152v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel dynamic filtering strategy for video motion magnification that separates texture and shape, eliminates noise, and preserves critical features using a global dynamic sparse cross-covariance attention mechanism and a multi-scale dual-path gating mechanism.</p><hr><h3>Diffusing Colors: Image Colorization with Text Guided Diffusion</h3>
<p>Nir Zabari,Aharon Azulay,Alexey Gorkor,Tavi Halperin,Ohad Fried</p>
<p><a href='http://arxiv.org/abs/2312.04145v1'>http://arxiv.org/abs/2312.04145v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method for colorizing grayscale images using diffusion techniques and text prompts, improving both visual quality and user control over the process.</p><hr><h3>Towards 4D Human Video Stylization</h3>
<p>Tiantian Wang,Xinxin Zuo,Fangzhou Mu,Jian Wang,Ming-Hsuan Yang</p>
<p><a href='http://arxiv.org/abs/2312.04143v1'>http://arxiv.org/abs/2312.04143v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for stylizing human videos in 4D (3D and time) by using NeRFs to represent both the person and their surroundings, allowing for animation across poses and viewpoints.</p><hr><h3>TimeDRL: Disentangled Representation Learning for Multivariate  Time-Series</h3>
<p>Ching Chang,Chiao-Tung Chan,Wei-Yao Wang,Wen-Chih Peng,Tien-Fu Chen</p>
<p><a href='http://arxiv.org/abs/2312.04142v1'>http://arxiv.org/abs/2312.04142v1</a></p>
<p><b>Compressor summary</b>: TimeDRL is a novel framework that learns disentangled embeddings from multivariate time-series data using timestamp-predictive and instance-contrastive tasks, without relying on augmentation methods or transformation-invariance.</p><hr><h3>Polarimetric Light Transport Analysis for Specular Inter-reflection</h3>
<p>Ryota Maeda,Shinsaku Hiura</p>
<p><a href='http://arxiv.org/abs/2312.04140v1'>http://arxiv.org/abs/2312.04140v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel polarimetric method to decompose specular inter-reflections of metal objects by analyzing the rotation direction of linear polarization.</p><hr><h3>Using a Large Language Model to generate a Design Structure Matrix</h3>
<p>Edwin C. Y. Koh</p>
<p><a href='http://arxiv.org/abs/2312.04134v1'>http://arxiv.org/abs/2312.04134v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a workflow using a large language model to help create Design Structure Matrices for complex engineering systems, which could save time and resources compared to traditional manual methods.</p><hr><h3>Analyzing the Inherent Response Tendency of LLMs: Real-World  Instructions-Driven Jailbreak</h3>
<p>Yanrui Du,Sendong Zhao,Ming Ma,Yuhan Chen,Bing Qin</p>
<p><a href='http://arxiv.org/abs/2312.04127v1'>http://arxiv.org/abs/2312.04127v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new jailbreak attack method called RADIAL, which exploits the inherent response tendencies of large language models to generate harmful responses when given specific real-world instructions with embedded malicious instructions.</p><hr><h3>Forensic Iris Image Synthesis</h3>
<p>Rasel Ahmed Bhuiyan,Adam Czajka</p>
<p><a href='http://arxiv.org/abs/2312.04125v1'>http://arxiv.org/abs/2312.04125v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new iris synthesis model using StyleGAN to generate realistic post-mortem iris images for data collection and training purposes in forensic identification.</p><hr><h3>Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic  Play</h3>
<p>Timothy Schaumlöffel,Arthur Aubret,Gemma Roig,Jochen Triesch</p>
<p><a href='http://arxiv.org/abs/2312.04118v1'>http://arxiv.org/abs/2312.04118v1</a></p>
<p><b>Compressor summary</b>: The study proposes a computational model to investigate how caregivers' utterances during play sessions can enhance infants' ability to recognize and categorize objects visually.</p><hr><h3>Instance Tracking in 3D Scenes from Egocentric Videos</h3>
<p>Yunhan Zhao,Haoyu Ma,Shu Kong,Charless Fowlkes</p>
<p><a href='http://arxiv.org/abs/2312.04117v1'>http://arxiv.org/abs/2312.04117v1</a></p>
<p><b>Compressor summary</b>: The authors introduce a new dataset and evaluation protocol for instance tracking in real-world 3D scenes from egocentric videos, and present a simple method that outperforms SOT-based approaches.</p><hr><h3>Multi-strategy Collaborative Optimized YOLOv5s and its Application in  Distance Estimation</h3>
<p>Zijian Shen,Zhenping Mu,Xiangxiang Li</p>
<p><a href='http://arxiv.org/abs/2312.04113v1'>http://arxiv.org/abs/2312.04113v1</a></p>
<p><b>Compressor summary</b>: The text describes a new neural network model for vehicle target detection and distance estimation in automobiles, which improves safety warnings and provides suggestions based on nonparametric testing.</p><hr><h3>Breaking the Entanglement of Homophily and Heterophily in  Semi-supervised Node Classification</h3>
<p>Henan Sun,Xunkai Li,Zhengyu Wu,Daohan Su,Rong-Hua Li,Guoren Wang</p>
<p><a href='http://arxiv.org/abs/2312.04111v1'>http://arxiv.org/abs/2312.04111v1</a></p>
<p><b>Compressor summary</b>: AMUD introduces a new GNN model that adapts to homophily and heterophily in directed graphs, improving node representations and graph learning efficiency.</p><hr><h3>Identity-Obscured Neural Radiance Fields: Privacy-Preserving 3D Facial  Reconstruction</h3>
<p>Jiayi Kong,Baixin Xu,Xurui Song,Chen Qian,Jun Luo,Ying He</p>
<p><a href='http://arxiv.org/abs/2312.04106v1'>http://arxiv.org/abs/2312.04106v1</a></p>
<p><b>Compressor summary</b>: The proposed method reconstructs 3D head geometry with NeRF using identity-obscured inputs to preserve facial privacy.</p><hr><h3>Enhancing the Rationale-Input Alignment for Self-explaining  Rationalization</h3>
<p>Wei Liu,Haozhao Wang,Jun Wang,Zhiying Deng,YuanKai Zhang,Cheng Wang,Ruixuan Li</p>
<p><a href='http://arxiv.org/abs/2312.04103v1'>http://arxiv.org/abs/2312.04103v1</a></p>
<p><b>Compressor summary</b>: The paper proposes DAR, a method that improves explanation quality in deep learning models by aligning the selected rationale with the original input to avoid the rationale shift problem.</p><hr><h3>Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning  Interference with Gradient Projection</h3>
<p>Tuan Hoang,Santu Rana,Sunil Gupta,Svetha Venkatesh</p>
<p><a href='http://arxiv.org/abs/2312.04095v1'>http://arxiv.org/abs/2312.04095v1</a></p>
<p><b>Compressor summary</b>: Projected-Gradient Unlearning (PGU) is a method for removing specific data samples from a machine learning model without affecting its performance on the remaining dataset, using an efficient algorithm that can handle any model and dataset size.</p><hr><h3>Open-Vocabulary Segmentation with Semantic-Assisted Calibration</h3>
<p>Yong Liu,Sule Bai,Guanbin Li,Yitong Wang,Yansong Tang</p>
<p><a href='http://arxiv.org/abs/2312.04089v1'>http://arxiv.org/abs/2312.04089v1</a></p>
<p><b>Compressor summary</b>: The paper proposes SCAN, a method for open-vocabulary segmentation that uses CLIP's generalized contextual prior to improve alignment of visual content with unbounded text and introduces SG-IoU, a new metric to address semantic duplication issues.</p><hr><h3>VRPTEST: Evaluating Visual Referring Prompting in Large Multimodal  Models</h3>
<p>Zongjie Li,Chaozheng Wang,Chaowei Liu,Pingchuan Ma,Daoyuan Wu,Shuai Wang,Cuiyun Gao</p>
<p><a href='http://arxiv.org/abs/2312.04087v1'>http://arxiv.org/abs/2312.04087v1</a></p>
<p><b>Compressor summary</b>: The study analyzes the performance of Large Multimodal Models (LMMs) using various visual referring prompting strategies, introducing a new benchmark dataset called VRPTEST and finding that the choice of prompt strategy significantly affects accuracy.</p><hr><h3>MTVG : Multi-text Video Generation with Text-to-Video Models</h3>
<p>Gyeongrok Oh,Jaehwan Jeong,Sieun Kim,Wonmin Byeon,Jinkyu Kim,Sungwoong Kim,Hyeokmin Kwon,Sangpil Kim</p>
<p><a href='http://arxiv.org/abs/2312.04086v1'>http://arxiv.org/abs/2312.04086v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel method for generating videos from multiple texts with diverse events, using a pre-trained diffusion-based model and several techniques to ensure visual consistency and coherence.</p><hr><h3>On the adaptation of in-context learners for system identification</h3>
<p>Dario Piga,Filippo Pura,Marco Forgione</p>
<p><a href='http://arxiv.org/abs/2312.04083v1'>http://arxiv.org/abs/2312.04083v1</a></p>
<p><b>Compressor summary</b>: The paper explores how adapting meta-models can improve predictive performance in different scenarios of system identification, enhancing robustness and versatility.</p><hr><h3>Large Language Models are Good Prompt Learners for Low-Shot Image  Classification</h3>
<p>Zhaoheng Zheng,Jingmin Wei,Xuefeng Hu,Haidong Zhu,Ram Nevatia</p>
<p><a href='http://arxiv.org/abs/2312.04076v1'>http://arxiv.org/abs/2312.04076v1</a></p>
<p><b>Compressor summary</b>: The paper proposes LLaMP, a method to integrate Large Language Models into pre-trained Vision-Language models for low-shot image classification by generating adaptive prompts for the CLIP text encoder.</p><hr><h3>A Transformer Model for Symbolic Regression towards Scientific Discovery</h3>
<p>Florian Lalande,Yoshitomo Matsubara,Naoya Chiba,Tatsunori Taniai,Ryo Igarashi,Yoshitala Ushiku</p>
<p><a href='http://arxiv.org/abs/2312.04070v1'>http://arxiv.org/abs/2312.04070v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new Transformer model for Symbolic Regression that can find mathematical expressions for datasets without interpretation issues, but with more computation and flexibility needed to avoid overfitting, achieving state-of-the-art results on SRSD datasets.</p><hr><h3>MeanCut: A Greedy-Optimized Graph Clustering via Path-based Similarity  and Degree Descent Criterion</h3>
<p>Dehua Peng,Zhipeng Gui,Huayi Wu</p>
<p><a href='http://arxiv.org/abs/2312.04067v1'>http://arxiv.org/abs/2312.04067v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new graph clustering method, MeanCut, that uses path-based similarity to handle non-spherical data and improve cluster associations, while reducing computational complexity and enhancing robustness.</p><hr><h3>Combining inherent knowledge of vision-language models with unsupervised  domain adaptation through self-knowledge distillation</h3>
<p>Thomas Westfechtel,Dexuan Zhang,Tatsuya Harada</p>
<p><a href='http://arxiv.org/abs/2312.04066v1'>http://arxiv.org/abs/2312.04066v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method that combines unsupervised domain adaptation with vision-language models to improve zero-shot prediction accuracy on image classification tasks, using data from source and target domains and adjusting class probabilities.</p><hr><h3>A Robust and Efficient Boundary Point Detection Method by Measuring  Local Direction Dispersion</h3>
<p>Dehua Peng,Zhipeng Gui,Huayi Wu</p>
<p><a href='http://arxiv.org/abs/2312.04065v1'>http://arxiv.org/abs/2312.04065v1</a></p>
<p><b>Compressor summary</b>: The paper proposes LoDD, a method for detecting boundary points in machine learning tasks, which uses KNN and eigenvalues of the covariance matrix to measure centrality and performs well on synthetic and real datasets.</p><hr><h3>An unsupervised approach towards promptable defect segmentation in  laser-based additive manufacturing by Segment Anything</h3>
<p>Israt Zarin Era,Imtiaz Ahmed,Zhichao Liu,Srinjoy Das</p>
<p><a href='http://arxiv.org/abs/2312.04063v1'>http://arxiv.org/abs/2312.04063v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a framework for real-time image segmentation in manufacturing using a Foundation model with unsupervised prompt generation, which could improve product quality and enable Industry 4.0.</p><hr><h3>Differentiable Registration of Images and LiDAR Point Clouds with  VoxelPoint-to-Pixel Matching</h3>
<p>Junsheng Zhou,Baorui Ma,Wenyuan Zhang,Yi Fang,Yu-Shen Liu,Zhizhong Han</p>
<p><a href='http://arxiv.org/abs/2312.04060v1'>http://arxiv.org/abs/2312.04060v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel method to register 2D images and 3D point clouds using a structured cross-modality latent space learned by a triplet network and a differentiable probabilistic PnP solver, achieving state-of-the-art results on KITTI and nuScenes datasets.</p><hr><h3>Comparing Large Language Model AI and Human-Generated Coaching Messages  for Behavioral Weight Loss</h3>
<p>Zhuoran Huang,Michael P. Berry,Christina Chwyl,Gary Hsieh,Jing Wei,Evan M. Forman</p>
<p><a href='http://arxiv.org/abs/2312.04059v1'>http://arxiv.org/abs/2312.04059v1</a></p>
<p><b>Compressor summary</b>: LLM AI chatbots like ChatGPT can generate personalized and novel weight-loss coaching messages that are as helpful as human-written ones, but need improvements in authenticity and data focus.</p><hr><h3>Jointly spatial-temporal representation learning for individual  trajectories</h3>
<p>Fei Huang,Jianrong Lv,Yang Yue</p>
<p><a href='http://arxiv.org/abs/2312.04055v1'>http://arxiv.org/abs/2312.04055v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method (ST-GraphRL) to represent human trajectories in a way that captures their spatial and temporal dependencies, which improves the performance of geospatial foundation models.</p><hr><h3>Multimodal Misinformation Detection in a South African Social Media  Environment</h3>
<p>Amica De Jager,Vukosi Marivate,Abioudun Modupe</p>
<p><a href='http://arxiv.org/abs/2312.04052v1'>http://arxiv.org/abs/2312.04052v1</a></p>
<p><b>Compressor summary</b>: The paper presents a multimodal misinformation detection model for South African social media that uses textual and visual information, and shows its improved performance compared to unimodal models.</p><hr><h3>Residual Graph Convolutional Network for Bird's-Eye-View Semantic  Segmentation</h3>
<p>Qiuxiao Chen,Xiaojun Qi</p>
<p><a href='http://arxiv.org/abs/2312.04044v1'>http://arxiv.org/abs/2312.04044v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Residual Graph Convolutional (RGC) module for Bird's-Eye-View semantic segmentation that improves global information and region-level semantic relationships using graph space projection and data augmentation.</p><hr><h3>Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes</h3>
<p>Hmrishav Bandyopadhyay,Subhadeep Koley,Ayan Das,Aneeshan Sain,Pinaki Nath Chowdhury,Tao Xiang,Ayan Kumar Bhunia,Yi-Zhe Song</p>
<p><a href='http://arxiv.org/abs/2312.04043v1'>http://arxiv.org/abs/2312.04043v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new framework for generating 3D shapes from sketches that simplifies the process, allows editing, and works efficiently.</p><hr><h3>Reconstruction of dynamical systems from data without time labels</h3>
<p>Zhijun Zeng,Pipi Hu,Chenglong Bao,Yi Zhu,Zuoqiang Shi</p>
<p><a href='http://arxiv.org/abs/2312.04038v1'>http://arxiv.org/abs/2312.04038v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to reconstruct dynamical systems from data without time labels using sliced Wasserstein distance to minimize distribution loss.</p><hr><h3>DiffusionPhase: Motion Diffusion in Frequency Domain</h3>
<p>Weilin Wan,Yiming Huang,Shutong Wu,Taku Komura,Wenping Wang,Dinesh Jayaraman,Lingjie Liu</p>
<p><a href='http://arxiv.org/abs/2312.04036v1'>http://arxiv.org/abs/2312.04036v1</a></p>
<p><b>Compressor summary</b>: The study presents a method for generating diverse and smooth human motion sequences from text descriptions using a network encoder and a conditional diffusion model in the frequency domain.</p><hr><h3>RoAST: Robustifying Language Models via Adversarial Perturbation with  Selective Training</h3>
<p>Jaehyung Kim,Yuning Mao,Rui Hou,Hanchao Yu,Davis Liang,Pascale Fung,Qifan Wang,Fuli Feng,Lifu Huang,Madian Khabsa</p>
<p><a href='http://arxiv.org/abs/2312.04032v1'>http://arxiv.org/abs/2312.04032v1</a></p>
<p><b>Compressor summary</b>: The paper proposes RoAST, a technique that enhances the multi-perspective robustness of pre-trained language models by incorporating adversarial perturbation and selective training during fine-tuning.</p><hr><h3>Modeling Boundedly Rational Agents with Latent Inference Budgets</h3>
<p>Athul Paul Jacob,Abhishek Gupta,Jacob Andreas</p>
<p><a href='http://arxiv.org/abs/2312.04030v1'>http://arxiv.org/abs/2312.04030v1</a></p>
<p><b>Compressor summary</b>: The latent inference budget model (L-IBM) is a new approach that explicitly simulates agents' computational constraints in models of bounded rationality, and shows promising results in various tasks involving suboptimal decision-making.</p><hr><h3>Improved Face Representation via Joint Label Classification and  Supervised Contrastive Clustering</h3>
<p>Zhenduo Zhang</p>
<p><a href='http://arxiv.org/abs/2312.04029v1'>http://arxiv.org/abs/2312.04029v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new method for improving face recognition by using cluster knowledge from face clustering tasks in two ways, extending ArcFace with a cluster-guided angular margin and aligning cluster centers with class centers in the classifier.</p><hr><h3>ImFace++: A Sophisticated Nonlinear 3D Morphable Face Model with  Implicit Neural Representations</h3>
<p>Mingwu Zheng,Haiyu Zhang,Hongyu Yang,Liming Chen,Di Huang</p>
<p><a href='http://arxiv.org/abs/2312.04028v1'>http://arxiv.org/abs/2312.04028v1</a></p>
<p><b>Compressor summary</b>: The paper introduces ImFace++, a novel 3D morphable face model that learns continuous neural representations with disentangled deformation fields, refinement displacement field, and Neural Blend-Field to capture complex facial shapes and expressions for various computer vision and graphics applications.</p><hr><h3>The sample complexity of multi-distribution learning</h3>
<p>Binghui Peng</p>
<p><a href='http://arxiv.org/abs/2312.04027v1'>http://arxiv.org/abs/2312.04027v1</a></p>
<p><b>Compressor summary</b>: The paper provides an algorithm for multi-distribution learning with sample complexity $\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$ and resolves a COLT 2023 open problem.</p><hr><h3>k* Distribution: Evaluating the Latent Space of Deep Neural Networks  using Local Neighborhood Analysis</h3>
<p>Shashank Kotyan,Ueda Tatsuya,Danilo Vasconcellos Vargas</p>
<p><a href='http://arxiv.org/abs/2312.04024v1'>http://arxiv.org/abs/2312.04024v1</a></p>
<p><b>Compressor summary</b>: The k* Distribution method analyzes the structure of sample distributions within specific classes in the learned latent space of neural networks, revealing different distribution types and enabling a deeper understanding of how these networks process various classes.</p><hr><h3>A Study on the Calibration of In-context Learning</h3>
<p>Hanlin Zhang,Yi-Fan Zhang,Yaodong Yu,Dhruv Madeka,Dean Foster,Eric Xing,Hima Lakkaraju,Sham Kakade</p>
<p><a href='http://arxiv.org/abs/2312.04021v1'>http://arxiv.org/abs/2312.04021v1</a></p>
<p><b>Compressor summary</b>: The study examines the trade-offs between performance and calibration of large language models in in-context learning tasks and suggests that current recalibration techniques may not be sufficient for ensuring reliability.</p><hr><h3>PartDistill: 3D Shape Part Segmentation by Vision-Language Model  Distillation</h3>
<p>Ardian Umam,Cheng-Kun Yang,Min-Hung Chen,Jen-Hui Chuang,Yen-Yu Lin</p>
<p><a href='http://arxiv.org/abs/2312.04016v1'>http://arxiv.org/abs/2312.04016v1</a></p>
<p><b>Compressor summary</b>: The paper introduces PartDistill, a framework that transfers 2D knowledge from vision-language models to improve 3D shape part segmentation using cross-modal distillation.</p><hr><h3>Natural-language-driven Simulation Benchmark and Copilot for Efficient  Production of Object Interactions in Virtual Road Scenes</h3>
<p>Kairui Yang,Zihao Guo,Gengjie Lin,Haotian Dong,Die Zuo,Jibin Peng,Zhao Huang,Zhecheng Xu,Fupeng Li,Ziyun Bai,Di Lin</p>
<p><a href='http://arxiv.org/abs/2312.04008v1'>http://arxiv.org/abs/2312.04008v1</a></p>
<p><b>Compressor summary</b>: The authors propose a natural-language-driven simulation for creating realistic object interactions in virtual driving scenes and present a new method called SimCopilot to evaluate their approach using the Language-to-Interaction dataset.</p><hr><h3>KOALA: Self-Attention Matters in Knowledge Distillation of Latent  Diffusion Models for Memory-Efficient and Fast Image Synthesis</h3>
<p>Youngwan Lee,Kwanyong Park,Yoorhim Cho,Yong-Ju Lee,Sung Ju Hwang</p>
<p><a href='http://arxiv.org/abs/2312.04005v1'>http://arxiv.org/abs/2312.04005v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an efficient text-to-image model by distilling knowledge from the larger and faster Stable Diffusion XL model, addressing its high computation cost and size requirements.</p><hr><h3>LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL  Architectures</h3>
<p>Vimal Thilak,Chen Huang,Omid Saremi,Laurent Dinh,Hanlin Goh,Preetum Nakkiran,Joshua M. Susskind,Etai Littwin</p>
<p><a href='http://arxiv.org/abs/2312.04000v1'>http://arxiv.org/abs/2312.04000v1</a></p>
<p><b>Compressor summary</b>: LiDAR is a metric that measures the quality of representations in joint embedding architectures by quantifying the rank of the LDA matrix associated with a surrogate self-supervised learning task.</p><hr><h3>Series2Vec: Similarity-based Self-supervised Representation Learning for  Time Series Classification</h3>
<p>Navid Mohammadi Foumani,Chang Wei Tan,Geoffrey I. Webb,Mahsa Salehi</p>
<p><a href='http://arxiv.org/abs/2312.03998v1'>http://arxiv.org/abs/2312.03998v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new self-supervised method called Series2Vec, which predicts the similarity between two time series in both temporal and spectral domains, and shows its effectiveness on various real-world datasets.</p><hr><h3>Stable diffusion for Data Augmentation in COCO and Weed Datasets</h3>
<p>Boyang Deng,Yuzhen Lu</p>
<p><a href='http://arxiv.org/abs/2312.03996v1'>http://arxiv.org/abs/2312.03996v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses using stable diffusion generative models to improve object detection and classification tasks with synthetic images from small datasets, and evaluates their performance on various categories from the COCO dataset and weed species in Michigan.</p><hr><h3>Style Transfer to Calvin and Hobbes comics using Stable Diffusion</h3>
<p>Sloke Shrestha,Sundar Sripada V. S.,Asvin Venkataramanan</p>
<p><a href='http://arxiv.org/abs/2312.03993v1'>http://arxiv.org/abs/2312.03993v1</a></p>
<p><b>Compressor summary</b>: The report describes using stable-diffusion-v1.5 with LoRA to perform style transfer on Calvin and Hobbes comics, achieving good visual results.</p><hr><h3>MICRO: Model-Based Offline Reinforcement Learning with a Conservative  Bellman Operator</h3>
<p>Xiao-Yin Liu,Xiao-Hu Zhou,Guo-Tao Li,Hao Li,Mei-Jiang Gui,Tian-Yu Xiang,De-Xing Huang,Zeng-Guang Hou</p>
<p><a href='http://arxiv.org/abs/2312.03991v1'>http://arxiv.org/abs/2312.03991v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new model-based offline reinforcement learning algorithm (MICRO) that balances performance and robustness by using a conservative Bellman operator and reduces computation cost compared to previous methods.</p><hr><h3>Rapid detection of rare events from in situ X-ray diffraction data using  machine learning</h3>
<p>Weijian Zheng,Jun-Sang Park,Peter Kenesei,Ahsan Ali,Zhengchun Liu,Ian T. Foster,Nicholas Schwarz,Rajkumar Kettimuthu,Antonino Miceli,Hemant Sharma</p>
<p><a href='http://arxiv.org/abs/2312.03989v1'>http://arxiv.org/abs/2312.03989v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a new automated technique for quickly detecting plasticity in metallic materials using high-energy X-ray microscopy, which is faster and works with sparser data than traditional methods.</p><hr><h3>Cost-Effective In-Context Learning for Entity Resolution: A Design Space  Exploration</h3>
<p>Meihao Fan,Xiaoyue Han,Ju Fan,Chengliang Chai,Nan Tang,Guoliang Li,Xiaoyong Du</p>
<p><a href='http://arxiv.org/abs/2312.03987v1'>http://arxiv.org/abs/2312.03987v1</a></p>
<p><b>Compressor summary</b>: The paper proposes BATCHER, a cost-effective batch prompting approach for entity resolution using large language models without fine-tuning or manual prompting.</p><hr><h3>Node-aware Bi-smoothing: Certified Robustness against Graph Injection  Attacks</h3>
<p>Yuni Lai,Yulin Zhu,Bailin Pan,Kai Zhou</p>
<p><a href='http://arxiv.org/abs/2312.03979v1'>http://arxiv.org/abs/2312.03979v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new framework for defending DGL models against graph injection attacks, which is model-agnostic and provides theoretical and empirical evidence of its effectiveness.</p><hr><h3>Improving Medical Report Generation with Adapter Tuning and Knowledge  Enhancement in Vision-Language Foundation Models</h3>
<p>Shibin Wu,Bang Yang,Zhiyu Ye,Haoqian Wang,Hairong Zheng,Tong Zhang</p>
<p><a href='http://arxiv.org/abs/2312.03970v1'>http://arxiv.org/abs/2312.03970v1</a></p>
<p><b>Compressor summary</b>: The study improves medical report generation using a customized vision-language model that integrates adapter tuning and medical knowledge enhancement, achieving better accuracy and coherence than existing methods.</p>