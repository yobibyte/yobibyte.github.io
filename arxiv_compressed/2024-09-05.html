
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-09-05</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-09-05 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>HiPrompt: Tuning-free Higher-Resolution Generation with Hierarchical  MLLM Prompts</h3>
<p><a href='http://arxiv.org/abs/2409.02919v1'>http://arxiv.org/abs/2409.02919v1</a></p>
<p><b>Compressor summary</b>: HiPrompt is a new method for generating high-resolution images using diffusion models, which improves the quality by providing both global and local guidance with hierarchical prompts and conditioning noise components on different prompt levels.</p><hr><h3>UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from  Endoscopic Sparse Views</h3>
<p><a href='http://arxiv.org/abs/2409.02917v1'>http://arxiv.org/abs/2409.02917v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new technique called uncertainty-aware conditional NeRF to improve visualization of surgical scenes by addressing challenges such as sparse views and photometric inconsistencies.</p><hr><h3>Masked Diffusion Models are Secretly Time-Agnostic Masked Models and  Exploit Inaccurate Categorical Sampling</h3>
<p><a href='http://arxiv.org/abs/2409.02908v1'>http://arxiv.org/abs/2409.02908v1</a></p>
<p><b>Compressor summary</b>: This paper reveals a theoretical issue with masked diffusion models (MDMs) and proposes a faster sampler that addresses it, showing that MDMs are not superior to auto-regressive models (ARMs).</p><hr><h3>Topological Methods in Machine Learning: A Tutorial for Practitioners</h3>
<p><a href='http://arxiv.org/abs/2409.02901v1'>http://arxiv.org/abs/2409.02901v1</a></p>
<p><b>Compressor summary</b>: TML uses algebraic topology techniques to analyze complex data structures and reveal insights hidden from traditional machine learning methods.</p><hr><h3>LongCite: Enabling LLMs to Generate Fine-grained Citations in  Long-context QA</h3>
<p><a href='http://arxiv.org/abs/2409.02897v1'>http://arxiv.org/abs/2409.02897v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to improve the trustworthiness of large language models by generating accurate answers with sentence-level citations in LQAC tasks.</p><hr><h3>LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via  Hybrid Architecture</h3>
<p><a href='http://arxiv.org/abs/2409.02889v1'>http://arxiv.org/abs/2409.02889v1</a></p>
<p><b>Compressor summary</b>: The paper introduces LongLLaVA, a hybrid MLLM that balances efficiency and effectiveness for multi-modal tasks, with improved performance and reduced costs compared to existing models.</p><hr><h3>Multi-stream deep learning framework to predict mild cognitive  impairment with Rey Complex Figure Test</h3>
<p><a href='http://arxiv.org/abs/2409.02883v1'>http://arxiv.org/abs/2409.02883v1</a></p>
<p><b>Compressor summary</b>: The authors developed a multi-stream deep learning framework to improve the reliability and accuracy of detecting mild cognitive impairment using the Rey Complex Figure Test, which could be useful in clinical settings.</p><hr><h3>Benchmarking Spurious Bias in Few-Shot Image Classifiers</h3>
<p><a href='http://arxiv.org/abs/2409.02882v1'>http://arxiv.org/abs/2409.02882v1</a></p>
<p><b>Compressor summary</b>: The paper introduces FewSTAB, a benchmarking system to assess and improve the robustness of few-shot image classifiers against spurious bias using pre-trained vision-language models and existing test data.</p><hr><h3>Configurable Foundation Models: Building LLMs from a Modular Perspective</h3>
<p><a href='http://arxiv.org/abs/2409.02877v1'>http://arxiv.org/abs/2409.02877v1</a></p>
<p><b>Compressor summary</b>: This paper proposes configurable foundation models using functional modules called bricks, which can improve efficiency and scalability of large language models by allowing dynamic configuration based on instructions.</p><hr><h3>Look Into the LITE in Deep Learning for Time Series Classification</h3>
<p><a href='http://arxiv.org/abs/2409.02869v1'>http://arxiv.org/abs/2409.02869v1</a></p>
<p><b>Compressor summary</b>: The paper introduces LITE, a lightweight deep learning architecture for Time Series Classification that is faster, consumes less resources, and performs well on multivariate time series data.</p><hr><h3>The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness  in Face Recognition</h3>
<p><a href='http://arxiv.org/abs/2409.02867v1'>http://arxiv.org/abs/2409.02867v1</a></p>
<p><b>Compressor summary</b>: The paper explores how using balanced authentic and synthetic data affects face recognition accuracy and fairness, finding that diffusion-based models improve accuracy while pre-trained generative methods have little impact on fairness.</p><hr><h3>Hybrid-Segmentor: A Hybrid Approach to Automated Fine-Grained Crack  Segmentation in Civil Infrastructure</h3>
<p><a href='http://arxiv.org/abs/2409.02866v1'>http://arxiv.org/abs/2409.02866v1</a></p>
<p><b>Compressor summary</b>: The Hybrid-Segmentor model uses self-attention to detect and segment different types of cracks in infrastructure with high accuracy and generalization capabilities.</p><hr><h3>Bioinformatics Retrieval Augmentation Data (BRAD) Digital Assistant</h3>
<p><a href='http://arxiv.org/abs/2409.02864v1'>http://arxiv.org/abs/2409.02864v1</a></p>
<p><b>Compressor summary</b>: BRAD is a prototype digital assistant that can handle various bioinformatics tasks, such as question-answering, software pipeline execution, and automation of workflows.</p><hr><h3>Human-VDM: Learning Single-Image 3D Human Gaussian Splatting from Video  Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2409.02851v1'>http://arxiv.org/abs/2409.02851v1</a></p>
<p><b>Compressor summary</b>: Human-VDM is a novel method for generating high-quality 3D humans from a single RGB image using Video Diffusion Models and Gaussian Splatting, addressing inconsistent view issues in existing methods.</p><hr><h3>Oops, I Sampled it Again: Reinterpreting Confidence Intervals in  Few-Shot Learning</h3>
<p><a href='http://arxiv.org/abs/2409.02850v1'>http://arxiv.org/abs/2409.02850v1</a></p>
<p><b>Compressor summary</b>: The paper shows that using sampling with replacement in few-shot learning leads to misleading confidence intervals and proposes methods to improve them.</p><hr><h3>MaDis-Stereo: Enhanced Stereo Matching via Distilled Masked Image  Modeling</h3>
<p><a href='http://arxiv.org/abs/2409.02846v1'>http://arxiv.org/abs/2409.02846v1</a></p>
<p><b>Compressor summary</b>: The paper proposes MaDis-Stereo, a Transformer-based stereo matching model that uses Masked Image Modeling and knowledge distillation to improve performance on data-scarce tasks like ETH3D and KITTI 2015.</p><hr><h3>Historical German Text Normalization Using Type- and Token-Based  Language Modeling</h3>
<p><a href='http://arxiv.org/abs/2409.02841v1'>http://arxiv.org/abs/2409.02841v1</a></p>
<p><b>Compressor summary</b>: The report presents a machine learning-based normalization system for historic German texts using Transformer models, achieving state-of-the-art accuracy with limited data.</p><hr><h3>R2GQA: Retriever-Reader-Generator Question Answering System to Support  Students Understanding Legal Regulations in Higher Education</h3>
<p><a href='http://arxiv.org/abs/2409.02840v1'>http://arxiv.org/abs/2409.02840v1</a></p>
<p><b>Compressor summary</b>: The R2GQA system helps students understand legal regulations by retrieving, reading, and generating answers from documents using advanced techniques and a new Vietnamese dataset.</p><hr><h3>Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency  Discussions by Few-Shot Learning with Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2409.02836v1'>http://arxiv.org/abs/2409.02836v1</a></p>
<p><b>Compressor summary</b>: The study analyzes different types of statements and emotions in cryptocurrency discussions using advanced natural language processing techniques and finds distinct patterns and interplay between predictive, hope, and regret sentiments across five cryptocurrencies.</p><hr><h3>CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the  Mathematics Reasoning of Large Multimodal Models</h3>
<p><a href='http://arxiv.org/abs/2409.02834v1'>http://arxiv.org/abs/2409.02834v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a Chinese multimodal math dataset to evaluate and enhance large multimodal models' mathematical reasoning skills, and proposes a new model (Math-LMM) that improves performance on various problem types.</p><hr><h3>ExpLLM: Towards Chain of Thought for Facial Expression Recognition</h3>
<p><a href='http://arxiv.org/abs/2409.02828v1'>http://arxiv.org/abs/2409.02828v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method called ExpLLM that uses large language models to generate a chain of thought for accurate facial expression recognition, outperforming current methods and even GPT-4o in recognizing micro-expressions.</p><hr><h3>Deep Learning Meets Satellite Images -- An Evaluation on Handcrafted and  Learning-based Features for Multi-date Satellite Stereo Images</h3>
<p><a href='http://arxiv.org/abs/2409.02825v1'>http://arxiv.org/abs/2409.02825v1</a></p>
<p><b>Compressor summary</b>: The paper compares different feature extraction and matching methods for digital surface models generation from satellite images, showing that traditional methods can be competitive with deep learning ones.</p><hr><h3>MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding  Benchmark</h3>
<p><a href='http://arxiv.org/abs/2409.02813v1'>http://arxiv.org/abs/2409.02813v1</a></p>
<p><b>Compressor summary</b>: The paper presents MMMU-Pro, a challenging benchmark for multimodal models that tests their ability to integrate visual and textual information by embedding questions within images, and shows that current models perform significantly worse on it.</p><hr><h3>Boosting Certificate Robustness for Time Series Classification with  Efficient Self-Ensemble</h3>
<p><a href='http://arxiv.org/abs/2409.02802v1'>http://arxiv.org/abs/2409.02802v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Adversarial robustness is a challenge for time series classification (TSC)
- Randomized Smoothing provides provable lower bound on robustness radius but struggles with poor robustness datasets
- Self-ensemble method improves robustness by reducing variance of classification margins and addressing computational overhead issue

Summary:
The paper proposes a self-ensemble method to enhance adversarial robustness for time series classification, improving on Randomized Smoothing's performance and lower bound.</p><hr><h3>Towards a Unified View of Preference Learning for Large Language Models:  A Survey</h3>
<p><a href='http://arxiv.org/abs/2409.02795v1'>http://arxiv.org/abs/2409.02795v1</a></p>
<p><b>Compressor summary</b>: The text discusses a survey of preference alignment strategies for large language models, breaking them down into four components and providing examples to understand their strengths and challenges.</p><hr><h3>UnLearning from Experience to Avoid Spurious Correlations</h3>
<p><a href='http://arxiv.org/abs/2409.02792v1'>http://arxiv.org/abs/2409.02792v1</a></p>
<p><b>Compressor summary</b>: ULE is a new approach that improves robustness of deep neural networks by training two models in parallel: a student model that learns spurious correlations and a teacher model that unlearns the student's mistakes.</p><hr><h3>Unifying Causal Representation Learning with the Invariance Principle</h3>
<p><a href='http://arxiv.org/abs/2409.02772v1'>http://arxiv.org/abs/2409.02772v1</a></p>
<p><b>Compressor summary</b>: The paper shows that many causal representation learning methods align representations to data symmetries, not necessarily causal ones, and proposes a unified method that can use different assumptions based on relevant invariances for applications like treatment effect estimation.</p><hr><h3>An incremental preference elicitation-based approach to learning  potentially non-monotonic preferences in multi-criteria sorting</h3>
<p><a href='http://arxiv.org/abs/2409.02760v1'>http://arxiv.org/abs/2409.02760v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an active learning approach for learning non-monotonic preferences in MCS problems using max-margin optimization and information amount measurement.</p><hr><h3>A Comparative Study of Pre-training and Self-training</h3>
<p><a href='http://arxiv.org/abs/2409.02751v1'>http://arxiv.org/abs/2409.02751v1</a></p>
<p><b>Compressor summary</b>: Pre-training and fine-tuning is the best semi-supervised learning approach for sentiment analysis and natural language inference tasks, while self-training has no extra advantages.</p><hr><h3>Tractable Offline Learning of Regular Decision Processes</h3>
<p><a href='http://arxiv.org/abs/2409.02747v1'>http://arxiv.org/abs/2409.02747v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two new techniques for offline RL in non-Markovian environments, improving on previous algorithms by using a formal language pseudometric and Count-Min-Sketch.</p><hr><h3>Task-Oriented Communication for Graph Data: A Graph Information  Bottleneck Approach</h3>
<p><a href='http://arxiv.org/abs/2409.02728v1'>http://arxiv.org/abs/2409.02728v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a method to create small, task-focused subgraphs from large graphs using GNNs and GIB principle, which reduces communication costs while preserving essential information.</p><hr><h3>Pooling And Attention: What Are Effective Designs For LLm-Based  Embedding Models?</h3>
<p><a href='http://arxiv.org/abs/2409.02727v1'>http://arxiv.org/abs/2409.02727v1</a></p>
<p><b>Compressor summary</b>: This study explores optimal design and pooling strategies for Large Language Models (LLMs) based embedding models by conducting large-scale experiments and proposes a new pooling method, Multi-Layers Trainable Pooling, which improves performance in text similarity and retrieval tasks.</p><hr><h3>Pre-training data selection for biomedical domain adaptation using  journal impact metrics</h3>
<p><a href='http://arxiv.org/abs/2409.02725v1'>http://arxiv.org/abs/2409.02725v1</a></p>
<p><b>Compressor summary</b>: The study investigates how using specific quality metrics for scientific papers to refine a pre-training dataset affects BERT's performance on biomedical language understanding tasks.</p><hr><h3>A Data Selection Approach for Enhancing Low Resource Machine Translation  Using Cross-Lingual Sentence Representations</h3>
<p><a href='http://arxiv.org/abs/2409.02712v1'>http://arxiv.org/abs/2409.02712v1</a></p>
<p><b>Compressor summary</b>: This study proposes a data filtering approach using cross-lingual sentence representations to improve machine translation quality for low-resource English-Marathi language pairs.</p><hr><h3>Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for  PostNL</h3>
<p><a href='http://arxiv.org/abs/2409.02711v1'>http://arxiv.org/abs/2409.02711v1</a></p>
<p><b>Compressor summary</b>: PostNL developed an AI system called SuperTracy to improve parcel tracking communication using generative AI technologies like Retrieval-Augmented Generation.</p><hr><h3>Few-shot Multi-Task Learning of Linear Invariant Features with Meta  Subspace Pursuit</h3>
<p><a href='http://arxiv.org/abs/2409.02708v1'>http://arxiv.org/abs/2409.02708v1</a></p>
<p><b>Compressor summary</b>: Meta-SP is a new algorithm for multi-task linear models that learns an invariant low-rank subspace shared by different tasks and outperforms other methods.</p><hr><h3>Decision Transformer for Enhancing Neural Local Search on the Job Shop  Scheduling Problem</h3>
<p><a href='http://arxiv.org/abs/2409.02697v1'>http://arxiv.org/abs/2409.02697v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve a deep reinforcement learning agent for job shop scheduling by training it on search trajectories and achieves state-of-the-art results with machine learning-enhanced search.</p><hr><h3>Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for  Problem-Solving Improvement of LLMs</h3>
<p><a href='http://arxiv.org/abs/2409.02686v1'>http://arxiv.org/abs/2409.02686v1</a></p>
<p><b>Compressor summary</b>: The paper explores why large language models struggle with reasoning tasks, proposes a causal framework to understand their limitations, and introduces Deconfounded Causal Adaptation (DCA), a novel fine-tuning method that improves their performance with minimal parameters.</p><hr><h3>Rethinking HTG Evaluation: Bridging Generation and Recognition</h3>
<p><a href='http://arxiv.org/abs/2409.02683v1'>http://arxiv.org/abs/2409.02683v1</a></p>
<p><b>Compressor summary</b>: The paper introduces three new metrics for evaluating handwriting generation models that consider style, content, and diversity, and shows they are better than existing metrics like FID.</p><hr><h3>Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon</h3>
<p><a href='http://arxiv.org/abs/2409.02681v1'>http://arxiv.org/abs/2409.02681v1</a></p>
<p><b>Compressor summary</b>: The study uses a mixed RNN model with LSTM and GRU architectures to predict monthly fire spot counts in the Amazon using satellite data, showing improved accuracy and capturing seasonal patterns.</p><hr><h3>Independence Constrained Disentangled Representation Learning from  Epistemological Perspective</h3>
<p><a href='http://arxiv.org/abs/2409.02672v1'>http://arxiv.org/abs/2409.02672v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method for disentangled representation learning that combines mutual information and independence constraints within a GAN framework, improving the quality of controllable generation and explainability.</p><hr><h3>Creating Domain-Specific Translation Memories for Machine Translation  Fine-tuning: The TRENCARD Bilingual Cardiology Corpus</h3>
<p><a href='http://arxiv.org/abs/2409.02667v1'>http://arxiv.org/abs/2409.02667v1</a></p>
<p><b>Compressor summary</b>: The article presents a semi-automatic method to create domain-specific translation memories from Turkish cardiology journals for various language applications.</p><hr><h3>Standing on the Shoulders of Giants: Reprogramming Visual-Language Model  for General Deepfake Detection</h3>
<p><a href='http://arxiv.org/abs/2409.02664v1'>http://arxiv.org/abs/2409.02664v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method to improve deepfake detection by repurposing vision-language models and manipulating their input without tuning the model parameters.</p><hr><h3>PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for  One-Shot Talking Head Generation</h3>
<p><a href='http://arxiv.org/abs/2409.02657v1'>http://arxiv.org/abs/2409.02657v1</a></p>
<p><b>Compressor summary</b>: PoseTalk is a system that generates lip-synchronized talking head videos with free head poses using both audio and text inputs, addressing loss-imbalance issues and achieving better pose diversity and realness.</p><hr><h3>Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any  Objects</h3>
<p><a href='http://arxiv.org/abs/2409.02653v1'>http://arxiv.org/abs/2409.02653v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Skip-and-Play, a depth-based pose control method for text-to-image generation that reduces shape dependency on depth maps while preserving the pose.</p><hr><h3>Learning-Based Error Detection System for Advanced Vehicle Instrument  Cluster Rendering</h3>
<p><a href='http://arxiv.org/abs/2409.02647v1'>http://arxiv.org/abs/2409.02647v1</a></p>
<p><b>Compressor summary</b>: The text proposes a learning-based monitoring approach to detect and counter rendering errors in digital displays of the automotive industry using telltales that separate good and corrupted content.</p><hr><h3>MADiff: Motion-Aware Mamba Diffusion Models for Hand Trajectory  Prediction on Egocentric Videos</h3>
<p><a href='http://arxiv.org/abs/2409.02638v1'>http://arxiv.org/abs/2409.02638v1</a></p>
<p><b>Compressor summary</b>: MADiff is a method that predicts future hand waypoints in egocentric videos using diffusion models with motion-aware denoising and scene understanding, achieving real-time performance and reasonable results.</p><hr><h3>Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion  Dependency</h3>
<p><a href='http://arxiv.org/abs/2409.02634v1'>http://arxiv.org/abs/2409.02634v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Loopy, an end-to-end audio-only conditioned video diffusion model that generates natural and high-quality human video without spatial motion templates.</p><hr><h3>Evaluating Environments Using Exploratory Agents</h3>
<p><a href='http://arxiv.org/abs/2409.02632v1'>http://arxiv.org/abs/2409.02632v1</a></p>
<p><b>Compressor summary</b>: The paper presents an exploratory agent that evaluates and optimizes procedurally generated game levels for player exploration based on motivations and a fitness function.</p><hr><h3>(Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in  Large Models</h3>
<p><a href='http://arxiv.org/abs/2409.02628v1'>http://arxiv.org/abs/2409.02628v1</a></p>
<p><b>Compressor summary</b>: Epistemic uncertainty collapse occurs in deep learning models as complexity increases due to implicit ensembling, challenging the assumption of better uncertainty quantification with larger models.</p><hr><h3>PUB: Plot Understanding Benchmark and Dataset for Evaluating Large  Language Models on Synthetic Visual Data Interpretation</h3>
<p><a href='http://arxiv.org/abs/2409.02617v1'>http://arxiv.org/abs/2409.02617v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new dataset to evaluate how well large language models understand various types of visual data, using text prompts and questions related to images.</p><hr><h3>GoT-CQA: Graph-of-Thought Guided Compositional Reasoning for Chart  Question Answering</h3>
<p><a href='http://arxiv.org/abs/2409.02611v1'>http://arxiv.org/abs/2409.02611v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel Graph-of-Thought guided compositional reasoning model called GoT-CQA for answering questions based on chart content, which performs well in complex reasoning tasks.</p><hr><h3>A Medical Multimodal Large Language Model for Pediatric Pneumonia</h3>
<p><a href='http://arxiv.org/abs/2409.02608v1'>http://arxiv.org/abs/2409.02608v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Hypothesizing Missing Causal Variables with LLMs</h3>
<p><a href='http://arxiv.org/abs/2409.02604v1'>http://arxiv.org/abs/2409.02604v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments</h3>
<p><a href='http://arxiv.org/abs/2409.02598v1'>http://arxiv.org/abs/2409.02598v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>An Analysis of Linear Complexity Attention Substitutes with BEST-RQ</h3>
<p><a href='http://arxiv.org/abs/2409.02596v1'>http://arxiv.org/abs/2409.02596v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Multiview Random Vector Functional Link Network for Predicting  DNA-Binding Proteins</h3>
<p><a href='http://arxiv.org/abs/2409.02588v1'>http://arxiv.org/abs/2409.02588v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>BMI Prediction from Handwritten English Characters Using a Convolutional  Neural Network</h3>
<p><a href='http://arxiv.org/abs/2409.02584v1'>http://arxiv.org/abs/2409.02584v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Solving Video Inverse Problems Using Image Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2409.02574v1'>http://arxiv.org/abs/2409.02574v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>More is More: Addition Bias in Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2409.02569v1'>http://arxiv.org/abs/2409.02569v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>How Do You Perceive My Face? Recognizing Facial Expressions in  Multi-Modal Context by Modeling Mental Representations</h3>
<p><a href='http://arxiv.org/abs/2409.02566v1'>http://arxiv.org/abs/2409.02566v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Interacting Multiple Model-based Joint Homography Matrix and Multiple  Object State Estimation</h3>
<p><a href='http://arxiv.org/abs/2409.02562v1'>http://arxiv.org/abs/2409.02562v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Vision-Language Navigation with Continual Learning</h3>
<p><a href='http://arxiv.org/abs/2409.02561v1'>http://arxiv.org/abs/2409.02561v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Low-Resolution Object Recognition with Cross-Resolution Relational  Contrastive Distillation</h3>
<p><a href='http://arxiv.org/abs/2409.02555v1'>http://arxiv.org/abs/2409.02555v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>A Sequential Decision-Making Model for Perimeter Identification</h3>
<p><a href='http://arxiv.org/abs/2409.02549v1'>http://arxiv.org/abs/2409.02549v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Real-Time Dynamic Scale-Aware Fusion Detection Network: Take Road Damage  Detection as an example</h3>
<p><a href='http://arxiv.org/abs/2409.02546v1'>http://arxiv.org/abs/2409.02546v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>UniTT-Stereo: Unified Training of Transformer for Enhanced Stereo  Matching</h3>
<p><a href='http://arxiv.org/abs/2409.02545v1'>http://arxiv.org/abs/2409.02545v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>StyleTokenizer: Defining Image Style by a Single Instance for  Controlling Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2409.02543v1'>http://arxiv.org/abs/2409.02543v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Understanding eGFR Trajectories and Kidney Function Decline via Large  Multimodal Models</h3>
<p><a href='http://arxiv.org/abs/2409.02530v1'>http://arxiv.org/abs/2409.02530v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Sample what you cant compress</h3>
<p><a href='http://arxiv.org/abs/2409.02529v1'>http://arxiv.org/abs/2409.02529v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Cog-GA: A Large Language Models-based Generative Agent for  Vision-Language Navigation in Continuous Environments</h3>
<p><a href='http://arxiv.org/abs/2409.02522v1'>http://arxiv.org/abs/2409.02522v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic  Reasoning with Argumentation Theory-Driven Prompts</h3>
<p><a href='http://arxiv.org/abs/2409.02519v1'>http://arxiv.org/abs/2409.02519v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Continual Diffuser (CoD): Mastering Continual Offline Reinforcement  Learning with Experience Rehearsal</h3>
<p><a href='http://arxiv.org/abs/2409.02512v1'>http://arxiv.org/abs/2409.02512v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth  Estimation</h3>
<p><a href='http://arxiv.org/abs/2409.02494v1'>http://arxiv.org/abs/2409.02494v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Reliable Deep Diffusion Tensor Estimation: Rethinking the Power of  Data-Driven Optimization Routine</h3>
<p><a href='http://arxiv.org/abs/2409.02492v1'>http://arxiv.org/abs/2409.02492v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>TP-GMOT: Tracking Generic Multiple Object by Textual Prompt with  Motion-Appearance Cost (MAC) SORT</h3>
<p><a href='http://arxiv.org/abs/2409.02490v1'>http://arxiv.org/abs/2409.02490v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image  Indoor Depth by Meta-Initialization</h3>
<p><a href='http://arxiv.org/abs/2409.02486v1'>http://arxiv.org/abs/2409.02486v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Volumetric Surfaces: Representing Fuzzy Geometries with Multiple Meshes</h3>
<p><a href='http://arxiv.org/abs/2409.02482v1'>http://arxiv.org/abs/2409.02482v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Word and Phrase Features in Graph Convolutional Network for Automatic  Question Classification</h3>
<p><a href='http://arxiv.org/abs/2409.02481v1'>http://arxiv.org/abs/2409.02481v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels</h3>
<p><a href='http://arxiv.org/abs/2409.02465v1'>http://arxiv.org/abs/2409.02465v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>What is lost in Normalization? Exploring Pitfalls in Multilingual ASR  Model Evaluations</h3>
<p><a href='http://arxiv.org/abs/2409.02449v1'>http://arxiv.org/abs/2409.02449v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Detecting Korean Food Using Image using Hierarchical Model</h3>
<p><a href='http://arxiv.org/abs/2409.02448v1'>http://arxiv.org/abs/2409.02448v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>ForeCal: Random Forest-based Calibration for DNNs</h3>
<p><a href='http://arxiv.org/abs/2409.02446v1'>http://arxiv.org/abs/2409.02446v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Non-target Divergence Hypothesis: Toward Understanding Domain Gaps in  Cross-Modal Knowledge Distillation</h3>
<p><a href='http://arxiv.org/abs/2409.02438v1'>http://arxiv.org/abs/2409.02438v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Adversarial Learning for Neural PDE Solvers with Sparse Data</h3>
<p><a href='http://arxiv.org/abs/2409.02431v1'>http://arxiv.org/abs/2409.02431v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Training-free Color-Style Disentanglement for Constrained Text-to-Image  Synthesis</h3>
<p><a href='http://arxiv.org/abs/2409.02429v1'>http://arxiv.org/abs/2409.02429v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Large Language Models as Efficient Reward Function Searchers for  Custom-Environment Multi-Objective Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2409.02428v1'>http://arxiv.org/abs/2409.02428v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Diffusion Models Learn Low-Dimensional Distributions via Subspace  Clustering</h3>
<p><a href='http://arxiv.org/abs/2409.02426v1'>http://arxiv.org/abs/2409.02426v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Relative-Translation Invariant Wasserstein Distance</h3>
<p><a href='http://arxiv.org/abs/2409.02416v1'>http://arxiv.org/abs/2409.02416v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Abstractive Text Summarization: State of the Art, Challenges, and  Improvements</h3>
<p><a href='http://arxiv.org/abs/2409.02413v1'>http://arxiv.org/abs/2409.02413v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Adaptive Class Emergence Training: Enhancing Neural Network Stability  and Generalization through Progressive Target Evolution</h3>
<p><a href='http://arxiv.org/abs/2409.02410v1'>http://arxiv.org/abs/2409.02410v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Learning Privacy-Preserving Student Networks via  Discriminative-Generative Distillation</h3>
<p><a href='http://arxiv.org/abs/2409.02404v1'>http://arxiv.org/abs/2409.02404v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Determination of language families using deep learning</h3>
<p><a href='http://arxiv.org/abs/2409.02393v1'>http://arxiv.org/abs/2409.02393v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Building Math Agents with Multi-Turn Iterative Preference Learning</h3>
<p><a href='http://arxiv.org/abs/2409.02392v1'>http://arxiv.org/abs/2409.02392v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Multi-modal Situated Reasoning in 3D Scenes</h3>
<p><a href='http://arxiv.org/abs/2409.02389v1'>http://arxiv.org/abs/2409.02389v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Large Language Models and Cognitive Science: A Comprehensive Review of  Similarities, Differences, and Challenges</h3>
<p><a href='http://arxiv.org/abs/2409.02387v1'>http://arxiv.org/abs/2409.02387v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Unified Framework with Consistency across Modalities for Human Activity  Recognition</h3>
<p><a href='http://arxiv.org/abs/2409.02385v1'>http://arxiv.org/abs/2409.02385v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>STAB: Speech Tokenizer Assessment Benchmark</h3>
<p><a href='http://arxiv.org/abs/2409.02384v1'>http://arxiv.org/abs/2409.02384v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Coral Model Generation from Single Images for Virtual Reality  Applications</h3>
<p><a href='http://arxiv.org/abs/2409.02376v1'>http://arxiv.org/abs/2409.02376v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>How Privacy-Savvy Are Large Language Models? A Case Study on Compliance  and Privacy Technical Review</h3>
<p><a href='http://arxiv.org/abs/2409.02375v1'>http://arxiv.org/abs/2409.02375v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Exploring Low-Dimensional Subspaces in Diffusion Models for Controllable  Image Editing</h3>
<p><a href='http://arxiv.org/abs/2409.02374v1'>http://arxiv.org/abs/2409.02374v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Do Large Language Models Possess Sensitive to Sentiment?</h3>
<p><a href='http://arxiv.org/abs/2409.02370v1'>http://arxiv.org/abs/2409.02370v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Optimal Neural Network Approximation for High-Dimensional Continuous  Functions</h3>
<p><a href='http://arxiv.org/abs/2409.02363v1'>http://arxiv.org/abs/2409.02363v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Diversify-verify-adapt: Efficient and Robust Retrieval-Augmented  Ambiguous Question Answering</h3>
<p><a href='http://arxiv.org/abs/2409.02361v1'>http://arxiv.org/abs/2409.02361v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>Understanding the Role of Functional Diversity in Weight-Ensembling with  Ingredient Selection and Multidimensional Scaling</h3>
<p><a href='http://arxiv.org/abs/2409.02347v1'>http://arxiv.org/abs/2409.02347v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for  Retrieval</h3>
<p><a href='http://arxiv.org/abs/2409.02343v1'>http://arxiv.org/abs/2409.02343v1</a></p>
<p><b>Compressor summary</b>: </p>