
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-01-11</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-01-11 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes</h3>
<p>Mohamad Shahbazi,Liesbeth Claessens,Michael Niemeyer,Edo Collins,Alessio Tonioni,Luc Van Gool,Federico Tombari</p>
<p><a href='http://arxiv.org/abs/2401.05335v1'>http://arxiv.org/abs/2401.05335v1</a></p>
<p><b>Compressor summary</b>: InseRF is a novel method that can generate new objects in 3D scenes based on textual descriptions and 2D bounding boxes, without requiring explicit 3D information as input.</p><hr><h3>Towards Online Sign Language Recognition and Translation</h3>
<p>Ronglai Zuo,Fangyun Wei,Brian Mak</p>
<p><a href='http://arxiv.org/abs/2401.05336v1'>http://arxiv.org/abs/2401.05336v1</a></p>
<p><b>Compressor summary</b>: The authors present a novel online sign language recognition system that outperforms existing offline methods on three benchmarks.</p><hr><h3>URHand: Universal Relightable Hands</h3>
<p>Zhaoxi Chen,Gyeongsik Moon,Kaiwen Guo,Chen Cao,Stanislav Pidhorskyi,Tomas Simon,Rohan Joshi,Yuan Dong,Yichen Xu,Bernardo Pires,He Wen,Lucas Evans,Bo Peng,Julia Buffalini,Autumn Trimble,Kevyn McPhail,Melissa Schoeller,Shoou-I Yu,Javier Romero,Michael Zollhöfer,Yaser Sheikh,Ziwei Liu,Shunsuke Saito</p>
<p><a href='http://arxiv.org/abs/2401.05334v1'>http://arxiv.org/abs/2401.05334v1</a></p>
<p><b>Compressor summary</b>: URHand is a universal relightable hand model that can be personalized with few images, generalize to natural illuminations and novel identities, and render photorealistically under any lighting condition.</p><hr><h3>Arrival Time Prediction for Autonomous Shuttle Services in the Real  World: Evidence from Five Cities</h3>
<p>Carolin Schmidt,Mathias Tygesen,Filipe Rodrigues</p>
<p><a href='http://arxiv.org/abs/2401.05322v1'>http://arxiv.org/abs/2401.05322v1</a></p>
<p><b>Compressor summary</b>: The study presents a punctuality prediction system for autonomous shuttles using various models, including graph neural networks, to enhance customer trust in shared automated vehicles.</p><hr><h3>Leveraging Print Debugging to Improve Code Generation in Large Language  Models</h3>
<p>Xueyu Hu,Kun Kuang,Jiankai Sun,Hongxia Yang,Fei Wu</p>
<p><a href='http://arxiv.org/abs/2401.05319v1'>http://arxiv.org/abs/2401.05319v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an in-context learning method to improve LLMs' performance in debugging programming problems using print statements.</p><hr><h3>Can Probabilistic Feedback Drive User Impacts in Online Platforms?</h3>
<p>Jessica Dai,Bailey Flanigan,Nika Haghtalab,Meena Jagadeesan,Chara Podimata</p>
<p><a href='http://arxiv.org/abs/2401.05304v1'>http://arxiv.org/abs/2401.05304v1</a></p>
<p><b>Compressor summary</b>: The text explains how content recommender systems can negatively affect users due to differences in feedback rates and how no-regret algorithms may not address this issue.</p><hr><h3>I am a Strange Dataset: Metalinguistic Tests for Language Models</h3>
<p>Tristan Thrush,Jared Moore,Miguel Monares,Christopher Potts,Douwe Kiela</p>
<p><a href='http://arxiv.org/abs/2401.05300v1'>http://arxiv.org/abs/2401.05300v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new dataset, "I am a Strange Dataset", to test large language models' ability to handle metalinguistic self-reference and other metalinguistic language tasks.</p><hr><h3>Enhanced Muscle and Fat Segmentation for CT-Based Body Composition  Analysis: A Comparative Study</h3>
<p>Benjamin Hou,Tejas Sudharshan Mathai,Jianfei Liu,Christopher Parnell,Ronald M. Summers</p>
<p><a href='http://arxiv.org/abs/2401.05294v1'>http://arxiv.org/abs/2401.05294v1</a></p>
<p><b>Compressor summary</b>: The study compares an internal tool with TotalSegmentator for segmenting muscle and fat from CT scans, finding the internal tool more accurate for subcutaneous fat and muscle while having a high agreement for visceral fat.</p><hr><h3>Score Distillation Sampling with Learned Manifold Corrective</h3>
<p>Thiemo Alldieck,Nikos Kolotouros,Cristian Sminchisescu</p>
<p><a href='http://arxiv.org/abs/2401.05293v1'>http://arxiv.org/abs/2401.05293v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes a popular image diffusion method for controlling optimization problems using text prompts, identifies its noisy gradient issue, and proposes a fix by training a shallow network to mimic the denoising deficiency of the model.</p><hr><h3>INACIA: Integrating Large Language Models in Brazilian Audit Courts:  Opportunities and Challenges</h3>
<p>Jayr Pereira,Andre Assumpcao,Julio Trecenti,Luiz Airosa,Caio Lente,Jhonatan Cléto,Guilherme Dobins,Rodrigo Nogueira,Luis Mitchell,Roberto Lotufo</p>
<p><a href='http://arxiv.org/abs/2401.05273v1'>http://arxiv.org/abs/2401.05273v1</a></p>
<p><b>Compressor summary</b>: INACIA is a system that uses artificial intelligence to automate case analysis and generate recommendations for the Brazilian Federal Court of Accounts, demonstrating high performance and potential for improving efficiency and fairness in legal systems.</p><hr><h3>AUTOACT: Automatic Agent Learning from Scratch via Self-Planning</h3>
<p>Shuofei Qiao,Ningyu Zhang,Runnan Fang,Yujie Luo,Wangchunshu Zhou,Yuchen Eleanor Jiang,Chengfei Lv,Huajun Chen</p>
<p><a href='http://arxiv.org/abs/2401.05268v1'>http://arxiv.org/abs/2401.05268v1</a></p>
<p><b>Compressor summary</b>: AutoAct is a framework that automatically learns and synthesizes planning trajectories for language agents without relying on large-scale annotated data or closed-source models, achieving comparable performance to GPT-3.5-Turbo.</p><hr><h3>PIXART-δ: Fast and Controllable Image Generation with Latent  Consistency Models</h3>
<p>Junsong Chen,Yue Wu,Simian Luo,Enze Xie,Sayak Paul,Ping Luo,Hang Zhao,Zhenguo Li</p>
<p><a href='http://arxiv.org/abs/2401.05252v1'>http://arxiv.org/abs/2401.05252v1</a></p>
<p><b>Compressor summary</b>: PIXART-{\delta} is a fast and efficient text-to-image synthesis framework that combines LCM and ControlNet with PIXART-{\alpha}, enabling high-quality image generation in 2-4 steps with fine-grained control and low memory requirements.</p><hr><h3>ReACT: Reinforcement Learning for Controller Parametrization using  B-Spline Geometries</h3>
<p>Thomas Rudolf,Daniel Flögel,Tobias Schürmann,Simon Süß,Stefan Schwab,Sören Hohmann</p>
<p><a href='http://arxiv.org/abs/2401.05251v1'>http://arxiv.org/abs/2401.05251v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a novel approach using deep reinforcement learning to automatically parametrize controllers for complex, nonlinear systems with parameter-variant behavior, using B-spline geometries and long short-term memory neural networks for efficient adaptation and actor regularizations.</p><hr><h3>CASA: Causality-driven Argument Sufficiency Assessment</h3>
<p>Xiao Liu,Yansong Feng,Kai-Wei Chang</p>
<p><a href='http://arxiv.org/abs/2401.05249v1'>http://arxiv.org/abs/2401.05249v1</a></p>
<p><b>Compressor summary</b>: The paper proposes CASA, a framework to assess if an argument's premises support its conclusion using causality-driven probability of sufficiency and large language models, and demonstrates its effectiveness in fallacy detection and writing assistance.</p><hr><h3>Decoupling Decision-Making in Fraud Prevention through Classifier  Calibration for Business Logic Action</h3>
<p>Emanuele Luzio,Moacir Antonelli Ponti,Christian Ramirez Arevalo,Luis Argerich</p>
<p><a href='http://arxiv.org/abs/2401.05240v1'>http://arxiv.org/abs/2401.05240v1</a></p>
<p><b>Compressor summary</b>: The paper explores how calibration strategies can help decouple machine learning classifiers from score-based actions in business logic frameworks, and evaluates their trade-offs and performance in a real-world scenario.</p><hr><h3>Structure from Duplicates: Neural Inverse Graphics from a Pile of  Objects</h3>
<p>Tianhang Cheng,Wei-Chiu Ma,Kaiyu Guan,Antonio Torralba,Shenlong Wang</p>
<p><a href='http://arxiv.org/abs/2401.05236v1'>http://arxiv.org/abs/2401.05236v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Structure from Duplicates (SfD) is a new inverse graphics framework that reconstructs 3D geometry, material, and illumination from a single image with multiple identical objects.
- SfD uses object duplicates as a prior for inverse graphics and a robust SfM formulation for joint pose estimation.
- SfD achieves more realistic and detailed 3D reconstructions than existing models.

Summary:
SfD is a novel method that reconstructs 3D properties from a single image of identical objects, using them as prior information and improving the quality of reconstruction.</p><hr><h3>Taming "data-hungry" reinforcement learning? Stability in continuous  state-action spaces</h3>
<p>Yaqi Duan,Martin J. Wainwright</p>
<p><a href='http://arxiv.org/abs/2401.05233v1'>http://arxiv.org/abs/2401.05233v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new framework for analyzing continuous state-action RL with fast convergence rates, focusing on two key stability properties related to value functions and policies, and connecting off-line and transfer learning.</p><hr><h3>Measuring Natural Scenes SFR of Automotive Fisheye Cameras</h3>
<p>Daniel Jakab,Eoin Martino Grua,Brian Micheal Deegan,Anthony Scanlan,Pepijn Van De Ven,Ciarán Eising</p>
<p><a href='http://arxiv.org/abs/2401.05232v1'>http://arxiv.org/abs/2401.05232v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a modified NS-SFR algorithm for measuring MTF and optical quality in wide FOV camera datasets for vehicle automation.</p><hr><h3>Do Vision and Language Encoders Represent the World Similarly?</h3>
<p>Mayug Maniparambil,Raiymbek Akshulakov,Yasser Abdelaziz Dahou Djilali,Sanath Narayan,Mohamed El Amine Seddik,Karttikeya Mangalam,Noel E. O'Connor</p>
<p><a href='http://arxiv.org/abs/2401.05224v1'>http://arxiv.org/abs/2401.05224v1</a></p>
<p><b>Compressor summary</b>: The study explores if uni-modal vision and language models can be aligned without training by using graph matching techniques, showing promising results on downstream tasks.</p><hr><h3>Invariant Causal Prediction with Locally Linear Models</h3>
<p>Alexander Mey,Rui Manuel Castro</p>
<p><a href='http://arxiv.org/abs/2401.05218v1'>http://arxiv.org/abs/2401.05218v1</a></p>
<p><b>Compressor summary</b>: The paper proposes LoLICaP, a method for identifying causal parents from observational data under linear and invariant causal structures across different environments.</p><hr><h3>Exploring Vulnerabilities of No-Reference Image Quality Assessment  Models: A Query-Based Black-Box Method</h3>
<p>Chenxi Yang,Yujia Liu,Dingquan Li,Tingting jiang</p>
<p><a href='http://arxiv.org/abs/2401.05217v1'>http://arxiv.org/abs/2401.05217v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel query-based black box attack on no-reference image quality assessment methods, which overcomes limitations of existing attacks and reveals the vulnerability of these methods to black-box attacks.</p><hr><h3>Pre-trained Large Language Models for Financial Sentiment Analysis</h3>
<p>Wei Luo,Dihong Gong</p>
<p><a href='http://arxiv.org/abs/2401.05215v1'>http://arxiv.org/abs/2401.05215v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Financial sentiment analysis classifies financial news titles into positive, negative, or neutral categories
- The paper proposes to adapt pretrained large language models (LLMs) for this task
- LLMs are trained on huge text corpora and can be fine-tuned with few samples
- The paper uses the Llama2-7B model with supervised fine-tuning technique
- The approach outperforms previous state-of-the-art algorithms

Summary:
The paper adapts pretrained large language models to classify financial news titles into sentiment categories, using the Llama2-7B model and supervised fine-tuning, and achieves better results than previous methods.</p><hr><h3>A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts  into a Verbalizer</h3>
<p>Yong Ma,Senlin Luo,Yu-Ming Shang,Zhengjun Li,Yong Liu</p>
<p><a href='http://arxiv.org/abs/2401.05204v1'>http://arxiv.org/abs/2401.05204v1</a></p>
<p><b>Compressor summary</b>: Our novel approach to constructing verbalizers for prompt-tuning uses task-specific scenarios to create label words, improving zero-shot text classification performance and reducing bias.</p><hr><h3>Video-based Automatic Lameness Detection of Dairy Cows using Pose  Estimation and Multiple Locomotion Traits</h3>
<p>Helena Russello,Rik van der Tol,Menno Holzhauer,Eldert J. van Henten,Gert Kootstra</p>
<p><a href='http://arxiv.org/abs/2401.05202v1'>http://arxiv.org/abs/2401.05202v1</a></p>
<p><b>Compressor summary</b>: The study developed an automated lameness detection system for cows using deep-learning image processing, extracting keypoints and locomotion traits from outdoor videos, and improving classification accuracy by including multiple traits.</p><hr><h3>Monte Carlo Tree Search for Recipe Generation using GPT-2</h3>
<p>Karan Taneja,Richard Segal,Richard Goodwin</p>
<p><a href='http://arxiv.org/abs/2401.05199v1'>http://arxiv.org/abs/2401.05199v1</a></p>
<p><b>Compressor summary</b>: RecipeMC is a method to generate more credible and preferred food recipes using GPT-2 and Monte Carlo Tree Search with reward functions.</p><hr><h3>Experiment Planning with Function Approximation</h3>
<p>Aldo Pacchiano,Jonathan N. Lee,Emma Brunskill</p>
<p><a href='http://arxiv.org/abs/2401.05193v1'>http://arxiv.org/abs/2401.05193v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two experiment planning strategies for contextual bandit problems using function approximation, one with eluder planning and sampling that achieves optimality guarantees, and another with uniform sampler for small action spaces.</p><hr><h3>Divide and Conquer for Large Language Models Reasoning</h3>
<p>Zijie Meng,Yan Zhang,Zhaopeng Feng,Yang Feng,Gaoang Wang,Joey Tianyi Zhou,Jian Wu,Zuozhu Liu</p>
<p><a href='http://arxiv.org/abs/2401.05190v1'>http://arxiv.org/abs/2401.05190v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Divide and Conquer strategy for large language models to improve their reasoning abilities on multi-choice questions by handling different subsets of tasks with different methods.</p><hr><h3>Can ChatGPT Rival Neural Machine Translation? A Comparative Study</h3>
<p>Zhaokun Jiang,Ziyin Zhang</p>
<p><a href='http://arxiv.org/abs/2401.05176v1'>http://arxiv.org/abs/2401.05176v1</a></p>
<p><b>Compressor summary</b>: The paper compares ChatGPT and NMT engines for Chinese-English translation using automated metrics and human evaluation, finding that ChatGPT performs better with contextual information.</p><hr><h3>CLIP-guided Source-free Object Detection in Aerial Images</h3>
<p>Nanqing Liu,Xun Xu,Yongyi Su,Chengxin Liu,Peiliang Gong,Heng-Chao Li</p>
<p><a href='http://arxiv.org/abs/2401.05168v1'>http://arxiv.org/abs/2401.05168v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The text proposes a novel object detection method (SFOD) for aerial images with domain adaptation challenges
- SFOD uses self-training and CLIP-guided aggregation to generate pseudo-labels from unlabeled data
- SFOD is evaluated on two new datasets and shows better performance than other methods

Summary:
The text introduces a novel method (SFOD) for detecting objects in aerial images with domain adaptation issues, using self-training and CLIP-guided aggregation to create pseudo-labels from unlabeled data. The method is tested on two new datasets and outperforms other algorithms.</p><hr><h3>Watermark Text Pattern Spotting in Document Images</h3>
<p>Mateusz Krubinski,Stefan Matcovici,Diana Grigore,Daniel Voinea,Alin-Ionut Popa</p>
<p><a href='http://arxiv.org/abs/2401.05167v1'>http://arxiv.org/abs/2401.05167v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Watermark text spotting in document images can reveal information about the scope, audience and authenticity of records
- Existing methods face challenges due to varied writing styles in the wild
- A new benchmark (K-Watermark) and a solution (Wextract) are proposed to detect and extract watermark text from documents
- The solution outperforms baselines by 5 AP points in detection and 4 points in character accuracy

Summary:
The paper presents a novel approach for detecting and extracting watermark text from document images, which can provide valuable information about the records. It introduces a new benchmark and a state-of-the-art solution that surpass existing methods by a significant margin.</p><hr><h3>REACT 2024: the Second Multiple Appropriate Facial Reaction Generation  Challenge</h3>
<p>Siyang Song,Micol Spitale,Cheng Luo,Cristina Palmero,German Barquero,Hengde Zhu,Sergio Escalera,Michel Valstar,Tobias Baur,Fabien Ringeval,Elisabeth Andre,Hatice Gunes</p>
<p><a href='http://arxiv.org/abs/2401.05166v1'>http://arxiv.org/abs/2401.05166v1</a></p>
<p><b>Compressor summary</b>: The REACT 2024 challenge aims to develop machine learning models that generate diverse and realistic human facial reactions in response to speaker behaviors in dyadic interactions, using data from NOXI and RECOLA datasets.</p><hr><h3>MISS: A Generative Pretraining and Finetuning Approach for Med-VQA</h3>
<p>Jiawei Chen,Dingkang Yang,Yue Jiang,Yuxuan Lei,Lihua Zhang</p>
<p><a href='http://arxiv.org/abs/2401.05163v1'>http://arxiv.org/abs/2401.05163v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a large-scale self-supervised learning framework for medical visual question answering, treating it as a generative task and extending traditional image datasets with language models.</p><hr><h3>Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion  Models for Enhanced Skin Disease Classification using ViT and CNN</h3>
<p>Muhammad Ali Farooq,Wang Yao,Michael Schukat,Mark A Little,Peter Corcoran</p>
<p><a href='http://arxiv.org/abs/2401.05159v1'>http://arxiv.org/abs/2401.05159v1</a></p>
<p><b>Compressor summary</b>: The study shows that using synthetic skin lesion data from stable diffusion models enhances the performance and generalization of machine learning models for real-world skin lesion analysis.</p><hr><h3>Toward distortion-aware change detection in realistic scenarios</h3>
<p>Yitao Zhao,Heng-Chao Li,Nanqing Liu,Rui Wang</p>
<p><a href='http://arxiv.org/abs/2401.05157v1'>http://arxiv.org/abs/2401.05157v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a self-supervised framework to address bitemporal geometric distortion in change detection tasks using pretext representation pre-training, image alignment, and fine-tuning.</p><hr><h3>CrossDiff: Exploring Self-Supervised Representation of Pansharpening via  Cross-Predictive Diffusion Model</h3>
<p>Yinghui Xing,Litao Qu,ShiZhou Zhang,Xiuwei Zhang,Yanning Zhang</p>
<p><a href='http://arxiv.org/abs/2401.05153v1'>http://arxiv.org/abs/2401.05153v1</a></p>
<p><b>Compressor summary</b>: The paper proposes CrossDiff, a cross-predictive diffusion model that uses self-supervised representation to improve pansharpening by combining spatial and spectral features from PAN and MS images.</p><hr><h3>Machine Learning to Promote Translational Research: Predicting Patent  and Clinical Trial Inclusion in Dementia Research</h3>
<p>Matilda Beinat,Julian Beinat,Mohammed Shoaib,Jorge Gomez Magenti</p>
<p><a href='http://arxiv.org/abs/2401.05145v1'>http://arxiv.org/abs/2401.05145v1</a></p>
<p><b>Compressor summary</b>: This study uses machine learning to predict which dementia research papers will have practical applications, aiming to improve translation of discoveries into treatments and reduce the societal and economic burden of the disease.</p><hr><h3>Yes, this is what I was looking for! Towards Multi-modal Medical  Consultation Concern Summary Generation</h3>
<p>Abhisek Tiwari,Shreyangshu Bera,Sriparna Saha,Pushpak Bhattacharyya,Samrat Ghosh</p>
<p><a href='http://arxiv.org/abs/2401.05134v1'>http://arxiv.org/abs/2401.05134v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a system to generate short summaries of patients' concerns during doctor-patient consultations using nonverbal cues, personal information, and a multitasking framework.</p><hr><h3>Neural Population Learning beyond Symmetric Zero-sum Games</h3>
<p>Siqi Liu,Luke Marris,Marc Lanctot,Georgios Piliouras,Joel Z. Leibo,Nicolas Heess</p>
<p><a href='http://arxiv.org/abs/2401.05133v1'>http://arxiv.org/abs/2401.05133v1</a></p>
<p><b>Compressor summary</b>: The paper proposes NeuPL-JPSRO, a method for finding equilibria in complex general-sum games using neural networks and transfer learning, which works well empirically and theoretically.</p><hr><h3>Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving  Vision Transformer</h3>
<p>Teru Nagamori,Sayaka Shiota,Hitoshi Kiya</p>
<p><a href='http://arxiv.org/abs/2401.05126v1'>http://arxiv.org/abs/2401.05126v1</a></p>
<p><b>Compressor summary</b>: The proposed method enables privacy-preserving training and testing of deep neural networks using encrypted images without sacrificing performance.</p><hr><h3>BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation</h3>
<p>Samuele Garda,Ulf Leser</p>
<p><a href='http://arxiv.org/abs/2401.05125v1'>http://arxiv.org/abs/2401.05125v1</a></p>
<p><b>Compressor summary</b>: BELHD is a new method for biomedical entity linking that handles homonyms by preprocessing the knowledge base and using candidate sharing for contrastive learning, improving results on 10 corpora.</p><hr><h3>Any-Way Meta Learning</h3>
<p>Junhoo Lee,Yearim Kim,Hyunho Lee,Nojun Kwak</p>
<p><a href='http://arxiv.org/abs/2401.05097v1'>http://arxiv.org/abs/2401.05097v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an "any-way" learning paradigm that overcomes fixed cardinality constraints in meta-learning by using label equivalence from episodic task sampling and improves performance, convergence speed, and stability.</p><hr><h3>SwiMDiff: Scene-wide Matching Contrastive Learning with Diffusion  Constraint for Remote Sensing Image</h3>
<p>Jiayuan Tian,Jie Lei,Jiaqing Zhang,Weiying Xie,Yunsong Li</p>
<p><a href='http://arxiv.org/abs/2401.05093v1'>http://arxiv.org/abs/2401.05093v1</a></p>
<p><b>Compressor summary</b>: SwiMDiff is a novel self-supervised pre-training framework for remote sensing images that addresses challenges in contrastive learning by scene-wide matching and pixel-level diffusion constraints, improving performance in change detection and land-cover classification tasks.</p><hr><h3>Hierarchical Classification of Transversal Skills in Job Ads Based on  Sentence Embeddings</h3>
<p>Florin Leon,Marius Gavrilescu,Sabina-Adriana Floria,Alina-Adriana Minea</p>
<p><a href='http://arxiv.org/abs/2401.05073v1'>http://arxiv.org/abs/2401.05073v1</a></p>
<p><b>Compressor summary</b>: The paper presents a deep learning model that identifies transversal skills needed for different jobs by analyzing job ads in multiple languages and using ESCO taxonomy.</p><hr><h3>Aligning Translation-Specific Understanding to General Understanding in  Large Language Models</h3>
<p>Yichong Huang,Xiaocheng Feng,Baohang Li,Chengpeng Fu,Wenshuai Huo,Ting Liu,Bing Qin</p>
<p><a href='http://arxiv.org/abs/2401.05072v1'>http://arxiv.org/abs/2401.05072v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel translation process (xIoD) that aligns general understanding and content-specific knowledge in LLMs by interpreting difficult words across languages and enhancing translations with these interpretations.</p><hr><h3>MISS: Multiclass Interpretable Scoring Systems</h3>
<p>Michal K. Grzeszczyk,Tomasz Trzciński,Arkadiusz Sitek</p>
<p><a href='http://arxiv.org/abs/2401.05069v1'>http://arxiv.org/abs/2401.05069v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new machine-learning method for creating interpretable scoring systems for multiclass problems, useful for decision making in healthcare and criminal justice.</p><hr><h3>Application of Deep Learning in Blind Motion Deblurring: Current Status  and Future Prospects</h3>
<p>Yawen Xiang,Heng Zhou,Chengyang Li,Fangwei Sun,Zhongbo Li,Yongqiang Xie</p>
<p><a href='http://arxiv.org/abs/2401.05055v1'>http://arxiv.org/abs/2401.05055v1</a></p>
<p><b>Compressor summary</b>: This paper reviews deep learning methods for blind motion deblurring, comparing their advantages and limitations on various datasets.</p><hr><h3>Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding</h3>
<p>Yuu Jinnai,Ukyo Honda,Tetsuro Morimura,Peinan Zhang</p>
<p><a href='http://arxiv.org/abs/2401.05054v1'>http://arxiv.org/abs/2401.05054v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two new methods, DMBR and KMBR, to generate high-quality and diverse sentences by adding diversity objectives to MBR decoding, and shows their effectiveness on various text generation tasks.</p><hr><h3>Content-Aware Depth-Adaptive Image Restoration</h3>
<p>Tom Richard Vargis,Siavash Ghiasvand</p>
<p><a href='http://arxiv.org/abs/2401.05049v1'>http://arxiv.org/abs/2401.05049v1</a></p>
<p><b>Compressor summary</b>: The paper presents a modular image restoration pipeline using existing models and allowing user control over the process, adaptable for various object categories like medical images.</p><hr><h3>CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation  in Classification Tasks</h3>
<p>Kaizheng Wang,Keivan Shariatmadar,Shireen Kudukkil Manchingal,Fabio Cuzzolin,David Moens,Hans Hallez</p>
<p><a href='http://arxiv.org/abs/2401.05043v1'>http://arxiv.org/abs/2401.05043v1</a></p>
<p><b>Compressor summary</b>: CreINNs are novel interval neural networks that estimate both weight uncertainty and credal sets for improved out-of-distribution detection with less computational complexity than existing methods.</p><hr><h3>Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk</h3>
<p>Dennis Ulmer,Elman Mansimov,Kaixiang Lin,Justin Sun,Xibin Gao,Yi Zhang</p>
<p><a href='http://arxiv.org/abs/2401.05033v1'>http://arxiv.org/abs/2401.05033v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Large language models are powerful but hard to specialize for specific functions
- Instructing tuning requires many human-generated samples, which are costly or unavailable
- Self-talk method uses LLMs in different roles to collect data for fine-tuning
- Automated metric measures dialogue success and filters data for training
- Self-talk data improves results and quality of dialogues

Summary:
The paper proposes a self-talk method that uses large language models to engage in conversations in various roles, collecting data for fine-tuning without human input. It introduces an automated metric to measure dialogue success and filter data, and shows that self-talk data improves results and quality of dialogues.</p><hr><h3>AdvMT: Adversarial Motion Transformer for Long-term Human Motion  Prediction</h3>
<p>Sarmad Idrees,Jongeun Choi,Seokman Sohn</p>
<p><a href='http://arxiv.org/abs/2401.05018v1'>http://arxiv.org/abs/2401.05018v1</a></p>
<p><b>Compressor summary</b>: AdvMT is a new model for predicting human movements that uses a transformer encoder and a temporal continuity discriminator to capture spatial and temporal dependencies, resulting in more accurate and realistic motion predictions.</p><hr><h3>An Information Theoretic Approach to Interaction-Grounded Learning</h3>
<p>Xiaoyan Hu,Farzan Farnia,Ho-fung Leung</p>
<p><a href='http://arxiv.org/abs/2401.05015v1'>http://arxiv.org/abs/2401.05015v1</a></p>
<p><b>Compressor summary</b>: VI-IGL is a new information-theoretic method for reinforcement learning that infers latent rewards from feedback variables using conditional mutual information and shows improved performance compared to previous methods.</p><hr><h3>Source-Free Cross-Modal Knowledge Transfer by Unleashing the Potential  of Task-Irrelevant Data</h3>
<p>Jinjing Zhu,Yucheng Chen,Lin Wang</p>
<p><a href='http://arxiv.org/abs/2401.05014v1'>http://arxiv.org/abs/2401.05014v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework to transfer knowledge between modalities without access to source data by using task-irrelevant data to bridge the gaps and enhance knowledge transfer.</p><hr><h3>HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling for  Long-Term Forecasting</h3>
<p>Shubao Zhao,Ming Jin,Zhaoxiang Hou,Chengyi Yang,Zengxiang Li,Qingsong Wen,Yi Wang</p>
<p><a href='http://arxiv.org/abs/2401.05012v1'>http://arxiv.org/abs/2401.05012v1</a></p>
<p><b>Compressor summary</b>: HiMTM is a new hierarchical multi-scale model for time series forecasting that outperforms existing self-supervised and end-to-end methods.</p><hr><h3>Dual-Perspective Knowledge Enrichment for Semi-Supervised 3D Object  Detection</h3>
<p>Yucheng Han,Na Zhao,Weiling Chen,Keng Teck Ma,Hanwang Zhang</p>
<p><a href='http://arxiv.org/abs/2401.05011v1'>http://arxiv.org/abs/2401.05011v1</a></p>
<p><b>Compressor summary</b>: DPKE is a novel approach for semi-supervised 3D object detection that enriches knowledge from data and feature perspectives, improving performance over existing methods.</p><hr><h3>Less is More : A Closer Look at Multi-Modal Few-Shot Learning</h3>
<p>Chunpeng Zhou,Haishuai Wang,Xilu Yuan,Zhi Yu,Jiajun Bu</p>
<p><a href='http://arxiv.org/abs/2401.05010v1'>http://arxiv.org/abs/2401.05010v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a simple and effective framework for few-shot learning that leverages textual information and pre-trained language models, achieving impressive results and surpassing state-of-the-art methods in 1-shot learning tasks.</p><hr><h3>Temporal Analysis of World Disaster Risk:A Machine Learning Approach to  Cluster Dynamics</h3>
<p>Christian Mulomba Mukendi,Hyebong Choi</p>
<p><a href='http://arxiv.org/abs/2401.05007v1'>http://arxiv.org/abs/2401.05007v1</a></p>
<p><b>Compressor summary</b>: This paper evaluates global disaster risk management efforts using the World Risk Index and finds that traditional long-term strategies are not effective, suggesting a need for innovative approaches tailored to highly vulnerable countries.</p><hr><h3>Optimising Graph Representation for Hardware Implementation of Graph  Convolutional Networks for Event-based Vision</h3>
<p>Kamil Jeziorek,Piotr Wzorek,Krzysztof Blachut,Andrea Pinna,Tomasz Kryjak</p>
<p><a href='http://arxiv.org/abs/2401.04988v1'>http://arxiv.org/abs/2401.04988v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Event-based vision processes data from neuromorphic cameras using Graph Convolutional Networks (GCNs)
- Paper presents hardware implementation of graph generation from event camera data
- Proposes simplifications and modifications to graph representation
- Results show minimal impact on object detection performance

Summary:
The paper proposes and implements a hardware module for generating graphs from event camera data for event-based vision, with minimal impact on object detection.</p><hr><h3>Structure-Preserving Physics-Informed Neural Networks With Energy or  Lyapunov Structure</h3>
<p>Haoyu Chu,Yuto Miyatake,Wenjun Cui,Shikui Wei,Daisuke Furihata</p>
<p><a href='http://arxiv.org/abs/2401.04986v1'>http://arxiv.org/abs/2401.04986v1</a></p>
<p><b>Compressor summary</b>: The text proposes structure-preserving physics-informed neural networks to improve learning efficiency and apply them to downstream tasks like robust image recognition.</p><hr><h3>MGNet: Learning Correspondences via Multiple Graphs</h3>
<p>Luanyuan Dai,Xiaoyu Du,Hanwang Zhang,Jinhui Tang</p>
<p><a href='http://arxiv.org/abs/2401.04984v1'>http://arxiv.org/abs/2401.04984v1</a></p>
<p><b>Compressor summary</b>: The paper proposes MGNet, a method that combines multiple complementary graphs to find correspondences using graph neural networks and Graph Soft Degree Attention.</p><hr><h3>Invertible Solution of Neural Differential Equations for Analysis of  Irregularly-Sampled Time Series</h3>
<p>YongKyung Oh,Dongyoung Lim,Sungil Kim</p>
<p><a href='http://arxiv.org/abs/2401.04979v1'>http://arxiv.org/abs/2401.04979v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel Neural CDEs-based method that ensures invertibility and better modeling of dynamic temporal dynamics for analyzing irregular and incomplete time series data, outperforming existing models in classification and interpolation tasks.</p><hr><h3>Closed-Form Interpretation of Neural Network Classifiers with Symbolic  Regression Gradients</h3>
<p>Sebastian Johann Wetzel</p>
<p><a href='http://arxiv.org/abs/2401.04978v1'>http://arxiv.org/abs/2401.04978v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method for interpreting neural network classifiers by finding an intersection between their equivalence classes and symbolic equations, enabling automated scientific discovery.</p><hr><h3>HaltingVT: Adaptive Token Halting Transformer for Efficient Video  Recognition</h3>
<p>Qian Wu,Ruoxuan Cui,Yuke Li,Haoqi Zhu</p>
<p><a href='http://arxiv.org/abs/2401.04975v1'>http://arxiv.org/abs/2401.04975v1</a></p>
<p><b>Compressor summary</b>: The paper introduces HaltingVT, a video transformer that adaptively removes redundant tokens to improve efficiency and performance in action recognition tasks.</p><hr><h3>Whose wife is it anyway? Assessing bias against same-gender  relationships in machine translation</h3>
<p>Ian Stewart,Rada Mihalcea</p>
<p><a href='http://arxiv.org/abs/2401.04972v1'>http://arxiv.org/abs/2401.04972v1</a></p>
<p><b>Compressor summary</b>: This text discusses how machine translation (MT) systems often fail to accurately translate sentences about same-gender relationships, and examines factors that influence this bias in natural language processing (NLP).</p><hr><h3>Large Model based Sequential Keyframe Extraction for Video Summarization</h3>
<p>Kailong Tan,Yuxiang Zhou,Qianchen Xia,Rui Liu,Yong Chen</p>
<p><a href='http://arxiv.org/abs/2401.04962v1'>http://arxiv.org/abs/2401.04962v1</a></p>
<p><b>Compressor summary</b>: LMSKE is a video summarization method that uses large models to cut videos into shots, generate visual features, cluster candidate keyframes, and eliminate redundancy to create a summary with minimum frames.</p><hr><h3>ECC-PolypDet: Enhanced CenterNet with Contrastive Learning for Automatic  Polyp Detection</h3>
<p>Yuncheng Jiang,Zixun Zhang,Yiwen Hu,Guanbin Li,Xiang Wan,Song Wu,Shuguang Cui,Silin Huang,Zhen Li</p>
<p><a href='http://arxiv.org/abs/2401.04961v1'>http://arxiv.org/abs/2401.04961v1</a></p>
<p><b>Compressor summary</b>: ECC-PolypDet is a new method that uses contrastive learning and other techniques to improve polyp detection in colorectal cancer screening, outperforming existing approaches.</p><hr><h3>EmMixformer: Mix transformer for eye movement recognition</h3>
<p>Huafeng Qin,Hongyu Zhu,Xin Jin,Qun Song,Mounim A. El-Yacoubi,Xinbo Gao</p>
<p><a href='http://arxiv.org/abs/2401.04956v1'>http://arxiv.org/abs/2401.04956v1</a></p>
<p><b>Compressor summary</b>: EmMixformer uses a transformer, attention LSTM, and Fourier transformer to capture local and global temporal dependencies in eye movement data for improved recognition accuracy.</p><hr><h3>Can AI Write Classical Chinese Poetry like Humans? An Empirical Study  Inspired by Turing Test</h3>
<p>Zekun Deng,Hao Yang,Jun Wang</p>
<p><a href='http://arxiv.org/abs/2401.04952v1'>http://arxiv.org/abs/2401.04952v1</a></p>
<p><b>Compressor summary</b>: The paper introduces ProFTAP, a framework to evaluate AI's poetry writing ability, and shows that current LLMs can write classical Chinese poems comparable to humans, even surpassing GPT-4.</p><hr><h3>Latency-aware Road Anomaly Segmentation in Videos: A Photorealistic  Dataset and New Metrics</h3>
<p>Beiwen Tian,Huan-ang Gao,Leiyao Cui,Yupeng Zheng,Lan Luo,Baofeng Wang,Rong Zhi,Guyue Zhou,Hao Zhao</p>
<p><a href='http://arxiv.org/abs/2401.04942v1'>http://arxiv.org/abs/2401.04942v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new video anomaly segmentation dataset for autonomous driving, using synthetic data enhanced with a generative adversarial network to improve realism and providing two novel metrics for evaluating the safety of the algorithm.</p><hr><h3>Rethinking Test-time Likelihood: The Likelihood Path Principle and Its  Application to OOD Detection</h3>
<p>Sicong Huang,Jiawei He,Kry Yik Chau Lui</p>
<p><a href='http://arxiv.org/abs/2401.04933v1'>http://arxiv.org/abs/2401.04933v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new method for out of distribution detection using variational autoencoders, with provable guarantees and better empirical results than existing techniques.</p><hr><h3>The Impact of Reasoning Step Length on Large Language Models</h3>
<p>Mingyu Jin,Qinkai Yu,Dong shu,Haiyan Zhao,Wenyue Hua,Yanda Meng,Yongfeng Zhang,Mengnan Du</p>
<p><a href='http://arxiv.org/abs/2401.04925v1'>http://arxiv.org/abs/2401.04925v1</a></p>
<p><b>Compressor summary</b>: The number and length of reasoning steps in chain of thought prompts greatly affect large language models' reasoning abilities, with longer steps enhancing performance and shorter steps diminishing it.</p><hr><h3>Inconsistency-Based Data-Centric Active Open-Set Annotation</h3>
<p>Ruiyu Mao,Ouyang Xu,Yunhui Guo</p>
<p><a href='http://arxiv.org/abs/2401.04923v1'>http://arxiv.org/abs/2401.04923v1</a></p>
<p><b>Compressor summary</b>: NEAT is an efficient data-centric method for annotating open-set data, which improves upon existing active learning approaches by handling unknown classes and using clusterability of labels to select informative samples.</p><hr><h3>Diffusion-based Pose Refinement and Muti-hypothesis Generation for 3D  Human Pose Estimaiton</h3>
<p>Hongbo Kang,Yong Wang,Mengyuan Liu,Doudou Wu,Peng Liu,Xinlin Yuan,Wenming Yang</p>
<p><a href='http://arxiv.org/abs/2401.04921v1'>http://arxiv.org/abs/2401.04921v1</a></p>
<p><b>Compressor summary</b>: The DRPose framework refines the output of deterministic models for 3D human pose estimation using diffusion, denoising, and multi-step refinement, achieving state-of-the-art performance on both single and multi-hypothesis tasks.</p><hr><h3>SnapCap: Efficient Snapshot Compressive Video Captioning</h3>
<p>Jianqiao Sun,Yudi Su,Hao Zhang,Ziheng Cheng,Zequn Zeng,Zhengjue Wang,Bo Chen,Xin Yuan</p>
<p><a href='http://arxiv.org/abs/2401.04903v1'>http://arxiv.org/abs/2401.04903v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel video captioning pipeline called SnapCap that generates captions directly from compressed measurements obtained by a snapshot compressive sensing camera, improving efficiency and quality over traditional methods.</p><hr><h3>ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language  Models In Chinese Domain</h3>
<p>Bingchao Wang</p>
<p><a href='http://arxiv.org/abs/2401.04898v1'>http://arxiv.org/abs/2401.04898v1</a></p>
<p><b>Compressor summary</b>: This paper introduces ANGO, a Chinese multi-choice question benchmark for evaluating large language models with improved interpretability, question difficulty, and sampling strategies.</p><hr><h3>Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate  Group Conversations</h3>
<p>Manqing Mao,Paishun Ting,Yijian Xiang,Mingyang Xu,Julia Chen,Jianzhe Lin</p>
<p><a href='http://arxiv.org/abs/2401.04883v1'>http://arxiv.org/abs/2401.04883v1</a></p>
<p><b>Compressor summary</b>: The paper introduces MUCA, an LLM-based chatbot framework for group discussions that considers 3W design dimensions (what, when, and who) and uses an LLM-based simulator to improve efficiency in developing the framework.</p><hr><h3>Attendre: Wait To Attend By Retrieval With Evicted Queries in  Memory-Based Transformers for Long Context Processing</h3>
<p>Zi Yang,Nan Hua</p>
<p><a href='http://arxiv.org/abs/2401.04881v1'>http://arxiv.org/abs/2401.04881v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an efficient way to handle long sequences in LLMs by using eviction policies and a wait-to-attend mechanism that adapts to different architectures and tasks.</p><hr><h3>Knowledge-aware Graph Transformer for Pedestrian Trajectory Prediction</h3>
<p>Yu Liu,Yuexin Zhang,Kunming Li,Yongliang Qiao,Stewart Worrall,You-Fu Li,He Kong</p>
<p><a href='http://arxiv.org/abs/2401.04872v1'>http://arxiv.org/abs/2401.04872v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a graph transformer with self-attention and domain adaptation to improve pedestrian motion prediction across various scenarios, and introduces a new metric for evaluation.</p><hr><h3>Real-time and Continuous Turn-taking Prediction Using Voice Activity  Projection</h3>
<p>Koji Inoue,Bing'er Jiang,Erik Ekstedt,Tatsuya Kawahara,Gabriel Skantze</p>
<p><a href='http://arxiv.org/abs/2401.04868v1'>http://arxiv.org/abs/2401.04868v1</a></p>
<p><b>Compressor summary</b>: The paper presents a real-time turn-taking prediction system using voice activity projection (VAP), which combines contrastive predictive coding (CPC) and self/cross-attention transformers to map audio to future voice activities.</p><hr><h3>An Analysis of User Behaviours for Objectively Evaluating Spoken  Dialogue Systems</h3>
<p>Koji Inoue,Divesh Lala,Keiko Ochi,Tatsuya Kawahara,Gabriel Skantze</p>
<p><a href='http://arxiv.org/abs/2401.04867v1'>http://arxiv.org/abs/2401.04867v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an objective framework for evaluating spoken dialogue systems based on users' behaviours and shows how different behaviours correlate with subjective scores in three social dialogue tasks.</p><hr><h3>CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from  Monocular Video</h3>
<p>Xingyu Miao,Yang Bai,Haoran Duan,Yawen Huang,Fan Wan,Yang Long,Yefeng Zheng</p>
<p><a href='http://arxiv.org/abs/2401.04861v1'>http://arxiv.org/abs/2401.04861v1</a></p>
<p><b>Compressor summary</b>: Our method improves novel view generation from monocular videos by modeling object motion using a time-frequency domain module on top of a generalization NeRF.</p><hr><h3>Modality-Aware Representation Learning for Zero-shot Sketch-based Image  Retrieval</h3>
<p>Eunyi Lyou,Doyeon Lee,Jooeun Kim,Joonseok Lee</p>
<p><a href='http://arxiv.org/abs/2401.04860v1'>http://arxiv.org/abs/2401.04860v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel framework for zero-shot sketch-based image retrieval that aligns sketches and photos through texts and bridges the modality gap using an explicit modality encoding.</p><hr><h3>User Embedding Model for Personalized Language Prompting</h3>
<p>Sumanth Doddapaneni,Krishna Sayana,Ambarish Jash,Sukhdeep Sodhi,Dima Kuzmin</p>
<p><a href='http://arxiv.org/abs/2401.04858v1'>http://arxiv.org/abs/2401.04858v1</a></p>
<p><b>Compressor summary</b>: The study proposes a User Embedding Module (UEM) that converts user history in text form into embeddings, which improve recommendation systems' personalization and handle longer histories better than conventional methods.</p><hr><h3>Transportation Market Rate Forecast Using Signature Transform</h3>
<p>Haotian Gu,Tim Jacobs,Philip Kaminsky,Xin Guo,Xinyu Li</p>
<p><a href='http://arxiv.org/abs/2401.04857v1'>http://arxiv.org/abs/2401.04857v1</a></p>
<p><b>Compressor summary</b>: The authors propose a signature-based statistical technique for more accurate and interpretable marketplace rate forecasts, outperforming existing methods during crises like Covid-19 and the Ukraine war.</p><hr><h3>A Good Score Does not Lead to A Good Generative Model</h3>
<p>Sixu Li,Shi Chen,Qin Li</p>
<p><a href='http://arxiv.org/abs/2401.04856v1'>http://arxiv.org/abs/2401.04856v1</a></p>
<p><b>Compressor summary</b>: The paper shows that score-based generative models can fail to generate diverse samples even when the score function is well learned, by providing a counterexample where they produce blurry versions of training data.</p><hr><h3>Are Language Models More Like Libraries or Like Librarians?  Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs</h3>
<p>Harvey Lederman,Kyle Mahowald</p>
<p><a href='http://arxiv.org/abs/2401.04854v1'>http://arxiv.org/abs/2401.04854v1</a></p>
<p><b>Compressor summary</b>: The text discusses whether LLMs are cultural technologies that transmit information or possess a limited form of agency based on their ability to generate novel reference using new names for entities.</p>