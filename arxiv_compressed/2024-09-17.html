
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2024-09-17</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-09-17 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>RetrievalAttention: Accelerating Long-Context LLM Inference via Vector  Retrieval</h3>
<p><a href='http://arxiv.org/abs/2409.10516v1'>http://arxiv.org/abs/2409.10516v1</a></p>
<p><b>Compressor summary</b>: RetrievalAttention speeds up attention computation by using approximate nearest neighbor search and reducing data access to exploit sparsity, achieving sub-linear time complexity and lower GPU memory requirements.</p><hr><h3>DILA: Dictionary Label Attention for Mechanistic Interpretability in  High-dimensional Multi-label Medical Coding Prediction</h3>
<p><a href='http://arxiv.org/abs/2409.10504v1'>http://arxiv.org/abs/2409.10504v1</a></p>
<p><b>Compressor summary</b>: The DIctionary Label Attention module disentangles dense embeddings into sparse ones, making medical code predictions more accurate and interpretable by uncovering thousands of learned medical concepts.</p><hr><h3>Causal Language Modeling Can Elicit Search and Reasoning Capabilities on  Logic Puzzles</h3>
<p><a href='http://arxiv.org/abs/2409.10502v1'>http://arxiv.org/abs/2409.10502v1</a></p>
<p><b>Compressor summary</b>: The paper shows that Transformers can learn to solve Sudoku and Zebra puzzles by training on logical steps and have a hidden reasoning engine within their weights.</p><hr><h3>Partial Distribution Matching via Partial Wasserstein Adversarial  Networks</h3>
<p><a href='http://arxiv.org/abs/2409.10499v1'>http://arxiv.org/abs/2409.10499v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a partial distribution matching method using a Wasserstein adversarial network and shows its effectiveness in point set registration and domain adaptation tasks.</p><hr><h3>Flash STU: Fast Spectral Transform Units</h3>
<p><a href='http://arxiv.org/abs/2409.10489v1'>http://arxiv.org/abs/2409.10489v1</a></p>
<p><b>Compressor summary</b>: The paper presents an efficient PyTorch implementation of the Spectral Transform Unit (STU) that beats the Transformer and other state space models in different sequence prediction tasks like language, robotics, and simulated systems.</p><hr><h3>Do Pre-trained Vision-Language Models Encode Object States?</h3>
<p><a href='http://arxiv.org/abs/2409.10488v1'>http://arxiv.org/abs/2409.10488v1</a></p>
<p><b>Compressor summary</b>: The paper examines if vision-language models can recognize physical states of objects over time and suggests improvements for better performance.</p><hr><h3>Schrodinger's Memory: Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2409.10482v1'>http://arxiv.org/abs/2409.10482v1</a></p>
<p><b>Compressor summary</b>: </p><hr><h3>SimInversion: A Simple Framework for Inversion-Based Text-to-Image  Editing</h3>
<p><a href='http://arxiv.org/abs/2409.10476v1'>http://arxiv.org/abs/2409.10476v1</a></p>
<p><b>Compressor summary</b>: The text proposes improving DDIM inversion for image editing by disentangling the guidance scale and using a better scale (0.5) derived theoretically, leading to better performance and efficiency.</p><hr><h3>MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion</h3>
<p><a href='http://arxiv.org/abs/2409.10473v1'>http://arxiv.org/abs/2409.10473v1</a></p>
<p><b>Compressor summary</b>: Masked Conditional Diffusion (MacDiff) uses diffusion models and random masking to learn effective representations for human skeleton understanding, achieving state-of-the-art performance on benchmarks and improving fine-tuning in scarce labeled data scenarios.</p><hr><h3>Kolmogorov-Arnold Networks in Low-Data Regimes: A Comparative Study with  Multilayer Perceptrons</h3>
<p><a href='http://arxiv.org/abs/2409.10463v1'>http://arxiv.org/abs/2409.10463v1</a></p>
<p><b>Compressor summary</b>: This paper compares MLPs and KANs for modeling complex relationships with a focus on low-data regimes, introducing an effective technique to design MLPs with individualized activation functions that achieve higher predictive accuracy.</p><hr><h3>Signed Graph Autoencoder for Explainable and Polarization-Aware Network  Embeddings</h3>
<p><a href='http://arxiv.org/abs/2409.10452v1'>http://arxiv.org/abs/2409.10452v1</a></p>
<p><b>Compressor summary</b>: SGAAE is an explainable graph generative model that extracts node representations from signed networks based on polarization and archetypes, and shows high performance in signed link prediction tasks.</p><hr><h3>Deep-Wide Learning Assistance for Insect Pest Classification</h3>
<p><a href='http://arxiv.org/abs/2409.10445v1'>http://arxiv.org/abs/2409.10445v1</a></p>
<p><b>Compressor summary</b>: Key points:
- DeWi is a novel learning assistance for insect pest classification that uses a one-stage and alternating training strategy.
- It improves several Convolutional Neural Networks in discrimination and generalization by optimizing a triplet margin loss and data augmentation.
- It achieves the highest performances on two insect pest classification benchmarks.

Summary:
DeWi is a new method for classifying insect pests that uses a combined training strategy to improve both discrimination and generalization of Convolutional Neural Networks, resulting in the best performance on two datasets.</p><hr><h3>Structure-preserving learning for multi-symplectic PDEs</h3>
<p><a href='http://arxiv.org/abs/2409.10432v1'>http://arxiv.org/abs/2409.10432v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a machine learning method to infer energy-preserving reduced-order models from PDEs using data without requiring fully discrete operators or intrusive knowledge of the PDEs.</p><hr><h3>A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning  and BERT Integration</h3>
<p><a href='http://arxiv.org/abs/2409.10403v1'>http://arxiv.org/abs/2409.10403v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to improve disease diagnosis by using structured knowledge from external sources and enhancing language models' performance and interpretability on three datasets.</p><hr><h3>Revising the Structure of Recurrent Neural Networks to Eliminate  Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to  Time</h3>
<p><a href='http://arxiv.org/abs/2409.10388v1'>http://arxiv.org/abs/2409.10388v1</a></p>
<p><b>Compressor summary</b>: MI-RNN is a modified RNN that predicts over time intervals and can solve unsteady PDEs more accurately without numerical derivatives.</p><hr><h3>Mamba-ST: State Space Model for Efficient Style Transfer</h3>
<p><a href='http://arxiv.org/abs/2409.10385v1'>http://arxiv.org/abs/2409.10385v1</a></p>
<p><b>Compressor summary</b>: Mamba-ST is an efficient State-Space Model that performs style transfer by simulating cross-attention layers without extra modules, improving quality and reducing computational burden compared to transformers and diffusion models.</p><hr><h3>Instigating Cooperation among LLM Agents Using Adaptive Information  Modulation</h3>
<p><a href='http://arxiv.org/abs/2409.10372v1'>http://arxiv.org/abs/2409.10372v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new method that uses large language models and reinforcement learning to create more cooperative team behaviors in simulations.</p><hr><h3>Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L-FABP Using  GCN and Computational Modeling</h3>
<p><a href='http://arxiv.org/abs/2409.10370v1'>http://arxiv.org/abs/2409.10370v1</a></p>
<p><b>Compressor summary</b>: This study develops a novel approach using graph convolutional networks (GCNs) and molecular descriptors to predict the toxicity of per- and polyfluoroalkyl substances (PFAS), which are persistent environmental pollutants with known health concerns.</p><hr><h3>Robust image representations with counterfactual contrastive learning</h3>
<p><a href='http://arxiv.org/abs/2409.10365v1'>http://arxiv.org/abs/2409.10365v1</a></p>
<p><b>Compressor summary</b>: Counterfactual contrastive learning creates positive pairs for medical imaging that capture relevant domain variations, improving generalisation and performance on both in-distribution and out-of-distribution data.</p><hr><h3>2D or not 2D: How Does the Dimensionality of Gesture Representation  Affect 3D Co-Speech Gesture Generation?</h3>
<p><a href='http://arxiv.org/abs/2409.10357v1'>http://arxiv.org/abs/2409.10357v1</a></p>
<p><b>Compressor summary</b>: This paper explores how using 2D or 3D joint coordinates as training data affects the quality of speech-to-gesture deep generative models and compares the results with human gestures.</p><hr><h3>Taming Diffusion Models for Image Restoration: A Review</h3>
<p><a href='http://arxiv.org/abs/2409.10353v1'>http://arxiv.org/abs/2409.10353v1</a></p>
<p><b>Compressor summary</b>: This paper reviews diffusion models' applications in image restoration tasks, discussing their techniques, challenges, and future directions.</p><hr><h3>Detecting Sexism in German Online Newspaper Comments with Open-Source  Text Embeddings (Team GDA, GermEval2024 Shared Task 1: GerMS-Detect, Subtasks  1 and 2, Closed Track)</h3>
<p><a href='http://arxiv.org/abs/2409.10341v1'>http://arxiv.org/abs/2409.10341v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to detect sexism and misogyny in German online comments using text embeddings, achieving competitive results in a challenge and showing potential for scalability.</p><hr><h3>Hyperedge Modeling in Hypergraph Neural Networks by using Densest  Overlapping Subgraphs</h3>
<p><a href='http://arxiv.org/abs/2409.10340v1'>http://arxiv.org/abs/2409.10340v1</a></p>
<p><b>Compressor summary</b>: The text introduces hypergraphs, which extend graphs by allowing multiple nodes to be connected by a single hyperedge, and proposes a novel algorithm (DOSAGE) for finding densest overlapping subgraphs in hypergraphs that improves node classification performance.</p><hr><h3>The 20 questions game to distinguish large language models</h3>
<p><a href='http://arxiv.org/abs/2409.10338v1'>http://arxiv.org/abs/2409.10338v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to distinguish between large language models using a small number of binary questions, which could be useful for detecting model leaks.</p><hr><h3>InfoDisent: Explainability of Image Classification Models by Information  Disentanglement</h3>
<p><a href='http://arxiv.org/abs/2409.10329v1'>http://arxiv.org/abs/2409.10329v1</a></p>
<p><b>Compressor summary</b>: InfoDisent is a hybrid model that combines post-hoc and intrinsic methods to better understand and interpret the decisions made by pre-trained image classification networks.</p><hr><h3>Baking Relightable NeRF for Real-time Direct/Indirect Illumination  Rendering</h3>
<p><a href='http://arxiv.org/abs/2409.10327v1'>http://arxiv.org/abs/2409.10327v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to perform real-time relighting using a CNN renderer for direct illumination and a hash grid-based renderer for indirect illumination, trained with distillation from a pre-trained teacher model.</p><hr><h3>PSHuman: Photorealistic Single-view Human Reconstruction using  Cross-Scale Diffusion</h3>
<p><a href='http://arxiv.org/abs/2409.10141v1'>http://arxiv.org/abs/2409.10141v1</a></p>
<p><b>Compressor summary</b>: PSHuman uses cross-scale diffusion and parametric models to reconstruct detailed and photorealistic 3D human meshes from monocular RGB images, addressing challenges like self-occlusions and clothing topology.</p><hr><h3>StruEdit: Structured Outputs Enable the Fast and Accurate Knowledge  Editing for Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2409.10132v1'>http://arxiv.org/abs/2409.10132v1</a></p>
<p><b>Compressor summary</b>: StruEdit is a method to update large language models' answers with current knowledge by editing structured reasoning triplets, improving accuracy and speed.</p><hr><h3>Evaluating the Efficacy of Instance Incremental vs. Batch Learning in  Delayed Label Environments: An Empirical Study on Tabular Data Streaming for  Fraud Detection</h3>
<p><a href='http://arxiv.org/abs/2409.10111v1'>http://arxiv.org/abs/2409.10111v1</a></p>
<p><b>Compressor summary</b>: This study evaluates whether instance incremental or batch incremental learning is better for real-world fraud detection problems with delayed labels, finding that batch incremental models perform similarly or better in terms of predictive performance and interpretability.</p><hr><h3>A Comparative Study of Open Source Computer Vision Models for  Application on Small Data: The Case of CFRP Tape Laying</h3>
<p><a href='http://arxiv.org/abs/2409.10104v1'>http://arxiv.org/abs/2409.10104v1</a></p>
<p><b>Compressor summary</b>: The study explores how Transfer Learning can help train AI models in small data contexts for quality control of CFRP tape laying in aerospace manufacturing using optical sensors.</p><hr><h3>Robust Reinforcement Learning with Dynamic Distortion Risk Measures</h3>
<p><a href='http://arxiv.org/abs/2409.10096v1'>http://arxiv.org/abs/2409.10096v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework for robust risk-aware reinforcement learning using dynamic distortion risk measures, neural networks, and actor-critic algorithms to handle uncertainty and environmental dynamics.</p><hr><h3>DDoS: Diffusion Distribution Similarity for Out-of-Distribution  Detection</h3>
<p><a href='http://arxiv.org/abs/2409.10094v1'>http://arxiv.org/abs/2409.10094v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a diffusion-based OoD detection framework that uses a novel similarity metric in feature and probability spaces to measure distribution disparities between original and generated images, achieving better performance than existing methods.</p><hr><h3>MotionCom: Automatic and Motion-Aware Image Composition with LLM and  Video Diffusion Prior</h3>
<p><a href='http://arxiv.org/abs/2409.10090v1'>http://arxiv.org/abs/2409.10090v1</a></p>
<p><b>Compressor summary</b>: MotionCom is a novel image composition method that uses a large vision language model and video diffusion prior for automatic integration of objects into new scenes with realistic motion and interaction.</p><hr><h3>A Riemannian Approach to Ground Metric Learning for Optimal Transport</h3>
<p><a href='http://arxiv.org/abs/2409.10085v1'>http://arxiv.org/abs/2409.10085v1</a></p>
<p><b>Compressor summary</b>: This paper proposes learning a latent ground metric for optimal transport distances in machine learning and signal processing applications using Riemannian geometry.</p><hr><h3>DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality  Image Fusion</h3>
<p><a href='http://arxiv.org/abs/2409.10080v1'>http://arxiv.org/abs/2409.10080v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new framework called DAE-Fuse that uses a two-phase autoencoder to generate sharp and natural fused images from different imaging modalities.</p><hr><h3>LLM-DER:A Named Entity Recognition Method Based on Large Language Models  for Chinese Coal Chemical Domain</h3>
<p><a href='http://arxiv.org/abs/2409.10077v1'>http://arxiv.org/abs/2409.10077v1</a></p>
<p><b>Compressor summary</b>: The paper proposes LLM-DER, a framework that uses large language models to enrich entity information and evaluate plausibility for complex domain-specific entity recognition in Chinese.</p><hr><h3>Steinmetz Neural Networks for Complex-Valued Data</h3>
<p><a href='http://arxiv.org/abs/2409.10075v1'>http://arxiv.org/abs/2409.10075v1</a></p>
<p><b>Compressor summary</b>: Steinmetz Neural Networks use real-valued subnetworks with coupled outputs to process complex-valued data and Analytic Neural Networks enforce analytic signal representations for better generalization error bounds and performance.</p><hr><h3>Increasing faithfulness in human-human dialog summarization with Spoken  Language Understanding tasks</h3>
<p><a href='http://arxiv.org/abs/2409.10070v1'>http://arxiv.org/abs/2409.10070v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using semantic information from goal-oriented human-human dialogues to improve summarization and introduces a new dataset version for research on this topic.</p><hr><h3>Enhancing Anomaly Detection via Generating Diversified and  Hard-to-distinguish Synthetic Anomalies</h3>
<p><a href='http://arxiv.org/abs/2409.10069v1'>http://arxiv.org/abs/2409.10069v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a domain-agnostic method for unsupervised anomaly detection using conditional perturbators and a discriminator that generates diverse and hard-to-distinguish synthetic anomalies.</p><hr><h3>Spatiotemporal Covariance Neural Networks</h3>
<p><a href='http://arxiv.org/abs/2409.10068v1'>http://arxiv.org/abs/2409.10068v1</a></p>
<p><b>Compressor summary</b>: The STVNN model uses joint spatiotemporal convolutions to process multivariate time series, addressing instabilities in traditional methods like PCA and improving stability for dynamic data settings.</p><hr><h3>MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid  via Edge LLM</h3>
<p><a href='http://arxiv.org/abs/2409.10064v1'>http://arxiv.org/abs/2409.10064v1</a></p>
<p><b>Compressor summary</b>: MindGuard is a mobile mental healthcare system using an LLM to provide personalized screening and intervention conversations, addressing the low treatment rate due to stigma and improving accessibility in mental healthcare.</p><hr><h3>Householder Pseudo-Rotation: A Novel Approach to Activation Editing in  LLMs with Direction-Magnitude Perspective</h3>
<p><a href='http://arxiv.org/abs/2409.10053v1'>http://arxiv.org/abs/2409.10053v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new editing method for large language models that preserves activation magnitudes and improves safety benchmarks by rotating activations instead of adding steering vectors.</p><hr><h3>Global Lightning-Ignited Wildfires Prediction and Climate Change  Projections based on Explainable Machine Learning Models</h3>
<p><a href='http://arxiv.org/abs/2409.10046v1'>http://arxiv.org/abs/2409.10046v1</a></p>
<p><b>Compressor summary</b>: This study develops machine learning models to characterize and predict lightning-ignited wildfires globally, showing that climate change increases their risk and highlighting the importance of tailored models for different types of fires.</p><hr><h3>Learning Latent Wireless Dynamics from Channel State Information</h3>
<p><a href='http://arxiv.org/abs/2409.10045v1'>http://arxiv.org/abs/2409.10045v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new machine learning technique to model and predict wireless channel dynamics using compressed representations of channel state information.</p><hr><h3>Benchmarking Large Language Model Uncertainty for Prompt Optimization</h3>
<p><a href='http://arxiv.org/abs/2409.10044v1'>http://arxiv.org/abs/2409.10044v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a benchmark dataset to evaluate different types of uncertainty in LLMs, highlighting the need for improved metrics that better guide prompt optimization.</p><hr><h3>DENSER: 3D Gaussians Splatting for Scene Reconstruction of Dynamic Urban  Environments</h3>
<p><a href='http://arxiv.org/abs/2409.10041v1'>http://arxiv.org/abs/2409.10041v1</a></p>
<p><b>Compressor summary</b>: DENSER uses wavelets to improve 3D Gaussian splatting for dynamic urban scene reconstruction, outperforming existing methods on the KITTI dataset.</p><hr><h3>On the Diagram of Thought</h3>
<p><a href='http://arxiv.org/abs/2409.10038v1'>http://arxiv.org/abs/2409.10038v1</a></p>
<p><b>Compressor summary</b>: Diagram of Thought (DoT) is a framework for modeling iterative reasoning in large language models using directed acyclic graphs, enhancing logical consistency and soundness while improving reasoning capabilities.</p><hr><h3>AttnMod: Attention-Based New Art Styles</h3>
<p><a href='http://arxiv.org/abs/2409.10028v1'>http://arxiv.org/abs/2409.10028v1</a></p>
<p><b>Compressor summary</b>: AttnMod modifies cross attention in diffusion models to create new art styles that are not achievable with standard prompts.</p><hr><h3>LithoHoD: A Litho Simulator-Powered Framework for IC Layout Hotspot  Detection</h3>
<p><a href='http://arxiv.org/abs/2409.10021v1'>http://arxiv.org/abs/2409.10021v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Hotspot detection techniques for VLSI fabrication need to generalize well to real-world scenarios
- The proposed framework integrates a lithography simulator and an object detection network with cross-attention blocks
- The framework outperforms previous methods on real-world data

Summary:
The paper presents a novel hotspot detection framework for VLSI fabrication that combines a lithography simulator and an object detection network, enabling better generalization to real-world scenarios.</p><hr><h3>AceParse: A Comprehensive Dataset with Diverse Structured Texts for  Academic Literature Parsing</h3>
<p><a href='http://arxiv.org/abs/2409.10016v1'>http://arxiv.org/abs/2409.10016v1</a></p>
<p><b>Compressor summary</b>: The paper introduces AceParse, a comprehensive dataset for parsing diverse structured texts in academic literature, and presents AceParser, a multimodal model that outperforms the previous state-of-the-art in this task.</p><hr><h3>HALO: Hallucination Analysis and Learning Optimization to Empower LLMs  with Retrieval-Augmented Context for Guided Clinical Decision Making</h3>
<p><a href='http://arxiv.org/abs/2409.10011v1'>http://arxiv.org/abs/2409.10011v1</a></p>
<p><b>Compressor summary</b>: HALO is a framework that detects and mitigates hallucinations in medical question-answering systems by using multiple queries, retrieving context from external sources, and scoring relevance to improve the accuracy of large language models.</p><hr><h3>SelECT-SQL: Self-correcting ensemble Chain-of-Thought for Text-to-SQL</h3>
<p><a href='http://arxiv.org/abs/2409.10007v1'>http://arxiv.org/abs/2409.10007v1</a></p>
<p><b>Compressor summary</b>: SelECT-SQL is a new in-context learning approach that combines chain-of-thought prompting, self-correction, and ensemble methods to improve Text-to-SQL conversion accuracy using large language models like GPT-3.5-Turbo, achieving state-of-the-art results on challenging benchmarks.</p><hr><h3>SHIRE: Enhancing Sample Efficiency using Human Intuition in  REinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2409.09990v1'>http://arxiv.org/abs/2409.09990v1</a></p>
<p><b>Compressor summary</b>: SHIRE is a framework that uses human intuition encoded in PGMs to improve sample efficiency and explainability of Deep RL policies in robotic tasks.</p><hr><h3>Comprehensive Study on Sentiment Analysis: From Rule-based to modern LLM  based system</h3>
<p><a href='http://arxiv.org/abs/2409.09989v1'>http://arxiv.org/abs/2409.09989v1</a></p>
<p><b>Compressor summary</b>: This paper reviews the evolution of sentiment analysis in NLP, its challenges, and future trends.</p><hr><h3>Convergence of Sharpness-Aware Minimization Algorithms using Increasing  Batch Size and Decaying Learning Rate</h3>
<p><a href='http://arxiv.org/abs/2409.09984v1'>http://arxiv.org/abs/2409.09984v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes the effect of increasing batch sizes or decaying learning rates on the GSAM algorithm's ability to find flat local minima in deep neural networks.</p><hr><h3>From Bytes to Bites: Using Country Specific Machine Learning Models to  Predict Famine</h3>
<p><a href='http://arxiv.org/abs/2409.09980v1'>http://arxiv.org/abs/2409.09980v1</a></p>
<p><b>Compressor summary</b>: The study shows that using machine learning, especially Random Forests, can help predict household nutrition in countries facing hunger crises by analyzing various factors, but better data is needed for more accurate results.</p><hr><h3>2S-ODIS: Two-Stage Omni-Directional Image Synthesis by Geometric  Distortion Correction</h3>
<p><a href='http://arxiv.org/abs/2409.09969v1'>http://arxiv.org/abs/2409.09969v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel omni-directional image synthesis method that uses a pre-trained VQGAN model and reduces training time by using two stages: global coarse image creation and local refinement.</p><hr><h3>An Offline Adaptation Framework for Constrained Multi-Objective  Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2409.09958v1'>http://arxiv.org/abs/2409.09958v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for multi-objective reinforcement learning that adapts to preferences and safety constraints from demonstrations without explicit input.</p><hr><h3>Deep Graph Anomaly Detection: A Survey and New Perspectives</h3>
<p><a href='http://arxiv.org/abs/2409.09957v1'>http://arxiv.org/abs/2409.09957v1</a></p>
<p><b>Compressor summary</b>: This text reviews deep learning methods for graph anomaly detection (GAD), discussing challenges, methodologies, and datasets, and provides a taxonomy of 13 fine-grained categories.</p><hr><h3>Uncertainty-Guided Appearance-Motion Association Network for  Out-of-Distribution Action Detection</h3>
<p><a href='http://arxiv.org/abs/2409.09953v1'>http://arxiv.org/abs/2409.09953v1</a></p>
<p><b>Compressor summary</b>: UAAN is a novel network that detects out-of-distribution actions in videos using both appearance and motion features, outperforming existing methods.</p><hr><h3>Optimal ablation for interpretability</h3>
<p><a href='http://arxiv.org/abs/2409.09951v1'>http://arxiv.org/abs/2409.09951v1</a></p>
<p><b>Compressor summary</b>: Optimal ablation is a new method for measuring the importance of model components in machine learning models, which has advantages over existing methods and can improve interpretability tasks.</p><hr><h3>Gaps or Hallucinations? Gazing into Machine-Generated Legal Analysis for  Fine-grained Text Evaluations</h3>
<p><a href='http://arxiv.org/abs/2409.09947v1'>http://arxiv.org/abs/2409.09947v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new way to evaluate machine-generated legal analysis by identifying gaps between human and machine outputs and create a detector with an annotated dataset to measure these gaps.</p><hr><h3>Tracking the spatial dynamics of the synthetic opioid crisis in the USA,  2013-2020 using human mobility-based graph neural network</h3>
<p><a href='http://arxiv.org/abs/2409.09945v1'>http://arxiv.org/abs/2409.09945v1</a></p>
<p><b>Compressor summary</b>: This study analyzes how synthetic opioids and heroin spread in the U.S. from 2013 to 2020 using a graph convolutional neural network model that accounts for spatial connections between counties.</p><hr><h3>Fault Analysis And Predictive Maintenance Of Induction Motor Using  Machine Learning</h3>
<p><a href='http://arxiv.org/abs/2409.09944v1'>http://arxiv.org/abs/2409.09944v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Paper presents machine learning model for induction motor fault detection and classification using three phase voltages and currents as inputs
- Aims to protect vital electrical components and prevent abnormal event progression through early detection and diagnosis
- Uses fast forward artificial neural network model to detect common electrical faults
- Interfaces the model with a real motor to test its performance

Summary:
The paper proposes a machine learning model that uses voltages and currents of induction motors to detect and classify common electrical faults, with the goal of protecting vital electrical components.</p><hr><h3>Generalizability of Graph Neural Network Force Fields for Predicting  Solid-State Properties</h3>
<p><a href='http://arxiv.org/abs/2409.09931v1'>http://arxiv.org/abs/2409.09931v1</a></p>
<p><b>Compressor summary</b>: This study shows that a machine learning model can accurately predict properties of solid materials, even when trained only on some aspects and tested on unseen configurations.</p><hr><h3>Mining of Switching Sparse Networks for Missing Value Imputation in  Multivariate Time Series</h3>
<p><a href='http://arxiv.org/abs/2409.09930v1'>http://arxiv.org/abs/2409.09930v1</a></p>
<p><b>Compressor summary</b>: MissNet is a method to accurately impute missing values in multivariate time series data by exploiting temporal dependency and inter-correlation using adaptive networks.</p><hr><h3>Towards Data Contamination Detection for Modern Large Language Models:  Limitations, Inconsistencies, and Oracle Challenges</h3>
<p><a href='http://arxiv.org/abs/2409.09927v1'>http://arxiv.org/abs/2409.09927v1</a></p>
<p><b>Compressor summary</b>: The authors evaluate five data contamination detection methods on four state-of-the-art LLMs using eight challenging datasets, finding significant limitations and inconsistencies in current approaches.</p><hr><h3>Multi-Step Embed to Control: A Novel Deep Learning-based Approach for  Surrogate Modelling in Reservoir Simulation</h3>
<p><a href='http://arxiv.org/abs/2409.09920v1'>http://arxiv.org/abs/2409.09920v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a deep learning-based surrogate model that uses multiple forward transitions in latent space to improve long-term predictions for two-phase reservoir simulations.</p><hr><h3>SFR-RAG: Towards Contextually Faithful LLMs</h3>
<p><a href='http://arxiv.org/abs/2409.09916v1'>http://arxiv.org/abs/2409.09916v1</a></p>
<p><b>Compressor summary</b>: SFR-RAG is a small language model that uses external context to generate accurate and relevant answers, outperforming larger models like GPT-4o with fewer parameters.</p><hr><h3>Forearm Ultrasound based Gesture Recognition on Edge</h3>
<p><a href='http://arxiv.org/abs/2409.09915v1'>http://arxiv.org/abs/2409.09915v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to recognize hand gestures using forearm ultrasound and deep neural networks on low-resource devices like Raspberry Pi with high accuracy and low latency.</p><hr><h3>Rediscovering the Latent Dimensions of Personality with Large Language  Models as Trait Descriptors</h3>
<p><a href='http://arxiv.org/abs/2409.09905v1'>http://arxiv.org/abs/2409.09905v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel method that uses large language models to reveal latent personality dimensions without relying on explicit questionnaires and show that their approach can predict Big Five traits more accurately than previous methods.</p>