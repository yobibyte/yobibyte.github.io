
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2024-04-02</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-04-02 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Unsolvable Problem Detection: Evaluating Trustworthiness of Vision  Language Models</h3>
<p><a href='http://arxiv.org/abs/2403.20331v1'>http://arxiv.org/abs/2403.20331v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Unsolvable Problem Detection (UPD) to test Vision Language Models' ability to handle unanswerable questions in VQA tasks and explores various solutions to improve their performance.</p><hr><h3>Are We on the Right Way for Evaluating Large Vision-Language Models?</h3>
<p><a href='http://arxiv.org/abs/2403.20330v1'>http://arxiv.org/abs/2403.20330v1</a></p>
<p><b>Compressor summary</b>: MMStar is a new benchmark for evaluating large vision-language models that requires visual content and avoids unintentional data leakage, addressing issues in current multi-modal evaluations.</p><hr><h3>ReALM: Reference Resolution As Language Modeling</h3>
<p><a href='http://arxiv.org/abs/2403.20329v1'>http://arxiv.org/abs/2403.20329v1</a></p>
<p><b>Compressor summary</b>: The paper shows how large language models can be used to improve reference resolution for different types of entities, including on-screen ones, and achieve performance comparable to or better than GPT-4.</p><hr><h3>Gecko: Versatile Text Embeddings Distilled from Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2403.20327v1'>http://arxiv.org/abs/2403.20327v1</a></p>
<p><b>Compressor summary</b>: Gecko is a compact text embedding model that uses distilled knowledge from large language models to achieve strong retrieval performance.</p><hr><h3>Localising the Seizure Onset Zone from Single-Pulse Electrical  Stimulation Responses with a Transformer</h3>
<p><a href='http://arxiv.org/abs/2403.20324v1'>http://arxiv.org/abs/2403.20324v1</a></p>
<p><b>Compressor summary</b>: The paper presents Transformer models with cross-channel attention for localizing the epileptogenic focus using electrical stimulation responses, achieving better results than previous methods and handling different electrode placements and patient variability.</p><hr><h3>Towards a Framework for Evaluating Explanations in Automated Fact  Verification</h3>
<p><a href='http://arxiv.org/abs/2403.20322v1'>http://arxiv.org/abs/2403.20322v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework for systematically evaluating rationalizing explanations in NLP, with examples from automated fact verification.</p><hr><h3>MTLoRA: A Low-Rank Adaptation Approach for Efficient Multi-Task Learning</h3>
<p><a href='http://arxiv.org/abs/2403.20320v1'>http://arxiv.org/abs/2403.20320v1</a></p>
<p><b>Compressor summary</b>: MTLoRA is a novel framework for efficient fine-tuning of multi-task learning models that achieves better accuracy and efficiency than existing methods while reducing the number of trainable parameters by 3.6x.</p><hr><h3>SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular  3D Detection of Large Objects</h3>
<p><a href='http://arxiv.org/abs/2403.20318v1'>http://arxiv.org/abs/2403.20318v1</a></p>
<p><b>Compressor summary</b>: The paper investigates the problem of monocular 3D detectors generalizing to large objects and proposes SeaBird, a method that uses segmentation in bird's view with dice loss for better noise-robustness.</p><hr><h3>Convolutional Prompting meets Language Models for Continual Learning</h3>
<p><a href='http://arxiv.org/abs/2403.20317v1'>http://arxiv.org/abs/2403.20317v1</a></p>
<p><b>Compressor summary</b>: ConvPrompt is a novel convolutional prompt creation mechanism for continuous learning that uses layer-specific embeddings, generates text descriptions for each category, and adapts the number of prompts based on task similarity, improving performance without increasing parameter overhead.</p><hr><h3>Learn "No" to Say "Yes" Better: Improving Vision-Language Models via  Negations</h3>
<p><a href='http://arxiv.org/abs/2403.20312v1'>http://arxiv.org/abs/2403.20312v1</a></p>
<p><b>Compressor summary</b>: This paper introduces CoN-CLIP, a framework that improves vision-language models' understanding of negations by using CC-Neg, a new dataset, and modifying CLIP's contrastive loss, leading to better zero-shot image classification and compositionality performance.</p><hr><h3>InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40  Seconds</h3>
<p><a href='http://arxiv.org/abs/2403.20309v1'>http://arxiv.org/abs/2403.20309v1</a></p>
<p><b>Compressor summary</b>: InstantSplat is a framework that combines point-based representations with dense stereo models to quickly estimate camera intrinsics and extrinsics from sparse-view images, improving novel view synthesis performance.</p><hr><h3>ChainNet: Structured Metaphor and Metonymy in WordNet</h3>
<p><a href='http://arxiv.org/abs/2403.20308v1'>http://arxiv.org/abs/2403.20308v1</a></p>
<p><b>Compressor summary</b>: ChainNet is a lexical resource that captures how senses of words are related by metaphor or metonymy in the Open English Wordnet.</p><hr><h3>Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM  Inference</h3>
<p><a href='http://arxiv.org/abs/2403.20306v1'>http://arxiv.org/abs/2403.20306v1</a></p>
<p><b>Compressor summary</b>: The paper discusses how to optimize energy usage and performance of large language models in data centers by exploring trade-offs between various parameters.</p><hr><h3>Can LLMs Correct Physicians, Yet? Investigating Effective Interaction  Methods in the Medical Domain</h3>
<p><a href='http://arxiv.org/abs/2403.20288v1'>http://arxiv.org/abs/2403.20288v1</a></p>
<p><b>Compressor summary</b>: Large Language Models can assist and correct physicians in medical decision-making tasks by interacting effectively with them, depending on prompt design and accuracy.</p><hr><h3>Benchmarking Counterfactual Image Generation</h3>
<p><a href='http://arxiv.org/abs/2403.20287v1'>http://arxiv.org/abs/2403.20287v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a framework for evaluating counterfactual image generation methods using various metrics and provides a Python package to benchmark different approaches.</p><hr><h3>LayerNorm: A key component in parameter-efficient fine-tuning</h3>
<p><a href='http://arxiv.org/abs/2403.20284v1'>http://arxiv.org/abs/2403.20284v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes BERT components, finds output LayerNorm is crucial for fine-tuning, and shows that fine-tuning a small part of it can achieve comparable or better results than full fine-tuning.</p><hr><h3>Sparse multimodal fusion with modal channel attention</h3>
<p><a href='http://arxiv.org/abs/2403.20280v1'>http://arxiv.org/abs/2403.20280v1</a></p>
<p><b>Compressor summary</b>: The paper explores how masked multimodal transformers can learn robust embeddings when modalities are sparse and proposes a new attention mechanism (MCA) that improves embedding quality and task performance.</p><hr><h3>LUQ: Long-text Uncertainty Quantification for LLMs</h3>
<p><a href='http://arxiv.org/abs/2403.20279v1'>http://arxiv.org/abs/2403.20279v1</a></p>
<p><b>Compressor summary</b>: Extsc{Luq} is a new UQ method for long text generation that helps identify and reduce nonfactual outputs in large language models.</p><hr><h3>Snap-it, Tap-it, Splat-it: Tactile-Informed 3D Gaussian Splatting for  Reconstructing Challenging Surfaces</h3>
<p><a href='http://arxiv.org/abs/2403.20275v1'>http://arxiv.org/abs/2403.20275v1</a></p>
<p><b>Compressor summary</b>: Tactile-Informed 3DGS is a new method that uses touch data and vision to create more accurate and smoother 3D object models, especially for non-Lambertian surfaces like shiny or reflective ones.</p><hr><h3>CATSNet: a context-aware network for Height Estimation in a Forested  Area based on Pol-TomoSAR data</h3>
<p><a href='http://arxiv.org/abs/2403.20273v1'>http://arxiv.org/abs/2403.20273v1</a></p>
<p><b>Compressor summary</b>: CATSNet is a context-aware deep learning method that uses convolutional neural networks to estimate forest and ground heights from TomoSAR data, outperforming existing techniques by leveraging patch-based information and context within MB TomoSAR data.</p><hr><h3>Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to  Comprehend What You Want</h3>
<p><a href='http://arxiv.org/abs/2403.20271v1'>http://arxiv.org/abs/2403.20271v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new model and dataset for visual prompting with artificial intelligence, improving the ability of multimodal language models to understand images and follow instructions.</p><hr><h3>Latxa: An Open Language Model and Evaluation Suite for Basque</h3>
<p><a href='http://arxiv.org/abs/2403.20266v1'>http://arxiv.org/abs/2403.20266v1</a></p>
<p><b>Compressor summary</b>: Latxa is a large language model family for Basque with new pretraining and evaluation datasets, improving Basque LLM performance.</p><hr><h3>ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language  Models</h3>
<p><a href='http://arxiv.org/abs/2403.20262v1'>http://arxiv.org/abs/2403.20262v1</a></p>
<p><b>Compressor summary</b>: ELITR-Bench is a new benchmark for long-context LLMs focused on a meeting assistant scenario, revealing gaps between open-source and proprietary models and limitations of GPT-4's evaluation method.</p><hr><h3>Prototype-based Interpretable Breast Cancer Prediction Models: Analysis  and Challenges</h3>
<p><a href='http://arxiv.org/abs/2403.20260v1'>http://arxiv.org/abs/2403.20260v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework to evaluate the quality of interpretable prototype-based models for breast cancer prediction using mammography, finding that while they perform well compared to black-box models, prototype quality still needs improvement.</p><hr><h3>Benchmarking the Robustness of Temporal Action Detection Models Against  Temporal Corruptions</h3>
<p><a href='http://arxiv.org/abs/2403.20254v1'>http://arxiv.org/abs/2403.20254v1</a></p>
<p><b>Compressor summary</b>: This paper evaluates the robustness of temporal action detection methods to frame corruptions, builds two benchmarks, and proposes a simple but effective method to improve robustness using FrameDrop augmentation and Temporal-Robust Consistency loss.</p><hr><h3>MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image  Segmentation</h3>
<p><a href='http://arxiv.org/abs/2403.20253v1'>http://arxiv.org/abs/2403.20253v1</a></p>
<p><b>Compressor summary</b>: The paper presents MedCLIP-SAM, a novel framework that uses CLIP and SAM models to generate segmentation of medical images using text prompts in zero-shot and weakly supervised settings, improving data efficiency and generalizability.</p><hr><h3>Using LLMs to Model the Beliefs and Preferences of Targeted Populations</h3>
<p><a href='http://arxiv.org/abs/2403.20252v1'>http://arxiv.org/abs/2403.20252v1</a></p>
<p><b>Compressor summary</b>: The text discusses using large language models to align with human population preferences for various applications and evaluates different fine-tuning approaches and a new loss term for this purpose.</p><hr><h3>Relation Rectification in Diffusion Model</h3>
<p><a href='http://arxiv.org/abs/2403.20249v1'>http://arxiv.org/abs/2403.20249v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Relation Rectification, a method that uses Heterogeneous Graph Convolutional Networks to adjust text embeddings and improve the visual representation of relationships between objects in text-to-image diffusion models.</p><hr><h3>Enhancing Dimension-Reduced Scatter Plots with Class and Feature  Centroids</h3>
<p><a href='http://arxiv.org/abs/2403.20246v1'>http://arxiv.org/abs/2403.20246v1</a></p>
<p><b>Compressor summary</b>: The study proposes a method to increase interpretability of dimension-reduced biomedical data by overlaying class and feature centroids on scatter plots.</p><hr><h3>Long-Tailed Anomaly Detection with Learnable Class Names</h3>
<p><a href='http://arxiv.org/abs/2403.20236v1'>http://arxiv.org/abs/2403.20236v1</a></p>
<p><b>Compressor summary</b>: LTAD is a novel method that detects defects in images from multiple and long-tailed classes without relying on class names, using reconstruction and semantic modules.</p><hr><h3>Artificial Neural Networks-based Real-time Classification of ENG Signals  for Implanted Nerve Interfaces</h3>
<p><a href='http://arxiv.org/abs/2403.20234v1'>http://arxiv.org/abs/2403.20234v1</a></p>
<p><b>Compressor summary</b>: The article explores the use of artificial neural networks to classify motor/sensory stimuli from electroneurographic signals in implanted nerve interfaces for neuropathy recovery.</p><hr><h3>U-VAP: User-specified Visual Appearance Personalization via Decoupled  Self Augmentation</h3>
<p><a href='http://arxiv.org/abs/2403.20231v1'>http://arxiv.org/abs/2403.20231v1</a></p>
<p><b>Compressor summary</b>: The study proposes a new method for fine-grained visual appearance personalization that uses user-provided sentences and a decoupled self-augmentation strategy to learn target attributes and improve controllability and flexibility.</p><hr><h3>Graph Neural Aggregation-diffusion with Metastability</h3>
<p><a href='http://arxiv.org/abs/2403.20221v1'>http://arxiv.org/abs/2403.20221v1</a></p>
<p><b>Compressor summary</b>: GRADE is a novel graph neural network model that uses nonlinear diffusion and aggregation to avoid over-smoothing and create node clusters.</p><hr><h3>Advancing the Arabic WordNet: Elevating Content Quality</h3>
<p><a href='http://arxiv.org/abs/2403.20215v1'>http://arxiv.org/abs/2403.20215v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a revised Arabic WordNet that improves its quality and covers multiple aspects of lexico-semantic resources.</p><hr><h3>H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language  Model</h3>
<p><a href='http://arxiv.org/abs/2403.20213v1'>http://arxiv.org/abs/2403.20213v1</a></p>
<p><b>Compressor summary</b>: The authors developed a helpful and honest remote sensing vision-language model (H2RSVLM) that improves spatial perception and answers only answerable questions using two new datasets, HqDC-1.4M and RSSA.</p><hr><h3>On Size and Hardness Generalization in Unsupervised Learning for the  Travelling Salesman Problem</h3>
<p><a href='http://arxiv.org/abs/2403.20212v1'>http://arxiv.org/abs/2403.20212v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how various factors affect the performance and generalization of unsupervised learning methods for solving the Travelling Salesman Problem (TSP) using a graph neural network and a heat map approach.</p><hr><h3>Unleashing the Potential of Large Language Models for Predictive Tabular  Tasks in Data Science</h3>
<p><a href='http://arxiv.org/abs/2403.20208v1'>http://arxiv.org/abs/2403.20208v1</a></p>
<p><b>Compressor summary</b>: This research trains a large language model on a corpus of tables with annotations and shows its effectiveness in solving classification, regression, and imputation tasks for tabular data.</p><hr><h3>The Future of Combating Rumors? Retrieval, Discrimination, and  Generation</h3>
<p><a href='http://arxiv.org/abs/2403.20204v1'>http://arxiv.org/abs/2403.20204v1</a></p>
<p><b>Compressor summary</b>: The text proposes a comprehensive debunking process using AI that detects rumors and provides explanations to refute misinformation, ensuring high credibility assessment and relevant knowledge retrieval.</p><hr><h3>Automatic Alignment of Discourse Relations of Different Discourse  Annotation Frameworks</h3>
<p><a href='http://arxiv.org/abs/2403.20196v1'>http://arxiv.org/abs/2403.20196v1</a></p>
<p><b>Compressor summary</b>: The paper presents a fully automatic method to map discourse relations from different frameworks using label embeddings learned by contrastive learning.</p><hr><h3>Enhancing Lithological Mapping with Spatially Constrained Bayesian  Network (SCB-Net): An Approach for Field Data-Constrained Predictions with  Uncertainty Evaluation</h3>
<p><a href='http://arxiv.org/abs/2403.20195v1'>http://arxiv.org/abs/2403.20195v1</a></p>
<p><b>Compressor summary</b>: The Spatially Constrained Bayesian Network (SCB-Net) is a new architecture that effectively uses auxiliary data and learns from spatial patterns to create reliable geological maps with uncertainty assessment.</p><hr><h3>Motion Inversion for Video Customization</h3>
<p><a href='http://arxiv.org/abs/2403.20193v1'>http://arxiv.org/abs/2403.20193v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Motion Embeddings, a new way to represent and manipulate motion in videos using one-dimensional vectors that work well with video diffusion models.</p><hr><h3>Sketch-to-Architecture: Generative AI-aided Architectural Design</h3>
<p><a href='http://arxiv.org/abs/2403.20186v1'>http://arxiv.org/abs/2403.20186v1</a></p>
<p><b>Compressor summary</b>: The text describes a novel workflow that uses generative AI to create floorplans and 3D models from sketches, enabling faster architectural design based on textual descriptions.</p><hr><h3>HARMamba: Efficient Wearable Sensor Human Activity Recognition Based on  Bidirectional Selective SSM</h3>
<p><a href='http://arxiv.org/abs/2403.20183v1'>http://arxiv.org/abs/2403.20183v1</a></p>
<p><b>Compressor summary</b>: HARMamba is a lightweight selective state space model for real-time wearable sensor activity recognition that outperforms Transformer-based models while reducing computational and memory overhead.</p><hr><h3>Measuring Taiwanese Mandarin Language Understanding</h3>
<p><a href='http://arxiv.org/abs/2403.20180v1'>http://arxiv.org/abs/2403.20180v1</a></p>
<p><b>Compressor summary</b>: This paper introduces TMLU, a new evaluation suite for Chinese language models, especially Taiwanese Mandarin, that covers various subjects and assesses their knowledge and reasoning skills with explanations.</p><hr><h3>Artificial consciousness. Some logical and conceptual preliminaries</h3>
<p><a href='http://arxiv.org/abs/2403.20177v1'>http://arxiv.org/abs/2403.20177v1</a></p>
<p><b>Compressor summary</b>: The text discusses the theoretical and empirical possibility of artificial consciousness, suggesting that dimensions and profiles of consciousness should be used for a balanced discussion, and outlines a research strategy for realizing "awareness" in artificial systems.</p><hr><h3>HGS-Mapping: Online Dense Mapping Using Hybrid Gaussian Representation  in Urban Scenes</h3>
<p><a href='http://arxiv.org/abs/2403.20159v1'>http://arxiv.org/abs/2403.20159v1</a></p>
<p><b>Compressor summary</b>: The paper proposes HGS-Mapping, a fast and accurate online dense mapping framework for urban scenes using Hybrid Gaussian Representation, which models different parts of the scene with Gaussians with distinct properties.</p><hr><h3>ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned  Language Models</h3>
<p><a href='http://arxiv.org/abs/2403.20158v1'>http://arxiv.org/abs/2403.20158v1</a></p>
<p><b>Compressor summary</b>: The study compares ChatGPT's ability to detect different types of media bias against fine-tuned models, showing mixed results.</p><hr><h3>A Systematic Analysis of Subwords and Cross-Lingual Transfer in  Multilingual Translation</h3>
<p><a href='http://arxiv.org/abs/2403.20157v1'>http://arxiv.org/abs/2403.20157v1</a></p>
<p><b>Compressor summary</b>: Subword methods improve machine translation for low-resource languages, but their effectiveness depends on orthographic word boundaries and fine-tuning methods.</p><hr><h3>Talk3D: High-Fidelity Talking Portrait Synthesis via Personalized 3D  Generative Prior</h3>
<p><a href='http://arxiv.org/abs/2403.20153v1'>http://arxiv.org/abs/2403.20153v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Talk3D, a framework that uses 3D-aware generative prior to synthesize realistic talking head animations from audio inputs, achieving better performance than existing methods.</p><hr><h3>A Learning-based Incentive Mechanism for Mobile AIGC Service in  Decentralized Internet of Vehicles</h3>
<p><a href='http://arxiv.org/abs/2403.20151v1'>http://arxiv.org/abs/2403.20151v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a decentralized incentive mechanism using multi-agent deep reinforcement learning for allocating AI-generated content on roadside units in the Internet of Vehicles, improving user experience and reducing latency.</p><hr><h3>TFB: Towards Comprehensive and Fair Benchmarking of Time Series  Forecasting Methods</h3>
<p><a href='http://arxiv.org/abs/2403.20150v1'>http://arxiv.org/abs/2403.20150v1</a></p>
<p><b>Compressor summary</b>: TFB is an automated benchmark for comparing time series forecasting methods across diverse domains, datasets, and evaluation strategies.</p><hr><h3>Conformal Prediction for Stochastic Decision-Making of PV Power in  Electricity Markets</h3>
<p><a href='http://arxiv.org/abs/2403.20149v1'>http://arxiv.org/abs/2403.20149v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how conformal prediction, a probabilistic forecasting method, improves photovoltaic power predictions for electricity markets using different bidding strategies and shows that it outperforms linear methods in profit and energy balance.</p><hr><h3>IndiBias: A Benchmark Dataset to Measure Social Biases in Language  Models for Indian Context</h3>
<p><a href='http://arxiv.org/abs/2403.20147v1'>http://arxiv.org/abs/2403.20147v1</a></p>
<p><b>Compressor summary</b>: IndiBias is a new dataset for evaluating social biases in Indian context and languages, covering various dimensions and intersectionality, based on existing resources and LLMs' inputs.</p><hr><h3>Fine-tuning Large Language Models for Automated Diagnostic Screening  Summaries</h3>
<p><a href='http://arxiv.org/abs/2403.20145v1'>http://arxiv.org/abs/2403.20145v1</a></p>
<p><b>Compressor summary</b>: The authors evaluate state-of-the-art language models for generating summaries from mental health examinations, finding that their fine-tuned model performs well and could potentially improve support in developing countries.</p><hr><h3>StegoGAN: Leveraging Steganography for Non-Bijective Image-to-Image  Translation</h3>
<p><a href='http://arxiv.org/abs/2403.20142v1'>http://arxiv.org/abs/2403.20142v1</a></p>
<p><b>Compressor summary</b>: StegoGAN is a novel GAN-based model that uses steganography to prevent spurious features in non-bijective image translation tasks, enhancing semantic consistency without extra supervision.</p><hr><h3>Accurate Block Quantization in LLMs with Outliers</h3>
<p><a href='http://arxiv.org/abs/2403.20137v1'>http://arxiv.org/abs/2403.20137v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method to improve quantization accuracy using low precision BFP formats by rearranging outliers in weights and activations, reducing memory footprint without compromising model accuracy.</p><hr><h3>User Modeling Challenges in Interactive AI Assistant Systems</h3>
<p><a href='http://arxiv.org/abs/2403.20134v1'>http://arxiv.org/abs/2403.20134v1</a></p>
<p><b>Compressor summary</b>: The text discusses how AI assistants can better understand users' mental states to provide more personalized guidance during tasks using large language models.</p><hr><h3>The Impact of Prompts on Zero-Shot Detection of AI-Generated Text</h3>
<p><a href='http://arxiv.org/abs/2403.20127v1'>http://arxiv.org/abs/2403.20127v1</a></p>
<p><b>Compressor summary</b>: This paper examines how prompts affect the accuracy of zero-shot detectors in identifying AI-generated texts and proposes a framework to evaluate them.</p><hr><h3>ECLIPSE: Efficient Continual Learning in Panoptic Segmentation with  Visual Prompt Tuning</h3>
<p><a href='http://arxiv.org/abs/2403.20126v1'>http://arxiv.org/abs/2403.20126v1</a></p>
<p><b>Compressor summary</b>: The paper presents ECLIPSE, a novel method for continual panoptic segmentation that fine-tunes prompt embeddings and uses logit manipulation to address catastrophic forgetting and plasticity, achieving state-of-the-art results.</p><hr><h3>Application of Machine Learning Algorithms in Classifying Postoperative  Success in Metabolic Bariatric Surgery: A Comprehensive Study</h3>
<p><a href='http://arxiv.org/abs/2403.20124v1'>http://arxiv.org/abs/2403.20124v1</a></p>
<p><b>Compressor summary</b>: The study proposes a novel machine learning approach to classify patients undergoing metabolic bariatric surgery, showing that enhanced KNN and Decision Tree models with oversampling techniques can achieve high accuracy in predicting patient outcomes.</p><hr><h3>Learning using granularity statistical invariants for classification</h3>
<p><a href='http://arxiv.org/abs/2403.20122v1'>http://arxiv.org/abs/2403.20122v1</a></p>
<p><b>Compressor summary</b>: LUGSI is a new learning paradigm that improves classification performance and speed on large-scale datasets by using granularity statistical invariants to enhance structural information and reduce computational cost.</p><hr><h3>Segmentation, Classification and Interpretation of Breast Cancer Medical  Images using Human-in-the-Loop Machine Learning</h3>
<p><a href='http://arxiv.org/abs/2403.20112v1'>http://arxiv.org/abs/2403.20112v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a doctor-in-the-loop method to improve machine learning models for breast cancer analysis using genomic data and image analysis, but finds that it is not always effective due to the complexity of the domain.</p><hr><h3>Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic  Rewards for Goal-directed Molecular Generation</h3>
<p><a href='http://arxiv.org/abs/2403.20109v1'>http://arxiv.org/abs/2403.20109v1</a></p>
<p><b>Compressor summary</b>: Mol-AIR is a reinforcement learning framework for generating molecules with desired properties using adaptive intrinsic rewards and random distillation network, improving drug discovery efficiency.</p><hr><h3>Aggregating Local and Global Features via Selective State Spaces Model  for Efficient Image Deblurring</h3>
<p><a href='http://arxiv.org/abs/2403.20106v1'>http://arxiv.org/abs/2403.20106v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an efficient image deblurring network using selective structured state spaces and aggregate local and global blocks to balance between accuracy and efficiency.</p><hr><h3>FreeSeg-Diff: Training-Free Open-Vocabulary Segmentation with Diffusion  Models</h3>
<p><a href='http://arxiv.org/abs/2403.20105v1'>http://arxiv.org/abs/2403.20105v1</a></p>
<p><b>Compressor summary</b>: The text describes a zero-shot, training-free method for image segmentation using foundation models like CLIP and diffusion models, which achieves competitive results compared to weakly-supervised approaches.</p><hr><h3>NLP for Counterspeech against Hate: A Survey and How-To Guide</h3>
<p><a href='http://arxiv.org/abs/2403.20103v1'>http://arxiv.org/abs/2403.20103v1</a></p>
<p><b>Compressor summary</b>: The paper provides a guide for NLP researchers to conduct counterspeech research against online hate by describing steps, best practices, and open challenges.</p><hr><h3>RealKIE: Five Novel Datasets for Enterprise Key Information Extraction</h3>
<p><a href='http://arxiv.org/abs/2403.20101v1'>http://arxiv.org/abs/2403.20101v1</a></p>
<p><b>Compressor summary</b>: RealKIE is a new benchmark with five diverse datasets for key information extraction research, focusing on enterprise applications and addressing real-world challenges like text serialization, sparse annotations, and complex tables.</p><hr><h3>ITCMA: A Generative Agent Based on a Computational Consciousness  Structure</h3>
<p><a href='http://arxiv.org/abs/2403.20097v1'>http://arxiv.org/abs/2403.20097v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a computational consciousness structure called ITCM and an agent (ITCMA) that enhances LLMs' understanding of implicit instructions and common-sense knowledge for better performance in open-world settings, including real-world tasks with robots.</p><hr><h3>Modeling Weather Uncertainty for Multi-weather Co-Presence Estimation</h3>
<p><a href='http://arxiv.org/abs/2403.20092v1'>http://arxiv.org/abs/2403.20092v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes a new method to handle multiple weather conditions in outdoor scenes for computer vision tasks
- The method models weather uncertainty using a Gaussian mixture model and prior-posterior learning
- A new dataset (MePe) is introduced to benchmark the proposed method and other weather classification tasks
- The method achieves state-of-the-art performance and generalization capabilities

Summary:
The paper presents a novel approach to handle multiple weather conditions in outdoor scenes using a Gaussian mixture model and prior-posterior learning, along with a new dataset and benchmarks.</p><hr><h3>Implications of the AI Act for Non-Discrimination Law and Algorithmic  Fairness</h3>
<p><a href='http://arxiv.org/abs/2403.20089v1'>http://arxiv.org/abs/2403.20089v1</a></p>
<p><b>Compressor summary</b>: The text discusses fairness in AI from a European law perspective, highlighting the need for bridging algorithmic fairness and non-discrimination law through the AI Act, which may affect bias detection and correction strategies.</p><hr><h3>An Efficient Approach for Studying Cross-Lingual Transfer in  Multilingual Language Models</h3>
<p><a href='http://arxiv.org/abs/2403.20088v1'>http://arxiv.org/abs/2403.20088v1</a></p>
<p><b>Compressor summary</b>: The authors study how different languages influence the performance of pre-trained multilingual models on various target languages, using adapter units to disentangle language effects and provide a list of recommended transfer configurations.</p><hr><h3>IPA Transcription of Bengali Texts</h3>
<p><a href='http://arxiv.org/abs/2403.20084v1'>http://arxiv.org/abs/2403.20084v1</a></p>
<p><b>Compressor summary</b>: The text discusses the need for a standardized IPA system for Bengali pronunciation and presents a new framework that includes a novel dataset and deep learning-based benchmarks.</p><hr><h3>Mixed-precision Supernet Training from Vision Foundation Models using  Low Rank Adapter</h3>
<p><a href='http://arxiv.org/abs/2403.20080v1'>http://arxiv.org/abs/2403.20080v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to optimize and compress large vision models using mixed-precision search and memory-efficient training, achieving significant BitOPs reduction without sacrificing performance.</p><hr><h3>SGD: Street View Synthesis with Gaussian Splatting and Diffusion Prior</h3>
<p><a href='http://arxiv.org/abs/2403.20079v1'>http://arxiv.org/abs/2403.20079v1</a></p>
<p><b>Compressor summary</b>: The text proposes a new approach that improves neural rendering for street scenes by combining a diffusion model and multi-modal data to handle deviations from training viewpoints.</p><hr><h3>Negative Label Guided OOD Detection with Pretrained Vision-Language  Models</h3>
<p><a href='http://arxiv.org/abs/2403.20078v1'>http://arxiv.org/abs/2403.20078v1</a></p>
<p><b>Compressor summary</b>: NegLabel is a novel OOD detection method for vision-language models that uses negative labels from corpus databases and achieves state-of-the-art performance on various benchmarks and domains.</p><hr><h3>Cross-Lingual Transfer Robustness to Lower-Resource Languages on  Adversarial Datasets</h3>
<p><a href='http://arxiv.org/abs/2403.20056v1'>http://arxiv.org/abs/2403.20056v1</a></p>
<p><b>Compressor summary</b>: The study examines how well multilingual language models perform in recognizing named entities across different languages, finding that transfer ability depends on shared entity chunks and robustness to input perturbations.</p><hr><h3>Embracing Unknown Step by Step: Towards Reliable Sparse Training in Real  World</h3>
<p><a href='http://arxiv.org/abs/2403.20047v1'>http://arxiv.org/abs/2403.20047v1</a></p>
<p><b>Compressor summary</b>: Sparse training can make deep neural networks unreliable in detecting out-of-distribution data, but a new method improves their performance and reliability without increasing costs or requiring extra data.</p><hr><h3>Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to  Boost for Reasoning</h3>
<p><a href='http://arxiv.org/abs/2403.20046v1'>http://arxiv.org/abs/2403.20046v1</a></p>
<p><b>Compressor summary</b>: The study explores how large language models can learn from their mistakes in reasoning tasks using new benchmark CoTErrorSet and two methods: self-rethinking prompting and mistake tuning.</p><hr><h3>Transformer-Lite: High-efficiency Deployment of Large Language Models on  Mobile Phone GPUs</h3>
<p><a href='http://arxiv.org/abs/2403.20041v1'>http://arxiv.org/abs/2403.20041v1</a></p>
<p><b>Compressor summary</b>: The authors propose four optimization techniques to improve LLM deployment on mobile devices and achieve significant speedups in inference tasks compared to existing methods.</p><hr><h3>NeSLAM: Neural Implicit Mapping and Self-Supervised Feature Tracking  With Depth Completion and Denoising</h3>
<p><a href='http://arxiv.org/abs/2403.20034v1'>http://arxiv.org/abs/2403.20034v1</a></p>
<p><b>Compressor summary</b>: NeSLAM is a framework that improves 3D reconstruction and camera tracking in RGB-D SLAM systems using NeRF, dense depth estimation, SDF scene representation, and self-supervised feature tracking.</p><hr><h3>HO-Gaussian: Hybrid Optimization of 3D Gaussian Splatting for Urban  Scenes</h3>
<p><a href='http://arxiv.org/abs/2403.20032v1'>http://arxiv.org/abs/2403.20032v1</a></p>
<p><b>Compressor summary</b>: HO-Gaussian is a hybrid method that improves neural rendering of urban scenes by combining 3D Gaussian Splatting with grid-based volume and view-dependent color representation, overcoming previous limitations and enabling real-time photo-realistic results on multi-camera datasets.</p><hr><h3>A Unified Framework for Human-centric Point Cloud Video Understanding</h3>
<p><a href='http://arxiv.org/abs/2403.20031v1'>http://arxiv.org/abs/2403.20031v1</a></p>
<p><b>Compressor summary</b>: Key points:

- Human-centric PVU is a field that extracts and interprets human features from point clouds for various applications.
- Previous works rely on huge labeled data, which has poor generalization capability.
- The paper proposes a unified framework that uses prior knowledge and inherent features to improve performance on action recognition and 3D pose estimation.

Summary:
The paper presents a novel framework for human-centric point cloud video understanding that leverages prior knowledge and data features to achieve state-of-the-art results on action recognition and 3D pose estimation tasks.</p><hr><h3>FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint  Textual and Visual Clues</h3>
<p><a href='http://arxiv.org/abs/2403.20026v1'>http://arxiv.org/abs/2403.20026v1</a></p>
<p><b>Compressor summary</b>: The Feature Swapping Multi-modal Reasoning (FSMR) model enhances textual and visual understanding by exchanging features between images and words, using a pre-trained visual-language encoder and a multi-modal cross-attention mechanism.</p><hr><h3>Psychometry: An Omnifit Model for Image Reconstruction from Human Brain  Activity</h3>
<p><a href='http://arxiv.org/abs/2403.20022v1'>http://arxiv.org/abs/2403.20022v1</a></p>
<p><b>Compressor summary</b>: Psychometry is an omnifit model that uses fMRI data from different subjects to reconstruct images by capturing inter-subject commonalities and individual differences, enhancing the representation with subject-specific memories.</p><hr><h3>Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion</h3>
<p><a href='http://arxiv.org/abs/2403.20015v1'>http://arxiv.org/abs/2403.20015v1</a></p>
<p><b>Compressor summary</b>: The paper presents a text data augmentation method that deletes adverbs to preserve semantics while being efficient and effective for various tasks.</p><hr><h3>DerainNeRF: 3D Scene Estimation with Adhesive Waterdrop Removal</h3>
<p><a href='http://arxiv.org/abs/2403.20013v1'>http://arxiv.org/abs/2403.20013v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes a method to remove waterdrops from multi-view images degraded by weather conditions
- The method uses an attention network and a Neural Radiance Field model
- The method can generate clear 3D scenes and high-quality novel-view images with waterdrops removed
- The method outperforms existing SOTA methods for image adhesive waterdrop removal

Summary:
The paper presents a novel method that uses an attention network and a Neural Radiance Field model to remove waterdrops from multi-view images and generate clear 3D scenes and high-quality novel-view images, surpassing existing SOTA methods.</p><hr><h3>Colorful Cutout: Enhancing Image Data Augmentation with Curriculum  Learning</h3>
<p><a href='http://arxiv.org/abs/2403.20012v1'>http://arxiv.org/abs/2403.20012v1</a></p>
<p><b>Compressor summary</b>: The study introduces colorful cutout, a curriculum data augmentation technique for images that gradually increases noise and difficulty, improving generalization and performance.</p><hr><h3>On Large Language Models' Hallucination with Regard to Known Facts</h3>
<p><a href='http://arxiv.org/abs/2403.20009v1'>http://arxiv.org/abs/2403.20009v1</a></p>
<p><b>Compressor summary</b>: The text investigates how large language models can know correct answers but still hallucinate, using inference dynamics analysis and a classifier based on output token probabilities.</p><hr><h3>Large Language Model based Situational Dialogues for Second Language  Learning</h3>
<p><a href='http://arxiv.org/abs/2403.20005v1'>http://arxiv.org/abs/2403.20005v1</a></p>
<p><b>Compressor summary</b>: The paper proposes situational dialogue models for second language learners to practice conversational skills using large language models, which can handle various topics and are evaluated automatically.</p><hr><h3>Grounding and Enhancing Grid-based Models for Neural Fields</h3>
<p><a href='http://arxiv.org/abs/2403.20002v1'>http://arxiv.org/abs/2403.20002v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a theoretical framework for analyzing grid-based neural field models and develops a novel model, MulFAGrid, which outperforms existing models in various tasks.</p><hr><h3>DeepHeteroIoT: Deep Local and Global Learning over Heterogeneous IoT  Sensor Data</h3>
<p><a href='http://arxiv.org/abs/2403.19996v1'>http://arxiv.org/abs/2403.19996v1</a></p>
<p><b>Compressor summary</b>: Key points:
- IoT sensor data has heterogeneity (different timestamps, frequencies, locations, units)
- Traditional time series classification algorithms struggle with this heterogeneity
- Proposed deep learning model combines CNN and BGRU to learn local and global features
- Model outperforms state-of-the-art methods and baselines

Summary:
The paper proposes a novel deep learning model that learns both local and global features from heterogeneous IoT sensor data, achieving better classification results than existing methods.</p><hr><h3>Development of Compositionality and Generalization through Interactive  Learning of Language and Action of Robots</h3>
<p><a href='http://arxiv.org/abs/2403.19995v1'>http://arxiv.org/abs/2403.19995v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The text discusses how humans can apply learned behavior to unlearned situations using compositionality, a skill that combines language and action.
- The authors propose a neural network model that integrates vision, proprioception, and language to learn this skill in robots.
- The results show that increasing task variations improves generalization and that visual attention and working memory are crucial for achieving linguistic goals.

Summary:
The text presents a brain-inspired model that teaches robots compositionality, the ability to reuse language and action parts in new situations, and shows how it benefits from increased task variation and visual attention.</p><hr><h3>MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm  System</h3>
<p><a href='http://arxiv.org/abs/2403.19992v1'>http://arxiv.org/abs/2403.19992v1</a></p>
<p><b>Compressor summary</b>: MindArm is a low-cost, non-invasive neuro-driven prosthetic arm system that uses EEG electrodes and a deep neural network to translate brain signals into prosthetic arm motions.</p><hr><h3>Stable Surface Regularization for Fast Few-Shot NeRF</h3>
<p><a href='http://arxiv.org/abs/2403.19985v1'>http://arxiv.org/abs/2403.19985v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an algorithm that uses a new surface regularization technique called ASDF to generate high-quality novel views from few input images, making it faster and more stable than existing methods.</p><hr><h3>A Parallel Attention Network for Cattle Face Recognition</h3>
<p><a href='http://arxiv.org/abs/2403.19980v1'>http://arxiv.org/abs/2403.19980v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Cattle face recognition is important for animal husbandry and behavioral research
- New large-scale dataset ICRWE created for wild environments
- Novel parallel attention network (PANet) introduced for cattle face recognition
- PANet achieves 88.03% accuracy on ICRWE, the state-of-the-art approach

Summary:
The paper presents a new large-scale dataset and a novel network for recognizing cattle faces in wild environments, achieving the highest accuracy so far.</p><hr><h3>Semantically-Shifted Incremental Adapter-Tuning is A Continual  ViTransformer</h3>
<p><a href='http://arxiv.org/abs/2403.19979v1'>http://arxiv.org/abs/2403.19979v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for continuous learning that improves on previous approaches by using adapter tuning and feature sampling without expanding the model or retaining old samples.</p><hr><h3>eTraM: Event-based Traffic Monitoring Dataset</h3>
<p><a href='http://arxiv.org/abs/2403.19976v1'>http://arxiv.org/abs/2403.19976v1</a></p>
<p><b>Compressor summary</b>: Event cameras can be used for static traffic monitoring with high performance, as shown by the novel eTraM dataset and its evaluation on various scenarios and models.</p><hr><h3>Context-Aware Integration of Language and Visual References for Natural  Language Tracking</h3>
<p><a href='http://arxiv.org/abs/2403.19975v1'>http://arxiv.org/abs/2403.19975v1</a></p>
<p><b>Compressor summary</b>: TNL aims to track a target in a video using language, but existing methods have issues with drift and ambiguity; the proposed joint multi-modal framework improves accuracy and consistency by leveraging visual and linguistic cues and decoding them together.</p><hr><h3>Separate, Dynamic and Differentiable (SMART) Pruner for Block/Output  Channel Pruning on Computer Vision Tasks</h3>
<p><a href='http://arxiv.org/abs/2403.19969v1'>http://arxiv.org/abs/2403.19969v1</a></p>
<p><b>Compressor summary</b>: The SMART pruner is a new technique for improving the accuracy of DNN pruning by using a learnable probability mask, differentiable Top k operator, and dynamic temperature parameter in a dynamic, differentiable, and adaptable way.</p><hr><h3>Rewrite the Stars</h3>
<p><a href='http://arxiv.org/abs/2403.19967v1'>http://arxiv.org/abs/2403.19967v1</a></p>
<p><b>Compressor summary</b>: The paper explores how element-wise multiplication (star operation) can create non-linear features in neural networks without increasing size and introduces StarNet, a prototype that shows promising results.</p><hr><h3>FairRAG: Fair Human Generation via Fair Retrieval Augmentation</h3>
<p><a href='http://arxiv.org/abs/2403.19964v1'>http://arxiv.org/abs/2403.19964v1</a></p>
<p><b>Compressor summary</b>: FairRAG is a framework that uses external images to improve fairness and diversity in text-to-image generation models by applying debiasing strategies.</p><hr><h3>Efficient Modulation for Vision Networks</h3>
<p><a href='http://arxiv.org/abs/2403.19963v1'>http://arxiv.org/abs/2403.19963v1</a></p>
<p><b>Compressor summary</b>: The text introduces a novel design for efficient vision networks called EfficientMod, which improves accuracy and efficiency by using a modulation mechanism with an MLP block.</p><hr><h3>Enhancing the General Agent Capabilities of Low-Parameter LLMs through  Tuning and Multi-Branch Reasoning</h3>
<p><a href='http://arxiv.org/abs/2403.19962v1'>http://arxiv.org/abs/2403.19962v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to improve LLMs' abilities as intelligent agents by using GPT-4-constructed data, supervised fine-tuning, and techniques like multi-path reasoning and task decomposition.</p><hr><h3>Coverage-Guaranteed Prediction Sets for Out-of-Distribution Data</h3>
<p><a href='http://arxiv.org/abs/2403.19950v1'>http://arxiv.org/abs/2403.19950v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for making confident predictions in out-of-distribution settings by modifying split conformal prediction and proves its validity.</p><hr><h3>FairCLIP: Harnessing Fairness in Vision-Language Learning</h3>
<p><a href='http://arxiv.org/abs/2403.19949v1'>http://arxiv.org/abs/2403.19949v1</a></p>
<p><b>Compressor summary</b>: Key points:
- FairVLMed is a new medical vision-language dataset for studying fairness in VL models
- CLIP and BLIP2, two widely-used VL models, show significant biases across four protected attributes
- FairCLIP is a proposed method to reduce these biases using optimal transport

Summary:
The paper introduces FairVLMed, the first dataset for fairness analysis of medical vision-language models. It shows that CLIP and BLIP2 are biased towards certain subgroups and proposes FairCLIP to mitigate these biases.</p><hr><h3>Binarized Low-light Raw Video Enhancement</h3>
<p><a href='http://arxiv.org/abs/2403.19944v1'>http://arxiv.org/abs/2403.19944v1</a></p>
<p><b>Compressor summary</b>: The paper explores using extremely compact binary neural networks for low-light raw video enhancement, addressing issues of temporal information fusion and performance gap between binary and full precision convolutions.</p><hr><h3>TDANet: A Novel Temporal Denoise Convolutional Neural Network With  Attention for Fault Diagnosis</h3>
<p><a href='http://arxiv.org/abs/2403.19943v1'>http://arxiv.org/abs/2403.19943v1</a></p>
<p><b>Compressor summary</b>: TDANet is a novel Deep Learning technique for fault diagnosis in noisy industrial environments, using multi-scale 2D convolutions and attention modules to enhance signal features and achieve high diagnostic accuracy.</p><hr><h3>Diverse Feature Learning by Self-distillation and Reset</h3>
<p><a href='http://arxiv.org/abs/2403.19941v1'>http://arxiv.org/abs/2403.19941v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Diverse Feature Learning (DFL), which combines self-distillation and reset to help models preserve important features and learn new ones for image classification.</p><hr><h3>SLFNet: Generating Semantic Logic Forms from Natural Language Using  Semantic Probability Graphs</h3>
<p><a href='http://arxiv.org/abs/2403.19936v1'>http://arxiv.org/abs/2403.19936v1</a></p>
<p><b>Compressor summary</b>: SLFNet is a new neural network for natural language interfaces that uses syntactic information, semantic probability graphs, and Multi-Head SLF Attention to convert user commands into structured forms.</p><hr><h3>CP HDR: A feature point detection and description library for LDR and  HDR images</h3>
<p><a href='http://arxiv.org/abs/2403.19935v1'>http://arxiv.org/abs/2403.19935v1</a></p>
<p><b>Compressor summary</b>: The authors review feature point detection and description methods for high dynamic range images and propose two modified algorithms (SIFT for HDR and Harris for HDR) that improve performance in computer vision tasks.</p><hr><h3>Are LLMs Effective Backbones for Fine-tuning? An Experimental  Investigation of Supervised LLMs on Chinese Short Text Matching</h3>
<p><a href='http://arxiv.org/abs/2403.19930v1'>http://arxiv.org/abs/2403.19930v1</a></p>
<p><b>Compressor summary</b>: The paper studies how to fine-tune large language models for a specific natural language understanding task in supervised settings, focusing on Chinese short text matching and examining different factors that affect performance.</p><hr><h3>DiJiang: Efficient Large Language Models through Compact Kernelization</h3>
<p><a href='http://arxiv.org/abs/2403.19928v1'>http://arxiv.org/abs/2403.19928v1</a></p>
<p><b>Compressor summary</b>: The paper introduces DiJiang, a linear complexity model for Transformers that reduces training costs and inference speeds using frequency domain kernelization and Discrete Cosine Transform.</p><hr><h3>Video-Based Human Pose Regression via Decoupled Space-Time Aggregation</h3>
<p><a href='http://arxiv.org/abs/2403.19926v1'>http://arxiv.org/abs/2403.19926v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel video-based human pose regression method that efficiently captures spatial and temporal dependencies using a Decoupled Space-Time Aggregation network (DSTA) without relying on intermediate heatmaps.</p><hr><h3>Decision Mamba: Reinforcement Learning via Sequence Modeling with  Selective State Spaces</h3>
<p><a href='http://arxiv.org/abs/2403.19925v1'>http://arxiv.org/abs/2403.19925v1</a></p>
<p><b>Compressor summary</b>: The paper explores combining Decision Transformer and Mamba frameworks to improve sequential decision-making in reinforcement learning tasks by enhancing sequence modeling efficiency and effectiveness.</p><hr><h3>SceneTracker: Long-term Scene Flow Estimation Network</h3>
<p><a href='http://arxiv.org/abs/2403.19924v1'>http://arxiv.org/abs/2403.19924v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel network called SceneTracker that can estimate long-term 3D motion in scenes by using appearance and depth correlation features and the Transformer architecture.</p><hr><h3>MI-NeRF: Learning a Single Face NeRF from Multiple Identities</h3>
<p><a href='http://arxiv.org/abs/2403.19920v1'>http://arxiv.org/abs/2403.19920v1</a></p>
<p><b>Compressor summary</b>: MI-NeRF is a single neural network that learns non-rigid facial motion for multiple identities from monocular videos, using a multiplicative module to capture identity and non-identity information interactions.</p><hr><h3>Diff-Reg v1: Diffusion Matching Model for Registration Problem</h3>
<p><a href='http://arxiv.org/abs/2403.19919v1'>http://arxiv.org/abs/2403.19919v1</a></p>
<p><b>Compressor summary</b>: The diffusion matching model uses a denoising process to create robust correspondences for registration tasks, addressing challenges like large deformation and scale inconsistency in complex scenarios.</p><hr><h3>MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of  Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2403.19913v1'>http://arxiv.org/abs/2403.19913v1</a></p>
<p><b>Compressor summary</b>: MANGO is a benchmark for evaluating large language models' mapping and navigation skills using text-based mazes and questions.</p><hr><h3>Automated Identification and Segmentation of Hi Sources in CRAFTS Using  Deep Learning Method</h3>
<p><a href='http://arxiv.org/abs/2403.19912v1'>http://arxiv.org/abs/2403.19912v1</a></p>
<p><b>Compressor summary</b>: The method uses machine learning to identify and segment radio waves from space in 3D data, with high accuracy and recall rates.</p><hr><h3>Beyond the Known: Novel Class Discovery for Open-world Graph Learning</h3>
<p><a href='http://arxiv.org/abs/2403.19907v1'>http://arxiv.org/abs/2403.19907v1</a></p>
<p><b>Compressor summary</b>: The paper introduces ORAL, a novel method for discovering novel classes on graphs using semi-supervised learning and multi-scale features.</p><hr><h3>Classification of Diabetic Retinopathy using Pre-Trained Deep Learning  Models</h3>
<p><a href='http://arxiv.org/abs/2403.19905v1'>http://arxiv.org/abs/2403.19905v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper presents a CAD system for automatic classification of retinal images into five DR classes using CNNs and fine-tuning techniques.
- The model is trained on fundus images with different resolutions and tested on the Kaggle platform.
- The achieved AUC values are reported for various deep learning models.

Summary:
The paper introduces a CAD system that uses CNNs and fine-tuning to classify retinal images into five DR classes, achieving different AUC values for various models.</p><hr><h3>Fully Geometric Panoramic Localization</h3>
<p><a href='http://arxiv.org/abs/2403.19904v1'>http://arxiv.org/abs/2403.19904v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel localization method using only 2D-3D line geometry, avoiding visual descriptors and achieving fast and accurate results for challenging scenes.</p><hr><h3>Heterogeneous Network Based Contrastive Learning Method for PolSAR Land  Cover Classification</h3>
<p><a href='http://arxiv.org/abs/2403.19902v1'>http://arxiv.org/abs/2403.19902v1</a></p>
<p><b>Compressor summary</b>: HCLNet is a novel method that uses heterogeneous architecture and contrastive learning to improve PolSAR image classification with few-shot learning and multi-features, addressing the challenges of labeled data scarcity and scattering confusion.</p><hr><h3>Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models  for Image Inpainting</h3>
<p><a href='http://arxiv.org/abs/2403.19898v1'>http://arxiv.org/abs/2403.19898v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new model called StrDiffusion that guides image inpainting with structure-based semantics to reduce semantic discrepancy between masked and unmasked regions.</p><hr><h3>Disentangling Racial Phenotypes: Fine-Grained Control of Race-related  Facial Phenotype Characteristics</h3>
<p><a href='http://arxiv.org/abs/2403.19897v1'>http://arxiv.org/abs/2403.19897v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel GAN framework that enables fine-grained control over race-related facial features in 2D images using a new dataset and preserving facial identity for racial bias mitigation.</p><hr><h3>Nonlinearity Enhanced Adaptive Activation Function</h3>
<p><a href='http://arxiv.org/abs/2403.19896v1'>http://arxiv.org/abs/2403.19896v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an improved activation function for neural networks, which can increase accuracy without much extra computation, but has some tradeoffs and requires adjustable parameters.</p><hr><h3>PLoc: A New Evaluation Criterion Based on Physical Location for  Autonomous Driving Datasets</h3>
<p><a href='http://arxiv.org/abs/2403.19893v1'>http://arxiv.org/abs/2403.19893v1</a></p>
<p><b>Compressor summary</b>: This paper proposes PLoc, a novel evaluation criterion for object detection in autonomous driving based on physical location, and presents ApolloScape-R, a re-annotated dataset reflecting this criterion.</p><hr><h3>Towards a Robust Retrieval-Based Summarization System</h3>
<p><a href='http://arxiv.org/abs/2403.19889v1'>http://arxiv.org/abs/2403.19889v1</a></p>
<p><b>Compressor summary</b>: The paper proposes LogicSumm, a framework to evaluate large language models' robustness in summarization tasks, and SummRAG, a system to improve their performance by fine-tuning them on realistic scenarios.</p><hr><h3>MambaMixer: Efficient Selective State Space Models with Dual Token and  Channel Selection</h3>
<p><a href='http://arxiv.org/abs/2403.19888v1'>http://arxiv.org/abs/2403.19888v1</a></p>
<p><b>Compressor summary</b>: MambaMixer combines selective token and channel mixing to improve scalability and performance in vision and time series tasks, outperforming existing models.</p>