
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="stylesheet" href="../style.css"/>
		<title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
		<h1>arxiv compressed, 2023-11-27</h1>
		<p>This page contains one-sentence summaries of cs.AI/ML/CV papers announced on 2023-11-27 generated by the compressor, my personal LLM-based project.</p>
	<hr><h3>Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating  Video-based Large Language Models</h3>
<p>Munan Ning,Bin Zhu,Yujia Xie,Bin Lin,Jiaxi Cui,Lu Yuan,Dongdong Chen,Li Yuan</p>
<p><a href='http://arxiv.org/abs/2311.16103v1'>http://arxiv.org/abs/2311.16103v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Video-Bench, a comprehensive evaluation system for video-based large language models, with 10 tasks covering understanding, question-answering, and decision-making.</p><hr><h3>Test-time Adaptation of Discriminative Models via Diffusion Generative  Feedback</h3>
<p>Mihir Prabhudesai,Tsung-Wei Ke,Alexander C. Li,Deepak Pathak,Katerina Fragkiadaki</p>
<p><a href='http://arxiv.org/abs/2311.16102v1'>http://arxiv.org/abs/2311.16102v1</a></p>
<p><b>Compressor summary</b>: Diffusion-TTA adapts pre-trained discriminative models using generative feedback from a diffusion model, improving their accuracy in various tasks.</p><hr><h3>How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for  Vision LLMs</h3>
<p>Haoqin Tu,Chenhang Cui,Zijun Wang,Yiyang Zhou,Bingchen Zhao,Junlin Han,Wangchunshu Zhou,Huaxiu Yao,Cihang Xie</p>
<p><a href='http://arxiv.org/abs/2311.16101v1'>http://arxiv.org/abs/2311.16101v1</a></p>
<p><b>Compressor summary</b>: This study evaluates Vision LLMs' visual reasoning abilities by introducing a comprehensive safety evaluation suite that covers OOD generalization and adversarial robustness, revealing their strengths and weaknesses in handling different conditions.</p><hr><h3>GART: Gaussian Articulated Template Models</h3>
<p>Jiahui Lei,Yufu Wang,Georgios Pavlakos,Lingjie Liu,Kostas Daniilidis</p>
<p><a href='http://arxiv.org/abs/2311.16099v1'>http://arxiv.org/abs/2311.16099v1</a></p>
<p><b>Compressor summary</b>: GART is a model that uses moving 3D Gaussians to represent deformable subjects in monocular videos with efficient reconstruction and rendering.</p><hr><h3>CG-HOI: Contact-Guided 3D Human-Object Interaction Generation</h3>
<p>Christian Diller,Angela Dai</p>
<p><a href='http://arxiv.org/abs/2311.16097v1'>http://arxiv.org/abs/2311.16097v1</a></p>
<p><b>Compressor summary</b>: CG-HOI is a method for generating realistic 3D human-object interactions from text by modeling contact between the human body and object geometry.</p><hr><h3>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for  High-fidelity Human Avatar Modeling</h3>
<p>Zhe Li,Zerong Zheng,Lizhen Wang,Yebin Liu</p>
<p><a href='http://arxiv.org/abs/2311.16096v1'>http://arxiv.org/abs/2311.16096v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new method for creating realistic and dynamic human avatars using a combination of 2D and 3D neural networks, which can adapt to different clothing styles and poses.</p><hr><h3>Street TryOn: Learning In-the-Wild Virtual Try-On from Unpaired Person  Images</h3>
<p>Aiyu Cui,Jay Mahajan,Viraj Shah,Preeti Gomathinayagam,Svetlana Lazebnik</p>
<p><a href='http://arxiv.org/abs/2311.16094v1'>http://arxiv.org/abs/2311.16094v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a Street TryOn benchmark and a novel method for virtual try-on on in-the-wild scenes without paired data, using DensePose warping correction and diffusion-based inpainting.</p><hr><h3>Have we built machines that think like people?</h3>
<p>Luca M. Schulze Buschoff,Elif Akata,Matthias Bethge,Eric Schulz</p>
<p><a href='http://arxiv.org/abs/2311.16093v1'>http://arxiv.org/abs/2311.16093v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates how well vision-based large language models perform in intuitive physics, causal reasoning, and intuitive psychology tasks, finding that they are still far from human capabilities in these domains.</p><hr><h3>Self-correcting LLM-controlled Diffusion Models</h3>
<p>Tsung-Han Wu,Long Lian,Joseph E. Gonzalez,Boyi Li,Trevor Darrell</p>
<p><a href='http://arxiv.org/abs/2311.16090v1'>http://arxiv.org/abs/2311.16090v1</a></p>
<p><b>Compressor summary</b>: SLD is a framework that generates images from text prompts, assesses their alignment, and performs self-corrections to ensure correctness in the resulting image, without needing additional training or integrating with existing diffusion models.</p><hr><h3>DUnE: Dataset for Unified Editing</h3>
<p>Afra Feyza Akyürek,Eric Pan,Garry Kuwanto,Derry Wijaya</p>
<p><a href='http://arxiv.org/abs/2311.16087v1'>http://arxiv.org/abs/2311.16087v1</a></p>
<p><b>Compressor summary</b>: This paragraph discusses a study that explores different ways to edit language models beyond factual data, introduces a new benchmark called DUnE, and shows that no existing methods have completely solved the generalized editing problem.</p><hr><h3>MAST: Model-Agnostic Sparsified Training</h3>
<p>Yury Demidovich,Grigory Malinovsky,Egor Shulgin,Peter Richtárik</p>
<p><a href='http://arxiv.org/abs/2311.16086v1'>http://arxiv.org/abs/2311.16086v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new optimization problem that uses pre-trained models and random sketch operators for sparsification during machine learning model training, leading to improved convergence rates and relaxed assumptions.</p><hr><h3>BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using  Genre Classification</h3>
<p>Dmitri Roussinov,Serge Sharoff</p>
<p><a href='http://arxiv.org/abs/2311.16083v1'>http://arxiv.org/abs/2311.16083v1</a></p>
<p><b>Compressor summary</b>: The paper shows that PLMs struggle with topic changes in text classification tasks, proposes using synthetic texts to improve performance, and provides empirical results and code for replication.</p><hr><h3>ViT-Lens-2: Gateway to Omni-modal Intelligence</h3>
<p>Weixian Lei,Yixiao Ge,Kun Yi,Jianfeng Zhang,Difei Gao,Dylan Sun,Yuying Ge,Ying Shan,Mike Zheng Shou</p>
<p><a href='http://arxiv.org/abs/2311.16081v1'>http://arxiv.org/abs/2311.16081v1</a></p>
<p><b>Compressor summary</b>: The paper introduces ViT-Lens-2, a method for efficient learning of diverse modalities using pretrained vision transformers and modality alignment with existing foundation models.</p><hr><h3>MEDITRON-70B: Scaling Medical Pretraining for Large Language Models</h3>
<p>Zeming Chen,Alejandro Hernández Cano,Angelika Romanou,Antoine Bonnet,Kyle Matoba,Francesco Salvi,Matteo Pagliardini,Simin Fan,Andreas Köpf,Amirkeivan Mohtashami,Alexandre Sallinen,Alireza Sakhaeirad,Vinitra Swamy,Igor Krawczuk,Deniz Bayazit,Axel Marmet,Syrielle Montariol,Mary-Anne Hartley,Martin Jaggi,Antoine Bosselut</p>
<p><a href='http://arxiv.org/abs/2311.16079v1'>http://arxiv.org/abs/2311.16079v1</a></p>
<p><b>Compressor summary</b>: MEDITRON is an open-source suite of large-scale medical language models that outperform several closed-source models on medical benchmarks.</p><hr><h3>BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical  Knowledge Graph Insights</h3>
<p>François Remy,Kris Demuynck,Thomas Demeester</p>
<p><a href='http://arxiv.org/abs/2311.16075v1'>http://arxiv.org/abs/2311.16075v1</a></p>
<p><b>Compressor summary</b>: The study uses Large Language Models and UMLS knowledge graph to create high-fidelity representations of biomedical concepts and sentences, improving performance on various tasks and releasing a multilingual model.</p><hr><h3>A Survey on Vulnerability of Federated Learning: A Learning Algorithm  Perspective</h3>
<p>Xianghua Xie,Chen Hu,Hanchi Ren,Jingjing Deng</p>
<p><a href='http://arxiv.org/abs/2311.16065v1'>http://arxiv.org/abs/2311.16065v1</a></p>
<p><b>Compressor summary</b>: This paper reviews malicious attacks on federated learning (FL) systems, categorizes them into four types, and discusses defense strategies that aim to protect FL's learning process, data, and models from manipulation and sabotage.</p><hr><h3>DiffSLVA: Harnessing Diffusion Models for Sign Language Video  Anonymization</h3>
<p>Zhaoyang Xia,Carol Neidle,Dimitris N. Metaxas</p>
<p><a href='http://arxiv.org/abs/2311.16060v1'>http://arxiv.org/abs/2311.16060v1</a></p>
<p><b>Compressor summary</b>: The research introduces DiffSLVA, a method that uses diffusion models and image features to anonymize sign language videos without losing linguistic content, potentially benefiting Deaf and Hard-of-Hearing communities.</p><hr><h3>Metric Space Magnitude for Evaluating Unsupervised Representation  Learning</h3>
<p>Katharina Limbeck,Rayna Andreeva,Rik Sarkar,Bastian Rieck</p>
<p><a href='http://arxiv.org/abs/2311.16054v1'>http://arxiv.org/abs/2311.16054v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces magnitude as a measure of the effective size of a space, and presents a new quality measure for dimensionality reduction tasks based on dissimilarity between magnitude functions.</p><hr><h3>Exploring Attribute Variations in Style-based GANs using Diffusion  Models</h3>
<p>Rishubh Parihar,Prasanna Balaji,Raghav Magazine,Sarthak Vora,Tejan Karmali,Varun Jampani,R. Venkatesh Babu</p>
<p><a href='http://arxiv.org/abs/2311.16052v1'>http://arxiv.org/abs/2311.16052v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method for diverse attribute editing by modeling multidimensional attribute edits using disentangled latent spaces of pretrained GANs and training a Denoising Diffusion Probabilistic Model.</p><hr><h3>Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF  Decomposition and Ray Tracing</h3>
<p>Jian Gao,Chun Gu,Youtian Lin,Hao Zhu,Xun Cao,Li Zhang,Yao Yao</p>
<p><a href='http://arxiv.org/abs/2311.16043v1'>http://arxiv.org/abs/2311.16043v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a new method to render 3D scenes from multiple images using point-based rendering, which allows for editing, ray-tracing, and real-time relighting of the scene.</p><hr><h3>Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps</h3>
<p>Jane Wu,Diego Thomas,Ronald Fedkiw</p>
<p><a href='http://arxiv.org/abs/2311.16042v1'>http://arxiv.org/abs/2311.16042v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method using deep learning to reconstruct 3D clothed humans from 2D normal maps and RGB images, without volumetric information ground truth.</p><hr><h3>OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving</h3>
<p>Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Borui Zhang,Yueqi Duan,Jiwen Lu</p>
<p><a href='http://arxiv.org/abs/2311.16038v1'>http://arxiv.org/abs/2311.16038v1</a></p>
<p><b>Compressor summary</b>: The paper proposes OccWorld, a world model that predicts the movement of the ego car and the evolution of surrounding scenes in 3D occupancy space, using scene tokens and a GPT-like generative transformer.</p><hr><h3>GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions</h3>
<p>Jiemin Fang,Junjie Wang,Xiaopeng Zhang,Lingxi Xie,Qi Tian</p>
<p><a href='http://arxiv.org/abs/2311.16037v1'>http://arxiv.org/abs/2311.16037v1</a></p>
<p><b>Compressor summary</b>: The GaussianEditor framework allows delicate and precise editing of 3D scenes using text instructions and 3D Gaussians, with faster training speed compared to previous methods.</p><hr><h3>Machine Learning-Enhanced Aircraft Landing Scheduling under  Uncertainties</h3>
<p>Yutian Pang,Peng Zhao,Jueming Hu,Yongming Liu</p>
<p><a href='http://arxiv.org/abs/2311.16030v1'>http://arxiv.org/abs/2311.16030v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a machine learning-enhanced landing scheduling method that reduces aircraft delays, improves safety, and considers uncertainties in flight events.</p><hr><h3>A Neural Framework for Generalized Causal Sensitivity Analysis</h3>
<p>Dennis Frauen,Fergus Imrie,Alicia Curth,Valentyn Melnychuk,Stefan Feuerriegel,Mihaela van der Schaar</p>
<p><a href='http://arxiv.org/abs/2311.16026v1'>http://arxiv.org/abs/2311.16026v1</a></p>
<p><b>Compressor summary</b>: NeuralCSA is a neural framework for causal sensitivity analysis that works with various sensitivity models, treatment types, and causal queries, and can infer valid bounds on the causal query of interest.</p><hr><h3>Forecasting Auxiliary Energy Consumption for Electric Heavy-Duty  Vehicles</h3>
<p>Yuantao Fan,Zhenkan Wang,Sepideh Pashami,Slawomir Nowaczyk,Henrik Ydreskog</p>
<p><a href='http://arxiv.org/abs/2311.16003v1'>http://arxiv.org/abs/2311.16003v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve energy consumption prediction and explainability for electric commercial vehicles by training multiple regression models on subsets of data based on relevant sub-populations.</p><hr><h3>Closing the ODE-SDE gap in score-based diffusion models through the  Fokker-Planck equation</h3>
<p>Teo Deveney,Jan Stanczuk,Lisa Maria Kreusser,Chris Budd,Carola-Bibiane Schönlieb</p>
<p><a href='http://arxiv.org/abs/2311.15996v1'>http://arxiv.org/abs/2311.15996v1</a></p>
<p><b>Compressor summary</b>: This paper analyses the differences between ODE and SDE dynamics in score-based diffusion models and proposes a regularisation term to reduce these differences, but it may degrade SDE sample quality.</p><hr><h3>Sensitivity-Based Layer Insertion for Residual and Feedforward Neural  Networks</h3>
<p>Evelyn Herberg,Roland Herzog,Frederik Köhne,Leonie Kreis,Anton Schiela</p>
<p><a href='http://arxiv.org/abs/2311.15995v1'>http://arxiv.org/abs/2311.15995v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to insert new layers in neural networks during training using sensitivity-based techniques, which improves training efficiency and reduces computational effort.</p><hr><h3>Unified Batch Normalization: Identifying and Alleviating the Feature  Condensation in Batch Normalization and a Unified Framework</h3>
<p>Shaobo Wang,Xiangdong Zhang,Junchi Yan</p>
<p><a href='http://arxiv.org/abs/2311.15993v1'>http://arxiv.org/abs/2311.15993v1</a></p>
<p><b>Compressor summary</b>: UBN is a two-stage framework that alleviates feature condensation and unifies various BN variants to improve neural network training stability and convergence.</p><hr><h3>DiffAnt: Diffusion Models for Action Anticipation</h3>
<p>Zeyun Zhong,Chengzhi Wu,Manuel Martin,Michael Voit,Juergen Gall,Jürgen Beyerer</p>
<p><a href='http://arxiv.org/abs/2311.15991v1'>http://arxiv.org/abs/2311.15991v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new generative model that captures different possible future actions by iteratively generating them from Gaussian noise, conditioned on the observed video, and show its effectiveness on four benchmark datasets.</p><hr><h3>Should We Learn Most Likely Functions or Parameters?</h3>
<p>Shikai Qiu,Tim G. J. Rudner,Sanyam Kapoor,Andrew Gordon Wilson</p>
<p><a href='http://arxiv.org/abs/2311.15990v1'>http://arxiv.org/abs/2311.15990v1</a></p>
<p><b>Compressor summary</b>: The text discusses alternatives to standard regularized training methods by directly estimating the most likely function implied by a model and data, which can improve generalization and robustness.</p><hr><h3>Sparsify-then-Classify: From Internal Neurons of Large Language Models  To Efficient Text Classifiers</h3>
<p>Yilun Liu,Difan Jiao,Ashton Anderson</p>
<p><a href='http://arxiv.org/abs/2311.15983v1'>http://arxiv.org/abs/2311.15983v1</a></p>
<p><b>Compressor summary</b>: The Sparsify-then-Classify (STC) approach improves text classification performance by using all internal representations of Large Language Models with multiple pooling strategies and sparsifying task-specific features.</p><hr><h3>Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion</h3>
<p>Yuanxun Lu,Jingyang Zhang,Shiwei Li,Tian Fang,David McKinnon,Yanghai Tsin,Long Quan,Xun Cao,Yao Yao</p>
<p><a href='http://arxiv.org/abs/2311.15980v1'>http://arxiv.org/abs/2311.15980v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel method for generating diverse and high-fidelity 3D content using a multi-view 2.5D diffusion model that is fine-tuned from a pre-trained 2D diffusion model, without the need for score distillation sampling or extensive 3D training data.</p><hr><h3>Soil Organic Carbon Estimation from Climate-related Features with Graph  Neural Network</h3>
<p>Weiying Zhao,Natalia Efremova</p>
<p><a href='http://arxiv.org/abs/2311.15979v1'>http://arxiv.org/abs/2311.15979v1</a></p>
<p><b>Compressor summary</b>: The study compared four Graph Neural Network operators to estimate soil organic carbon using satellite data and found that PESAGE and PETransformer models performed best, showing the potential of GNNs in predicting SOC.</p><hr><h3>Text2Loc: 3D Point Cloud Localization from Natural Language</h3>
<p>Yan Xia,Letian Shi,Zifeng Ding,João F. Henriques,Daniel Cremers</p>
<p><a href='http://arxiv.org/abs/2311.15977v1'>http://arxiv.org/abs/2311.15977v1</a></p>
<p><b>Compressor summary</b>: The Text2Loc neural network uses natural language descriptions and a coarse-to-fine localization pipeline to improve 3D point cloud localization accuracy by up to 2 times over previous methods.</p><hr><h3>FALCON: Fairness Learning via Contrastive Attention Approach to  Continual Semantic Scene Understanding in Open World</h3>
<p>Thanh-Dat Truong,Utsav Prabhu,Bhiksha Raj,Jackson Cothren,Khoa Luu</p>
<p><a href='http://arxiv.org/abs/2311.15965v1'>http://arxiv.org/abs/2311.15965v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new Fairness Contrastive Clustering loss to address catastrophic forgetting and fairness in continual learning for semantic scene understanding, and proposes an attention-based visual grammar approach for background shift and unknown classes.</p><hr><h3>Efficient Pre-training for Localized Instruction Generation of Videos</h3>
<p>Anil Batra,Davide Moltisanti,Laura Sevilla-Lara,Marcus Rohrbach,Frank Keller</p>
<p><a href='http://arxiv.org/abs/2311.15964v1'>http://arxiv.org/abs/2311.15964v1</a></p>
<p><b>Compressor summary</b>: Sieve-&-Swap is a technique to automatically filter and improve procedural video transcripts for better step localization and instruction generation with less computational resources.</p><hr><h3>From Pixels to Titles: Video Game Identification by Screenshots using  Convolutional Neural Networks</h3>
<p>Fabricio Breve</p>
<p><a href='http://arxiv.org/abs/2311.15963v1'>http://arxiv.org/abs/2311.15963v1</a></p>
<p><b>Compressor summary</b>: The paper shows how convolutional neural networks can identify video games from single screenshots with high accuracy, using different architectures and initial weights.</p><hr><h3>Addressing Long-Horizon Tasks by Integrating Program Synthesis and State  Machines</h3>
<p>Yu-An Lin,Chen-Tao Lee,Guan-Ting Liu,Pu-Jen Cheng,Shao-Hua Sun</p>
<p><a href='http://arxiv.org/abs/2311.15960v1'>http://arxiv.org/abs/2311.15960v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Program Machine Policies (POMPs), which combine programmatic RL and state machine policies to represent complex behaviors and address long-term tasks, outperforming previous methods on various tasks and generalizing inductively without fine-tuning.</p><hr><h3>A Quantitative Approach to Understand Self-Supervised Models as  Cross-lingual Feature Extractors</h3>
<p>Shuyue Stella Li,Beining Xu,Xiangyu Zhang,Hexin Liu,Wenhan Chao,Leibny Paola Garcia</p>
<p><a href='http://arxiv.org/abs/2311.15954v1'>http://arxiv.org/abs/2311.15954v1</a></p>
<p><b>Compressor summary</b>: The study examines how self-supervised learning (SSL) models perform as feature extractors in cross-lingual settings and proposes a new metric, PSR, to measure their effectiveness using ASR performance.</p><hr><h3>Replay across Experiments: A Natural Extension of Off-Policy RL</h3>
<p>Dhruva Tirumala,Thomas Lampe,Jose Enrique Chen,Tuomas Haarnoja,Sandy Huang,Guy Lever,Ben Moran,Tim Hertweck,Leonard Hasenclever,Martin Riedmiller,Nicolas Heess,Markus Wulfmeier</p>
<p><a href='http://arxiv.org/abs/2311.15951v1'>http://arxiv.org/abs/2311.15951v1</a></p>
<p><b>Compressor summary</b>: Replay Across Experiments (RaE) is a simple framework that uses experience from previous experiments to improve RL performance, exploration, and bootstrapping while requiring minimal changes.</p><hr><h3>GloNets: Globally Connected Neural Networks</h3>
<p>Antonio Di Cecco,Carlo Metta,Marco Fantozzi,Francesco Morandin,Maurizio Parton</p>
<p><a href='http://arxiv.org/abs/2311.15947v1'>http://arxiv.org/abs/2311.15947v1</a></p>
<p><b>Compressor summary</b>: GloNet is a new architecture that helps deep neural networks work better at higher depths by uniformly connecting and regulating information flow across the network.</p><hr><h3>Leveraging deep active learning to identify low-resource mobility  functioning information in public clinical notes</h3>
<p>Tuan-Dung Le,Zhuqi Miao,Samuel Alvarado,Brittany Smith,William Paiva,Thanh Thieu</p>
<p><a href='http://arxiv.org/abs/2311.15946v1'>http://arxiv.org/abs/2311.15946v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces a new dataset for extracting and analyzing mobility functioning information from clinical notes using BERT and CRF models.</p><hr><h3>Over-Squashing in Riemannian Graph Neural Networks</h3>
<p>Julia Balla</p>
<p><a href='http://arxiv.org/abs/2311.15945v1'>http://arxiv.org/abs/2311.15945v1</a></p>
<p><b>Compressor summary</b>: The paper investigates whether using Riemannian manifolds of variable curvature in Hyperbolic Graph Neural Networks (HGNNs) can reduce over-squashing, a phenomenon where node features become insensitive to distant nodes in the graph.</p><hr><h3>Tell2Design: A Dataset for Language-Guided Floor Plan Generation</h3>
<p>Sicong Leng,Yang Zhou,Mohammed Haroon Dupty,Wee Sun Lee,Sam Conrad Joyce,Wei Lu</p>
<p><a href='http://arxiv.org/abs/2311.15941v1'>http://arxiv.org/abs/2311.15941v1</a></p>
<p><b>Compressor summary</b>: The authors introduce a new dataset, model, and evaluation method for generating floor plans from natural language descriptions, aiming to advance the field of language-guided design generation.</p><hr><h3>Physics-informed neural networks for transformed geometries and  manifolds</h3>
<p>Samuel Burbulla</p>
<p><a href='http://arxiv.org/abs/2311.15940v1'>http://arxiv.org/abs/2311.15940v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve physics-informed neural networks (PINNs) by incorporating geometric transformations, allowing them to handle complex or varying shapes better and enable shape optimization.</p><hr><h3>Unleashing the Power of Prompt-driven Nucleus Instance Segmentation</h3>
<p>Zhongyi Shui,Yunlong Zhang,Kai Yao,Chenglu Zhu,Yuxuan Sun,Lin Yang</p>
<p><a href='http://arxiv.org/abs/2311.15939v1'>http://arxiv.org/abs/2311.15939v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel framework that uses a point prompter and a segment anything model (SAM) for automatic nuclear instance segmentation in histology images, achieving state-of-the-art results.</p><hr><h3>Optimal Transport Aggregation for Visual Place Recognition</h3>
<p>Sergio Izquierdo,Javier Civera</p>
<p><a href='http://arxiv.org/abs/2311.15937v1'>http://arxiv.org/abs/2311.15937v1</a></p>
<p><b>Compressor summary</b>: SALAD is a new method for visual place recognition that uses optimal transport to aggregate local features, discards non-informative ones, and leverages a fast-learning backbone to achieve better performance than existing approaches.</p><hr><h3>A new fuzzy multi-attribute group decision-making method based on TOPSIS  and optimization models</h3>
<p>Qixiao Hu,Shiquan Zhang,Chaolang Hu,Yuetong Liu</p>
<p><a href='http://arxiv.org/abs/2311.15933v1'>http://arxiv.org/abs/2311.15933v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method for multi-attribute group decision-making using TOPSIS and optimization models with interval-valued intuitionistic fuzzy sets, which combines subjective and objective weighting methods and is demonstrated on a real case study.</p><hr><h3>WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large  Language Models</h3>
<p>Youssef Benchekroun,Megi Dervishi,Mark Ibrahim,Jean-Baptiste Gaya,Xavier Martinet,Grégoire Mialon,Thomas Scialom,Emmanuel Dupoux,Dieuwke Hupkes,Pascal Vincent</p>
<p><a href='http://arxiv.org/abs/2311.15930v1'>http://arxiv.org/abs/2311.15930v1</a></p>
<p><b>Compressor summary</b>: WorldSense is a benchmark to test LLMs' ability to understand simple arrangements of entities, but current chat-LLMs make errors and have response biases even with three objects.</p><hr><h3>Reinforcement Learning for Wildfire Mitigation in Simulated Disaster  Environments</h3>
<p>Alexander Tapley,Marissa Dotter,Michael Doyle,Aidan Fennelly,Dhanuj Gandikota,Savanna Smith,Michael Threet,Tim Welsh</p>
<p><a href='http://arxiv.org/abs/2311.15925v1'>http://arxiv.org/abs/2311.15925v1</a></p>
<p><b>Compressor summary</b>: The paper introduces SimFire, a realistic wildfire simulator, and SimHarness, an agent-based machine learning system to generate land management strategies, to help prepare for and react to increasingly severe fire seasons due to climate change.</p><hr><h3>Diagnosis driven Anomaly Detection for CPS</h3>
<p>Henrik S. Steude,Lukas Moddemann,Alexander Diedrich,Jonas Ehrhardt,Oliver Niggemann</p>
<p><a href='http://arxiv.org/abs/2311.15924v1'>http://arxiv.org/abs/2311.15924v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method that combines deep learning-based anomaly detection with Consistency-Based Diagnosis for holistic diagnosis in Cyber-Physical Systems and show its effectiveness on simulated and real data.</p><hr><h3>A Fully Data-Driven Approach for Realistic Traffic Signal Control Using  Offline Reinforcement Learning</h3>
<p>Jianxiong Li,Shichao Lin,Tianyu Shi,Chujie Tian,Yu Mei,Jian Song,Xianyuan Zhan,Ruimin Li</p>
<p><a href='http://arxiv.org/abs/2311.15920v1'>http://arxiv.org/abs/2311.15920v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a data-driven framework for traffic signal control using machine learning and traffic flow theory to infer rewards from coarse-grained data and learn policies from historical datasets.</p><hr><h3>ADM-Loc: Actionness Distribution Modeling for Point-supervised Temporal  Action Localization</h3>
<p>Elahe Vahdani,Yingli Tian</p>
<p><a href='http://arxiv.org/abs/2311.15916v1'>http://arxiv.org/abs/2311.15916v1</a></p>
<p><b>Compressor summary</b>: The paper introduces ADM-Loc, a novel framework for detecting actions in videos with limited annotations, by generating action proposals from a composite distribution and enforcing consistency in action classification scores.</p><hr><h3>Computer Vision for Carriers: PATRIOT</h3>
<p>Ari Goodman,Gurpreet Singh,James Hing,Ryan O'Shea</p>
<p><a href='http://arxiv.org/abs/2311.15914v1'>http://arxiv.org/abs/2311.15914v1</a></p>
<p><b>Compressor summary</b>: PATRIOT is a prototype system that uses existing camera feeds and passive sensing to automatically track and update aircraft positions on a virtual Ouija board interface, improving deck tracking efficiency and safety without GPS sensors.</p><hr><h3>LIFT OFF: LoRaWAN Installation and Fiducial Tracking Operations for the  Flightline of the Future</h3>
<p>Ari Goodman,Ryan O'Shea</p>
<p><a href='http://arxiv.org/abs/2311.15912v1'>http://arxiv.org/abs/2311.15912v1</a></p>
<p><b>Compressor summary</b>: LIFT OFF is a hybrid framework that uses machine vision, GPS sensors, and LoRaWAN to provide real-time situational awareness of people, equipment, and aircraft positions in various environments, including military flightlines.</p><hr><h3>Enhancing Perceptual Quality in Video Super-Resolution through  Temporally-Consistent Detail Synthesis using Diffusion Models</h3>
<p>Claudio Rota,Marco Buzzelli,Joost van de Weijer</p>
<p><a href='http://arxiv.org/abs/2311.15908v1'>http://arxiv.org/abs/2311.15908v1</a></p>
<p><b>Compressor summary</b>: The paper proposes StableVSR, a method that uses Diffusion Models and Temporal Conditioning Module to enhance the quality of upscaled videos by synthesizing realistic and temporally-consistent details.</p><hr><h3>MetaDefa: Meta-learning based on Domain Enhancement and Feature  Alignment for Single Domain Generalization</h3>
<p>Can Sun,Hao Zheng,Zhigang Hu,Liu Yang,Meiguang Zheng,Bo Xu</p>
<p><a href='http://arxiv.org/abs/2311.15906v1'>http://arxiv.org/abs/2311.15906v1</a></p>
<p><b>Compressor summary</b>: MetaDefa is a novel meta-learning method that improves SDG model generalization by enhancing domains and aligning features using background substitution, visual corruptions, and class activation maps.</p><hr><h3>Data Generation for Post-OCR correction of Cyrillic handwriting</h3>
<p>Evgenii Davydkin,Aleksandr Markelov,Egor Iuldashev,Anton Dudkin,Ivan Krivorotov</p>
<p><a href='http://arxiv.org/abs/2311.15896v1'>http://arxiv.org/abs/2311.15896v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method to generate realistic synthetic Cyrillic handwriting and use it to create a large dataset for training a post-OCR correction model, which can improve error identification and evaluation of student performance.</p><hr><h3>Stability-Informed Initialization of Neural Ordinary Differential  Equations</h3>
<p>Theodor Westny,Arman Mohammadi,Daniel Jung,Erik Frisk</p>
<p><a href='http://arxiv.org/abs/2311.15890v1'>http://arxiv.org/abs/2311.15890v1</a></p>
<p><b>Compressor summary</b>: The paper explores how different aspects of neural ODE training impact performance and introduces a new initialization technique based on stability regions.</p><hr><h3>FLASC: A Flare-Sensitive Clustering Algorithm: Extending HDBSCAN* for  Detecting Branches in Clusters</h3>
<p>D. M. Bot,J. Peeters,J. Liesenborgs,J. Aerts</p>
<p><a href='http://arxiv.org/abs/2311.15887v1'>http://arxiv.org/abs/2311.15887v1</a></p>
<p><b>Compressor summary</b>: FLASC is a flare-sensitive clustering algorithm that improves upon HDBSCAN* by differentiating branches within detected clusters and offering two variants with varying computational cost and noise robustness.</p><hr><h3>EVCap: Retrieval-Augmented Image Captioning with External Visual-Name  Memory for Open-World Comprehension</h3>
<p>Jiaxuan Li,Duc Minh Vo,Akihiro Sugimoto,Hideki Nakayama</p>
<p><a href='http://arxiv.org/abs/2311.15879v1'>http://arxiv.org/abs/2311.15879v1</a></p>
<p><b>Compressor summary</b>: EVCap is a retrieval-augmented image captioning method that uses external visual-name memory to enable LLMs to describe novel objects without relying on large amounts of data or scaling up network parameters.</p><hr><h3>RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation  and Consistency Regularization</h3>
<p>Kwanyoung Kim,Yujin Oh,Sangjoon Park,Hwa Kyung Byun,Jin Sung Kim,Yong Bae Kim,Jong Chul Ye</p>
<p><a href='http://arxiv.org/abs/2311.15876v1'>http://arxiv.org/abs/2311.15876v1</a></p>
<p><b>Compressor summary</b>: RO-LLaMA is a versatile AI model that can handle various tasks in radiation oncology, thanks to the CEFTune technique and LLM-driven segmentation framework.</p><hr><h3>InterControl: Generate Human Motion Interactions by Controlling Every  Joint</h3>
<p>Zhenzhi Wang,Jingbo Wang,Dahua Lin,Bo Dai</p>
<p><a href='http://arxiv.org/abs/2311.15864v1'>http://arxiv.org/abs/2311.15864v1</a></p>
<p><b>Compressor summary</b>: InterControl is a novel approach that uses motion diffusion models and controlnets to generate realistic human interactions with flexible spatial control of every joint.</p><hr><h3>SiTH: Single-view Textured Human Reconstruction with Image-Conditioned  Diffusion</h3>
<p>Hsuan-I Ho,Jie Song,Otmar Hilliges</p>
<p><a href='http://arxiv.org/abs/2311.15855v1'>http://arxiv.org/abs/2311.15855v1</a></p>
<p><b>Compressor summary</b>: SiTH is a novel pipeline that uses an image-conditioned diffusion model to create lifelike and detailed 3D human reconstructions from single images by decomposing the problem into hallucination and reconstruction subproblems.</p><hr><h3>A systematic study comparing hyperparameter optimization engines on  tabular data</h3>
<p>Balazs Kegl</p>
<p><a href='http://arxiv.org/abs/2311.15854v1'>http://arxiv.org/abs/2311.15854v1</a></p>
<p><b>Compressor summary</b>: The authors compare different hyperparameter optimization engines using normalization and aggregation methods and identify three top-performing engines.</p><hr><h3>Single-Model and Any-Modality for Video Object Tracking</h3>
<p>Zongwei Wu,Jilai Zheng,Xiangxuan Ren,Florin-Alexandru Vasluianu,Chao Ma,Danda Pani Paudel,Luc Van Gool,Radu Timofte</p>
<p><a href='http://arxiv.org/abs/2311.15851v1'>http://arxiv.org/abs/2311.15851v1</a></p>
<p><b>Compressor summary</b>: Un-Track is a single transformer-based tracker that learns a common latent space for multiple modalities using RGB-X pairs and achieves significant F-score gains on various datasets without modality-specific fine-tuning.</p><hr><h3>Learning with Noisy Low-Cost MOS for Image Quality Assessment via  Dual-Bias Calibration</h3>
<p>Lei Wang,Qingbo Wu,Desen Yuan,King Ngi Ngan,Hongliang Li,Fanman Meng,Linfeng Xu</p>
<p><a href='http://arxiv.org/abs/2311.15846v1'>http://arxiv.org/abs/2311.15846v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for learning robust image quality assessment models from low-cost opinion scores, which can perform well even with noisy and limited data.</p><hr><h3>Learning Disentangled Identifiers for Action-Customized Text-to-Image  Generation</h3>
<p>Siteng Huang,Biao Gong,Yutong Feng,Xi Chen,Yuqian Fu,Yu Liu,Donglin Wang</p>
<p><a href='http://arxiv.org/abs/2311.15841v1'>http://arxiv.org/abs/2311.15841v1</a></p>
<p><b>Compressor summary</b>: The study introduces a new method called Action-Disentangled Identifier (ADI) for text-to-image generation that improves action customization by learning action-specific identifiers and blocking the inversion of irrelevant features.</p><hr><h3>Utilizing Explainability Techniques for Reinforcement Learning Model  Assurance</h3>
<p>Alexander Tapley,Kyle Gatesman,Luis Robaina,Brett Bissey,Joseph Weissman</p>
<p><a href='http://arxiv.org/abs/2311.15838v1'>http://arxiv.org/abs/2311.15838v1</a></p>
<p><b>Compressor summary</b>: ARLIN Toolkit helps identify weaknesses in Deep Reinforcement Learning models using clear explanations and visualizations, making them safer to use in real situations.</p><hr><h3>Syn3DWound: A Synthetic Dataset for 3D Wound Bed Analysis</h3>
<p>Léo Lebrat,Rodrigo Santa Cruz,Remi Chierchia,Yulia Arzhaeva,Mohammad Ali Armin,Joshua Goldsmith,Jeremy Oorloff,Prithvi Reddy,Chuong Nguyen,Lars Petersson,Michelle Barakat-Johnson,Georgina Luscombe,Clinton Fookes,Olivier Salvado,David Ahmedt-Aristizabal</p>
<p><a href='http://arxiv.org/abs/2311.15836v1'>http://arxiv.org/abs/2311.15836v1</a></p>
<p><b>Compressor summary</b>: Syn3DWound is an open-source dataset of realistic simulated wounds with annotations, aimed at improving machine learning-based wound management through image analysis.</p><hr><h3>Temporal Action Localization for Inertial-based Human Activity  Recognition</h3>
<p>Marius Bock,Michael Moeller,Kristof Van Laerhoven</p>
<p><a href='http://arxiv.org/abs/2311.15831v1'>http://arxiv.org/abs/2311.15831v1</a></p>
<p><b>Compressor summary</b>: This paper shows how temporal attention models can improve wearable human activity recognition using raw data, outperforming previous methods with up to 25% better results.</p><hr><h3>Scale-Dropout: Estimating Uncertainty in Deep Neural Networks Using  Stochastic Scale</h3>
<p>Soyed Tuhin Ahmed,Kamal Danouchi,Michael Hefenbrock,Guillaume Prenat,Lorena Anghel,Mehdi B. Tahoori</p>
<p><a href='http://arxiv.org/abs/2311.15816v1'>http://arxiv.org/abs/2311.15816v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Scale Dropout, a novel regularization technique for binary neural networks, and Monte Carlo-Scale Dropout-based Bayesian neural networks for efficient uncertainty estimation on spintronic memory-based computation-in-memory architectures with significant energy savings.</p><hr><h3>FlowZero: Zero-Shot Text-to-Video Synthesis with LLM-Driven Dynamic  Scene Syntax</h3>
<p>Yu Lu,Linchao Zhu,Hehe Fan,Yi Yang</p>
<p><a href='http://arxiv.org/abs/2311.15813v1'>http://arxiv.org/abs/2311.15813v1</a></p>
<p><b>Compressor summary</b>: FlowZero is a novel framework that uses LLMs and image diffusion models to generate temporally-coherent videos from complex spatio-temporal text descriptions.</p><hr><h3>C-SAW: Self-Supervised Prompt Learning for Image Generalization in  Remote Sensing</h3>
<p>Avigyan Bhattacharya,Mainak Singha,Ankit Jha,Biplab Banerjee</p>
<p><a href='http://arxiv.org/abs/2311.15812v1'>http://arxiv.org/abs/2311.15812v1</a></p>
<p><b>Compressor summary</b>: C-SAW is a method that improves CLIP's performance in analyzing optical remote sensing images by enhancing visual features and prompt learning, addressing domain and content variations.</p><hr><h3>Exploring Artificial Intelligence Methods for Energy Prediction in  Healthcare Facilities: An In-Depth Extended Systematic Review</h3>
<p>Marjan FatehiJananloo,Helen Stopps,J. J. McArthur</p>
<p><a href='http://arxiv.org/abs/2311.15807v1'>http://arxiv.org/abs/2311.15807v1</a></p>
<p><b>Compressor summary</b>: The study reviewed 17 articles using machine learning and AI to predict hospital energy consumption, finding that occupancy and meteorological data are significant factors, while highlighting the need for more research on optimizing methods and integrating real-time data.</p><hr><h3>PIPE : Parallelized Inference Through Post-Training Quantization  Ensembling of Residual Expansions</h3>
<p>Edouard Yvinec,Arnaud Dapogny,Kevin Bailly</p>
<p><a href='http://arxiv.org/abs/2311.15806v1'>http://arxiv.org/abs/2311.15806v1</a></p>
<p><b>Compressor summary</b>: PIPE is a data-free quantization method for deep neural networks that adapts well to different devices and achieves good accuracy-speed trade-offs using residual error expansion, group sparsity, and ensemble approximation.</p><hr><h3>SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using  Neural Radiance Fields</h3>
<p>Quentin Herau,Nathan Piasco,Moussab Bennehar,Luis Roldão,Dzmitry Tsishkou,Cyrille Migniot,Pascal Vasseur,Cédric Demonceaux</p>
<p><a href='http://arxiv.org/abs/2311.15803v1'>http://arxiv.org/abs/2311.15803v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a NeRF-based sensor calibration method for autonomous driving that uses overlapping areas and improves accuracy and robustness.</p><hr><h3>Rethinking Privacy in Machine Learning Pipelines from an Information  Flow Control Perspective</h3>
<p>Lukas Wutschitz,Boris Köpf,Andrew Paverd,Saravan Rajmohan,Ahmed Salem,Shruti Tople,Santiago Zanella-Béguelin,Menglin Xia,Victor Rühle</p>
<p><a href='http://arxiv.org/abs/2311.15792v1'>http://arxiv.org/abs/2311.15792v1</a></p>
<p><b>Compressor summary</b>: The authors propose using metadata in machine learning systems to address security and privacy issues and compare two methods for achieving user-level non-interference, finding that retrieval augmented models provide the best balance of utility, scalability, and flexibility.</p><hr><h3>YUAN 2.0: A Large Language Model with Localized Filtering-based  Attention</h3>
<p>Shaohua Wu,Xudong Zhao,Shenling Wang,Jiangang Luo,Lingjun Li,Xi Chen,Bing Zhao,Wei Wang,Tong Yu,Rongguo Zhang,Jiahua Zhang,Chao Wang</p>
<p><a href='http://arxiv.org/abs/2311.15786v1'>http://arxiv.org/abs/2311.15786v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a new language model called Yuan 2.0 that uses local dependencies in natural language to improve attention, has a large number of parameters, and can perform well in various tasks such as code generation and math problem-solving.</p><hr><h3>Relationship between Model Compression and Adversarial Robustness: A  Review of Current Evidence</h3>
<p>Svetlana Pavlitska,Hannes Grolig,J. Marius Zöllner</p>
<p><a href='http://arxiv.org/abs/2311.15782v1'>http://arxiv.org/abs/2311.15782v1</a></p>
<p><b>Compressor summary</b>: The paper reviews how different techniques to make neural networks smaller can affect their ability to resist attacks, but the results are not consistent.</p><hr><h3>Increasing Coverage and Precision of Textual Information in Multilingual  Knowledge Graphs</h3>
<p>Simone Conia,Min Li,Daniel Lee,Umar Farooq Minhas,Ihab Ilyas,Yunyao Li</p>
<p><a href='http://arxiv.org/abs/2311.15781v1'>http://arxiv.org/abs/2311.15781v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new task called Knowledge Graph Enhancement (KGE) that aims to improve the quality and quantity of textual information for non-English entity names and descriptions in Wikidata using a novel unsupervised approach, M-NTA, which combines Machine Translation, Web Search, and Large Language Models. They also introduce WikiKGE-10, the first benchmark to evaluate KGE methods across 10 languages and 7 language families.</p><hr><h3>Stable Segment Anything Model</h3>
<p>Qi Fan,Xin Tao,Lei Ke,Mingqiao Ye,Yuan Zhang,Pengfei Wan,Zhongyuan Wang,Yu-Wing Tai,Chi-Keung Tang</p>
<p><a href='http://arxiv.org/abs/2311.15776v1'>http://arxiv.org/abs/2311.15776v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes how well SAM can segment objects with low-quality prompts and proposes Stable-SAM, which adjusts feature sampling locations to improve stability without changing the model architecture or adding many parameters.</p><hr><h3>Check, Locate, Rectify: A Training-Free Layout Calibration System for  Text-to-Image Generation</h3>
<p>Biao Gong,Siteng Huang,Yutong Feng,Shiwei Zhang,Yuyuan Li,Yu Liu</p>
<p><a href='http://arxiv.org/abs/2311.15773v1'>http://arxiv.org/abs/2311.15773v1</a></p>
<p><b>Compressor summary</b>: SimM is a system that adjusts image generation to match textual layout instructions without needing additional training, using a pipeline of error detection and rectification with minimal overhead.</p><hr><h3>Attend Who is Weak: Enhancing Graph Condensation via Cross-Free  Adversarial Training</h3>
<p>Xinglin Li,Kun Wang,Hanhui Deng,Yuxuan Liang,Di Wu</p>
<p><a href='http://arxiv.org/abs/2311.15772v1'>http://arxiv.org/abs/2311.15772v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Shock Absorber, a perturbation technique that enhances graph neural networks' robustness and stability by generating synthetic graphs with minimal additional time overhead.</p><hr><h3>Side4Video: Spatial-Temporal Side Network for Memory-Efficient  Image-to-Video Transfer Learning</h3>
<p>Huanjin Yao,Wenhao Wu,Zhiheng Li</p>
<p><a href='http://arxiv.org/abs/2311.15769v1'>http://arxiv.org/abs/2311.15769v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Side4Video, a method for memory-efficient fine-tuning of large vision models to video understanding using a lightweight spatial-temporal side network.</p><hr><h3>Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges</h3>
<p>Nianwen Si,Hao Zhang,Heyu Chang,Wenlin Zhang,Dan Qu,Weiqiang Zhang</p>
<p><a href='http://arxiv.org/abs/2311.15766v1'>http://arxiv.org/abs/2311.15766v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses knowledge unlearning as a solution to mitigate risks associated with large language models' potential to retain harmful knowledge without compromising their capabilities.</p><hr><h3>Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage  and Sharing in LLMs</h3>
<p>Yunxin Li,Baotian Hu,Wei Wang,Xiaochun Cao,Min Zhang</p>
<p><a href='http://arxiv.org/abs/2311.15759v1'>http://arxiv.org/abs/2311.15759v1</a></p>
<p><b>Compressor summary</b>: The paper proposes MKS2, an approach to improve multimodal language models by enhancing their visual memory and collaboration abilities, leading to better reasoning and performance on benchmarks.</p><hr><h3>Learning Multi-Frequency Partial Correlation Graphs</h3>
<p>Gabriele D'Acunto,Paolo Di Lorenzo,Francesco Bonchi,Stefania Sardellitti,Sergio Barbarossa</p>
<p><a href='http://arxiv.org/abs/2311.15756v1'>http://arxiv.org/abs/2311.15756v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two methods to learn partial correlations between time series across different frequency bands, and shows their effectiveness on synthetic and financial data.</p><hr><h3>One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion  Schedule Flaws and Enhancing Low-Frequency Controls</h3>
<p>Minghui Hu,Jianbin Zheng,Chuanxia Zheng,Chaoyue Wang,Dacheng Tao,Tat-Jen Cham</p>
<p><a href='http://arxiv.org/abs/2311.15744v1'>http://arxiv.org/abs/2311.15744v1</a></p>
<p><b>Compressor summary</b>: The text proposes a new method called One More Step (OMS) to improve image quality in diffusion models by integrating a compact network and an additional step during inference while preserving original model parameters.</p><hr><h3>Machine Learning-Based Jamun Leaf Disease Detection: A Comprehensive  Review</h3>
<p>Auvick Chandra Bhowmik,Dr. Md. Taimur Ahad,Yousuf Rayhan Emon</p>
<p><a href='http://arxiv.org/abs/2311.15741v1'>http://arxiv.org/abs/2311.15741v1</a></p>
<p><b>Compressor summary</b>: The paper reviews image processing techniques and Vision Transformer models used for detecting plant leaf diseases, with potential applications for jamun leaf disease detection.</p><hr><h3>Optimization of Image Processing Algorithms for Character Recognition in  Cultural Typewritten Documents</h3>
<p>Mariana Dias,Carla Teixeira Lopes</p>
<p><a href='http://arxiv.org/abs/2311.15740v1'>http://arxiv.org/abs/2311.15740v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates how image processing methods and parameter tuning in Optical Character Recognition (OCR) can improve the recognition of text in images of typewritten cultural heritage documents.</p><hr><h3>GPT4Vis: What Can GPT-4 Do for Zero-shot Visual Recognition?</h3>
<p>Wenhao Wu,Huanjin Yao,Mengxi Zhang,Yuxin Song,Wanli Ouyang,Jingdong Wang</p>
<p><a href='http://arxiv.org/abs/2311.15732v1'>http://arxiv.org/abs/2311.15732v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates GPT-4's linguistic and visual capabilities in zero-shot recognition tasks across images, videos, and point clouds, finding improved performance with rich textual descriptions.</p><hr><h3>Adinkra Symbol Recognition using Classical Machine Learning and Deep  Learning</h3>
<p>Michael Adjeisah,Kwame Omono Asamoah,Martha Asamoah Yeboah,Raji Rafiu King,Godwin Ferguson Achaab,Kingsley Adjei</p>
<p><a href='http://arxiv.org/abs/2311.15728v1'>http://arxiv.org/abs/2311.15728v1</a></p>
<p><b>Compressor summary</b>: The researchers created a dataset and model to recognize and classify Adinkra symbols, an example of using AI for cultural preservation and community empowerment.</p><hr><h3>MARIS: Referring Image Segmentation via Mutual-Aware Attention Features</h3>
<p>Mengxi Zhang,Yiming Liu,Xiangjun Yin,Huanjing Yue,Jingyu Yang</p>
<p><a href='http://arxiv.org/abs/2311.15727v1'>http://arxiv.org/abs/2311.15727v1</a></p>
<p><b>Compressor summary</b>: MARIS is a referring image segmentation method that uses the Segment Anything Model and mutual-aware attention to improve cross-modal fusion for more accurate segmentation.</p><hr><h3>Italian Crossword Generator: Enhancing Education through Interactive  Word Puzzles</h3>
<p>Kamyar Zeinalipour,Tommaso laquinta,Asya Zanollo,Giovanni Angelini,Leonardo Rigutini,Marco Maggini,Marco Gori</p>
<p><a href='http://arxiv.org/abs/2311.15723v1'>http://arxiv.org/abs/2311.15723v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes how advanced language models can be used to generate and verify educational crossword clues, enhancing student engagement and learning outcomes.</p><hr><h3>GLIME: General, Stable and Local LIME Explanation</h3>
<p>Zeren Tan,Yang Tian,Jian Li</p>
<p><a href='http://arxiv.org/abs/2311.15722v1'>http://arxiv.org/abs/2311.15722v1</a></p>
<p><b>Compressor summary</b>: GLIME is an improved method for explaining machine learning models that addresses instability and low local fidelity issues in LIME by using faster convergence, a local and unbiased sampling distribution, and flexible sampling choices.</p><hr><h3>Variational Autoencoders for Feature Exploration and Malignancy  Prediction of Lung Lesions</h3>
<p>Benjamin Keel,Aaron Quyn,David Jayne,Samuel D. Relton</p>
<p><a href='http://arxiv.org/abs/2311.15719v1'>http://arxiv.org/abs/2311.15719v1</a></p>
<p><b>Compressor summary</b>: The study uses generative AI models to analyze lung cancer lesions from CT scans and develop an interpretable classifier with high accuracy and a clear latent space.</p><hr><h3>Justifiable Artificial Intelligence: Engineering Large Language Models  for Legal Applications</h3>
<p>Sabine Wehnert</p>
<p><a href='http://arxiv.org/abs/2311.15716v1'>http://arxiv.org/abs/2311.15716v1</a></p>
<p><b>Compressor summary</b>: The author proposes using Justifiable AI to increase trust in Large Language Models' legal outputs by gathering evidence for and against their predictions.</p><hr><h3>SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation</h3>
<p>Jiehong Lin,Lihua Liu,Dekun Lu,Kui Jia</p>
<p><a href='http://arxiv.org/abs/2311.15707v1'>http://arxiv.org/abs/2311.15707v1</a></p>
<p><b>Compressor summary</b>: SAM-6D is a framework that uses two sub-networks to detect new objects in cluttered scenes and estimate their 6D poses using instance segmentation and pose estimation, outperforming existing methods on BOP Benchmark datasets.</p><hr><h3>Cerbero-7B: A Leap Forward in Language-Specific LLMs Through Enhanced  Chat Corpus Generation and Evaluation</h3>
<p>Federico A. Galatolo,Mario G. C. A. Cimino</p>
<p><a href='http://arxiv.org/abs/2311.15698v1'>http://arxiv.org/abs/2311.15698v1</a></p>
<p><b>Compressor summary</b>: The study presents a novel method to generate high-quality chat corpora using a generator and embedder LLM, evaluate them with a new MLM metric, and improve the performance of an Italian LLM.</p><hr><h3>Automated discovery of trade-off between utility, privacy and fairness  in machine learning models</h3>
<p>Bogdan Ficiu,Neil D. Lawrence,Andrei Paleyes</p>
<p><a href='http://arxiv.org/abs/2311.15691v1'>http://arxiv.org/abs/2311.15691v1</a></p>
<p><b>Compressor summary</b>: The authors propose a pipeline called PFairDP, which uses Bayesian optimization to find Pareto-optimal points between fairness, privacy, and utility of machine learning models in a multi-objective optimization problem.</p><hr><h3>Information theoretic study of the neural geometry induced by category  learning</h3>
<p>Laurent Bonnasse-Gahot,Jean-Pierre Nadal</p>
<p><a href='http://arxiv.org/abs/2311.15682v1'>http://arxiv.org/abs/2311.15682v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses an information theoretic approach to evaluate the efficiency of category learning in biological and artificial neural networks, focusing on the coding and decoding costs and the expansion of neural space near decision boundaries.</p><hr><h3>Model-agnostic Body Part Relevance Assessment for Pedestrian Detection</h3>
<p>Maurice Günder,Sneha Banerjee,Rafet Sifa,Christian Bauckhage</p>
<p><a href='http://arxiv.org/abs/2311.15679v1'>http://arxiv.org/abs/2311.15679v1</a></p>
<p><b>Compressor summary</b>: The authors propose a framework to use sampling-based explanation methods in pedestrian detection and introduce a new method similar to KernelSHAP that is more efficient for large-scale datasets.</p><hr><h3>Accelerating Hierarchical Associative Memory: A Deep Equilibrium  Approach</h3>
<p>Cédric Goemaere,Johannes Deleu,Thomas Demeester</p>
<p><a href='http://arxiv.org/abs/2311.15673v1'>http://arxiv.org/abs/2311.15673v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two strategies to speed up memory retrieval in Hierarchical Associative Memory models, which are a type of neural network, by using faster solvers and alternating optimization of layers.</p><hr><h3>HAVE-FUN: Human Avatar Reconstruction from Few-Shot Unconstrained Images</h3>
<p>Xihe Yang,Xingyu Chen,Shaohui Wang,Daiheng Gao,Xiaoguang Han,Baoyuan Wang</p>
<p><a href='http://arxiv.org/abs/2311.15672v1'>http://arxiv.org/abs/2311.15672v1</a></p>
<p><b>Compressor summary</b>: The paper proposes HaveFun, a framework for reconstructing human avatars from few-shot unconstrained photos using a tetrahedral representation and a two-phase optimization method.</p><hr><h3>Deformation-Guided Unsupervised Non-Rigid Shape Matching</h3>
<p>Aymen Merrouche,Joao Regateiro,Stefanie Wuhrer,Edmond Boyer</p>
<p><a href='http://arxiv.org/abs/2311.15668v1'>http://arxiv.org/abs/2311.15668v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a robust unsupervised method for matching shapes with fine details and different types of noise using a hierarchical patch representation and a near-rigid deformation model.</p><hr><h3>Technical Report for Argoverse Challenges on 4D Occupancy Forecasting</h3>
<p>Pengfei Zheng,Kanokphan Lertniphonphan,Feng Chen,Siwei Chen,Bingchuan Sun,Jun Xie,Zhepeng Wang</p>
<p><a href='http://arxiv.org/abs/2311.15660v1'>http://arxiv.org/abs/2311.15660v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a LiDAR-based 4D occupancy forecasting method that outperforms the baseline and ranks first in Argoverse Challenges at CVPR 2023.</p><hr><h3>Regularization by Texts for Latent Diffusion Inverse Solvers</h3>
<p>Jeongsol Kim,Geon Yeong Park,Hyungjin Chung,Jong Chul Ye</p>
<p><a href='http://arxiv.org/abs/2311.15658v1'>http://arxiv.org/abs/2311.15658v1</a></p>
<p><b>Compressor summary</b>: The authors propose a new method called TReg that uses textual descriptions to help solve ill-posed inverse problems in latent diffusion models, improving their performance and accuracy.</p><hr><h3>Enhancing Diffusion Models with Text-Encoder Reinforcement Learning</h3>
<p>Chaofeng Chen,Annan Wang,Haoning Wu,Liang Liao,Wenxiu Sun,Qiong Yan,Weisi Lin</p>
<p><a href='http://arxiv.org/abs/2311.15657v1'>http://arxiv.org/abs/2311.15657v1</a></p>
<p><b>Compressor summary</b>: Text-to-image diffusion models can be improved by fine-tuning the text encoder using reinforcement learning, leading to better text-image alignment and visual quality.</p><hr><h3>MoDS: Model-oriented Data Selection for Instruction Tuning</h3>
<p>Qianlong Du,Chengqing Zong,Jiajun Zhang</p>
<p><a href='http://arxiv.org/abs/2311.15653v1'>http://arxiv.org/abs/2311.15653v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a MoDS approach to select high-quality and necessary instruction data for fine-tuning LLMs, outperforming the full original dataset.</p><hr><h3>Reinforcement Learning from Diffusion Feedback: Q* for Image Search</h3>
<p>Aboli Marathe</p>
<p><a href='http://arxiv.org/abs/2311.15648v1'>http://arxiv.org/abs/2311.15648v1</a></p>
<p><b>Compressor summary</b>: The paper introduces two models for image generation using model-agnostic learning, RLDF and noisy diffusion gradient, which use a special CFG encoding to guide semantic priors and produce high-quality images from single input images.</p><hr><h3>Bandits Meet Mechanism Design to Combat Clickbait in Online  Recommendation</h3>
<p>Thomas Kleine Buening,Aadirupa Saha,Christos Dimitrakakis,Haifeng Xu</p>
<p><a href='http://arxiv.org/abs/2311.15647v1'>http://arxiv.org/abs/2311.15647v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a learning algorithm for online recommendation systems that considers both click-through rates and post-click rewards, and designs an incentive mechanism to encourage desirable arm behavior while minimizing regret.</p><hr><h3>PaintNeSF: Artistic Creation of Stylized Scenes with Vectorized 3D  Strokes</h3>
<p>Hao-Bin Duan,Miao Wang,Yan-Xun Li,Yong-Liang Yang</p>
<p><a href='http://arxiv.org/abs/2311.15637v1'>http://arxiv.org/abs/2311.15637v1</a></p>
<p><b>Compressor summary</b>: PaintNeSF is a new technique that uses vector strokes to create stylized 3D images from multi-view 2D images, optimizing stroke parameters with gradient descent and maintaining consistent appearance across views.</p><hr><h3>The WebCrow French Crossword Solver</h3>
<p>Giovanni Angelini,Marco Ernandes,Tommaso laquinta,Caroline Stehlé,Fanny Simões,Kamyar Zeinalipour,Andrea Zugarini,Marco Gori</p>
<p><a href='http://arxiv.org/abs/2311.15626v1'>http://arxiv.org/abs/2311.15626v1</a></p>
<p><b>Compressor summary</b>: The authors present a crossword solver for French that uses multiple modules to find candidate answers from various sources and performs well compared to humans in challenges.</p><hr><h3>Only Positive Cases: 5-fold High-order Attention Interaction Model for  Skin Segmentation Derived Classification</h3>
<p>Renkai Wu,Yinghao Liu,Pengchen Liang,Qing Chang</p>
<p><a href='http://arxiv.org/abs/2311.15625v1'>http://arxiv.org/abs/2311.15625v1</a></p>
<p><b>Compressor summary</b>: The paper proposes MHA-UNet, a model that uses high-order attention interaction to segment skin lesions and detect their presence or absence in an explainable way without needing negative samples.</p><hr><h3>Injecting linguistic knowledge into BERT for Dialogue State Tracking</h3>
<p>Xiaohan Feng,Xixin Wu,Helen Meng</p>
<p><a href='http://arxiv.org/abs/2311.15623v1'>http://arxiv.org/abs/2311.15623v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an unsupervised method to improve BERT's performance and interpretability in dialogue state tracking tasks using linguistic knowledge extracted from conversations.</p><hr><h3>Align before Adapt: Leveraging Entity-to-Region Alignments for  Generalizable Video Action Recognition</h3>
<p>Yifei Chen,Dapeng Chen,Ruijin Liu,Sai Zhou,Wenyuan Xue,Wei Peng</p>
<p><a href='http://arxiv.org/abs/2311.15619v1'>http://arxiv.org/abs/2311.15619v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new "Align before Adapt" paradigm for video action recognition that leverages region-aware image embeddings matched to a text corpus and exploits the visual-language alignment of VLP during adaptation to better understand actions by bridging the gap with complex activity semantics.</p><hr><h3>Technical Report for Argoverse Challenges on Unified Sensor-based  Detection, Tracking, and Forecasting</h3>
<p>Zhepeng Wang,Feng Chen,Kanokphan Lertniphonphan,Siwei Chen,Jinyao Bao,Pengfei Zheng,Jinbao Zhang,Kaer Huang,Tao Zhang</p>
<p><a href='http://arxiv.org/abs/2311.15615v1'>http://arxiv.org/abs/2311.15615v1</a></p>
<p><b>Compressor summary</b>: The report introduces Le3DE2E, a unified network for sensor-based detection, tracking, and forecasting in autonomous driving, which achieved 1st place in Argoverse Challenges at CVPR 2023 WAD.</p><hr><h3>FreeAL: Towards Human-Free Active Learning in the Era of Large Language  Models</h3>
<p>Ruixuan Xiao,Yiwen Dong,Junbo Zhao,Runze Wu,Minmin Lin,Gang Chen,Haobo Wang</p>
<p><a href='http://arxiv.org/abs/2311.15614v1'>http://arxiv.org/abs/2311.15614v1</a></p>
<p><b>Compressor summary</b>: The authors propose a collaborative learning framework called FreeAL that uses a large language model as an active annotator and a small language model as a student to distill and filter task-specific knowledge, reducing the annotation cost and improving zero-shot performances.</p><hr><h3>A manometric feature descriptor with linear-SVM to distinguish  esophageal contraction vigor</h3>
<p>Jialin Liu,Lu Yan,Xiaowei Liu,Yuzhuo Dai,Fanggen Lu,Yuanting Ma,Muzhou Hou,Zheng Wang</p>
<p><a href='http://arxiv.org/abs/2311.15609v1'>http://arxiv.org/abs/2311.15609v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a study that used image processing of high-resolution manometry data to predict esophageal contraction vigor and make the evaluation of esophageal dynamic function easier and more accurate.</p><hr><h3>2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic  Segmentation</h3>
<p>Ozan Unal,Dengxin Dai,Lukas Hoyer,Yigit Baran Can,Luc Van Gool</p>
<p><a href='http://arxiv.org/abs/2311.15605v1'>http://arxiv.org/abs/2311.15605v1</a></p>
<p><b>Compressor summary</b>: IGNet is a method for weakly-supervised LiDAR semantic segmentation that uses RGB images to compensate for boundary estimation and false negative issues, achieving state-of-the-art results with minimal annotations.</p><hr><h3>UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio,  Video, Point Cloud, Time-Series and Image Recognition</h3>
<p>Xiaohan Ding,Yiyuan Zhang,Yixiao Ge,Sijie Zhao,Lin Song,Xiangyu Yue,Ying Shan</p>
<p><a href='http://arxiv.org/abs/2311.15599v1'>http://arxiv.org/abs/2311.15599v1</a></p>
<p><b>Compressor summary</b>: The paper proposes architectural guidelines for large-kernel ConvNets, which outperform conventional ConvNets in image recognition and show universal perception ability across modalities.</p><hr><h3>Can Vision-Language Models Think from a First-Person Perspective?</h3>
<p>Sijie Cheng,Zhicheng Guo,Jingwen Wu,Kechen Fang,Peng Li,Huaping Liu,Yang Liu</p>
<p><a href='http://arxiv.org/abs/2311.15596v1'>http://arxiv.org/abs/2311.15596v1</a></p>
<p><b>Compressor summary</b>: EgoThink is a new visual question-answering test for vision-language models that assesses their first-person perspective abilities using egocentric video clips, which can help improve autonomous agents and robotics.</p><hr><h3>A Simple Geometric-Aware Indoor Positioning Interpolation Algorithm  Based on Manifold Learning</h3>
<p>Suorong Yang,Geng Zhang,Jian Zhao,Furao Shen</p>
<p><a href='http://arxiv.org/abs/2311.15583v1'>http://arxiv.org/abs/2311.15583v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a simple geometric-aware interpolation algorithm for indoor positioning that exploits local topological manifold using manifold learning principles, improving accuracy and efficiency over existing methods.</p><hr><h3>Real Time GAZED: Online Shot Selection and Editing of Virtual Cameras  from Wide-Angle Monocular Video Recordings</h3>
<p>Sudheer Achary,Rohit Girmaji,Adhiraj Anil Deshmukh,Vineet Gandhi</p>
<p><a href='http://arxiv.org/abs/2311.15581v1'>http://arxiv.org/abs/2311.15581v1</a></p>
<p><b>Compressor summary</b>: Real Time GAZED is a novel system that allows users to create high-quality, professionally edited videos in real-time by combining the GAZED framework with CineFilter, a new camera trajectory stabilization technique.</p><hr><h3>Experimental Analysis of Large-scale Learnable Vector Storage  Compression</h3>
<p>Hailin Zhang,Penghao Zhao,Xupeng Miao,Yingxia Shao,Zirui Liu,Tong Yang,Bin Cui</p>
<p><a href='http://arxiv.org/abs/2311.15578v1'>http://arxiv.org/abs/2311.15578v1</a></p>
<p><b>Compressor summary</b>: The paper compares 14 embedding compression methods in machine learning tasks, evaluates their performance under different memory budgets, and recommends the best approach for each use case.</p><hr><h3>EucliDreamer: Fast and High-Quality Texturing for 3D Models with Stable  Diffusion Depth</h3>
<p>Cindy Le,Congrui Hetang,Ang Cao,Yihui He</p>
<p><a href='http://arxiv.org/abs/2311.15573v1'>http://arxiv.org/abs/2311.15573v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new way to create realistic textures for 3D models using text descriptions and depth information, and shows that it outperforms existing methods in quality, diversity, and speed.</p><hr><h3>Improving Adaptability and Generalizability of Efficient Transfer  Learning for Vision-Language Models</h3>
<p>Yongjin Yang,Jongwoo Ko,Se-Young Yun</p>
<p><a href='http://arxiv.org/abs/2311.15569v1'>http://arxiv.org/abs/2311.15569v1</a></p>
<p><b>Compressor summary</b>: This paper explores how vision-language models (VLMs) use prompts and adapters for image classification tasks, and proposes an adaptive ensemble method to improve generalization across domains.</p><hr><h3>Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing  AI-Generated Text</h3>
<p>Finbarrs Oketunji</p>
<p><a href='http://arxiv.org/abs/2311.15565v1'>http://arxiv.org/abs/2311.15565v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a research project that employs advanced deep learning models to distinguish AI-generated texts from human-written ones using a diverse dataset and natural language processing techniques.</p><hr><h3>Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval</h3>
<p>Fan Jiang,Qiongkai Xu,Tom Drummond,Trevor Cohn</p>
<p><a href='http://arxiv.org/abs/2311.15564v1'>http://arxiv.org/abs/2311.15564v1</a></p>
<p><b>Compressor summary</b>: ABEL is a simple unsupervised method to enhance passage retrieval by iteratively improving a dense retriever and a reranker, achieving strong results on BEIR benchmark and adapting well to new tasks and domains.</p><hr><h3>Noisy Self-Training with Synthetic Queries for Dense Retrieval</h3>
<p>Fan Jiang,Tom Drummond,Trevor Cohn</p>
<p><a href='http://arxiv.org/abs/2311.15563v1'>http://arxiv.org/abs/2311.15563v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new self-training framework that improves neural retrievers without external data and shows better performance on different benchmarks, even with limited training data.</p><hr><h3>Fully Authentic Visual Question Answering Dataset from Online  Communities</h3>
<p>Chongyan Chen,Mengchen Liu,Noel Codella,Yunsheng Li,Lu Yuan,Danna Gurari</p>
<p><a href='http://arxiv.org/abs/2311.15562v1'>http://arxiv.org/abs/2311.15562v1</a></p>
<p><b>Compressor summary</b>: The paper introduces VQAonline, a new VQA dataset with longer answers from online forums, and evaluates six models on it.</p><hr><h3>ET3D: Efficient Text-to-3D Generation via Multi-View Distillation</h3>
<p>Yiming Chen,Zhiqi Li,Peidong Liu</p>
<p><a href='http://arxiv.org/abs/2311.15561v1'>http://arxiv.org/abs/2311.15561v1</a></p>
<p><b>Compressor summary</b>: The authors propose a fast text-to-3D generation method that uses images from a pre-trained text-to-image diffusion model to train a 3D generative network, which takes only about 8 milliseconds per 3D asset.</p><hr><h3>PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI  Generated Images</h3>
<p>Jiquan Yuan,Xinyan Cao,Changjin Li,Fanyi Yang,Jinlong Lin,Xixin Cao</p>
<p><a href='http://arxiv.org/abs/2311.15556v1'>http://arxiv.org/abs/2311.15556v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new database (PKU-I2IQA) and two benchmark models for evaluating the quality of AI-generated images in various scenarios.</p><hr><h3>Instruct2Attack: Language-Guided Semantic Adversarial Attacks</h3>
<p>Jiang Liu,Chen Wei,Yuxiang Guo,Heng Yu,Alan Yuille,Soheil Feizi,Chun Pong Lau,Rama Chellappa</p>
<p><a href='http://arxiv.org/abs/2311.15551v1'>http://arxiv.org/abs/2311.15551v1</a></p>
<p><b>Compressor summary</b>: Instruct2Attack (I2A) is a language-guided semantic attack that uses latent diffusion models to generate natural and diverse adversarial examples based on image and text instructions, breaking state-of-the-art neural networks even under strong defenses.</p><hr><h3>Deficiency of Large Language Models in Finance: An Empirical Examination  of Hallucination</h3>
<p>Haoqiang Kang,Xiao-Yang Liu</p>
<p><a href='http://arxiv.org/abs/2311.15548v1'>http://arxiv.org/abs/2311.15548v1</a></p>
<p><b>Compressor summary</b>: The paper investigates and proposes solutions for the problem of large language models hallucinating or making up information when performing financial tasks.</p><hr><h3>Dataset Distillation in Latent Space</h3>
<p>Yuxuan Duan,Jianfu Zhang,Liqing Zhang</p>
<p><a href='http://arxiv.org/abs/2311.15547v1'>http://arxiv.org/abs/2311.15547v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method for dataset distillation using latent space to address problems with time and space complexity and info-compactness, enabling better compression and performance.</p><hr><h3>Out-of-Distribution Generalized Dynamic Graph Neural Network for Human  Albumin Prediction</h3>
<p>Zeyang Zhang,Xingwang Li,Fei Teng,Ning Lin,Xueling Zhu,Xin Wang,Wenwu Zhu</p>
<p><a href='http://arxiv.org/abs/2311.15545v1'>http://arxiv.org/abs/2311.15545v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Human albumin is important for health, but hard to predict and dose accurately, especially for critically ill patients.
- The paper proposes a framework called DyG-HAP that uses dynamic graph regression and attention to capture invariant and variant patterns in the data.
- The paper also introduces a new dataset (ANIC) for evaluating albumin prediction methods.

Summary:
The paper presents DyG-HAP, a framework that uses graphs and attention to predict human albumin levels accurately for ICU patients, and a new dataset (ANIC) to test it on.</p><hr><h3>The effect of source disclosure on evaluation of AI-generated messages:  A two-part study</h3>
<p>Sue Lim,Ralf Schmälzle</p>
<p><a href='http://arxiv.org/abs/2311.15544v1'>http://arxiv.org/abs/2311.15544v1</a></p>
<p><b>Compressor summary</b>: This paper explores how people's evaluation of AI-generated health prevention messages changes depending on whether they know the source is AI or human, and how their negative attitudes towards AI affect this preference.</p><hr><h3>Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images  with Vision Language Models</h3>
<p>Tong Zhang,Haoyang Liu,Peiyan Zhang,Yuxuan Cheng,Haohan Wang</p>
<p><a href='http://arxiv.org/abs/2311.15543v1'>http://arxiv.org/abs/2311.15543v1</a></p>
<p><b>Compressor summary</b>: The text introduces Simple-SVG-Generation (Sextsuperscript{2}VGextsuperscript{2}), a method that generates accurate and simple SVGs for images, improving readability and interpretability compared to previous methods.</p><hr><h3>EAFP-Med: An Efficient Adaptive Feature Processing Module Based on  Prompts for Medical Image Detection</h3>
<p>Xiang Li,Long Lan,Husam Lahza,Shaowu Yang,Shuihua Wang,Wenjing Yang,Hengzhu Liu,Yudong Zhang</p>
<p><a href='http://arxiv.org/abs/2311.15540v1'>http://arxiv.org/abs/2311.15540v1</a></p>
<p><b>Compressor summary</b>: EAFP-Med is a module that uses language models to adaptively process lesion features in different medical imaging technologies, improving disease detection performance.</p><hr><h3>SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation</h3>
<p>Bin Xie,Jiale Cao,Jin Xie,Fahad Shahbaz Khan,Yanwei Pang</p>
<p><a href='http://arxiv.org/abs/2311.15537v1'>http://arxiv.org/abs/2311.15537v1</a></p>
<p><b>Compressor summary</b>: The paper proposes SED, an encoder-decoder model for open-vocabulary semantic segmentation that uses a hierarchical backbone and category early rejection to improve efficiency and accuracy.</p><hr><h3>SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation</h3>
<p>Jia Li,Yanyan Shen,Lei Chen,Charles Wang Wai NG</p>
<p><a href='http://arxiv.org/abs/2311.15530v1'>http://arxiv.org/abs/2311.15530v1</a></p>
<p><b>Compressor summary</b>: Key points:
- SSIN is a novel data-driven self-supervised learning framework for rainfall spatial interpolation
- SpaFormer model uses Transformer architecture and random masking to learn embeddings and model spatial correlations
- SSIN outperforms state-of-the-art solutions on two real-world datasets and shows effectiveness on traffic spatial interpolation

Summary:
SSIN is a new method that uses SpaFormer, a Transformer-based model with self-supervision, to interpolate rainfall distribution from historical data and achieve better results than existing methods.</p><hr><h3>Efficient Dataset Distillation via Minimax Diffusion</h3>
<p>Jianyang Gu,Saeed Vahidian,Vyacheslav Kungurtsev,Haonan Wang,Wei Jiang,Yang You,Yiran Chen</p>
<p><a href='http://arxiv.org/abs/2311.15529v1'>http://arxiv.org/abs/2311.15529v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to reduce the storage and computational cost of training networks using generative diffusion techniques that enhance representativeness and diversity, achieving better performance with less distillation time compared to previous methods.</p><hr><h3>Overview of the VLSP 2022 -- Abmusu Shared Task: A Data Challenge for  Vietnamese Abstractive Multi-document Summarization</h3>
<p>Mai-Vu Tran,Hoang-Quynh Le,Duy-Cat Can,Quoc-An Nguyen</p>
<p><a href='http://arxiv.org/abs/2311.15525v1'>http://arxiv.org/abs/2311.15525v1</a></p>
<p><b>Compressor summary</b>: The paper describes the VLSP 2022 shared task on Vietnamese abstractive multi-document summarization (Abmusu) and presents a human-annotated dataset of Vietnamese news documents in 8 categories.</p><hr><h3>A Comparative and Experimental Study on Automatic Question Answering  Systems and its Robustness against Word Jumbling</h3>
<p>Shashidhar Reddy Javaji,Haoran Hu,Sai Sameer Vennam,Vijaya Gajanan Buddhavarapu</p>
<p><a href='http://arxiv.org/abs/2311.15513v1'>http://arxiv.org/abs/2311.15513v1</a></p>
<p><b>Compressor summary</b>: Question answer generation using NLP models is widely used in various applications, improving customer satisfaction and ease of usage, but can be affected by human errors.</p><hr><h3>Sparse Pedestrian Character Learning for Trajectory Prediction</h3>
<p>Yonghao Dong,Le Wang,Sanpin Zhou,Gang Hua,Changyin Sun</p>
<p><a href='http://arxiv.org/abs/2311.15512v1'>http://arxiv.org/abs/2311.15512v1</a></p>
<p><b>Compressor summary</b>: TSNet is a novel network for pedestrian trajectory prediction in autonomous driving that uses a sparse character graph to learn and remove harmful negative character information, achieving state-of-the-art performance.</p><hr><h3>CaesarNeRF: Calibrated Semantic Representation for Few-shot  Generalizable Neural Rendering</h3>
<p>Haidong Zhu,Tianyu Ding,Tianyi Chen,Ilya Zharkov,Ram Nevatia,Luming Liang</p>
<p><a href='http://arxiv.org/abs/2311.15510v1'>http://arxiv.org/abs/2311.15510v1</a></p>
<p><b>Compressor summary</b>: CaesarNeRF is an end-to-end approach that combines scene-level and pixel-level representations to improve few-shot, generalizable neural rendering with a holistic understanding of scenes.</p><hr><h3>A Corpus for Named Entity Recognition in Chinese Novels with  Multi-genres</h3>
<p>Hanjie Zhao,Jinge Xie,Yuchen Yan,Yuxiang Jia,Yawen Ye,Hongying Zan</p>
<p><a href='http://arxiv.org/abs/2311.15509v1'>http://arxiv.org/abs/2311.15509v1</a></p>
<p><b>Compressor summary</b>: The authors build a large corpus of annotated named entities from different genres of Chinese novels and study the characteristics, genre differences, and challenges of named entity recognition in literature.</p><hr><h3>Improving Word Sense Disambiguation in Neural Machine Translation with  Salient Document Context</h3>
<p>Elijah Rippeth,Marine Carpuat,Kevin Duh,Matt Post</p>
<p><a href='http://arxiv.org/abs/2311.15507v1'>http://arxiv.org/abs/2311.15507v1</a></p>
<p><b>Compressor summary</b>: The authors propose a simple and scalable way to resolve translation ambiguity in neural machine translation using extra-sentential context without sense annotation or model changes, and evaluate their method on a new challenge set.</p><hr><h3>Learning with Complementary Labels Revisited: A Consistent Approach via  Negative-Unlabeled Learning</h3>
<p>Wei Wang,Takashi Ishida,Yu-Jie Zhang,Gang Niu,Masashi Sugiyama</p>
<p><a href='http://arxiv.org/abs/2311.15502v1'>http://arxiv.org/abs/2311.15502v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel complementary-label learning method that doesn't need uniform distribution assumption or ordinary-label training set, uses negative-unlabeled binary classification, and has theoretical guarantees and experimental validation.</p><hr><h3>Function-constrained Program Synthesis</h3>
<p>Patrick Hajali,Ignas Budvytis</p>
<p><a href='http://arxiv.org/abs/2311.15500v1'>http://arxiv.org/abs/2311.15500v1</a></p>
<p><b>Compressor summary</b>: The authors present a technique for using user-provided code and generating modular sub-functions to aid LLMs in solving programming tasks, as well as introducing a new evaluation method for assessing their performance.</p><hr><h3>Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning  and Optimization Functions for Enhanced Precision</h3>
<p>Gabriel De Araujo,Shanlin Sun,Xiaohui Xie</p>
<p><a href='http://arxiv.org/abs/2311.15497v1'>http://arxiv.org/abs/2311.15497v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new image registration method that combines learning and optimization to improve accuracy, efficiency, and smoothness.</p><hr><h3>Optimizing and Fine-tuning Large Language Model for Urban Renewal</h3>
<p>Xi Wang,Xianyao Ling,Tom Zhang,Xuecao Li,Shaolan Wang,Zhixing Li,Liang Zhang,Peng Gong</p>
<p><a href='http://arxiv.org/abs/2311.15490v1'>http://arxiv.org/abs/2311.15490v1</a></p>
<p><b>Compressor summary</b>: The study uses ChatGLM to generate QA datasets for urban renewal, then fine-tunes it with Prefix and LoRA methods to improve performance in knowledge QA tasks.</p><hr><h3>Global $\mathcal{L}^2$ minimization with certainty via geometrically  adapted gradient descent in Deep Learning</h3>
<p>Thomas Chen</p>
<p><a href='http://arxiv.org/abs/2311.15487v1'>http://arxiv.org/abs/2311.15487v1</a></p>
<p><b>Compressor summary</b>: The paper introduces two modified versions of gradient descent flow for different levels of over- and under-parametrization in Deep Learning, with invariant geometric meanings and proven convergence properties.</p><hr><h3>Automatic Time Signature Determination for New Scores Using Lyrics for  Latent Rhythmic Structure</h3>
<p>Callie C. Liao,Duoduo Liao,Jesse Guessford</p>
<p><a href='http://arxiv.org/abs/2311.15480v1'>http://arxiv.org/abs/2311.15480v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method using lyrics as input to generate time signatures for lyrical songs, discovering patterns and utilizing explainable machine learning models with high accuracy.</p><hr><h3>AerialBooth: Mutual Information Guidance for Text Controlled Aerial View  Synthesis from a Single Image</h3>
<p>Divya Kothandaraman,Tianyi Zhou,Ming Lin,Dinesh Manocha</p>
<p><a href='http://arxiv.org/abs/2311.15478v1'>http://arxiv.org/abs/2311.15478v1</a></p>
<p><b>Compressor summary</b>: AerialBooth is a new method that can generate aerial views from a single image based on its text description, using a pretrained model and mutual information guidance.</p><hr><h3>DreamCreature: Crafting Photorealistic Virtual Creatures from  Imagination</h3>
<p>Kam Woh Ng,Xiatian Zhu,Yi-Zhe Song,Tao Xiang</p>
<p><a href='http://arxiv.org/abs/2311.15477v1'>http://arxiv.org/abs/2311.15477v1</a></p>
<p><b>Compressor summary</b>: DreamCreature is a novel method that generates new hybrid creatures by extracting sub-concepts from unlabeled images and composing them in a text-to-image model.</p><hr><h3>MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers</h3>
<p>Yawar Siddiqui,Antonio Alliegro,Alexey Artemov,Tatiana Tommasi,Daniele Sirigatti,Vladislav Rosov,Angela Dai,Matthias Nießner</p>
<p><a href='http://arxiv.org/abs/2311.15475v1'>http://arxiv.org/abs/2311.15475v1</a></p>
<p><b>Compressor summary</b>: MeshGPT is a new method for generating compact triangle meshes using a sequence-based approach inspired by large language models, which improves upon existing methods with better shape coverage and lower FID scores.</p>
