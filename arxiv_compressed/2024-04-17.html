
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2024-04-17</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-04-17 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Nearly Optimal Algorithms for Contextual Dueling Bandits from  Adversarial Feedback</h3>
<p><a href='http://arxiv.org/abs/2404.10776v1'>http://arxiv.org/abs/2404.10776v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a robust algorithm for learning from human feedback in generative models, even when the feedback is adversarial and manipulative.</p><hr><h3>COMBO: Compositional World Models for Embodied Multi-Agent Cooperation</h3>
<p><a href='http://arxiv.org/abs/2404.10775v1'>http://arxiv.org/abs/2404.10775v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for multi-agent cooperation using a compositional world model that generates videos from partial observations and enables online planning.</p><hr><h3>MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents</h3>
<p><a href='http://arxiv.org/abs/2404.10774v1'>http://arxiv.org/abs/2404.10774v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method to train smaller models with low cost that can fact-check LLM outputs by using synthetic data generated with GPT-4.</p><hr><h3>Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction in  Unbounded Scenes</h3>
<p><a href='http://arxiv.org/abs/2404.10772v1'>http://arxiv.org/abs/2404.10772v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Gaussian Opacity Fields (GOF), a new method for efficient and high-quality surface reconstruction from 3D Gaussians, using ray-tracing-based volume rendering and marching tetrahedra.</p><hr><h3>TENG: Time-Evolving Natural Gradient for Solving PDEs with Deep Neural  Net</h3>
<p><a href='http://arxiv.org/abs/2404.10771v1'>http://arxiv.org/abs/2404.10771v1</a></p>
<p><b>Compressor summary</b>: The paper presents Time-Evolving Natural Gradient (TENG), a method that uses neural networks to solve partial differential equations (PDEs) with high accuracy by optimizing variational principles and time integration.</p><hr><h3>RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting</h3>
<p><a href='http://arxiv.org/abs/2404.10765v1'>http://arxiv.org/abs/2404.10765v1</a></p>
<p><b>Compressor summary</b>: The paper proposes RefFusion, a 3D inpainting method that uses a reference image to enable high-quality synthesis and control over the reconstructed scene, achieving state-of-the-art results for various tasks.</p><hr><h3>LaDiC: Are Diffusion Models Really Inferior to Autoregressive  Counterparts for Image-to-Text Generation?</h3>
<p><a href='http://arxiv.org/abs/2404.10763v1'>http://arxiv.org/abs/2404.10763v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new diffusion model, LaDiC, for image captioning that leverages a latent space for captions and improves performance without pre-training or extra modules.</p><hr><h3>TorchSurv: A Lightweight Package for Deep Survival Analysis</h3>
<p><a href='http://arxiv.org/abs/2404.10761v1'>http://arxiv.org/abs/2404.10761v1</a></p>
<p><b>Compressor summary</b>: TorchSurv is a lightweight Python package that helps create custom deep survival models with PyTorch, especially for complex high-dimensional data.</p><hr><h3>Learning Feature Inversion for Multi-class Anomaly Detection under  General-purpose COCO-AD Benchmark</h3>
<p><a href='http://arxiv.org/abs/2404.10760v1'>http://arxiv.org/abs/2404.10760v1</a></p>
<p><b>Compressor summary</b>: This work introduces a large-scale COCO-AD dataset for anomaly detection, new evaluation metrics, and an effective InvAD framework for reconstruction-based methods.</p><hr><h3>Laplace-HDC: Understanding the geometry of binary hyperdimensional  computing</h3>
<p><a href='http://arxiv.org/abs/2404.10759v1'>http://arxiv.org/abs/2404.10759v1</a></p>
<p><b>Compressor summary</b>: The paper explores binary hyperdimensional computing, introduces a new encoding method called Laplace-HDC that improves accuracy, and discusses its limitations and potential solutions for image processing.</p><hr><h3>Watch Your Step: Optimal Retrieval for Continual Learning at Scale</h3>
<p><a href='http://arxiv.org/abs/2404.10758v1'>http://arxiv.org/abs/2404.10758v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a framework for evaluating and improving selective retrieval strategies in continual learning using replay buffers.</p><hr><h3>Settling Constant Regrets in Linear Markov Decision Processes</h3>
<p><a href='http://arxiv.org/abs/2404.10745v1'>http://arxiv.org/abs/2404.10745v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new RL algorithm, Cert-LSVI-UCB, that achieves constant regret guarantees for linear MDPs with misspecified transition kernels and rewards, and provides novel analysis techniques.</p><hr><h3>N-Agent Ad Hoc Teamwork</h3>
<p><a href='http://arxiv.org/abs/2404.10740v1'>http://arxiv.org/abs/2404.10740v1</a></p>
<p><b>Compressor summary</b>: The paper introduces N-agent ad hoc teamwork, a new multi-agent reinforcement learning problem, and proposes POAM, an algorithm that learns representations of teammate behaviors for cooperative task adaptation.</p><hr><h3>Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent  Collaboration</h3>
<p><a href='http://arxiv.org/abs/2404.10733v1'>http://arxiv.org/abs/2404.10733v1</a></p>
<p><b>Compressor summary</b>: BLR-HAC is a method that combines offline data and online logistic regression to initialize and update policies for human-agent collaboration tasks.</p><hr><h3>What is Meant by AGI? On the Definition of Artificial General  Intelligence</h3>
<p><a href='http://arxiv.org/abs/2404.10731v1'>http://arxiv.org/abs/2404.10731v1</a></p>
<p><b>Compressor summary</b>: The paper seeks a common definition for AGI by defining it as adapting to open environments with limited resources using intelligent principles.</p><hr><h3>Insight Gained from Migrating a Machine Learning Model to Intelligence  Processing Units</h3>
<p><a href='http://arxiv.org/abs/2404.10730v1'>http://arxiv.org/abs/2404.10730v1</a></p>
<p><b>Compressor summary</b>: The paper explores IPUs as accelerators for ML in materials science and battery research, using a CNN model for predicting effective conductivity with comparable performance to GPUs.</p><hr><h3>Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</h3>
<p><a href='http://arxiv.org/abs/2404.10719v1'>http://arxiv.org/abs/2404.10719v1</a></p>
<p><b>Compressor summary</b>: The paper compares reward-based (PPO) and reward-free (DPO) methods for aligning large language models with human preferences using theoretical, empirical, and benchmarking studies.</p><hr><h3>GazeHTA: End-to-end Gaze Target Detection with Head-Target Association</h3>
<p><a href='http://arxiv.org/abs/2404.10718v1'>http://arxiv.org/abs/2404.10718v1</a></p>
<p><b>Compressor summary</b>: The proposed GazeHTA method detects multiple head-target associations in a scene using a pre-trained diffusion model, enhanced head features, and a connection map for improved gaze target detection.</p><hr><h3>Mixed Prototype Consistency Learning for Semi-supervised Medical Image  Segmentation</h3>
<p><a href='http://arxiv.org/abs/2404.10717v1'>http://arxiv.org/abs/2404.10717v1</a></p>
<p><b>Compressor summary</b>: MPCL is a semi-supervised medical image segmentation method that uses mixed prototypes to improve class embeddings and achieve better performance than existing methods.</p><hr><h3>MOWA: Multiple-in-One Image Warping Model</h3>
<p><a href='http://arxiv.org/abs/2404.10716v1'>http://arxiv.org/abs/2404.10716v1</a></p>
<p><b>Compressor summary</b>: MOWA is a novel image warping model that can handle multiple tasks in one single model and generalize well to different scenarios.</p><hr><h3>A Plausibility Study of Using Augmented Reality in the  Ventriculoperitoneal Shunt Operations</h3>
<p><a href='http://arxiv.org/abs/2404.10713v1'>http://arxiv.org/abs/2404.10713v1</a></p>
<p><b>Compressor summary</b>: This paper explores augmented reality techniques for medical surgeries, focusing on a new approach to ventriculoperitoneal shunt operations using 3D models and the Microsoft HoloLens 2.</p><hr><h3>Dual Modalities of Text: Visual and Textual Generative Pre-training</h3>
<p><a href='http://arxiv.org/abs/2404.10710v1'>http://arxiv.org/abs/2404.10710v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a pre-training framework that combines visual and textual data to improve pixel-based language models.</p><hr><h3>Question Difficulty Ranking for Multiple-Choice Reading Comprehension</h3>
<p><a href='http://arxiv.org/abs/2404.10704v1'>http://arxiv.org/abs/2404.10704v1</a></p>
<p><b>Compressor summary</b>: The text explores automated methods for ranking MC questions by difficulty in English learning tests, comparing task transfer and zero-shot approaches, and finding that zero-shot comparative assessment is more effective than other methods.</p><hr><h3>ECLAIR: A High-Fidelity Aerial LiDAR Dataset for Semantic Segmentation</h3>
<p><a href='http://arxiv.org/abs/2404.10699v1'>http://arxiv.org/abs/2404.10699v1</a></p>
<p><b>Compressor summary</b>: ECLAIR is a large outdoor LiDAR dataset with 11 object categories for research in point cloud semantic segmentation.</p><hr><h3>Integrating knowledge bases to improve coreference and bridging  resolution for the chemical domain</h3>
<p><a href='http://arxiv.org/abs/2404.10696v1'>http://arxiv.org/abs/2404.10696v1</a></p>
<p><b>Compressor summary</b>: Our method improves coreference and bridging resolution in chemical patents by using external knowledge in a multi-task learning model.</p><hr><h3>MathWriting: A Dataset For Handwritten Mathematical Expression  Recognition</h3>
<p><a href='http://arxiv.org/abs/2404.10690v1'>http://arxiv.org/abs/2404.10690v1</a></p>
<p><b>Compressor summary</b>: MathWriting is the largest dataset of handwritten mathematical expressions, containing 630k samples that can be used for offline recognition and benchmarking.</p><hr><h3>Network architecture search of X-ray based scientific applications</h3>
<p><a href='http://arxiv.org/abs/2404.10689v1'>http://arxiv.org/abs/2404.10689v1</a></p>
<p><b>Compressor summary</b>: The authors propose an automated method to optimize neural network models for X-ray and electron microscopy using hyperparameter and architecture search, achieving improved performance and reduced resource usage.</p><hr><h3>Efficient Conditional Diffusion Model with Probability Flow Sampling for  Image Super-resolution</h3>
<p><a href='http://arxiv.org/abs/2404.10688v1'>http://arxiv.org/abs/2404.10688v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Efficient Conditional Diffusion Model with Probability Flow Sampling, a fast and high-quality image super-resolution method that uses a continuous-time conditional diffusion model and a hybrid parametrization for the denoiser network.</p><hr><h3>Generating Human Interaction Motions in Scenes with Text Control</h3>
<p><a href='http://arxiv.org/abs/2404.10685v1'>http://arxiv.org/abs/2404.10685v1</a></p>
<p><b>Compressor summary</b>: TeSMo is a method that generates realistic and diverse human-object interactions in different scenes using denoising diffusion models and detailed scene information.</p><hr><h3>Driver Fatigue Prediction using Randomly Activated Neural Networks for  Smart Ridesharing Platforms</h3>
<p><a href='http://arxiv.org/abs/2404.10684v1'>http://arxiv.org/abs/2404.10684v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new heuristic (DDS) and model (stochastic neural network with random activations) to predict how ridesharing drivers make decisions as they experience fatigue and cognitive decline during their shifts, outperforming existing methods in simulations and real data.</p><hr><h3>Simplex Decomposition for Portfolio Allocation Constraints in  Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10683v1'>http://arxiv.org/abs/2404.10683v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new reinforcement learning method, CAOSD, to optimize portfolios with allocation constraints, such as investing in green technologies while limiting fossil energy sector exposure, and shows it outperforms existing methods on real-world data.</p><hr><h3>StyleCity: Large-Scale 3D Urban Scenes Stylization with Vision-and-Text  Reference via Progressive Optimization</h3>
<p><a href='http://arxiv.org/abs/2404.10681v1'>http://arxiv.org/abs/2404.10681v1</a></p>
<p><b>Compressor summary</b>: StyleCity is a system that stylizes large-scale urban scenes using vision and text, generating harmonious backgrounds and enhancing semantics consistency for virtual production prototyping.</p><hr><h3>VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time</h3>
<p><a href='http://arxiv.org/abs/2404.10667v1'>http://arxiv.org/abs/2404.10667v1</a></p>
<p><b>Compressor summary</b>: VASA is a framework that generates realistic talking faces from images and audio, with high quality and fast performance, enabling engaging avatar interactions.</p><hr><h3>Assessing The Impact of CNN Auto Encoder-Based Image Denoising on Image  Classification Tasks</h3>
<p><a href='http://arxiv.org/abs/2404.10664v1'>http://arxiv.org/abs/2404.10664v1</a></p>
<p><b>Compressor summary</b>: The study proposes a novel method for defect detection in noisy images using deep learning models and denoising techniques, achieving significant improvements in accuracy compared to previous methods.</p><hr><h3>Continual Offline Reinforcement Learning via Diffusion-based Dual  Generative Replay</h3>
<p><a href='http://arxiv.org/abs/2404.10662v1'>http://arxiv.org/abs/2404.10662v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a dual generative replay framework for continual offline reinforcement learning that retains previous knowledge and mitigates forgetting by replaying high-fidelity samples of past tasks.</p><hr><h3>ViTextVQA: A Large-Scale Visual Question Answering Dataset for  Evaluating Vietnamese Text Comprehension in Images</h3>
<p><a href='http://arxiv.org/abs/2404.10652v1'>http://arxiv.org/abs/2404.10652v1</a></p>
<p><b>Compressor summary</b>: The authors introduce ViTextVQA, a Vietnamese dataset for visual question answering that focuses on understanding text in images and improve the performance of models by studying the order of processing OCR tokens.</p><hr><h3>Efficient Parking Search using Shared Fleet Data</h3>
<p><a href='http://arxiv.org/abs/2404.10646v1'>http://arxiv.org/abs/2404.10646v1</a></p>
<p><b>Compressor summary</b>: The paper explores how sharing parking spot availability data within a vehicle fleet can help drivers find free spots faster in smart cities.</p><hr><h3>Continuous Control Reinforcement Learning: Distributed Distributional  DrQ Algorithms</h3>
<p><a href='http://arxiv.org/abs/2404.10645v1'>http://arxiv.org/abs/2404.10645v1</a></p>
<p><b>Compressor summary</b>: Distributed Distributional DrQ is a model-free RL algorithm that uses distributional value functions and distributed actor policies to improve performance in continuous control tasks.</p><hr><h3>Self-playing Adversarial Language Game Enhances LLM Reasoning</h3>
<p><a href='http://arxiv.org/abs/2404.10642v1'>http://arxiv.org/abs/2404.10642v1</a></p>
<p><b>Compressor summary</b>: The authors study how self-play in an adversarial language game called SPAG can improve large language models' reasoning ability on various benchmarks.</p><hr><h3>Contextrast: Contextual Contrastive Learning for Semantic Segmentation</h3>
<p><a href='http://arxiv.org/abs/2404.10633v1'>http://arxiv.org/abs/2404.10633v1</a></p>
<p><b>Compressor summary</b>: Contextrast is a semantic segmentation method that uses contrastive learning to capture local/global contexts and their relationships, improving performance on various datasets.</p><hr><h3>HLAT: High-quality Large Language Model Pre-trained on AWS Trainium</h3>
<p><a href='http://arxiv.org/abs/2404.10630v1'>http://arxiv.org/abs/2404.10630v1</a></p>
<p><b>Compressor summary</b>: The paper presents HLAT, a large language model pre-trained on AWS Trainium using Neuron Distributed Training Library (NDTL), achieving comparable performance to baseline models trained on GPUs and TPUs.</p><hr><h3>Exploring selective image matching methods for zero-shot and few-sample  unsupervised domain adaptation of urban canopy prediction</h3>
<p><a href='http://arxiv.org/abs/2404.10626v1'>http://arxiv.org/abs/2404.10626v1</a></p>
<p><b>Compressor summary</b>: We propose and test simple methods to adapt a trained UNet for canopy cover and height estimation across different geographic settings using remotely sensed data, achieving better results than baselines and existing approaches.</p><hr><h3>Gaussian Splatting Decoder for 3D-aware Generative Adversarial Networks</h3>
<p><a href='http://arxiv.org/abs/2404.10625v1'>http://arxiv.org/abs/2404.10625v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to combine NeRF-based 3D GANs with 3D Gaussian Splatting for efficient rendering quality and real-time editing.</p><hr><h3>PyTorchGeoNodes: Enabling Differentiable Shape Programs for 3D Shape  Reconstruction</h3>
<p><a href='http://arxiv.org/abs/2404.10620v1'>http://arxiv.org/abs/2404.10620v1</a></p>
<p><b>Compressor summary</b>: PyTorchGeoNodes is a module for 3D object reconstruction from images using shape programs, allowing for semantic reasoning and optimization.</p><hr><h3>Private Attribute Inference from Images with Vision-Language Models</h3>
<p><a href='http://arxiv.org/abs/2404.10618v1'>http://arxiv.org/abs/2404.10618v1</a></p>
<p><b>Compressor summary</b>: The text discusses the privacy risks posed by large language and multimodal vision-language models that can accurately infer personal attributes from benign images posted online.</p><hr><h3>Enhancing 3D Fidelity of Text-to-3D using Cross-View Correspondences</h3>
<p><a href='http://arxiv.org/abs/2404.10603v1'>http://arxiv.org/abs/2404.10603v1</a></p>
<p><b>Compressor summary</b>: CorrespondentDream is an effective method to use cross-view correspondences from diffusion U-Net as additional 3D prior for NeRF models, improving their geometry and coherence with common sense.</p><hr><h3>Intra-operative tumour margin evaluation in breast-conserving surgery  with deep learning</h3>
<p><a href='http://arxiv.org/abs/2404.10600v1'>http://arxiv.org/abs/2404.10600v1</a></p>
<p><b>Compressor summary</b>: The study proposes and evaluates an intra-operative tumour margin evaluation scheme using specimen mammography, deep learning, and image thresholding to reduce the risk of local recurrences after breast retention surgery.</p><hr><h3>Automated Evaluation of Large Vision-Language Models on Self-driving  Corner Cases</h3>
<p><a href='http://arxiv.org/abs/2404.10595v1'>http://arxiv.org/abs/2404.10595v1</a></p>
<p><b>Compressor summary</b>: CODA-LM is a vision-language benchmark for self-driving that evaluates large language models' abilities in interpretable autonomous driving scenarios, especially challenging road corner cases.</p><hr><h3>Do Counterfactual Examples Complicate Adversarial Training?</h3>
<p><a href='http://arxiv.org/abs/2404.10588v1'>http://arxiv.org/abs/2404.10588v1</a></p>
<p><b>Compressor summary</b>: The study uses diffusion models to analyze how robust classifiers handle semantically altered data and finds that they struggle with low-norm counterfactual examples, suggesting a link between non-robustness and semantic features.</p><hr><h3>ReWiTe: Realistic Wide-angle and Telephoto Dual Camera Fusion Dataset  via Beam Splitter Camera Rig</h3>
<p><a href='http://arxiv.org/abs/2404.10584v1'>http://arxiv.org/abs/2404.10584v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new dataset, ReWiTe, that uses a hardware setup with two cellphones to capture authentic wide-angle and telephoto images for training deep learning methods in dual camera system fusion tasks, improving performance over existing synthetic datasets.</p><hr><h3>The application of Augmented Reality (AR) in Remote Work and Education</h3>
<p><a href='http://arxiv.org/abs/2404.10579v1'>http://arxiv.org/abs/2404.10579v1</a></p>
<p><b>Compressor summary</b>: This paper explores how Augmented Reality (AR) technology can improve remote work and online education by analyzing its features, advantages, challenges, scientific basis, technical support, performance, influencing factors, and future trends.</p><hr><h3>EMC$^2$: Efficient MCMC Negative Sampling for Contrastive Learning with  Global Convergence</h3>
<p><a href='http://arxiv.org/abs/2404.10575v1'>http://arxiv.org/abs/2404.10575v1</a></p>
<p><b>Compressor summary</b>: EMC^2 is an efficient Markov Chain Monte Carlo method for generating negative samples in contrastive learning, which achieves low computation and memory cost, global convergence, and competitive performance.</p><hr><h3>Uncertainty-guided Open-Set Source-Free Unsupervised Domain Adaptation  with Target-private Class Segregation</h3>
<p><a href='http://arxiv.org/abs/2404.10574v1'>http://arxiv.org/abs/2404.10574v1</a></p>
<p><b>Compressor summary</b>: This paper proposes a novel approach for source-free open-set domain adaptation that improves target-private sample segregation and robustness using clustering, uncertainty-based selection, and a new contrastive loss.</p><hr><h3>AAVDiff: Experimental Validation of Enhanced Viability and Diversity in  Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation</h3>
<p><a href='http://arxiv.org/abs/2404.10573v1'>http://arxiv.org/abs/2404.10573v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The study proposes an end-to-end diffusion model to generate capsid sequences with enhanced viability for gene therapy using rAAV vectors
- The model outperforms traditional methods and can generate viable sequences even in the absence of AAV9 capsid data
- The research contributes to the improvement of specificity and transduction efficiency in gene therapy applications

Summary:
The study presents a novel diffusion model that generates better capsid sequences for rAAV vectors, enhancing gene therapy outcomes.</p><hr><h3>Label merge-and-split: A graph-colouring approach for memory-efficient  brain parcellation</h3>
<p><a href='http://arxiv.org/abs/2404.10572v1'>http://arxiv.org/abs/2404.10572v1</a></p>
<p><b>Compressor summary</b>: Label merge-and-split reduces the number of labels for whole brain parcellation, improves accuracy and efficiency, and can be used in other semantic segmentation tasks.</p><hr><h3>CMU-Flownet: Exploring Point Cloud Scene Flow Estimation in Occluded  Scenario</h3>
<p><a href='http://arxiv.org/abs/2404.10571v1'>http://arxiv.org/abs/2404.10571v1</a></p>
<p><b>Compressor summary</b>: The paper proposes CMU-Flownet, a model that handles occlusions in LiDAR data by using a Correlation Matrix to estimate point similarity and an Occlusion-aware Cost Volume mechanism for better flow estimation.</p><hr><h3>HiGraphDTI: Hierarchical Graph Representation Learning for Drug-Target  Interaction Prediction</h3>
<p><a href='http://arxiv.org/abs/2404.10561v1'>http://arxiv.org/abs/2404.10561v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel deep learning method (HiGraphDTI) for predicting drug-target interactions that leverages hierarchical graph representations to capture chemical information from atoms, motifs, and molecules, as well as an attentional feature fusion module and a hierarchical attention mechanism for interpreting interaction mechanisms.</p><hr><h3>Construction of Domain-specified Japanese Large Language Model for  Finance through Continual Pre-training</h3>
<p><a href='http://arxiv.org/abs/2404.10555v1'>http://arxiv.org/abs/2404.10555v1</a></p>
<p><b>Compressor summary</b>: The study developed a Japanese financial-specific large language model by continually pre-training it with custom datasets, improving its performance and quality of outputs compared to the original model.</p><hr><h3>Unveiling the Misuse Potential of Base Large Language Models via  In-Context Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10552v1'>http://arxiv.org/abs/2404.10552v1</a></p>
<p><b>Compressor summary</b>: The text warns that large language models without ethical alignment can execute malicious instructions, posing significant risks and demanding improved security measures.</p><hr><h3>The Evolution of Learning: Assessing the Transformative Impact of  Generative AI on Higher Education</h3>
<p><a href='http://arxiv.org/abs/2404.10551v1'>http://arxiv.org/abs/2404.10551v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how generative AI models like ChatGPT influence higher education, exploring benefits, drawbacks, and transformative changes through a survey and scenario analysis of students' perspectives and attitudes.</p><hr><h3>Analytical Approximation of the ELBO Gradient in the Context of the  Clutter Problem</h3>
<p><a href='http://arxiv.org/abs/2404.10550v1'>http://arxiv.org/abs/2404.10550v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method to approximate the gradient of the Evidence Lower Bound in Bayesian networks with clutter problems using the reparameterization trick and local likelihood factor approximations, which is faster and more accurate than classical methods.</p><hr><h3>A/B testing under Interference with Partial Network Information</h3>
<p><a href='http://arxiv.org/abs/2404.10547v1'>http://arxiv.org/abs/2404.10547v1</a></p>
<p><b>Compressor summary</b>: The paper introduces UNITE, a new method to estimate global average treatment effects in A/B tests with social connections by using only information about neighbors without knowing the exact network structure.</p><hr><h3>SPVLoc: Semantic Panoramic Viewport Matching for 6D Camera Localization  in Unseen Environments</h3>
<p><a href='http://arxiv.org/abs/2404.10527v1'>http://arxiv.org/abs/2404.10527v1</a></p>
<p><b>Compressor summary</b>: SPVLoc is a global indoor localization method that uses a convolutional network to match a query image with a panoramic semantic layout of the environment and estimate its 6D camera pose.</p><hr><h3>MobileNetV4 - Universal Models for the Mobile Ecosystem</h3>
<p><a href='http://arxiv.org/abs/2404.10518v1'>http://arxiv.org/abs/2404.10518v1</a></p>
<p><b>Compressor summary</b>: MobileNetV4 is an efficient and versatile architecture for mobile devices that uses new blocks and search techniques to achieve high accuracy on various accelerators.</p><hr><h3>CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level  Granularity</h3>
<p><a href='http://arxiv.org/abs/2404.10513v1'>http://arxiv.org/abs/2404.10513v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new method for improving QA systems by generating more accurate and correct attributions using Chain-of-Thought reasoning.</p><hr><h3>Four-hour thunderstorm nowcasting using deep diffusion models of  satellite</h3>
<p><a href='http://arxiv.org/abs/2404.10512v1'>http://arxiv.org/abs/2404.10512v1</a></p>
<p><b>Compressor summary</b>: The text describes a new AI-based system (DDMS) for accurate and efficient convection nowcasting using diffusion processes and geostationary satellite data, which improves forecast lead time, coverage, and resolution compared to existing methods.</p><hr><h3>White Men Lead, Black Women Help: Uncovering Gender, Racial, and  Intersectional Bias in Language Agency</h3>
<p><a href='http://arxiv.org/abs/2404.10508v1'>http://arxiv.org/abs/2404.10508v1</a></p>
<p><b>Compressor summary</b>: The study finds significant social biases in human and AI-generated texts based on gender, race, and intersectional identities, with minority groups experiencing lower levels of agency.</p><hr><h3>Data Collection of Real-Life Knowledge Work in Context: The RLKWiC  Dataset</h3>
<p><a href='http://arxiv.org/abs/2404.10505v1'>http://arxiv.org/abs/2404.10505v1</a></p>
<p><b>Compressor summary</b>: The paper introduces RLKWiC, a new dataset of real-world knowledge work data that can help study and improve knowledge workers' productivity.</p><hr><h3>A Sentiment Analysis of Medical Text Based on Deep Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10503v1'>http://arxiv.org/abs/2404.10503v1</a></p>
<p><b>Compressor summary</b>: The paper explores how different deep learning networks affect sentiment analysis of medical texts using pre-trained models like BERT, and finds that CNN models perform best on smaller datasets.</p><hr><h3>Self-Supervised Visual Preference Alignment</h3>
<p><a href='http://arxiv.org/abs/2404.10501v1'>http://arxiv.org/abs/2404.10501v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an unsupervised method for improving vision-language models by generating and aligning responses with augmented image inputs, achieving high scores on complex reasoning tasks without GPT-4 supervision or human involvement.</p><hr><h3>When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical  Paradigm</h3>
<p><a href='http://arxiv.org/abs/2404.10500v1'>http://arxiv.org/abs/2404.10500v1</a></p>
<p><b>Compressor summary</b>: This paper introduces an Auto-Prompt Graphical Paradigm (APGP) that combines both stimulating and framework prompts to enhance problem-solving capabilities of large language models across multiple domains using automated approaches.</p><hr><h3>Robust Noisy Label Learning via Two-Stream Sample Distillation</h3>
<p><a href='http://arxiv.org/abs/2404.10499v1'>http://arxiv.org/abs/2404.10499v1</a></p>
<p><b>Compressor summary</b>: TSSD is a sample selection framework for noisy label learning that uses PSD to generate reliable samples and MSP to mine semi-hard samples from uncertain data, improving network robustness.</p><hr><h3>LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration  for IoT-based Perception System</h3>
<p><a href='http://arxiv.org/abs/2404.10498v1'>http://arxiv.org/abs/2404.10498v1</a></p>
<p><b>Compressor summary</b>: LAECIPS is a new edge-cloud framework for vision tasks that achieves high accuracy, low latency, and adapts to dynamic IoT data streams using plug-and-play models and hard input mining strategy.</p><hr><h3>Teaching Chinese Sign Language with Feedback in Mixed Reality</h3>
<p><a href='http://arxiv.org/abs/2404.10490v1'>http://arxiv.org/abs/2404.10490v1</a></p>
<p><b>Compressor summary</b>: The study proposes a new sign language teaching model using real-time vision, mixed reality, and improved hand-posture reconstruction to provide an immersive and effective learning experience.</p><hr><h3>AbsGS: Recovering Fine Details for 3D Gaussian Splatting</h3>
<p><a href='http://arxiv.org/abs/2404.10484v1'>http://arxiv.org/abs/2404.10484v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes the cause of over-reconstruction issue in 3D Gaussian Splatting technique and proposes a novel homodirectional view-space positional gradient criterion to split large Gaussians and recover fine details for better rendering quality.</p><hr><h3>Would You Trust an AI Doctor? Building Reliable Medical Predictions with  Kernel Dropout Uncertainty</h3>
<p><a href='http://arxiv.org/abs/2404.10483v1'>http://arxiv.org/abs/2404.10483v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new AI model that improves reliability on small medical datasets, addressing trust issues in healthcare AI.</p><hr><h3>BayesJudge: Bayesian Kernel Language Modelling with Confidence  Uncertainty in Legal Judgment Prediction</h3>
<p><a href='http://arxiv.org/abs/2404.10481v1'>http://arxiv.org/abs/2404.10481v1</a></p>
<p><b>Compressor summary</b>: BayesJudge is a novel Bayesian approach using deep learning and Gaussian Processes to improve prediction confidence and accuracy for legal tasks.</p><hr><h3>Efficient optimal dispersed Haar-like filters for face detection</h3>
<p><a href='http://arxiv.org/abs/2404.10476v1'>http://arxiv.org/abs/2404.10476v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel method to efficiently detect faces using optimally configured dispersed Haar-like filters that balance between-class and within-class variance.</p><hr><h3>Conversations as a Source for Teaching Scientific Concepts at Different  Education Levels</h3>
<p><a href='http://arxiv.org/abs/2404.10475v1'>http://arxiv.org/abs/2404.10475v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new data set from video transcripts to train language models for engaging and effective conversational teaching of scientific concepts across different audiences.</p><hr><h3>Toward a Realistic Benchmark for Out-of-Distribution Detection</h3>
<p><a href='http://arxiv.org/abs/2404.10474v1'>http://arxiv.org/abs/2404.10474v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new benchmark for evaluating out-of-distribution detection in deep neural networks, using ImageNet and Places365 datasets and varying the criteria for in-distribution classes.</p><hr><h3>DESTEIN: Navigating Detoxification of Language Models via Universal  Steering Pairs and Head-wise Activation Fusion</h3>
<p><a href='http://arxiv.org/abs/2404.10464v1'>http://arxiv.org/abs/2404.10464v1</a></p>
<p><b>Compressor summary</b>: DeStein is a novel method that reduces toxic outputs from language models by altering their activation space representations using self-induced steering pairs and arithmetic operations, achieving better performance than previous methods with lower resource and time cost.</p><hr><h3>Advancing Long-Term Multi-Energy Load Forecasting with Patchformer: A  Patch and Transformer-Based Approach</h3>
<p><a href='http://arxiv.org/abs/2404.10458v1'>http://arxiv.org/abs/2404.10458v1</a></p>
<p><b>Compressor summary</b>: Patchformer is a novel Transformer-based model that improves long-term multi-energy load forecasting by segmenting data into patches and capturing local and global dependencies.</p><hr><h3>Revealing data leakage in protein interaction benchmarks</h3>
<p><a href='http://arxiv.org/abs/2404.10457v1'>http://arxiv.org/abs/2404.10457v1</a></p>
<p><b>Compressor summary</b>: The text argues that machine learning for protein-protein interactions needs better evaluation strategies, data preparation, and structural similarity-based data splits to avoid overoptimistic evaluations and unfair benchmarking.</p><hr><h3>A Computer Vision-Based Quality Assessment Technique for the automatic  control of consumables for analytical laboratories</h3>
<p><a href='http://arxiv.org/abs/2404.10454v1'>http://arxiv.org/abs/2404.10454v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an AI-based automatic monitoring system for detecting anticoagulant substances in test tubes, which is competitive with existing models and could improve efficiency and sustainability in the production of plastic consumables.</p><hr><h3>Graph Neural Networks for Protein-Protein Interactions - A Short Survey</h3>
<p><a href='http://arxiv.org/abs/2404.10450v1'>http://arxiv.org/abs/2404.10450v1</a></p>
<p><b>Compressor summary</b>: This paper reviews different graph-based methods for predicting protein-protein interactions, discussing their applications and classifying them into two groups based on model structures.</p><hr><h3>SparseDM: Toward Sparse Efficient Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2404.10445v1'>http://arxiv.org/abs/2404.10445v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes a method to improve deployment efficiency of diffusion models on mobile devices.
- The method uses sparse masks and progressive sparsity training to control the trade-off between FID and MACs.
- The experiments show that the method reduces MACs by 50% while maintaining low FID.

Summary:
The paper introduces a method for improving diffusion models on mobile devices using sparse masks and progressive sparsity training, which achieves low FID and MACs.</p><hr><h3>AGHINT: Attribute-Guided Representation Learning on Heterogeneous  Information Networks with Transformer</h3>
<p><a href='http://arxiv.org/abs/2404.10443v1'>http://arxiv.org/abs/2404.10443v1</a></p>
<p><b>Compressor summary</b>: AGHINT is a new model for representing heterogeneous information networks, which improves node classification by considering attribute disparities and incorporating higher-order similar neighbor features.</p><hr><h3>1st Place Solution for ICCV 2023 OmniObject3D Challenge: Sparse-View  Reconstruction</h3>
<p><a href='http://arxiv.org/abs/2404.10441v1'>http://arxiv.org/abs/2404.10441v1</a></p>
<p><b>Compressor summary</b>: The report describes the winning method for reconstructing 3D objects from few images using Pixel-NeRF, depth supervision, and positional encoding.</p><hr><h3>Language Proficiency and F0 Entrainment: A Study of L2 English Imitation  in Italian, French, and Slovak Speakers</h3>
<p><a href='http://arxiv.org/abs/2404.10440v1'>http://arxiv.org/abs/2404.10440v1</a></p>
<p><b>Compressor summary</b>: The study examines how well second language learners of English can imitate native speakers' pitch variations in a reading task and finds that proficiency affects entrainment differently at individual and group levels.</p><hr><h3>The Unreasonable Effectiveness of Pre-Trained Features for Camera Pose  Refinement</h3>
<p><a href='http://arxiv.org/abs/2404.10438v1'>http://arxiv.org/abs/2404.10438v1</a></p>
<p><b>Compressor summary</b>: The paper presents a simple and effective method for pose refinement using pre-trained features, a particle filter, and a renderable scene representation.</p><hr><h3>Tree Bandits for Generative Bayes</h3>
<p><a href='http://arxiv.org/abs/2404.10436v1'>http://arxiv.org/abs/2404.10436v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a self-aware framework that learns from past trials and errors to accelerate ABC rejection sampling in generative models with obscured likelihood.</p><hr><h3>Explainable concept mappings of MRI: Revealing the mechanisms underlying  deep learning-based brain disease classification</h3>
<p><a href='http://arxiv.org/abs/2404.10433v1'>http://arxiv.org/abs/2404.10433v1</a></p>
<p><b>Compressor summary</b>: The study investigates how deep neural networks learn to classify Alzheimer's patients from normal controls using quantitative maps, and finds that they focus on brain regions near the basal ganglia.</p><hr><h3>MEEL: Multi-Modal Event Evolution Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10429v1'>http://arxiv.org/abs/2404.10429v1</a></p>
<p><b>Compressor summary</b>: MEEL is a new method to improve machines' ability to understand event relations across different data types by generating evolving graphs and using them for instruction tuning and guiding discrimination.</p><hr><h3>AudioProtoPNet: An interpretable deep learning model for bird sound  classification</h3>
<p><a href='http://arxiv.org/abs/2404.10420v1'>http://arxiv.org/abs/2404.10420v1</a></p>
<p><b>Compressor summary</b>: The study adapts a deep learning model that can accurately classify bird species from acoustic signals and provide interpretable explanations of its decisions using prototypical patterns.</p><hr><h3>Disentangling Instructive Information from Ranked Multiple Candidates  for Multi-Document Scientific Summarization</h3>
<p><a href='http://arxiv.org/abs/2404.10416v1'>http://arxiv.org/abs/2404.10416v1</a></p>
<p><b>Compressor summary</b>: This paper introduces summary candidates into Multi-Document Scientific Summarization (MDSS) to guide the decoding process, improve global information handling, and generate better summaries using a specialized pairwise comparison method and Conditional Variational Autoencoder.</p><hr><h3>Camera clustering for scalable stream-based active distillation</h3>
<p><a href='http://arxiv.org/abs/2404.10411v1'>http://arxiv.org/abs/2404.10411v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework to create efficient video object detection models using self-training and knowledge distillation, and shows that clustering cameras improves accuracy of distilled models.</p><hr><h3>Adversarial Identity Injection for Semantic Face Image Synthesis</h3>
<p><a href='http://arxiv.org/abs/2404.10408v1'>http://arxiv.org/abs/2404.10408v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an SIS architecture with cross-attention to generate realistic and identity-preserving faces using semantic, style, and identity features.</p><hr><h3>Comprehensive Survey of Model Compression and Speed up for Vision  Transformers</h3>
<p><a href='http://arxiv.org/abs/2404.10407v1'>http://arxiv.org/abs/2404.10407v1</a></p>
<p><b>Compressor summary</b>: The study compares four techniques to optimize Vision Transformers (ViT) for resource-constrained environments, improving their performance and efficiency.</p><hr><h3>Integration of Self-Supervised BYOL in Semi-Supervised Medical Image  Recognition</h3>
<p><a href='http://arxiv.org/abs/2404.10405v1'>http://arxiv.org/abs/2404.10405v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an enhanced medical image recognition method by combining self-supervised and semi-supervised learning techniques, which improves accuracy when labeled data is limited.</p><hr><h3>Portrait3D: Text-Guided High-Quality 3D Portrait Generation Using  Pyramid Representation and GANs Prior</h3>
<p><a href='http://arxiv.org/abs/2404.10394v1'>http://arxiv.org/abs/2404.10394v1</a></p>
<p><b>Compressor summary</b>: Portrait3D is a novel text-to-3D-portrait generation framework that overcomes geometry issues by using a joint geometry-appearance prior and a pyramid tri-grid 3D representation.</p><hr><h3>Offline Trajectory Generalization for Offline Reinforcement Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10393v1'>http://arxiv.org/abs/2404.10393v1</a></p>
<p><b>Compressor summary</b>: OTTO is a method to improve offline reinforcement learning by using World Transformers to predict dynamics and reward, and generating high-rewarded data simulations from offline data.</p><hr><h3>CNN-based explanation ensembling for dataset, representation and  explanations evaluation</h3>
<p><a href='http://arxiv.org/abs/2404.10387v1'>http://arxiv.org/abs/2404.10387v1</a></p>
<p><b>Compressor summary</b>: The authors explore how combining different explanations from deep learning models can reveal more reliable patterns and improve evaluation of the model's behavior.</p><hr><h3>Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large  Language Model for Domain Question Answering</h3>
<p><a href='http://arxiv.org/abs/2404.10384v1'>http://arxiv.org/abs/2404.10384v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Large language models (LLMs) excel at many tasks but struggle with domain-specific evaluations and hallucination problems
- Knowledge graphs (KGs) provide background knowledge for LLMs and enable reasoning and analysis
- The paper proposes a pipeline to select reasoning paths from KG based on LLM and a subgraph retrieval method based on CoT and page rank
- Experiments show that fewer LLM calls can achieve the same results as previous SOTAs models

Summary:
The paper presents a method to use knowledge graphs and large language models for reasoning and subgraph retrieval, reducing the dependency on LLM and achieving similar performance to existing models.</p><hr><h3>Learning to Score Sign Language with Two-stage Method</h3>
<p><a href='http://arxiv.org/abs/2404.10383v1'>http://arxiv.org/abs/2404.10383v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a two-stage method for sign language performance evaluation using pose reconstruction and smoothing methods, providing effective feedback and consistent results with professional assessments.</p><hr><h3>Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge  in the Era of Synthetic Data</h3>
<p><a href='http://arxiv.org/abs/2404.10378v1'>http://arxiv.org/abs/2404.10378v1</a></p>
<p><b>Compressor summary</b>: The paper overviews the 2nd edition of a face recognition challenge that explores using synthetic data to address privacy, bias, and performance issues in face recognition.</p><hr><h3>Know Yourself Better: Diverse Discriminative Feature Learning Improves  Open Set Recognition</h3>
<p><a href='http://arxiv.org/abs/2404.10370v1'>http://arxiv.org/abs/2404.10370v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes open set recognition methods and proposes a new approach that improves performance by leveraging feature diversity.</p><hr><h3>A Survey on Data-Driven Fault Diagnostic Techniques for Marine Diesel  Engines</h3>
<p><a href='http://arxiv.org/abs/2404.10363v1'>http://arxiv.org/abs/2404.10363v1</a></p>
<p><b>Compressor summary</b>: This paper discusses the significance of fault diagnosis in marine diesel engines for maritime safety, efficiency, and reliability, focusing on subsystems, common issues, and data-driven methods.</p><hr><h3>Improving Bracket Image Restoration and Enhancement with Flow-guided  Alignment and Enhanced Feature Aggregation</h3>
<p><a href='http://arxiv.org/abs/2404.10358v1'>http://arxiv.org/abs/2404.10358v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel framework called IREANet, which uses optical flow and residual blocks to align and aggregate features from multiple low dynamic range images to restore high quality high dynamic range images.</p><hr><h3>Optimization of Prompt Learning via Multi-Knowledge Representation for  Vision-Language Models</h3>
<p><a href='http://arxiv.org/abs/2404.10357v1'>http://arxiv.org/abs/2404.10357v1</a></p>
<p><b>Compressor summary</b>: CoKnow is a framework that improves Prompt Learning for Vision-Language Models by using Multi-Knowledge Representation to enhance context optimization and achieve better performance on various downstream tasks.</p><hr><h3>Generating Counterfactual Trajectories with Latent Diffusion Models for  Concept Discovery</h3>
<p><a href='http://arxiv.org/abs/2404.10356v1'>http://arxiv.org/abs/2404.10356v1</a></p>
<p><b>Compressor summary</b>: The study proposes a novel framework called CDCT to discover decision-relevant concepts from opaque deep learning models, which could improve trust and advance medical research.</p><hr><h3>Rethinking the Graph Polynomial Filter via Positive and Negative  Coupling Analysis</h3>
<p><a href='http://arxiv.org/abs/2404.10353v1'>http://arxiv.org/abs/2404.10353v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The text introduces a novel basis for spectral GNNs that incorporates graph information and decouples positive and negative activation.
- The basis is based on the Positive and Negative Coupling Analysis (PNCA) framework, which analyses the message propagation process and reveals hidden information.
- The proposed GSCNet achieves better or comparable results with less computational time than existing GNNs.

Summary:
The text presents a new basis for spectral GNNs that uses graph information and PNCA to decouple activation effects, leading to improved performance and efficiency over existing GNNs.</p><hr><h3>Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of  Language Models with Fine-grained Rewards</h3>
<p><a href='http://arxiv.org/abs/2404.10346v1'>http://arxiv.org/abs/2404.10346v1</a></p>
<p><b>Compressor summary</b>: Self-Explore is a method that helps language models improve their reasoning skills by exploring the first mistake in a rationale and using it as feedback for further improvement, achieving significant gains compared to supervised fine-tuning on GSM8K and MATH datasets.</p><hr><h3>The Ninth NTIRE 2024 Efficient Super-Resolution Challenge Report</h3>
<p><a href='http://arxiv.org/abs/2404.10343v1'>http://arxiv.org/abs/2404.10343v1</a></p>
<p><b>Compressor summary</b>: The paper reviews the NTIRE 2024 challenge on efficient single-image super-resolution, focusing on optimization aspects and outcomes, with four sub-tracks to evaluate runtime, FLOPs, parameters, and overall performance.</p><hr><h3>Referring Flexible Image Restoration</h3>
<p><a href='http://arxiv.org/abs/2404.10342v1'>http://arxiv.org/abs/2404.10342v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The text introduces a new challenge in image restoration called RFIR, where models need to remove specific degradation types based on human commands in images with multiple degradations.
- The text presents a synthetic dataset (RFIR) and a novel transformer-based model (TransRFIR) for this task, which use two attention modules (MHASA and MHACA) to perceive and remove degradation types.
- The text claims that TransRFIR achieves state-of-the-art performances and is released at https://github.com/GuanRunwei/FIR-CP.

Summary:
The text proposes a new image restoration task (RFIR) that requires models to remove specific degradation types in images with multiple degradations based on human commands, and introduces a synthetic dataset and a transformer-based model for this task that use novel attention modules.</p><hr><h3>Asset management, condition monitoring and Digital Twins: damage  detection and virtual inspection on a reinforced concrete bridge</h3>
<p><a href='http://arxiv.org/abs/2404.10341v1'>http://arxiv.org/abs/2404.10341v1</a></p>
<p><b>Compressor summary</b>: The text describes a bridge incident in Norway where a structural defect was detected by Internet of Things sensors and Digital Twin technology, highlighting the benefits of online monitoring and condition-based maintenance for infrastructure management.</p><hr><h3>Intriguing Properties of Positional Encoding in Time Series Forecasting</h3>
<p><a href='http://arxiv.org/abs/2404.10337v1'>http://arxiv.org/abs/2404.10337v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two new positional encodings for transformer-based time series forecasting methods and evaluates their performance in a dual-branch framework.</p><hr><h3>Efficiently Adversarial Examples Generation for Visual-Language Models  under Targeted Transfer Scenarios using Diffusion Models</h3>
<p><a href='http://arxiv.org/abs/2404.10335v1'>http://arxiv.org/abs/2404.10335v1</a></p>
<p><b>Compressor summary</b>: AdvDiffVLM generates natural and effective adversarial examples for large visual-language models using diffusion models and GradCAM-guided Mask method, improving speed and robustness compared to existing methods.</p><hr><h3>Prescribing the Right Remedy: Mitigating Hallucinations in Large  Vision-Language Models via Targeted Instruction Tuning</h3>
<p><a href='http://arxiv.org/abs/2404.10332v1'>http://arxiv.org/abs/2404.10332v1</a></p>
<p><b>Compressor summary</b>: The paper proposes DFTG, a framework that generates targeted instruction data for different large vision-language models to address their specific hallucination issues and improve their performance on cross-modal tasks.</p><hr><h3>Towards Complex Ontology Alignment using Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2404.10329v1'>http://arxiv.org/abs/2404.10329v1</a></p>
<p><b>Compressor summary</b>: The paper explores using large language models to automate the complex process of aligning ontologies in the Semantic Web, which is currently done manually by experts.</p><hr><h3>Graph neural network-based surrogate modelling for real-time hydraulic  prediction of urban drainage networks</h3>
<p><a href='http://arxiv.org/abs/2404.10324v1'>http://arxiv.org/abs/2404.10324v1</a></p>
<p><b>Compressor summary</b>: The text proposes a graph neural network (GNN)-based surrogate model for predicting hydraulic states in urban drainage networks, which incorporates physical constraints and outperforms a fully-connected neural network (NN) model in accuracy and cost-effectiveness.</p><hr><h3>Domain-Rectifying Adapter for Cross-Domain Few-Shot Segmentation</h3>
<p><a href='http://arxiv.org/abs/2404.10322v1'>http://arxiv.org/abs/2404.10322v1</a></p>
<p><b>Compressor summary</b>: Our method adapts a small adapter to rectify diverse target domain styles to the source domain for better few-shot semantic segmentation, using local-global style perturbations and cyclic domain alignment.</p><hr><h3>CARE to Compare: A real-world dataset for anomaly detection in wind  turbine data</h3>
<p><a href='http://arxiv.org/abs/2404.10320v1'>http://arxiv.org/abs/2404.10320v1</a></p>
<p><b>Compressor summary</b>: The authors present a new dataset for wind turbine anomaly detection with detailed fault information, and propose a CARE scoring method to evaluate anomaly detection models.</p><hr><h3>Application of Deep Learning Methods to Processing of Noisy Medical  Video Data</h3>
<p><a href='http://arxiv.org/abs/2404.10319v1'>http://arxiv.org/abs/2404.10319v1</a></p>
<p><b>Compressor summary</b>: The authors propose methods to improve cell counting in moving streams by adapting training and decision making processes.</p><hr><h3>SRGS: Super-Resolution 3D Gaussian Splatting</h3>
<p><a href='http://arxiv.org/abs/2404.10318v1'>http://arxiv.org/abs/2404.10318v1</a></p>
<p><b>Compressor summary</b>: The paper proposes SRGS, a method that improves 3D Gaussian Splatting for high-resolution novel view synthesis by densifying and learning texture features from low-resolution inputs using sub-pixel constraints and a pre-trained 2D super-resolution model.</p><hr><h3>LLMs4OM: Matching Ontologies with Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2404.10317v1'>http://arxiv.org/abs/2404.10317v1</a></p>
<p><b>Compressor summary</b>: The text introduces LLMs4OM, a novel approach that uses large language models for ontology matching tasks and shows they can outperform traditional methods in data integration.</p><hr><h3>Enhancing Confidence Expression in Large Language Models Through  Learning from Past Experience</h3>
<p><a href='http://arxiv.org/abs/2404.10315v1'>http://arxiv.org/abs/2404.10315v1</a></p>
<p><b>Compressor summary</b>: The paper proposes LePe, a method to improve confidence expression in large language models by learning from past experience, addressing key problems and designing a complete pipeline for data preparation and sampling.</p><hr><h3>Awareness of uncertainty in classification using a multivariate model  and multi-views</h3>
<p><a href='http://arxiv.org/abs/2404.10314v1'>http://arxiv.org/abs/2404.10314v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an uncertain AI model that estimates its own predictions' uncertainties and uses them for data augmentation and multimodal optimization.</p><hr><h3>OmniSSR: Zero-shot Omnidirectional Image Super-Resolution using Stable  Diffusion Model</h3>
<p><a href='http://arxiv.org/abs/2404.10312v1'>http://arxiv.org/abs/2404.10312v1</a></p>
<p><b>Compressor summary</b>: The OmniSSR method uses Stable Diffusion and tangent projection to achieve high-resolution omnidirectional image super-resolution with fidelity and realness, without training or fine-tuning.</p><hr><h3>Hierarchical Context Merging: Better Long Context Understanding for  Pre-trained LLMs</h3>
<p><a href='http://arxiv.org/abs/2404.10308v1'>http://arxiv.org/abs/2404.10308v1</a></p>
<p><b>Compressor summary</b>: HOMER is a new method that divides long inputs into smaller chunks, processes them collectively, and merges them using a hierarchical strategy to overcome the context limit of large language models without requiring training or expensive modifications.</p><hr><h3>Learnable Prompt for Few-Shot Semantic Segmentation in Remote Sensing  Domain</h3>
<p><a href='http://arxiv.org/abs/2404.10307v1'>http://arxiv.org/abs/2404.10307v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method that uses SegGPT and learnable prompts for few-shot segmentation, addressing catastrophic forgetting, object sizes, and discontinuities, with image similarity search for inference.</p><hr><h3>Balancing Speciality and Versatility: a Coarse to Fine Framework for  Supervised Fine-tuning Large Language Model</h3>
<p><a href='http://arxiv.org/abs/2404.10306v1'>http://arxiv.org/abs/2404.10306v1</a></p>
<p><b>Compressor summary</b>: CoFiTune is a framework that balances speciality and versatility in aligned large language models by updating specific modules and using soft-masking, achieving better performance across diverse tasks.</p><hr><h3>TC-OCR: TableCraft OCR for Efficient Detection & Recognition of Table  Structure & Content</h3>
<p><a href='http://arxiv.org/abs/2404.10305v1'>http://arxiv.org/abs/2404.10305v1</a></p>
<p><b>Compressor summary</b>: The research proposes an end-to-end deep learning pipeline for recognizing tables in document images, improving accuracy and efficiency over existing methods.</p><hr><h3>Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment  and Sleep Individuality Analysis</h3>
<p><a href='http://arxiv.org/abs/2404.10299v1'>http://arxiv.org/abs/2404.10299v1</a></p>
<p><b>Compressor summary</b>: This study developed a machine learning model that uses sleep sounds to accurately assess sleep quality and identifies the specific sound events and timing that affect individual sleep satisfaction.</p><hr><h3>Future Language Modeling from Temporal Document History</h3>
<p><a href='http://arxiv.org/abs/2404.10297v1'>http://arxiv.org/abs/2404.10297v1</a></p>
<p><b>Compressor summary</b>: The text introduces future language modeling, a task of predicting future texts based on their temporal history, which can be useful for various human activities and improve upon existing non-temporal language models.</p><hr><h3>Engineering software 2.0 by interpolating neural networks: unifying  training, solving, and calibration</h3>
<p><a href='http://arxiv.org/abs/2404.10296v1'>http://arxiv.org/abs/2404.10296v1</a></p>
<p><b>Compressor summary</b>: The interpolating neural network (INN) is a new AI approach that uses interpolation points in physical space to improve software programming, reducing parameters, increasing accuracy, and addressing data challenges.</p><hr><h3>From Data Deluge to Data Curation: A Filtering-WoRA Paradigm for  Efficient Text-based Person Search</h3>
<p><a href='http://arxiv.org/abs/2404.10292v1'>http://arxiv.org/abs/2404.10292v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Filtering-WoRA method to efficiently train person search models using synthetic data with minimal but effective data samples and fine-tuning, improving retrieval performance and reducing training time.</p><hr><h3>Tripod: Three Complementary Inductive Biases for Disentangled  Representation Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10282v1'>http://arxiv.org/abs/2404.10282v1</a></p>
<p><b>Compressor summary</b>: Tripod is a neural network autoencoder with three complementary inductive biases that improve disentangled representation learning, achieving state-of-the-art results on image benchmarks.</p><hr><h3>EucliDreamer: Fast and High-Quality Texturing for 3D Models with  Depth-Conditioned Stable Diffusion</h3>
<p><a href='http://arxiv.org/abs/2404.10279v1'>http://arxiv.org/abs/2404.10279v1</a></p>
<p><b>Compressor summary</b>: EucliDreamer is a method that generates realistic and diverse textures for 3D models based on text prompts using a depth-conditioned Stable Diffusion model, achieving superior quality and faster convergence than existing methods.</p><hr><h3>OptiGrad: A Fair and more Efficient Price Elasticity Optimization via a  Gradient Based Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10275v1'>http://arxiv.org/abs/2404.10275v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new gradient-based method for optimizing profit margins in insurance markets that directly integrates fairness criteria into pricing, addressing challenges faced by traditional methods.</p><hr><h3>Sparse Attention Regression Network Based Soil Fertility Prediction With  Ummaso</h3>
<p><a href='http://arxiv.org/abs/2404.10274v1'>http://arxiv.org/abs/2404.10274v1</a></p>
<p><b>Compressor summary</b>: The study presents a new method that combines UMAP and LASSO to improve predictions of soil fertility from imbalanced datasets, achieving high accuracy and interpretability.</p><hr><h3>Plug-and-Play Acceleration of Occupancy Grid-based NeRF Rendering using  VDB Grid and Hierarchical Ray Traversal</h3>
<p><a href='http://arxiv.org/abs/2404.10272v1'>http://arxiv.org/abs/2404.10272v1</a></p>
<p><b>Compressor summary</b>: The text introduces two techniques to improve the efficiency of ray-tracing in Occupancy Grid for Neural Radiance Field by using VDB grids and hierarchical digital differential analyzer.</p><hr><h3>Social Choice for AI Alignment: Dealing with Diverse Human Feedback</h3>
<p><a href='http://arxiv.org/abs/2404.10271v1'>http://arxiv.org/abs/2404.10271v1</a></p>
<p><b>Compressor summary</b>: The paper explores how social choice theory can help address ethical and safety challenges in fine-tuning foundation models like GPT-4 based on human preferences and principles.</p><hr><h3>Modeling Low-Resource Health Coaching Dialogues via Neuro-Symbolic Goal  Summarization and Text-Units-Text Generation</h3>
<p><a href='http://arxiv.org/abs/2404.10268v1'>http://arxiv.org/abs/2404.10268v1</a></p>
<p><b>Compressor summary</b>: The paper presents neuro-symbolic goal summarizer and dialogue generation models for health coaching that assist patients in setting and achieving physical activity goals, improve over previous methods, and introduce a new dataset and metric for evaluating patient responses.</p><hr><h3>OneActor: Consistent Character Generation via Cluster-Conditioned  Guidance</h3>
<p><a href='http://arxiv.org/abs/2404.10267v1'>http://arxiv.org/abs/2404.10267v1</a></p>
<p><b>Compressor summary</b>: OneActor is a novel method that generates consistent and high-quality images from text using cluster-conditioned diffusion models, without relying on external data or expensive tuning.</p><hr><h3>PreGSU-A Generalized Traffic Scene Understanding Model for Autonomous  Driving based on Pre-trained Graph Attention Network</h3>
<p><a href='http://arxiv.org/abs/2404.10263v1'>http://arxiv.org/abs/2404.10263v1</a></p>
<p><b>Compressor summary</b>: PreGSU is a generalized pre-trained scene understanding model for autonomous driving that learns universal interactions using graph attention networks and self-supervised tasks.</p><hr><h3>Uncovering Latent Arguments in Social Media Messaging by Employing  LLMs-in-the-Loop Strategy</h3>
<p><a href='http://arxiv.org/abs/2404.10259v1'>http://arxiv.org/abs/2404.10259v1</a></p>
<p><b>Compressor summary</b>: The authors propose a method using large language models to automatically discover arguments related to specific themes in social media discussions, reducing the need for manual coding and human intervention.</p><hr><h3>Masked Autoencoders for Microscopy are Scalable Learners of Cellular  Biology</h3>
<p><a href='http://arxiv.org/abs/2404.10242v1'>http://arxiv.org/abs/2404.10242v1</a></p>
<p><b>Compressor summary</b>: This paper compares weakly supervised classifiers and self-supervised masked autoencodters (MAEs) for featurizing microscopy images, showing that MAEs perform better and introducing a new channel-agnostic MAE architecture that generalizes well across different data.</p><hr><h3>Vision-and-Language Navigation via Causal Learning</h3>
<p><a href='http://arxiv.org/abs/2404.10241v1'>http://arxiv.org/abs/2404.10241v1</a></p>
<p><b>Compressor summary</b>: The paper introduces GOAT, a VLN model that uses causal inference and feature pooling to reduce dataset bias and improve performance on multiple VLN tasks.</p><hr><h3>MoE-TinyMed: Mixture of Experts for Tiny Medical Large Vision-Language  Models</h3>
<p><a href='http://arxiv.org/abs/2404.10237v1'>http://arxiv.org/abs/2404.10237v1</a></p>
<p><b>Compressor summary</b>: MoE-TinyMed is a low-parameter model for medical visual question answering that performs better than existing models with fewer resources.</p><hr><h3>Compressible and Searchable: AI-native Multi-Modal Retrieval System with  Learned Image Compression</h3>
<p><a href='http://arxiv.org/abs/2404.10234v1'>http://arxiv.org/abs/2404.10234v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a framework that combines AI-native multi-modal search with neural image compression, improving storage and retrieval efficiency for large multimedia datasets.</p><hr><h3>Generative Text Steganography with Large Language Model</h3>
<p><a href='http://arxiv.org/abs/2404.10229v1'>http://arxiv.org/abs/2404.10229v1</a></p>
<p><b>Compressor summary</b>: LLM-Stega is a black-box generative text steganography method that uses large language models' user interfaces to securely communicate secret messages with rich semantics.</p><hr><h3>Two-Stage Stance Labeling: User-Hashtag Heuristics with Graph Neural  Networks</h3>
<p><a href='http://arxiv.org/abs/2404.10228v1'>http://arxiv.org/abs/2404.10228v1</a></p>
<p><b>Compressor summary</b>: Key points:
- The paper proposes a two stage method for stance labeling using user-hashtag and user-user graphs
- The method uses label propagation, semi-supervised learning, and graph neural networks
- The method outperforms zero-shot stance labeling with LLMs on climate change and gun control tweets

Summary:
The paper presents a novel graph-based method for stance labeling that beats LLMs on tweets about climate change and gun control.</p><hr><h3>MS-MANO: Enabling Hand Pose Tracking with Biomechanical Constraints</h3>
<p><a href='http://arxiv.org/abs/2404.10227v1'>http://arxiv.org/abs/2404.10227v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new model for realistic hand motion analysis that combines a musculoskeletal system with a parametric hand model, and a pose refinement framework that uses a neural network to improve the estimated hand pose.</p><hr><h3>Find The Gap: Knowledge Base Reasoning For Visual Question Answering</h3>
<p><a href='http://arxiv.org/abs/2404.10226v1'>http://arxiv.org/abs/2404.10226v1</a></p>
<p><b>Compressor summary</b>: The text analyzes how to improve visual question answering by using large language models and external knowledge bases, focusing on the impact of explicit supervised retrieval and multi-hop reasoning.</p><hr><h3>GaitPoint+: A Gait Recognition Network Incorporating Point Cloud  Analysis and Recycling</h3>
<p><a href='http://arxiv.org/abs/2404.10213v1'>http://arxiv.org/abs/2404.10213v1</a></p>
<p><b>Compressor summary</b>: The text proposes a new gait recognition network, GaitPoint+, that uses both silhouette and skeleton features for more robust recognition, with a lightweight and fast key point learning module and a recycling max-pooling method to improve accuracy.</p><hr><h3>Anomaly Correction of Business Processes Using Transformer Autoencoder</h3>
<p><a href='http://arxiv.org/abs/2404.10211v1'>http://arxiv.org/abs/2404.10211v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Transformer autoencoder-based method for detecting and correcting business process anomalies without setting thresholds, outperforming previous methods in accuracy and efficiency.</p>