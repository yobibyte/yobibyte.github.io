
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, 2024-06-24</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2024-06-24 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student  Feedback to Make Mnemonic Learning Stick</h3>
<p><a href='http://arxiv.org/abs/2406.15352v1'>http://arxiv.org/abs/2406.15352v1</a></p>
<p><b>Compressor summary</b>: SMART is a mnemonic generator that learns from students' preferences and feedback to create effective mnemonics for learning new terms.</p><hr><h3>NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and  Benchmarking</h3>
<p><a href='http://arxiv.org/abs/2406.15349v1'>http://arxiv.org/abs/2406.15349v1</a></p>
<p><b>Compressor summary</b>: NAVSIM is a non-reactive simulator that uses large datasets to benchmark vision-based driving policies in a middle ground between open-loop and closed-loop evaluation, enabling large-scale real-world benchmarking and a new competition at CVPR 2024.</p><hr><h3>GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene  Expression Data in Alignment with Bioinformaticians</h3>
<p><a href='http://arxiv.org/abs/2406.15341v1'>http://arxiv.org/abs/2406.15341v1</a></p>
<p><b>Compressor summary</b>: GenoTEX is a benchmark dataset for evaluating and developing LLM-based agents to automatically explore gene expression data for disease association identification.</p><hr><h3>Image Conductor: Precision Control for Interactive Video Synthesis</h3>
<p><a href='http://arxiv.org/abs/2406.15339v1'>http://arxiv.org/abs/2406.15339v1</a></p>
<p><b>Compressor summary</b>: Image Conductor is a method for generating precise and controllable camera transitions and object movements from a single image, using a well-cultivated training strategy and a camera-free guidance technique.</p><hr><h3>Keystroke Dynamics Against Academic Dishonesty in the Age of LLMs</h3>
<p><a href='http://arxiv.org/abs/2406.15335v1'>http://arxiv.org/abs/2406.15335v1</a></p>
<p><b>Compressor summary</b>: The study proposes a method to detect cheating using keystroke dynamics in online exams, achieving moderate to high accuracy depending on the scenario.</p><hr><h3>Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning</h3>
<p><a href='http://arxiv.org/abs/2406.15334v1'>http://arxiv.org/abs/2406.15334v1</a></p>
<p><b>Compressor summary</b>: Our method compresses multimodal examples into fewer tokens using implicit representations extracted from attention heads, enabling LMMs to perform better many-shot in-context learning.</p><hr><h3>GeoLRM: Geometry-Aware Large Reconstruction Model for High-Quality 3D  Gaussian Generation</h3>
<p><a href='http://arxiv.org/abs/2406.15333v1'>http://arxiv.org/abs/2406.15333v1</a></p>
<p><b>Compressor summary</b>: GeoLRM is a novel approach that leverages geometric relationships between 3D and 2D images to predict high-quality assets using fewer Gaussians, less memory, and outperforming existing models.</p><hr><h3>Masked Extended Attention for Zero-Shot Virtual Try-On In The Wild</h3>
<p><a href='http://arxiv.org/abs/2406.15331v1'>http://arxiv.org/abs/2406.15331v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method for virtual try-on that uses a diffusion model with extended attention and no extra training, achieving better image quality and garment preservation.</p><hr><h3>Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance</h3>
<p><a href='http://arxiv.org/abs/2406.15330v1'>http://arxiv.org/abs/2406.15330v1</a></p>
<p><b>Compressor summary</b>: Gradient-Mask Tuning (GMT) is a method to improve large language models by selectively updating parameters based on gradient information, leading to better performance across various tasks and greater efficiency.</p><hr><h3>An End-to-End, Segmentation-Free, Arabic Handwritten Recognition Model  on KHATT</h3>
<p><a href='http://arxiv.org/abs/2406.15329v1'>http://arxiv.org/abs/2406.15329v1</a></p>
<p><b>Compressor summary</b>: The paper presents an image-based sequence recognition model that works without segmentation on a large handwritten Arabic text database and has various applications in different fields.</p><hr><h3>Fine-grained Attention in Hierarchical Transformers for Tabular  Time-series</h3>
<p><a href='http://arxiv.org/abs/2406.15327v1'>http://arxiv.org/abs/2406.15327v1</a></p>
<p><b>Compressor summary</b>: Fieldy is a fine-grained hierarchical model for tabular time-series data that uses both row-wise and column-wise attention to learn patterns at the field level, improving performance on regression and classification tasks.</p><hr><h3>Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks</h3>
<p><a href='http://arxiv.org/abs/2406.15325v1'>http://arxiv.org/abs/2406.15325v1</a></p>
<p><b>Compressor summary</b>: The paper introduces BICS, a benchmark to evaluate LLMs' ability to detect syntax bugs in large code, and reveals challenges and disparities among models.</p><hr><h3>Rethinking Remote Sensing Change Detection With A Mask View</h3>
<p><a href='http://arxiv.org/abs/2406.15320v1'>http://arxiv.org/abs/2406.15320v1</a></p>
<p><b>Compressor summary</b>: The paper proposes CDMask and CDMaskFormer, two models for remote sensing change detection that use mask view and adaptive change query to accurately identify changes in complex scenes.</p><hr><h3>LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs</h3>
<p><a href='http://arxiv.org/abs/2406.15319v1'>http://arxiv.org/abs/2406.15319v1</a></p>
<p><b>Compressor summary</b>: LongRAG improves answer retrieval by increasing the unit size and using a long context language model for extraction, achieving state-of-the-art results on NQ and HotpotQA.</p><hr><h3>Learning Spatio-Temporal Patterns of Polar Ice Layers With  Physics-Informed Graph Neural Network</h3>
<p><a href='http://arxiv.org/abs/2406.15299v1'>http://arxiv.org/abs/2406.15299v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a physics-informed hybrid graph neural network to learn and predict spatio-temporal patterns of polar ice layers from thickness data, using weather model measurements as physical node features.</p><hr><h3>NLP-KG: A System for Exploratory Search of Scientific Literature in  Natural Language Processing</h3>
<p><a href='http://arxiv.org/abs/2406.15294v1'>http://arxiv.org/abs/2406.15294v1</a></p>
<p><b>Compressor summary</b>: NLP-KG is a system that helps users explore NLP research literature using semantic search, survey papers, a hierarchy graph, and a chat interface.</p><hr><h3>Pessimistic asynchronous sampling in high-cost Bayesian optimization</h3>
<p><a href='http://arxiv.org/abs/2406.15291v1'>http://arxiv.org/abs/2406.15291v1</a></p>
<p><b>Compressor summary</b>: Asynchronous Bayesian optimization uses parallel experiments to speed up data generation and optimize complex systems with pessimistic predictions.</p><hr><h3>The Greek podcast corpus: Competitive speech models for low-resourced  languages with weakly supervised data</h3>
<p><a href='http://arxiv.org/abs/2406.15284v1'>http://arxiv.org/abs/2406.15284v1</a></p>
<p><b>Compressor summary</b>: The authors create a large corpus of Modern Greek podcasts using weak supervision and show that it improves ASR performance in the language.</p><hr><h3>FT-AED: Benchmark Dataset for Early Freeway Traffic Anomalous Event  Detection</h3>
<p><a href='http://arxiv.org/abs/2406.15283v1'>http://arxiv.org/abs/2406.15283v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a large lane-level freeway traffic dataset for anomaly detection, which could improve emergency response and clearance by reducing delays and errors in event identification and reporting.</p><hr><h3>Cross-Modality Safety Alignment</h3>
<p><a href='http://arxiv.org/abs/2406.15279v1'>http://arxiv.org/abs/2406.15279v1</a></p>
<p><b>Compressor summary</b>: The text introduces a new safety challenge for evaluating cross-modality interactions in AI systems that could lead to unsafe or unethical outputs.</p><hr><h3>Cognitive Map for Language Models: Optimal Planning via Verbally  Representing the World Model</h3>
<p><a href='http://arxiv.org/abs/2406.15275v1'>http://arxiv.org/abs/2406.15275v1</a></p>
<p><b>Compressor summary</b>: The paper explores how language models can improve their planning abilities by constructing a cognitive map of an environment, similar to human thinking.</p><hr><h3>You Only Acquire Sparse-channel (YOAS): A Unified Framework for  Dense-channel EEG Generation</h3>
<p><a href='http://arxiv.org/abs/2406.15269v1'>http://arxiv.org/abs/2406.15269v1</a></p>
<p><b>Compressor summary</b>: The YOAS framework generates dense-channel EEG signals from sparse-channel data by optimizing cross-channel problems, overcoming challenges through four stages, and improving data discernibility.</p><hr><h3>Towards Robust Training Datasets for Machine Learning with Ontologies: A  Case Study for Emergency Road Vehicle Detection</h3>
<p><a href='http://arxiv.org/abs/2406.15268v1'>http://arxiv.org/abs/2406.15268v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using ontologies to check the completeness and quality of ML training data in safety-critical domains like autonomous driving, increasing trust in model decisions.</p><hr><h3>Evaluating Diversity in Automatic Poetry Generation</h3>
<p><a href='http://arxiv.org/abs/2406.15267v1'>http://arxiv.org/abs/2406.15267v1</a></p>
<p><b>Compressor summary</b>: The paper evaluates automatic poetry generation systems and finds they are underdiverse in rhyme, semantics, and length, but style-conditioning and character-level modeling can improve diversity.</p><hr><h3>Perception of Phonological Assimilation by Neural Speech Recognition  Models</h3>
<p><a href='http://arxiv.org/abs/2406.15265v1'>http://arxiv.org/abs/2406.15265v1</a></p>
<p><b>Compressor summary</b>: The article investigates how Wav2Vec2, a neural speech recognition model, compensates for assimilated sounds like [m] in "clea[m] pan" during Automatic Speech Recognition, using linguistic context cues to infer the intended sounds.</p><hr><h3>Fingerprint Membership and Identity Inference Against Generative  Adversarial Networks</h3>
<p><a href='http://arxiv.org/abs/2406.15253v1'>http://arxiv.org/abs/2406.15253v1</a></p>
<p><b>Compressor summary</b>: This paper evaluates the risks of using generative models for biometrics and proposes an attack method on fingerprint datasets created by a generative network.</p><hr><h3>MantisScore: Building Automatic Metrics to Simulate Fine-grained Human  Feedback for Video Generation</h3>
<p><a href='http://arxiv.org/abs/2406.15252v1'>http://arxiv.org/abs/2406.15252v1</a></p>
<p><b>Compressor summary</b>: The paper introduces VideoFeedback, a large-scale dataset for video quality assessment, and MantisScore, a new metric that correlates well with human judges, improving on existing metrics.</p><hr><h3>Open Problem: Order Optimal Regret Bounds for Kernel-Based Reinforcement  Learning</h3>
<p><a href='http://arxiv.org/abs/2406.15250v1'>http://arxiv.org/abs/2406.15250v1</a></p>
<p><b>Compressor summary</b>: The text discusses the theoretical aspects of reinforcement learning, focusing on non-linear function approximation using kernel-based prediction, and the need for better performance guarantees in this case.</p><hr><h3>Unsupervised Morphological Tree Tokenizer</h3>
<p><a href='http://arxiv.org/abs/2406.15245v1'>http://arxiv.org/abs/2406.15245v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a deep learning approach to tokenize text with morphological structure guidance, which improves semantic information and outperforms existing methods on language modeling tasks.</p><hr><h3>Large Batch Analysis for Adagrad Under Anisotropic Smoothness</h3>
<p><a href='http://arxiv.org/abs/2406.15244v1'>http://arxiv.org/abs/2406.15244v1</a></p>
<p><b>Compressor summary</b>: The paper analyzes the convergence properties of Adagrad, an adaptive gradient algorithm, on smooth objective functions for large batch sizes, and shows its advantages over SGD in theory and practice.</p><hr><h3>Detecting Synthetic Lyrics with Few-Shot Inference</h3>
<p><a href='http://arxiv.org/abs/2406.15231v1'>http://arxiv.org/abs/2406.15231v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new dataset for detecting generated lyrics in music and evaluates various methods, showing that LLM2Vec outperforms previous approaches.</p><hr><h3>ExDAG: Exact learning of DAGs</h3>
<p><a href='http://arxiv.org/abs/2406.15229v1'>http://arxiv.org/abs/2406.15229v1</a></p>
<p><b>Compressor summary</b>: ExDAG is a new method for learning causal structures from data using mixed-integer quadratic programming that performs well in identifying DAGs with up to 50 vertices and outperforms existing solvers.</p><hr><h3>A LLM-Based Ranking Method for the Evaluation of Automatic  Counter-Narrative Generation</h3>
<p><a href='http://arxiv.org/abs/2406.15227v1'>http://arxiv.org/abs/2406.15227v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to evaluate and generate counter narratives using large language models, which achieve high correlation with human judgments.</p><hr><h3>Deep UAV Path Planning with Assured Connectivity in Dense Urban Setting</h3>
<p><a href='http://arxiv.org/abs/2406.15225v1'>http://arxiv.org/abs/2406.15225v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Deep Reinforcement Learning framework for planning UAV paths with good cellular network connectivity in urban scenarios.</p><hr><h3>Unsupervised Extraction of Dialogue Policies from Conversations</h3>
<p><a href='http://arxiv.org/abs/2406.15214v1'>http://arxiv.org/abs/2406.15214v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to extract and generate dialogue policies from conversational data using large language models and graph-based techniques for improved task-oriented dialogue systems.</p><hr><h3>Injecting Bias in Text-To-Image Models via Composite-Trigger Backdoors</h3>
<p><a href='http://arxiv.org/abs/2406.15213v1'>http://arxiv.org/abs/2406.15213v1</a></p>
<p><b>Compressor summary</b>: This paper shows how to inject biases into text-conditional image generative models with a backdoor that activates when triggered by specific words, highlighting the challenges of detecting and preventing such attacks.</p><hr><h3>How Effective is GPT-4 Turbo in Generating School-Level Questions from  Textbooks Based on Bloom's Revised Taxonomy?</h3>
<p><a href='http://arxiv.org/abs/2406.15211v1'>http://arxiv.org/abs/2406.15211v1</a></p>
<p><b>Compressor summary</b>: GPT-4 Turbo generates educational questions that require higher-order thinking skills, but its effectiveness varies by cognitive level and human evaluation.</p><hr><h3>Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in  Enhancing ADHD Therapy: Innovating Treatment Paradigms</h3>
<p><a href='http://arxiv.org/abs/2406.15198v1'>http://arxiv.org/abs/2406.15198v1</a></p>
<p><b>Compressor summary</b>: The study explores using advanced language models in robot-assisted therapy for ADHD, finding that ChatGPT-4 Turbo performs better for time-sensitive applications, while Claude-3 Opus prioritizes safe and engaging interactions.</p><hr><h3>Reward Steering with Evolutionary Heuristics for Decoding-time Alignment</h3>
<p><a href='http://arxiv.org/abs/2406.15193v1'>http://arxiv.org/abs/2406.15193v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to align LLM responses with user preferences by decoupling exploration and exploitation and using an evolutionary approach, which performs better than existing methods on two benchmarks.</p><hr><h3>Causal Learning in Biomedical Applications</h3>
<p><a href='http://arxiv.org/abs/2406.15189v1'>http://arxiv.org/abs/2406.15189v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a test for evaluating how well methods learn causality from time-series data, using the Krebs cycle and other metabolic models as examples.</p><hr><h3>UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world  Document Analysis</h3>
<p><a href='http://arxiv.org/abs/2406.15187v1'>http://arxiv.org/abs/2406.15187v1</a></p>
<p><b>Compressor summary</b>: The paper introduces UDA, a benchmark suite for evaluating LLMs and RAGs on real-world unstructured documents with expert-annotated Q&A pairs, highlighting the importance of parsing and retrieval.</p><hr><h3>DiffExplainer: Unveiling Black Box Models Via Counterfactual Generation</h3>
<p><a href='http://arxiv.org/abs/2406.15182v1'>http://arxiv.org/abs/2406.15182v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to generate counterfactual images that reveal influential features for AI model predictions, improving the reliability of medical image classification.</p><hr><h3>Hybrid Alignment Training for Large Language Models</h3>
<p><a href='http://arxiv.org/abs/2406.15178v1'>http://arxiv.org/abs/2406.15178v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Hybrid Alignment Training (Hbat) method for large language models that alternates between instruction-following and human-preference alignment, improving their performance on summarization and dialogue tasks.</p>