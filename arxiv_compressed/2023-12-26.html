
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2023-12-26</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2023-12-26 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>MACS: Mass Conditioned 3D Hand and Object Motion Synthesis</h3>
<p>Soshi Shimada,Franziska Mueller,Jan Bednarik,Bardia Doosti,Bernd Bickel,Danhang Tang,Vladislav Golyanik,Jonathan Taylor,Christian Theobalt,Thabo Beeler</p>
<p><a href='http://arxiv.org/abs/2312.14929v1'>http://arxiv.org/abs/2312.14929v1</a></p>
<p><b>Compressor summary</b>: MACS is a new approach for synthesizing natural 3D hand and object motions based on object mass and interaction type, which can be used for various applications such as generating training data, fast animation, and character interactions in computer games.</p><hr><h3>A Survey of Reinforcement Learning from Human Feedback</h3>
<p>Timo Kaufmann,Paul Weng,Viktor Bengs,Eyke Hüllermeier</p>
<p><a href='http://arxiv.org/abs/2312.14925v1'>http://arxiv.org/abs/2312.14925v1</a></p>
<p><b>Compressor summary</b>: RLHF is a technique that learns from human feedback to enhance AI performance and align its objectives with human values, with applications ranging from language models to various other domains.</p><hr><h3>Training Convolutional Neural Networks with the Forward-Forward  algorithm</h3>
<p>Riccardo Scodellaro,Ajinkya Kulkarni,Frauke Alves,Matthias Schröter</p>
<p><a href='http://arxiv.org/abs/2312.14924v1'>http://arxiv.org/abs/2312.14924v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new training method for Convolutional Neural Networks (CNNs) using the Forward Forward (FF) algorithm and achieves 99.0% accuracy on MNIST dataset with a novel labeling technique.</p><hr><h3>Fast-NTK: Parameter-Efficient Unlearning for Large-Scale Models</h3>
<p>Guihong Li,Hsiang Hsu,Chun-Fu Chen,Radu Marculescu</p>
<p><a href='http://arxiv.org/abs/2312.14923v1'>http://arxiv.org/abs/2312.14923v1</a></p>
<p><b>Compressor summary</b>: Fast-NTK is a novel algorithm that allows selective data removal from large-scale neural networks without retraining, reducing computational complexity by incorporating parameter-efficient fine-tuning methods.</p><hr><h3>A Novel Sampled Clustering Algorithm for Rice Phenotypic Data</h3>
<p>Mithun Singh,Kapil Ahuja,Milind B. Ratnaparkhe</p>
<p><a href='http://arxiv.org/abs/2312.14920v1'>http://arxiv.org/abs/2312.14920v1</a></p>
<p><b>Compressor summary</b>: The authors improve a spectral clustering algorithm for rice species by modifying the similarity matrix construction and scaling factor, resulting in better accuracy and speed compared to hierarchical clustering.</p><hr><h3>Lift-Attend-Splat: Bird's-eye-view camera-lidar fusion using  transformers</h3>
<p>James Gunn,Zygmunt Lenyk,Anuj Sharma,Andrea Donati,Alexandru Buburuzan,John Redford,Romain Mueller</p>
<p><a href='http://arxiv.org/abs/2312.14919v1'>http://arxiv.org/abs/2312.14919v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel fusion method for autonomous driving that bypasses monocular depth estimation and uses attention to select and fuse camera and lidar features in a bird's-eye-view grid, leading to better 3D object detection.</p><hr><h3>PoseGen: Learning to Generate 3D Human Pose Dataset with NeRF</h3>
<p>Mohsen Gholami,Rabab Ward,Z. Jane Wang</p>
<p><a href='http://arxiv.org/abs/2312.14915v1'>http://arxiv.org/abs/2312.14915v1</a></p>
<p><b>Compressor summary</b>: PoseGen uses NeRFs to generate diverse 3D human pose datasets, which improve the robustness of pre-trained pose estimators when applied to out-of-distribution samples.</p><hr><h3>FAST: Feature Aware Similarity Thresholding for Weak Unlearning in  Black-Box Generative Models</h3>
<p>Subhodip Panda,Prathosh AP</p>
<p><a href='http://arxiv.org/abs/2312.14895v1'>http://arxiv.org/abs/2312.14895v1</a></p>
<p><b>Compressor summary</b>: The text discusses the need for precise control over deep generative models, especially when they generate harmful content, and proposes a method called FAST that filters out unwanted features in black-box systems.</p><hr><h3>Theory of Hallucinations based on Equivariance</h3>
<p>Hisaichi Shibata</p>
<p><a href='http://arxiv.org/abs/2312.14504v1'>http://arxiv.org/abs/2312.14504v1</a></p>
<p><b>Compressor summary</b>: The text proposes a new theory that links insufficient equivarity in language models to hallucinations, and presents a novel technique based on T5 model to test this theory on a toy model.</p><hr><h3>ViStripformer: A Token-Efficient Transformer for Versatile Video  Restoration</h3>
<p>Fu-Jen Tsai,Yan-Tsung Peng,Chen-Yu Chang,Chan-Yu Li,Yen-Yu Lin,Chung-Chi Tsai,Chia-Wen Lin</p>
<p><a href='http://arxiv.org/abs/2312.14502v1'>http://arxiv.org/abs/2312.14502v1</a></p>
<p><b>Compressor summary</b>: ViStripformer is a video restoration method that uses strip attention to capture spatial and temporal information, outperforming traditional transformers in efficiency and effectiveness.</p><hr><h3>Hutchinson Trace Estimation for High-Dimensional and High-Order  Physics-Informed Neural Networks</h3>
<p>Zheyuan Hu,Zekun Shi,George Em Karniadakis,Kenji Kawaguchi</p>
<p><a href='http://arxiv.org/abs/2312.14499v1'>http://arxiv.org/abs/2312.14499v1</a></p>
<p><b>Compressor summary</b>: The text introduces Hutchinson Trace Estimation (HTE), which improves the performance of Physics-Informed Neural Networks (PINNs) when solving high-dimensional and high-order partial differential equations (PDEs) by reducing computational cost and memory consumption.</p><hr><h3>Context Enhanced Transformer for Single Image Object Detection</h3>
<p>Seungjun An,Seonghoon Park,Gyeongnyeon Kim,Jeongyeol Baek,Byeongwon Lee,Seungryong Kim</p>
<p><a href='http://arxiv.org/abs/2312.14492v1'>http://arxiv.org/abs/2312.14492v1</a></p>
<p><b>Compressor summary</b>: The paper proposes CETR, a single image object detection method that incorporates temporal context from videos using a memory module.</p><hr><h3>Language Model is a Branch Predictor for Simultaneous Machine  Translation</h3>
<p>Aoxiong Yin,Tianyun Zhong,Haoyuan Li,Siliang Tang,Zhou Zhao</p>
<p><a href='http://arxiv.org/abs/2312.14488v1'>http://arxiv.org/abs/2312.14488v1</a></p>
<p><b>Compressor summary</b>: The paper proposes using branch prediction techniques from CPUs to reduce translation latency in simultaneous machine translation, while preserving quality by predicting future source words and decoding output accordingly.</p><hr><h3>Part to Whole: Collaborative Prompting for Surgical Instrument  Segmentation</h3>
<p>Wenxi Yue,Jing Zhang,Kun Hu,Qiuxia Wu,Zongyuan Ge,Yong Xia,Jiebo Luo,Zhiyong Wang</p>
<p><a href='http://arxiv.org/abs/2312.14481v1'>http://arxiv.org/abs/2312.14481v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method, SP-SAM, for segmenting surgical instruments using text prompts and joint visual embeddings to better understand instrument structures and categories.</p><hr><h3>MonoLSS: Learnable Sample Selection For Monocular 3D Detection</h3>
<p>Zhenjia Li,Jinrang Jia,Yifeng Shi</p>
<p><a href='http://arxiv.org/abs/2312.14474v1'>http://arxiv.org/abs/2312.14474v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve monocular 3D detection of cars, cyclists, and pedestrians by selecting suitable samples adaptively using a Learnable Sample Selection module and enriching data with MixUp3D.</p><hr><h3>Not All Tasks Are Equally Difficult: Multi-Task Reinforcement Learning  with Dynamic Depth Routing</h3>
<p>Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng</p>
<p><a href='http://arxiv.org/abs/2312.14472v1'>http://arxiv.org/abs/2312.14472v1</a></p>
<p><b>Compressor summary</b>: Dynamic Depth Routing (D2R) is a framework that learns to flexibly adjust the number of modules used for different tasks in multi-task reinforcement learning, improving data efficiency and performance on robotics manipulation tasks.</p><hr><h3>Prototype-based Cross-Modal Object Tracking</h3>
<p>Lei Liu,Chenglong Li,Futian Wang,Longfeng Shen,Jin Tang</p>
<p><a href='http://arxiv.org/abs/2312.14471v1'>http://arxiv.org/abs/2312.14471v1</a></p>
<p><b>Compressor summary</b>: ProtoTrack is a cross-modal object tracker that adapts to target appearance variations using multi-modal prototypes and generates them with novel algorithms.</p><hr><h3>Safe Reinforcement Learning with Instantaneous Constraints: The Role of  Aggressive Exploration</h3>
<p>Honghao Wei,Xin Liu,Lei Ying</p>
<p><a href='http://arxiv.org/abs/2312.14470v1'>http://arxiv.org/abs/2312.14470v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a safe Reinforcement Learning algorithm that handles hard instantaneous constraints without knowing a safe action set or a safe graph, and works for general cost functions in Reproducing Kernel Hilbert Space.</p><hr><h3>FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for  Open-Vocabulary 3D Detection</h3>
<p>Dongmei Zhang,Chang Li,Ray Zhang,Shenghao Xie,Wei Xue,Xiaodong Xie,Shanghang Zhang</p>
<p><a href='http://arxiv.org/abs/2312.14465v1'>http://arxiv.org/abs/2312.14465v1</a></p>
<p><b>Compressor summary</b>: The paper proposes FM-OV3D, a method that blends knowledge from multiple pre-trained foundation models to improve open-vocabulary 3D detection tasks without dataset constraints.</p><hr><h3>How to Overcome Curse-of-Dimensionality for Out-of-Distribution  Detection?</h3>
<p>Soumya Suvra Ghosal,Yiyou Sun,Yixuan Li</p>
<p><a href='http://arxiv.org/abs/2312.14452v1'>http://arxiv.org/abs/2312.14452v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new OOD detection method called Subspace Nearest Neighbor (SNN) that uses subspace learning to reduce the curse-of-dimensionality and improve distance-based detection.</p><hr><h3>PUMA: Efficient Continual Graph Learning with Graph Condensation</h3>
<p>Yilun Liu,Ruihong Qiu,Yanran Tang,Hongzhi Yin,Zi Huang</p>
<p><a href='http://arxiv.org/abs/2312.14439v1'>http://arxiv.org/abs/2312.14439v1</a></p>
<p><b>Compressor summary</b>: The paper proposes PUMA, a memory bank for graph representation learning that condenses both labelled and unlabelled nodes, uses training-from-scratch, and prorogation to improve efficiency and effectiveness.</p><hr><h3>PC-Conv: Unifying Homophily and Heterophily with Two-fold Filtering</h3>
<p>Bingheng Li,Erlin Pan,Zhao Kang</p>
<p><a href='http://arxiv.org/abs/2312.14438v1'>http://arxiv.org/abs/2312.14438v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a two-fold filtering mechanism to extract homophily in heterophilic and vice versa, using graph heat equation and Possion-Charlier polynomials, and applies it to node classification with PCNet.</p><hr><h3>Scalable 3D Reconstruction From Single Particle X-Ray Diffraction Images  Based on Online Machine Learning</h3>
<p>Jay Shenoy,Axel Levy,Frédéric Poitevin,Gordon Wetzstein</p>
<p><a href='http://arxiv.org/abs/2312.14432v1'>http://arxiv.org/abs/2312.14432v1</a></p>
<p><b>Compressor summary</b>: X-RAI is a new online framework for reconstructing 3D structures of biomolecules from large X-ray free-electron laser datasets, enabling real-time capture and analysis of fleeting states under near-physiological conditions.</p><hr><h3>A Unified Industrial Large Knowledge Model Framework in Smart  Manufacturing</h3>
<p>Jay Lee,Hanqi Su</p>
<p><a href='http://arxiv.org/abs/2312.14428v1'>http://arxiv.org/abs/2312.14428v1</a></p>
<p><b>Compressor summary</b>: This paper introduces ILKMs, a framework to apply large language models in industry 4.0 and smart manufacturing by incorporating domain-specific knowledge, and compares them with LLMs using eight perspectives.</p><hr><h3>GROOD: GRadient-aware Out-Of-Distribution detection in interpolated  manifolds</h3>
<p>Mostafa ElAraby,Sabyasachi Sahoo,Yann Pequignot,Paul Novello,Liam Paull</p>
<p><a href='http://arxiv.org/abs/2312.14427v1'>http://arxiv.org/abs/2312.14427v1</a></p>
<p><b>Compressor summary</b>: GROOD is a novel framework that uses gradient space and class prototypes to distinguish between in-distribution and out-of-distribution samples in image classification tasks, improving robustness against over-confident predictions.</p><hr><h3>Efficacy of Machine-Generated Instructions</h3>
<p>Samaksh Gulati,Anshit Verma,Manoj Parmar,Palash Chaudhary</p>
<p><a href='http://arxiv.org/abs/2312.14423v1'>http://arxiv.org/abs/2312.14423v1</a></p>
<p><b>Compressor summary</b>: The study shows that machine-generated annotations can be a more efficient alternative to human-written instructions for fine-tuning language models.</p><hr><h3>Enhancing Actionable Formal Concept Identification with Base-Equivalent  Conceptual-Relevance</h3>
<p>Ayao Bobi,Rokia Missaoui,Mohamed Hamza Ibrahim</p>
<p><a href='http://arxiv.org/abs/2312.14421v1'>http://arxiv.org/abs/2312.14421v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new measure, BECR, for identifying important concepts in large data sets using formal concept analysis, based on the number of base and equivalent attributes and minimal generators per concept intent.</p><hr><h3>A Multi-Stage Adaptive Feature Fusion Neural Network for Multimodal Gait  Recognition</h3>
<p>Shinan Zou,Jianbo Xiong,Chao Fan,Shiqi Yu,Jin Tang</p>
<p><a href='http://arxiv.org/abs/2312.14410v1'>http://arxiv.org/abs/2312.14410v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel multimodal gait recognition algorithm that exploits the complementary advantages of multiple modalities using a multi-stage feature fusion strategy, an adaptive feature fusion module, and a multiscale spatial-temporal feature extractor.</p><hr><h3>AdvCloak: Customized Adversarial Cloak for Privacy Protection</h3>
<p>Xuannan Liu,Yaoyao Zhong,Xing Cui,Yuhang Zhang,Peipei Li,Weihong Deng</p>
<p><a href='http://arxiv.org/abs/2312.14407v1'>http://arxiv.org/abs/2312.14407v1</a></p>
<p><b>Compressor summary</b>: AdvCloak is a framework that protects privacy by automatically generating personalized adversarial masks for faces using generative models, achieving high naturalness and generalization ability.</p><hr><h3>Generative Pretraining at Scale: Transformer-Based Encoding of  Transactional Behavior for Fraud Detection</h3>
<p>Ze Yu Zhao,Zheng Zhu,Guilin Li,Wenhan Wang,Bo Wang</p>
<p><a href='http://arxiv.org/abs/2312.14406v1'>http://arxiv.org/abs/2312.14406v1</a></p>
<p><b>Compressor summary</b>: Key points:
- Autoregressive model using GPT for fraud detection in payment systems
- Confronts token explosion and reconstructs behavioral sequences
- No need for labeled data, uses unsupervised pretraining
- Integrates differential convolutional approach for anomaly detection
- Applicable in various transactional contexts

Summary:
The authors propose a novel GPT-based autoregressive model that detects fraud in payment systems by representing transactions without labels and enhancing anomaly detection with differential convolution.</p><hr><h3>Graph Attention-Based Symmetry Constraint Extraction for Analog Circuits</h3>
<p>Qi Xu,Lijie Wang,Jing Wang,Song Chen,Lin Cheng,Yi Kang</p>
<p><a href='http://arxiv.org/abs/2312.14405v1'>http://arxiv.org/abs/2312.14405v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a graph-based learning framework to automatically extract symmetric constraints in analog circuit layout, improving performance and reducing runtime compared to existing methods.</p><hr><h3>Cross-Covariate Gait Recognition: A Benchmark</h3>
<p>Shinan Zou,Chao Fan,Jianbo Xiong,Chuanfu Shen,Shiqi Yu,Jin Tang</p>
<p><a href='http://arxiv.org/abs/2312.14404v1'>http://arxiv.org/abs/2312.14404v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new large and diverse gait dataset (CCGR) and proposes a parsing-based approach for cross-covariate gait recognition, which is a challenging but important problem in gait research.</p><hr><h3>The Fairness Fair: Bringing Human Perception into Collective  Decision-Making</h3>
<p>Hadi Hosseini</p>
<p><a href='http://arxiv.org/abs/2312.14402v1'>http://arxiv.org/abs/2312.14402v1</a></p>
<p><b>Compressor summary</b>: This text discusses the importance of studying fairness in collective decision-making from various perspectives, including human perception, cognition, and interaction with AI, to better capture its complexities in real-world problems.</p><hr><h3>Unveiling Backbone Effects in CLIP: Exploring Representational Synergies  and Variances</h3>
<p>Cristian Rodriguez-Opazo,Edison Marrese-Taylor,Ehsan Abbasnejad,Hamed Damirchi,Ignacio M. Jara,Felipe Bravo-Marquez,Anton van den Hengel</p>
<p><a href='http://arxiv.org/abs/2312.14400v1'>http://arxiv.org/abs/2312.14400v1</a></p>
<p><b>Compressor summary</b>: The paper investigates how different neural architectures perform with CLIP and proposes a method to combine their predictions for better image classification.</p><hr><h3>Unsupervised Deep Learning Image Verification Method</h3>
<p>Enoch Solomon,Abraham Woubie,Eyael Solomon Emiru</p>
<p><a href='http://arxiv.org/abs/2312.14395v1'>http://arxiv.org/abs/2312.14395v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method to improve face verification using an autoencoder that converts face vectors into a novel representation by reconstructing neighboring face vectors based on cosine similarity, achieving a 56% relative improvement in EER over the baseline system.</p><hr><h3>AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent  Trajectory Prediction</h3>
<p>Tangwen Qian,Yile Chen,Gao Cong,Yongjun Xu,Fei Wang</p>
<p><a href='http://arxiv.org/abs/2312.14394v1'>http://arxiv.org/abs/2312.14394v1</a></p>
<p><b>Compressor summary</b>: AdapTraj is a new framework for multi-agent trajectory prediction that leverages multiple source domains and uses a causal formulation to model domain-invariant and domain-specific features, improving performance over existing methods.</p><hr><h3>StyleRetoucher: Generalized Portrait Image Retouching with GAN Priors</h3>
<p>Wanchao Su,Can Wang,Chen Liu,Hangzhou Han,Hongbo Fu,Jing Liao</p>
<p><a href='http://arxiv.org/abs/2312.14389v1'>http://arxiv.org/abs/2312.14389v1</a></p>
<p><b>Compressor summary</b>: StyleRetoucher is a novel automatic portrait image retouching framework that uses StyleGAN's generation and generalization ability to improve skin condition while preserving facial details, outperforming existing solutions.</p><hr><h3>Variance-insensitive and Target-preserving Mask Refinement for  Interactive Image Segmentation</h3>
<p>Chaowei Fang,Ziyin Zhou,Junye Chen,Hanjing Su,Qingyao Wu,Guanbin Li</p>
<p><a href='http://arxiv.org/abs/2312.14387v1'>http://arxiv.org/abs/2312.14387v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to improve point-based interactive image segmentation by refining the initial mask with consistent inferences and target-preserving zooming, achieving state-of-the-art results on various datasets.</p><hr><h3>Multimodal Attention Merging for Improved Speech Recognition and Audio  Event Classification</h3>
<p>Anirudh S. Sundar,Chao-Han Huck Yang,David M. Chan,Shalini Ghosh,Venkatesh Ravichandran,Phani Sankar Nidadavolu</p>
<p><a href='http://arxiv.org/abs/2312.14378v1'>http://arxiv.org/abs/2312.14378v1</a></p>
<p><b>Compressor summary</b>: MAM is a method that transfers knowledge from text and image models to speech and audio models using attention matrices, improving their performance on downstream tasks.</p><hr><h3>Learning Socio-Temporal Graphs for Multi-Agent Trajectory Prediction</h3>
<p>Yuke Li,Lixiong Chen,Guangyi Chen,Ching-Yao Chan,Kun Zhang,Stefano Anzellotti,Donglai Wei</p>
<p><a href='http://arxiv.org/abs/2312.14373v1'>http://arxiv.org/abs/2312.14373v1</a></p>
<p><b>Compressor summary</b>: The paper proposes STGformer, an attention-based model that captures pair-wise socio-temporal interactions among pedestrians using Directed Acyclic Graphs and achieves state-of-the-art prediction accuracy in trajectory prediction.</p><hr><h3>Training Neural Networks with Internal State, Unconstrained  Connectivity, and Discrete Activations</h3>
<p>Alexander Grushin</p>
<p><a href='http://arxiv.org/abs/2312.14359v1'>http://arxiv.org/abs/2312.14359v1</a></p>
<p><b>Compressor summary</b>: The paper explores the possibility of training machine learning models with internal state using binary activations and few layers, and proposes a new algorithm to do so, while discussing its limitations and potential benefits.</p><hr><h3>Don't Believe Everything You Read: Enhancing Summarization  Interpretability through Automatic Identification of Hallucinations in Large  Language Models</h3>
<p>Priyesh Vakharia,Devavrat Joshi,Meenal Chavan,Dhananjay Sonawane,Bhrigu Garg,Parsa Mazaheri,Ian Lane</p>
<p><a href='http://arxiv.org/abs/2312.14346v1'>http://arxiv.org/abs/2312.14346v1</a></p>
<p><b>Compressor summary</b>: The paper investigates LLM hallucinations, proposes a token-level approach to identify them, and applies it to improve dialogue summarization's interpretability and reliability.</p><hr><h3>Logic-Scaffolding: Personalized Aspect-Instructed Recommendation  Explanation Generation using LLMs</h3>
<p>Behnam Rahdari,Hao Ding,Ziwei Fan,Yifei Ma,Zhuotong Chen,Anoop Deoras,Branislav Kveton</p>
<p><a href='http://arxiv.org/abs/2312.14345v1'>http://arxiv.org/abs/2312.14345v1</a></p>
<p><b>Compressor summary</b>: Logic-Scaffolding is a framework that uses aspect-based explanation and chain-of-thought prompting to help Large Language Models generate reliable zero-shot explanations through intermediate reasoning steps.</p>