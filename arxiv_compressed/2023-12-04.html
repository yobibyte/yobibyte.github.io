
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
<a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center" width=50%></a>
            <h1>arxiv compressed, 2023-12-04</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on 2023-12-04 generated by the compressor, my personal LLM-based project.</p>
    <hr><h3>Dense Optical Tracking: Connecting the Dots</h3>
<p>Guillaume Le Moing,Jean Ponce,Cordelia Schmid</p>
<p><a href='http://arxiv.org/abs/2312.00786v1'>http://arxiv.org/abs/2312.00786v1</a></p>
<p><b>Compressor summary</b>: DOT is a fast point tracking method that uses key regions, nearest-neighbor interpolation, and a learnable optical flow estimator to handle occlusions and outperforms existing techniques while being much faster.</p><hr><h3>Sequential Modeling Enables Scalable Learning for Large Vision Models</h3>
<p>Yutong Bai,Xinyang Geng,Karttikeya Mangalam,Amir Bar,Alan Yuille,Trevor Darrell,Jitendra Malik,Alexei A Efros</p>
<p><a href='http://arxiv.org/abs/2312.00785v1'>http://arxiv.org/abs/2312.00785v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces a novel method to train a large vision model using visual sentences without linguistic data and shows it can handle various tasks with different prompts.</p><hr><h3>Making Large Multimodal Models Understand Arbitrary Visual Prompts</h3>
<p>Mu Cai,Haotian Liu,Siva Karthik Mustikovela,Gregory P. Meyer,Yuning Chai,Dennis Park,Yong Jae Lee</p>
<p><a href='http://arxiv.org/abs/2312.00784v1'>http://arxiv.org/abs/2312.00784v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces a new multimodal model that can understand user-friendly visual prompts like colored boxes or arrows on images and performs well on region-understanding tasks.</p><hr><h3>MorpheuS: Neural Dynamic 360Â° Surface Reconstruction from Monocular  RGB-D Video</h3>
<p>Hengyi Wang,Jingwen Wang,Lourdes Agapito</p>
<p><a href='http://arxiv.org/abs/2312.00778v1'>http://arxiv.org/abs/2312.00778v1</a></p>
<p><b>Compressor summary</b>: MorpheuS is a framework for reconstructing dynamic, deformable objects in 360 degrees from casually captured RGB-D videos using neural representations and a view-dependent diffusion prior.</p><hr><h3>VideoBooth: Diffusion-based Video Generation with Image Prompts</h3>
<p>Yuming Jiang,Tianxing Wu,Shuai Yang,Chenyang Si,Dahua Lin,Yu Qiao,Chen Change Loy,Ziwei Liu</p>
<p><a href='http://arxiv.org/abs/2312.00777v1'>http://arxiv.org/abs/2312.00777v1</a></p>
<p><b>Compressor summary</b>: VideoBooth is a video generation framework that uses image prompts to create customized and high-quality videos with coarse-to-fine embeddings and cross-frame attention layers.</p><hr><h3>Context Retrieval via Normalized Contextual Latent Interaction for  Conversational Agent</h3>
<p>Junfeng Liu,Zhuocheng Mei,Kewen Peng,Ranga Raju Vatsavai</p>
<p><a href='http://arxiv.org/abs/2312.00774v1'>http://arxiv.org/abs/2312.00774v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new method, PK-NCLI, that uses low-level normalized contextual latent interaction to efficiently identify relevant auxiliary information for improving conversational agents' responses and outperforms the existing state-of-the-art method, PK-FoCus.</p><hr><h3>Automated Material Properties Extraction For Enhanced Beauty Product  Discovery and Makeup Virtual Try-on</h3>
<p>Fatemeh Taheri Dezaki,Himanshu Arora,Rahul Suresh,Amin Banitalebi-Dehkordi</p>
<p><a href='http://arxiv.org/abs/2312.00766v1'>http://arxiv.org/abs/2312.00766v1</a></p>
<p><b>Compressor summary</b>: The paper introduces an automated pipeline using machine learning to extract material attributes from makeup product images, enhancing product discovery and virtual try-on experiences.</p><hr><h3>Explaining Knock-on Effects of Bias Mitigation</h3>
<p>Svetoslav Nizhnichenkov,Rahul Nair,Elizabeth Daly,Brian Mac Namee</p>
<p><a href='http://arxiv.org/abs/2312.00765v1'>http://arxiv.org/abs/2312.00765v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an explainable meta-classifier to identify cohorts affected by bias mitigation strategies, and shows that some mitigation methods negatively impact certain groups even with improved fairness metrics.</p><hr><h3>Deep Unlearning: Fast and Efficient Training-free Approach to Controlled  Forgetting</h3>
<p>Sangamesh Kodge,Gobinda Saha,Kaushik Roy</p>
<p><a href='http://arxiv.org/abs/2312.00761v1'>http://arxiv.org/abs/2312.00761v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new algorithm for machine unlearning that strategically removes classes from a model using novel spaces and a singular value decomposition-based technique, achieving good performance and efficiency in retaining accuracy and improving privacy against attacks.</p><hr><h3>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</h3>
<p>Albert Gu,Tri Dao</p>
<p><a href='http://arxiv.org/abs/2312.00752v1'>http://arxiv.org/abs/2312.00752v1</a></p>
<p><b>Compressor summary</b>: Mamba is a fast and scalable sequence model that uses selective structured state space models for content-based reasoning and achieves state-of-the-art performance on various modalities.</p><hr><h3>Mitigating Over-smoothing in Transformers via Regularized Nonlocal  Functionals</h3>
<p>Tam Nguyen,Tan M. Nguyen,Richard G. Baraniuk</p>
<p><a href='http://arxiv.org/abs/2312.00751v1'>http://arxiv.org/abs/2312.00751v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new type of transformer model that reduces token representation over-smoothing by penalizing the difference between input and output tokens using self-attention.</p><hr><h3>Deciphering Digital Detectives: Understanding LLM Behaviors and  Capabilities in Multi-Agent Mystery Games</h3>
<p>Dekun Wu,Haochen Shi,Zhiyuan Sun,Bang Liu</p>
<p><a href='http://arxiv.org/abs/2312.00746v1'>http://arxiv.org/abs/2312.00746v1</a></p>
<p><b>Compressor summary</b>: The study explores using Large Language Models (LLMs) in Chinese murder mystery role-playing games, introducing a new dataset and framework to improve AI agent performance and evaluation.</p><hr><h3>Adversarial Score Distillation: When score distillation meets GAN</h3>
<p>Min Wei,Jingkai Zhou,Junyao Sun,Xuesong Zhang</p>
<p><a href='http://arxiv.org/abs/2312.00739v1'>http://arxiv.org/abs/2312.00739v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new score distillation method (ASD) that improves stability and performance in various tasks by optimizing the discriminator using the Wasserstein Generative Adversarial Network (WGAN) paradigm.</p><hr><h3>SeaLLMs -- Large Language Models for Southeast Asia</h3>
<p>Xuan-Phi Nguyen,Wenxuan Zhang,Xin Li,Mahani Aljunied,Qingyu Tan,Liying Cheng,Guanzheng Chen,Yue Deng,Sen Yang,Chaoqun Liu,Hang Zhang,Lidong Bing</p>
<p><a href='http://arxiv.org/abs/2312.00738v1'>http://arxiv.org/abs/2312.00738v1</a></p>
<p><b>Compressor summary</b>: SeaLLMs are language models for Southeast Asian languages that respect local culture and perform better than ChatGPT in non-Latin languages.</p><hr><h3>Gaussian Grouping: Segment and Edit Anything in 3D Scenes</h3>
<p>Mingqiao Ye,Martin Danelljan,Fisher Yu,Lei Ke</p>
<p><a href='http://arxiv.org/abs/2312.00732v1'>http://arxiv.org/abs/2312.00732v1</a></p>
<p><b>Compressor summary</b>: Gaussian Grouping extends Gaussian Splatting to jointly reconstruct and segment objects in 3D scenes using Identity Encodings, 2D mask predictions, and spatial consistency regularization, enabling versatile scene editing applications.</p><hr><h3>Safe Reinforcement Learning in Tensor Reproducing Kernel Hilbert Space</h3>
<p>Xiaoyuan Cheng,Boli Chen,Liz Varga,Yukun Hu</p>
<p><a href='http://arxiv.org/abs/2312.00727v1'>http://arxiv.org/abs/2312.00727v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a stochastic model-based approach for safe reinforcement learning in partially observable environments using Predictive State Representation and Reproducing Kernel Hilbert Space.</p><hr><h3>Removing Biases from Molecular Representations via Information  Maximization</h3>
<p>Chenyu Wang,Sharut Gupta,Caroline Uhler,Tommi Jaakkola</p>
<p><a href='http://arxiv.org/abs/2312.00718v1'>http://arxiv.org/abs/2312.00718v1</a></p>
<p><b>Compressor summary</b>: InfoCORE is an information maximization method for removing batch effects in drug screening data, improving molecular property prediction and retrieval.</p><hr><h3>SpaCE: The Spatial Confounding Environment</h3>
<p>Mauricio Tec,Ana Trisovic,Michelle Audirac,Sophie Woodward,Naeem Khoshnevis,Francesca Dominici</p>
<p><a href='http://arxiv.org/abs/2312.00710v1'>http://arxiv.org/abs/2312.00710v1</a></p>
<p><b>Compressor summary</b>: SpaCE is a toolkit for assessing causal inference methods in studies with spatial confounding by providing realistic benchmark datasets and tools.</p><hr><h3>PointBeV: A Sparse Approach to BeV Predictions</h3>
<p>Loick Chambon,Eloi Zablocki,Mickael Chen,Florent Bartoccioni,Patrick Perez,Matthieu Cord</p>
<p><a href='http://arxiv.org/abs/2312.00703v1'>http://arxiv.org/abs/2312.00703v1</a></p>
<p><b>Compressor summary</b>: PointBeV is a sparse Bird's-eye View segmentation model that uses sparse cells instead of dense grids, improving memory efficiency and enabling better performance on vehicle, pedestrian, and lane detection tasks.</p><hr><h3>GIFT: Generative Interpretable Fine-Tuning Transformers</h3>
<p>Chinmay Savadikar,Xi Song,Tianfu Wu</p>
<p><a href='http://arxiv.org/abs/2312.00700v1'>http://arxiv.org/abs/2312.00700v1</a></p>
<p><b>Compressor summary</b>: GIFT is a method for fine-tuning Transformer models with built-in interpretability, using a Parameter-to-Cluster Attention mechanism to generate and explain the fine-tuning parameters.</p><hr><h3>Rethinking Detection Based Table Structure Recognition for Visually Rich  Documents</h3>
<p>Bin Xiao,Murat Simsek,Burak Kantarci,Ala Abu Alkheir</p>
<p><a href='http://arxiv.org/abs/2312.00699v1'>http://arxiv.org/abs/2312.00699v1</a></p>
<p><b>Compressor summary</b>: The paragraph discusses limitations of existing table detection methods, compares two-stage and transformer-based models, and identifies key design aspects for improving a two-stage model's performance in table structure recognition tasks.</p><hr><h3>Object Detector Differences when using Synthetic and Real Training Data</h3>
<p>Martin Georg Ljungqvist,Otto Nordander,Markus Skans,Arvid Mildner,Tony Liu,Pierre Nugues</p>
<p><a href='http://arxiv.org/abs/2312.00694v1'>http://arxiv.org/abs/2312.00694v1</a></p>
<p><b>Compressor summary</b>: The paper explores how training a neural network object detector on real vs synthetic data affects each layer using a similarity analysis method, and finds the largest differences in the head part of the network.</p><hr><h3>VisionaryVR: An Optical Simulation Tool for Evaluating and Optimizing  Vision Correction Solutions in Virtual Reality</h3>
<p>Benedikt W. Hosp,Martin Dechant,Yannick Sauer,Rajat Agarwala,Siegfried Wahl</p>
<p><a href='http://arxiv.org/abs/2312.00692v1'>http://arxiv.org/abs/2312.00692v1</a></p>
<p><b>Compressor summary</b>: The study introduces a virtual reality simulation tool for evaluating vision science methods in various real-world scenarios with high control and flexibility.</p><hr><h3>Open-vocabulary object 6D pose estimation</h3>
<p>Jaime Corsetti,Davide Boscaini,Changjae Oh,Andrea Cavallaro,Fabio Poiesi</p>
<p><a href='http://arxiv.org/abs/2312.00690v1'>http://arxiv.org/abs/2312.00690v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a new open-vocabulary object 6D pose estimation method that uses a textual prompt, no object model, and two viewpoints of two different scenes, outperforming existing methods on a new benchmark.</p><hr><h3>Towards Transparency in Coreference Resolution: A Quantum-Inspired  Approach</h3>
<p>Hadi Wazni,Mehrnoosh Sadrzadeh</p>
<p><a href='http://arxiv.org/abs/2312.00688v1'>http://arxiv.org/abs/2312.00688v1</a></p>
<p><b>Compressor summary</b>: The paper presents a Quantum Natural Language Processing system that uses Parametrised Quantum Circuits to perform pronoun resolution tasks and shows its effectiveness compared to classical systems.</p><hr><h3>Contextualized word senses: from attention to compositionality</h3>
<p>Pablo Gamallo</p>
<p><a href='http://arxiv.org/abs/2312.00680v1'>http://arxiv.org/abs/2312.00680v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a transparent and interpretable method for encoding word contexts based on semantic compositionality, and shows that it can compete with Transformers in calculating word sense similarity.</p><hr><h3>The Efficiency Spectrum of Large Language Models: An Algorithmic Survey</h3>
<p>Tianyu Ding,Tianyi Chen,Haidong Zhu,Jiachen Jiang,Yiqi Zhong,Jinxin Zhou,Guangzhi Wang,Zhihui Zhu,Ilya Zharkov,Luming Liang</p>
<p><a href='http://arxiv.org/abs/2312.00678v1'>http://arxiv.org/abs/2312.00678v1</a></p>
<p><b>Compressor summary</b>: The text summarizes a survey of algorithmic advancements to improve the efficiency of Large Language Models (LLMs) in various aspects, such as scaling laws, data utilization, and training strategies.</p><hr><h3>LightCLIP: Learning Multi-Level Interaction for Lightweight  Vision-Language Models</h3>
<p>Ying Nie,Wei He,Kai Han,Yehui Tang,Tianyu Guo,Fanyi Du,Yunhe Wang</p>
<p><a href='http://arxiv.org/abs/2312.00674v1'>http://arxiv.org/abs/2312.00674v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a multi-level alignment and masked language modeling approach to train lightweight CLIP models for vision-language tasks without increasing inference cost.</p><hr><h3>CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous  Cell Populations</h3>
<p>Mehdi Naouar,Gabriel Kalweit,Anusha Klett,Yannick Vogt,Paula Silvestrini,Diana Laura Infante Ramirez,Roland Mertelsmann,Joschka Boedecker,Maria Kalweit</p>
<p><a href='http://arxiv.org/abs/2312.00671v1'>http://arxiv.org/abs/2312.00671v1</a></p>
<p><b>Compressor summary</b>: CellMixer is an annotation-free approach that uses image-level labels to train a segmentation model for identifying different cell types in heterogeneous cell populations.</p><hr><h3>Generalized Label-Efficient 3D Scene Parsing via Hierarchical Feature  Aligned Pre-Training and Region-Aware Fine-tuning</h3>
<p>Kangcheng Liu,Yong-Jin Liu,Kai Tang,Ming Liu,Baoquan Chen</p>
<p><a href='http://arxiv.org/abs/2312.00663v1'>http://arxiv.org/abs/2312.00663v1</a></p>
<p><b>Compressor summary</b>: This paper presents a method to improve 3D scene understanding with limited labels by using pre-trained vision-language models, boundary awareness, and unsupervised learning.</p><hr><h3>Nonparametric Variational Regularisation of Pretrained Transformers</h3>
<p>Fabio Fehr,James Henderson</p>
<p><a href='http://arxiv.org/abs/2312.00662v1'>http://arxiv.org/abs/2312.00662v1</a></p>
<p><b>Compressor summary</b>: The authors propose extending Nonparametric Variational Information Bottleneck (NVIB) to all attention functions in Transformers, which improves out-of-domain generalisation without additional training and suggests that pretrained Transformers are implicitly NV Bayesian models.</p><hr><h3>Resource-constrained knowledge diffusion processes inspired by human  peer learning</h3>
<p>Ehsan Beikihassan,Amy K. Hoover,Ioannis Koutis,Ali Parviz,Niloofar Aghaieabiane</p>
<p><a href='http://arxiv.org/abs/2312.00660v1'>http://arxiv.org/abs/2312.00660v1</a></p>
<p><b>Compressor summary</b>: The paper explores how natural knowledge diffusion processes in networks of artificial learners can optimize performance under resource constraints, inspired by human peer learning.</p><hr><h3>Simple Transferability Estimation for Regression Tasks</h3>
<p>Cuong N. Nguyen,Phong Tran,Lam Si Tung Ho,Vu Dinh,Anh T. Tran,Tal Hassner,Cuong V. Nguyen</p>
<p><a href='http://arxiv.org/abs/2312.00656v1'>http://arxiv.org/abs/2312.00656v1</a></p>
<p><b>Compressor summary</b>: The authors propose two efficient methods for estimating how well deep learning models transfer from one task to another in regression tasks, and show that their methods significantly outperform existing approaches in both accuracy and efficiency.</p><hr><h3>Machine Learning for Health symposium 2023 -- Findings track</h3>
<p>Stefan Hegselmann,Antonio Parziale,Divya Shanmugam,Shengpu Tang,Mercy Nyamewaa Asiedu,Serina Chang,Thomas Hartvigsen,Harvineet Singh</p>
<p><a href='http://arxiv.org/abs/2312.00655v1'>http://arxiv.org/abs/2312.00655v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes the collection of accepted Findings papers from the 3rd Machine Learning for Health symposium (ML4H 2023), which featured health-related topics and two submission tracks, with all submissions undergoing a double-blind peer-review process.</p><hr><h3>TrackDiffusion: Multi-object Tracking Data Generation via Diffusion  Models</h3>
<p>Pengxiang Li,Zhili Liu,Kai Chen,Lanqing Hong,Yunzhi Zhuge,Dit-Yan Yeung,Huchuan Lu,Xu Jia</p>
<p><a href='http://arxiv.org/abs/2312.00651v1'>http://arxiv.org/abs/2312.00651v1</a></p>
<p><b>Compressor summary</b>: The paper introduces TrackDiffusion, a new architecture that generates continuous video sequences from tracklets, improving instance consistency and perceptual metrics, and enabling better training of multi-object tracking systems.</p><hr><h3>SPOT: Self-Training with Patch-Order Permutation for Object-Centric  Learning with Autoregressive Transformers</h3>
<p>Ioannis Kakogeorgiou,Spyros Gidaris,Konstantinos Karantzalos,Nikos Komodakis</p>
<p><a href='http://arxiv.org/abs/2312.00648v1'>http://arxiv.org/abs/2312.00648v1</a></p>
<p><b>Compressor summary</b>: This paper introduces two new techniques to improve slot-based autoencoders for unsupervised object segmentation in complex scenes.</p><hr><h3>Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation</h3>
<p>Paul Bricman</p>
<p><a href='http://arxiv.org/abs/2312.00645v1'>http://arxiv.org/abs/2312.00645v1</a></p>
<p><b>Compressor summary</b>: The authors propose hashmarking, a method to evaluate language models on sensitive topics without revealing the correct answers, by using cryptographic hashing of solutions before publication.</p><hr><h3>EvE: Exploiting Generative Priors for Radiance Field Enrichment</h3>
<p>Karim Kassab,Antoine Schnepf,Jean-Yves Franceschi,Laurent Caraffa,Jeremie Mary,ValÃ©rie Gouet-Brunet</p>
<p><a href='http://arxiv.org/abs/2312.00639v1'>http://arxiv.org/abs/2312.00639v1</a></p>
<p><b>Compressor summary</b>: EvE is a new method that uses generative networks to improve in-the-wild scene modeling and produce more realistic images, outperforming existing methods on novel view synthesis tasks.</p><hr><h3>Towards Efficient 3D Object Detection in Bird's-Eye-View Space for  Autonomous Driving: A Convolutional-Only Approach</h3>
<p>Yuxin Li,Qiang Han,Mengying Yu,Yuxin Jiang,Chaikiat Yeo,Yiheng Li,Zihang Huang,Nini Liu,Hsuanhan Chen,Xiaojun Wu</p>
<p><a href='http://arxiv.org/abs/2312.00633v1'>http://arxiv.org/abs/2312.00633v1</a></p>
<p><b>Compressor summary</b>: BEVENet is a fast and efficient 3D object detection framework that uses convolutional neural networks instead of vision-transformers, making it suitable for autonomous driving applications.</p><hr><h3>Rethinking the Domain Gap in Near-infrared Face Recognition</h3>
<p>Michail Tarasiou,Jiankang Deng,Stefanos Zafeiriou</p>
<p><a href='http://arxiv.org/abs/2312.00627v1'>http://arxiv.org/abs/2312.00627v1</a></p>
<p><b>Compressor summary</b>: The authors propose a framework for heterogeneous face recognition that uses large neural networks pre-trained on homogeneous visible data and fine-tuned on near-infrared data, achieving state-of-the-art results.</p><hr><h3>Forecasting Trends in Food Security: a Reservoir Computing Approach</h3>
<p>Joschka Herteux,Christoph RÃ¤th,Amine Baha,Giulia Martini,Duccio Piovani</p>
<p><a href='http://arxiv.org/abs/2312.00626v1'>http://arxiv.org/abs/2312.00626v1</a></p>
<p><b>Compressor summary</b>: The authors present a new quantitative method to forecast food consumption levels for 60 days in four countries using data from the World Food Programme's hunger monitoring system and various models, finding Reservoir Computing as the best performer for this task.</p><hr><h3>Practical Path-based Bayesian Optimization</h3>
<p>Jose Pablo Folch,James Odgers,Shiqiang Zhang,Robert M Lee,Behrang Shafei,David Walz,Calvin Tsay,Mark van der Wilk,Ruth Misener</p>
<p><a href='http://arxiv.org/abs/2312.00622v1'>http://arxiv.org/abs/2312.00622v1</a></p>
<p><b>Compressor summary</b>: The paper presents an extended SnAKe algorithm that handles costs and constraints for Bayesian optimization in data-driven experimental design.</p><hr><h3>Investigating a domain adaptation approach for integrating different  measurement instruments in a longitudinal clinical registry</h3>
<p>Maren Hackenberg,Michelle Pfaffenlehner,Max Behrens,Astrid Pechmann,Janbernd Kirschner,Harald Binder</p>
<p><a href='http://arxiv.org/abs/2312.00616v1'>http://arxiv.org/abs/2312.00616v1</a></p>
<p><b>Compressor summary</b>: The paper explores using deep learning and domain adaptation to combine different measurement instruments for assessing individuals over time, specifically in a spinal muscular atrophy registry.</p><hr><h3>Improving Plasticity in Online Continual Learning via Collaborative  Learning</h3>
<p>Maorong Wang,Nicolas Michel,Ling Xiao,Toshihiko Yamasaki</p>
<p><a href='http://arxiv.org/abs/2312.00600v1'>http://arxiv.org/abs/2312.00600v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Collaborative Continual Learning (CCL) to address the challenge of acquiring new knowledge in online learning, and introduces Distillation Chain (DC) as a novel collaborative learning scheme that improves model plasticity and performance.</p><hr><h3>Learning from One Continuous Video Stream</h3>
<p>JoÃ£o Carreira,Michael King,Viorica PÄtrÄucean,Dilara Gokay,CÄtÄlin Ionescu,Yi Yang,Daniel Zoran,Joseph Heyward,Carl Doersch,Yusuf Aytar,Dima Damen,Andrew Zisserman</p>
<p><a href='http://arxiv.org/abs/2312.00598v1'>http://arxiv.org/abs/2312.00598v1</a></p>
<p><b>Compressor summary</b>: The authors present a framework for online learning from continuous video streams, addressing challenges related to high frame correlations, and demonstrate its effectiveness through experiments with pixel-to-pixel modelling and future prediction tasks.</p><hr><h3>BCN: Batch Channel Normalization for Image Classification</h3>
<p>Afifa Khaled,Chao Li,Jia Ning,Kun He</p>
<p><a href='http://arxiv.org/abs/2312.00596v1'>http://arxiv.org/abs/2312.00596v1</a></p>
<p><b>Compressor summary</b>: BCN is a novel normalization technique for deep learning that adapts to both channel and batch dependence, enabling higher learning rates and better performance on different tasks.</p><hr><h3>Event Recognition in Laparoscopic Gynecology Videos with Hybrid  Transformers</h3>
<p>Sahar Nasirihaghighi,Negin Ghamsarian,Heinrich Husslein,Klaus Schoeffmann</p>
<p><a href='http://arxiv.org/abs/2312.00593v1'>http://arxiv.org/abs/2312.00593v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a dataset for recognizing critical events in laparoscopic gynecology videos using a hybrid transformer architecture and a frame sampling strategy that improves event recognition accuracy.</p><hr><h3>Tracking Object Positions in Reinforcement Learning: A Metric for  Keypoint Detection (extended version)</h3>
<p>Emma Cramer,Jonas Reiher,Sebastian Trimpe</p>
<p><a href='http://arxiv.org/abs/2312.00592v1'>http://arxiv.org/abs/2312.00592v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a metric to evaluate how well spatial autoencoders (SAEs) can track objects in images, which is important for robotic reinforcement learning (RL), and suggests three modifications to improve SAE architectures.</p><hr><h3>Less is More: Learning Reference Knowledge Using No-Reference Image  Quality Assessment</h3>
<p>Xudong Li,Jingyuan Zheng,Xiawu Zheng,Runze Hu,Enwei Zhang,Yuting Gao,Yunhang Shen,Ke Li,Yutao Liu,Pingyang Dai,Yan Zhang,Rongrong Ji</p>
<p><a href='http://arxiv.org/abs/2312.00591v1'>http://arxiv.org/abs/2312.00591v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method to assess image quality without reference images by learning from non-aligned references using feature distillation, achieving state-of-the-art performance.</p><hr><h3>Explainable Fraud Detection with Deep Symbolic Classification</h3>
<p>Samantha Visbeek,Erman Acar,Floris den Hengst</p>
<p><a href='http://arxiv.org/abs/2312.00586v1'>http://arxiv.org/abs/2312.00586v1</a></p>
<p><b>Compressor summary</b>: The paper proposes Deep Symbolic Classification (DSC), a framework that combines deep neural networks and reinforcement learning to search for explainable, transparent, and data-driven fraud detection models that can handle class imbalance without oversampling or undersampling.</p><hr><h3>The Ethics of Automating Legal Actors</h3>
<p>Josef Valvoda,Alec Thompson,Ryan Cotterell,Simone Teufel</p>
<p><a href='http://arxiv.org/abs/2312.00584v1'>http://arxiv.org/abs/2312.00584v1</a></p>
<p><b>Compressor summary</b>: The paper discusses the ethical challenges of using NLP models to automate the role of judges in common law systems, arguing that current models are not capable of shaping the law and even if they were, there would still be ethical concerns.</p><hr><h3>Pathway to a fully data-driven geotechnics: lessons from materials  informatics</h3>
<p>Stephen Wu,Yu Otake,Yosuke Higo,Ikumasa Yoshida</p>
<p><a href='http://arxiv.org/abs/2312.00581v1'>http://arxiv.org/abs/2312.00581v1</a></p>
<p><b>Compressor summary</b>: The paper discusses how data-driven methods and deep learning can improve geotechnics by addressing soil complexity and promoting open science, and envisions a future where advanced computational tools revolutionize the field.</p><hr><h3>Instruction-tuning Aligns LLMs to the Human Brain</h3>
<p>Khai Loong Aw,Syrielle Montariol,Badr AlKhamissi,Martin Schrimpf,Antoine Bosselut</p>
<p><a href='http://arxiv.org/abs/2312.00575v1'>http://arxiv.org/abs/2312.00575v1</a></p>
<p><b>Compressor summary</b>: Instruction-tuning enhances language models' similarity to human brain activity but not behavior on a reading task.</p><hr><h3>Generative models for visualising abstract social processes: Guiding  streetview image synthesis of StyleGAN2 with indices of deprivation</h3>
<p>Aleksi Knuutila</p>
<p><a href='http://arxiv.org/abs/2312.00570v1'>http://arxiv.org/abs/2312.00570v1</a></p>
<p><b>Compressor summary</b>: The paper applies GANs to study visual aspects of social processes in London, mapping how different areas vary in health, income, and environmental quality using image synthesis and comparing the results from three inversion techniques.</p><hr><h3>Explanatory Argument Extraction of Correct Answers in Resident Medical  Exams</h3>
<p>Iakes Goenaga,Aitziber Atutxa,Koldo Gojenola,Maite Oronoz,Rodrigo Agerri</p>
<p><a href='http://arxiv.org/abs/2312.00567v1'>http://arxiv.org/abs/2312.00567v1</a></p>
<p><b>Compressor summary</b>: The paper presents a new Spanish dataset for extractive question answering in Evidence-Based Medicine, with explanations written by medical doctors and benchmarks both correct and incorrect answers.</p><hr><h3>Interior Point Constrained Reinforcement Learning with Global  Convergence Guarantees</h3>
<p>Tingting Ni,Maryam Kamgarpour</p>
<p><a href='http://arxiv.org/abs/2312.00561v1'>http://arxiv.org/abs/2312.00561v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new zeroth-order interior point method for constrained Markov decision processes that guarantees constraint satisfaction during learning and converges faster than existing algorithms.</p><hr><h3>Questioning Biases in Case Judgment Summaries: Legal Datasets or Large  Language Models?</h3>
<p>Aniket Deroy,Subhankar Maity</p>
<p><a href='http://arxiv.org/abs/2312.00554v1'>http://arxiv.org/abs/2312.00554v1</a></p>
<p><b>Compressor summary</b>: The study examines how biases in legal dataset summaries and large language models affect justice systems and explores various types of biases, such as gender, race, crime against women, country names, and religious keywords.</p><hr><h3>Improving Unsupervised Relation Extraction by Augmenting Diverse  Sentence Pairs</h3>
<p>Qing Wang,Kang Zhou,Qiao Qiao,Yuepei Li,Qi Li</p>
<p><a href='http://arxiv.org/abs/2312.00552v1'>http://arxiv.org/abs/2312.00552v1</a></p>
<p><b>Compressor summary</b>: The paper introduces AugURE, a method for unsupervised relation extraction that increases positive pair diversity with cross-sentence augmentation and uses margin loss instead of NCE to improve relation representation learning.</p><hr><h3>Domain Adaptive Imitation Learning with Visual Observation</h3>
<p>Sungho Choi,Seungyul Han,Woojun Kim,Jongseong Chae,Whiyoung Jung,Youngchul Sung</p>
<p><a href='http://arxiv.org/abs/2312.00548v1'>http://arxiv.org/abs/2312.00548v1</a></p>
<p><b>Compressor summary</b>: The paper presents a novel framework for cross-domain imitation learning with visual observation that extracts domain-independent features to improve performance in practical scenarios.</p><hr><h3>Target-agnostic Source-free Domain Adaptation for Regression Tasks</h3>
<p>Tianlang He,Zhiqiu Xia,Jierun Chen,Haoliang Li,S. -H. Gary Chan</p>
<p><a href='http://arxiv.org/abs/2312.00540v1'>http://arxiv.org/abs/2312.00540v1</a></p>
<p><b>Compressor summary</b>: TASFAR is a new target-agnostic source-free domain adaptation method for regression tasks that uses prediction confidence to estimate a label density map and calibrate the source model on the target domain, achieving superior performance compared to existing approaches.</p><hr><h3>Trained MT Metrics Learn to Cope with Machine-translated References</h3>
<p>Jannis Vamvas,Tobias Domhan,Sony Trenous,Rico Sennrich,Eva Hasler</p>
<p><a href='http://arxiv.org/abs/2312.00536v1'>http://arxiv.org/abs/2312.00536v1</a></p>
<p><b>Compressor summary</b>: The paper compares two metrics for machine translation evaluation and finds that the trained one is more robust to machine-translated references, indicating unintended positive effects of metric training.</p><hr><h3>LiDAR-based curb detection for ground truth annotation in automated  driving validation</h3>
<p>Jose Luis ApellÃ¡niz,Mikel GarcÃ­a,Nerea Aranjuelo,Javier BarandiarÃ¡n,Marcos Nieto</p>
<p><a href='http://arxiv.org/abs/2312.00534v1'>http://arxiv.org/abs/2312.00534v1</a></p>
<p><b>Compressor summary</b>: The paper presents a method for detecting 3D curbs from LiDAR point clouds and shows how it reduces manual annotation time by 50.99%.</p><hr><h3>DeepDR: Deep Structure-Aware RGB-D Inpainting for Diminished Reality</h3>
<p>Christina Gsaxner,Shohei Mori,Dieter Schmalstieg,Jan Egger,Gerhard Paar,Werner Bailer,Denis Kalkofen</p>
<p><a href='http://arxiv.org/abs/2312.00532v1'>http://arxiv.org/abs/2312.00532v1</a></p>
<p><b>Compressor summary</b>: DeepDR is a new RGB-D inpainting framework that can remove real objects from scenes and generate coherent structure and 3D geometry, achieving high quality results at real-time speeds.</p><hr><h3>SurreyAI 2023 Submission for the Quality Estimation Shared Task</h3>
<p>Archchana Sindhujan,Diptesh Kanojia,Constantin Orasan,Tharindu Ranasinghe</p>
<p><a href='http://arxiv.org/abs/2312.00525v1'>http://arxiv.org/abs/2312.00525v1</a></p>
<p><b>Compressor summary</b>: The paper describes an approach that uses autoencoder pre-trained language models within the MonoTransQuest architecture to assess translation quality without reference, and shows that MonoTQ-InfoXLM-large performs best among the tested models.</p><hr><h3>Spatio-Temporal-Decoupled Masked Pre-training for Traffic Forecasting</h3>
<p>Haotian Gao,Renhe Jiang,Zheng Dong,Jinliang Deng,Xuan Song</p>
<p><a href='http://arxiv.org/abs/2312.00516v1'>http://arxiv.org/abs/2312.00516v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a new method called STD-MAE that uses masked autoencoders to learn complex spatio-temporal patterns in traffic data and improve forecasting performance.</p><hr><h3>Summarization-based Data Augmentation for Document Classification</h3>
<p>Yueguan Wang,Naoki Yoshinaga</p>
<p><a href='http://arxiv.org/abs/2312.00513v1'>http://arxiv.org/abs/2312.00513v1</a></p>
<p><b>Compressor summary</b>: SUMMaug is a data augmentation technique that uses summarization to generate pseudo examples for document classification tasks, improving robustness and accuracy.</p><hr><h3>On the Out-Of-Distribution Robustness of Self-Supervised Representation  Learning for Phonocardiogram Signals</h3>
<p>Aristotelis Ballas,Vasileios Papapanagiotou,Christos Diou</p>
<p><a href='http://arxiv.org/abs/2312.00502v1'>http://arxiv.org/abs/2312.00502v1</a></p>
<p><b>Compressor summary</b>: The authors propose contrastive self-supervised learning (SSL) to improve deep-learning models' effectiveness and robustness in detecting abnormalities in phonocardiogram signals using audio-based augmentations, addressing the scarcity of labeled data in medicine.</p><hr><h3>Global Localization: Utilizing Relative Spatio-Temporal Geometric  Constraints from Adjacent and Distant Cameras</h3>
<p>Mohammad Altillawi,Zador Pataki,Shile Li,Ziyuan Liu</p>
<p><a href='http://arxiv.org/abs/2312.00500v1'>http://arxiv.org/abs/2312.00500v1</a></p>
<p><b>Compressor summary</b>: The authors propose a novel network to train a deep neural network for camera localization in robotics and AR/VR applications using relative spatial and temporal geometric constraints, achieving better performance with very limited ground-truth data.</p><hr><h3>Explainable AI in Diagnosing and Anticipating Leukemia Using Transfer  Learning Method</h3>
<p>Wahidul Hasan Abir,Md. Fahim Uddin,Faria Rahman Khanam,Mohammad Monirujjaman Khan</p>
<p><a href='http://arxiv.org/abs/2312.00487v1'>http://arxiv.org/abs/2312.00487v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an automated detection method for Acute Lymphoblastic Leukemia using deep learning models and explainable artificial intelligence to improve accuracy and efficiency in diagnosis.</p><hr><h3>REDUCR: Robust Data Downsampling Using Class Priority Reweighting</h3>
<p>William Bankes,George Hughes,Ilija Bogunovic,Zi Wang</p>
<p><a href='http://arxiv.org/abs/2312.00486v1'>http://arxiv.org/abs/2312.00486v1</a></p>
<p><b>Compressor summary</b>: REDUCR is a data downsampling method that uses class priority reweighting to reduce training costs and improve worst-class generalization performance in image and text classification tasks.</p><hr><h3>Backbone-based Dynamic Graph Spatio-Temporal Network for Epidemic  Forecasting</h3>
<p>Junkai Mao,Yuexing Han,Gouhei Tanaka,Bing Wang</p>
<p><a href='http://arxiv.org/abs/2312.00485v1'>http://arxiv.org/abs/2312.00485v1</a></p>
<p><b>Compressor summary</b>: The proposed Backbone-based Dynamic Graph Spatio-Temporal Network (BDGSTN) is a novel deep learning model that combines static backbone graphs with temporal models for accurate epidemic forecasting, overcoming limitations of recurrent structures and showing superior complexity and efficiency.</p><hr><h3>MultiView Independent Component Analysis with Delays</h3>
<p>Ambroise Heurtebise,Pierre Ablin,Alexandre Gramfort</p>
<p><a href='http://arxiv.org/abs/2312.00484v1'>http://arxiv.org/abs/2312.00484v1</a></p>
<p><b>Compressor summary</b>: MVICAD is an improved MultiView ICA algorithm that accounts for source delays and better separates sources in observed signals, applicable to neuroscience data analysis.</p><hr><h3>Japanese Tort-case Dataset for Rationale-supported Legal Judgment  Prediction</h3>
<p>Hiroaki Yamada,Takenobu Tokunaga,Ryutaro Ohara,Akira Tokutsu,Keisuke Takeshita,Mihoko Sumida</p>
<p><a href='http://arxiv.org/abs/2312.00480v1'>http://arxiv.org/abs/2312.00480v1</a></p>
<p><b>Compressor summary</b>: The paper introduces JTD, a novel dataset for Japanese Legal Judgment Prediction with two tasks: tort prediction and rationale extraction, which requires identifying court-accepted arguments from party allegations.</p><hr><h3>Interpretable Meta-Learning of Physical Systems</h3>
<p>Matthieu Blanke,Marc Lelarge</p>
<p><a href='http://arxiv.org/abs/2312.00477v1'>http://arxiv.org/abs/2312.00477v1</a></p>
<p><b>Compressor summary</b>: The authors propose a simpler learning model for multi-environment generalization in machine learning, which can identify the physical parameters of the system and enable interpretable learning while having competitive performance and low computational cost.</p><hr><h3>A Bayesian approach for prompt optimization in pre-trained language  models</h3>
<p>Antonio Sabbatella,Andrea Ponti,Antonio Candelieri,Ilaria Giordani,Francesco Archetti</p>
<p><a href='http://arxiv.org/abs/2312.00471v1'>http://arxiv.org/abs/2312.00471v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a Bayesian optimization method for discrete prompt tuning in classification tasks, which can efficiently search for optimal token sequences without relying on large language models.</p><hr><h3>Unfolder: Fast localization and image rectification of a document with a  crease from folding in half</h3>
<p>A. M. Ershov,D. V. Tropin,E. E. Limonova,D. P. Nikolaev,V. V. Arlazarov</p>
<p><a href='http://arxiv.org/abs/2312.00467v1'>http://arxiv.org/abs/2312.00467v1</a></p>
<p><b>Compressor summary</b>: Unfolder is a novel algorithm that rectifies images of documents with a crease from folding in half, outperforming advanced neural network methods and having fast runtime on smartphones.</p><hr><h3>Learning Unorthogonalized Matrices for Rotation Estimation</h3>
<p>Kerui Gu,Zhihao Li,Shiyong Liu,Jianzhuang Liu,Songcen Xu,Youliang Yan,Michael Bi Mi,Kenji Kawaguchi,Angela Yao</p>
<p><a href='http://arxiv.org/abs/2312.00462v1'>http://arxiv.org/abs/2312.00462v1</a></p>
<p><b>Compressor summary</b>: The text discusses how removing orthogonalization from rotation matrices improves training efficiency and leads to better results in 3D computer vision tasks like human pose estimation.</p><hr><h3>Meta-Diversity Search in Complex Systems, A Recipe for Artificial  Open-Endedness ?</h3>
<p>Mayalen Etcheverry,Bert Wang-Chak Chan,ClÃ©ment Moulin-Frier,Pierre-Yves Oudeyer</p>
<p><a href='http://arxiv.org/abs/2312.00455v1'>http://arxiv.org/abs/2312.00455v1</a></p>
<p><b>Compressor summary</b>: The article presents a framework for generating endless complex artifacts in Minecraft using a complex system and a meta-diversity search algorithm, which learns to discover diverse patterns and seek novel sources of diversity.</p><hr><h3>An Encoding Framework for Binarized Images using HyperDimensional  Computing</h3>
<p>Laura Smets,Werner Van Leekwijck,Ing Jyh Tsang,Steven LatrÃ©</p>
<p><a href='http://arxiv.org/abs/2312.00454v1'>http://arxiv.org/abs/2312.00454v1</a></p>
<p><b>Compressor summary</b>: Hyperdimensional Computing (HDC) is a brain-inspired, lightweight machine learning method that performs well in image classification tasks with a novel encoding approach that preserves pattern similarity and improves accuracy and robustness.</p><hr><h3>Towards Generalizable Referring Image Segmentation via Target Prompt and  Visual Coherence</h3>
<p>Yajie Liu,Pu Ge,Haoxiang Ma,Shichao Fan,Qingjie Liu,Di Huang,Yunhong Wang</p>
<p><a href='http://arxiv.org/abs/2312.00452v1'>http://arxiv.org/abs/2312.00452v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel RIS method that improves generalization by using a prompt to handle linguistic style changes and a multi-modal fusion module to leverage spatial relations, achieving consistent gains on various datasets.</p><hr><h3>FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting</h3>
<p>Zehao Zhu,Zhiwen Fan,Yifan Jiang,Zhangyang Wang</p>
<p><a href='http://arxiv.org/abs/2312.00451v1'>http://arxiv.org/abs/2312.00451v1</a></p>
<p><b>Compressor summary</b>: The paper proposes FSGS, a few-shot view synthesis framework that uses 3D Gaussian Splatting to generate real-time and photo-realistic views from as few as three training images while accurately filling in sparse scene details.</p><hr><h3>Dolphins: Multimodal Language Model for Driving</h3>
<p>Yingzi Ma,Yulong Cao,Jiachen Sun,Marco Pavone,Chaowei Xiao</p>
<p><a href='http://arxiv.org/abs/2312.00438v1'>http://arxiv.org/abs/2312.00438v1</a></p>
<p><b>Compressor summary</b>: Dolphins is a vision-language model that can process multimodal inputs and generate outputs for various autonomous driving tasks by using Grounded Chain of Thought, open-source pretrained model, and human-like capabilities.</p><hr><h3>Enhancing Image Captioning with Neural Models</h3>
<p>Pooja Bhatnagar,Sai Mrunaal,Sachin Kamnure</p>
<p><a href='http://arxiv.org/abs/2312.00435v1'>http://arxiv.org/abs/2312.00435v1</a></p>
<p><b>Compressor summary</b>: This research compares different neural architectures for image captioning, proposes a new quality metric, and highlights the importance of data refinement and hyperparameter optimization.</p><hr><h3>PEFTDebias : Capturing debiasing information using PEFTs</h3>
<p>Sumit Agarwal,Aditya Srikanth Veerubhotla,Srijan Bansal</p>
<p><a href='http://arxiv.org/abs/2312.00434v1'>http://arxiv.org/abs/2312.00434v1</a></p>
<p><b>Compressor summary</b>: PEFTDebias is a new method that uses parameter-efficient fine-tuning to reduce biases in foundation models by acquiring debiasing parameters and incorporating them during training.</p><hr><h3>A Low-Power Neuromorphic Approach for Efficient Eye-Tracking</h3>
<p>Pietro Bonazzi,Sizhen Bian,Giovanni Lippolis,Yawei Li,Sadique Sheik,Michele Magno</p>
<p><a href='http://arxiv.org/abs/2312.00425v1'>http://arxiv.org/abs/2312.00425v1</a></p>
<p><b>Compressor summary</b>: The paper presents a neuromorphic eye-tracking method using a spiking neural network model called Retina, which performs better than the latest method with less power consumption and fewer parameters.</p><hr><h3>Towards Explaining Satellite Based Poverty Predictions with  Convolutional Neural Networks</h3>
<p>Hamid Sarmadi,Thorsteinn RÃ¶gnvaldsson,Nils Roger Carlsson,Mattias Ohlsson,Ibrahim Wahab,Ola Hall</p>
<p><a href='http://arxiv.org/abs/2312.00416v1'>http://arxiv.org/abs/2312.00416v1</a></p>
<p><b>Compressor summary</b>: The paper examines how deep convolutional neural networks predict poverty and development indicators from satellite images and identifies key features that influence their predictions.</p><hr><h3>Large-scale Vision-Language Models Learn Super Images for Efficient and  High-Performance Partially Relevant Video Retrieval</h3>
<p>Taichi Nishimura,Shota Nakada,Masayoshi Kondo</p>
<p><a href='http://arxiv.org/abs/2312.00414v1'>http://arxiv.org/abs/2312.00414v1</a></p>
<p><b>Compressor summary</b>: The paper presents an efficient method for retrieving partially relevant videos using super images and large-scale vision-and-language models, outperforming previous methods.</p><hr><h3>SCHEME: Scalable Channer Mixer for Vision Transformers</h3>
<p>Deepak Sridhar,Yunsheng Li,Nuno Vasconcelos</p>
<p><a href='http://arxiv.org/abs/2312.00412v1'>http://arxiv.org/abs/2312.00412v1</a></p>
<p><b>Compressor summary</b>: The paper proposes SCHEME, a method to improve Vision Transformers by using sparse feature mixing and a channel covariance attention mechanism, leading to better performance with fewer computations.</p><hr><h3>A framework for mining lifestyle profiles through multi-dimensional and  high-order mobility feature clustering</h3>
<p>Yeshuo Shu,Gangcheng Zhang,Keyi Liu,Jintong Tang,Liyan Xu</p>
<p><a href='http://arxiv.org/abs/2312.00411v1'>http://arxiv.org/abs/2312.00411v1</a></p>
<p><b>Compressor summary</b>: The study presents a method to extract high-order features from human mobility data and cluster users into different lifestyle profiles based on their movement patterns, time series, and place semantics.</p><hr><h3>CoLLiE: Collaborative Training of Large Language Models in an Efficient  Way</h3>
<p>Kai Lv,Shuo Zhang,Tianle Gu,Shuhao Xing,Jiawei Hong,Keyu Chen,Xiaoran Liu,Yuqing Yang,Honglin Guo,Tengxiao Liu,Yu Sun,Qipeng Guo,Hang Yan,Xipeng Qiu</p>
<p><a href='http://arxiv.org/abs/2312.00407v1'>http://arxiv.org/abs/2312.00407v1</a></p>
<p><b>Compressor summary</b>: CoLLiE is an efficient library that enables collaborative training of large language models with various optimizers and fine-tuning methods, offering efficiency, ease of use, and customization.</p><hr><h3>A Causality-Aware Pattern Mining Scheme for Group Activity Recognition  in a Pervasive Sensor Space</h3>
<p>Hyunju Kim,Heesuk Son,Dongman Lee</p>
<p><a href='http://arxiv.org/abs/2312.00404v1'>http://arxiv.org/abs/2312.00404v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an efficient group activity recognition scheme using causality patterns extracted from pervasive sensor data without user identification, achieving high accuracy and low runtime overhead in real environments.</p><hr><h3>VIoTGPT: Learning to Schedule Vision Tools towards Intelligent Video  Internet of Things</h3>
<p>Yaoyao Zhong,Mengshi Qi,Rui Wang,Yuhan Qiu,Yang Zhang,Huadong Ma</p>
<p><a href='http://arxiv.org/abs/2312.00401v1'>http://arxiv.org/abs/2312.00401v1</a></p>
<p><b>Compressor summary</b>: The paper introduces VIoTGPT, a framework that uses large language models to interact with humans, query knowledge from videos, and invoke vision models for complex tasks in the Video Internet of Things.</p><hr><h3>GFN-SR: Symbolic Regression with Generative Flow Networks</h3>
<p>Sida Li,Ioana Marinescu,Sebastian Musslick</p>
<p><a href='http://arxiv.org/abs/2312.00396v1'>http://arxiv.org/abs/2312.00396v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new method (GFN-SR) for symbolic regression using deep learning and stochastic policy learning, which performs better than existing methods in noisy data scenarios.</p><hr><h3>Study and Survey on Gesture Recognition Systems</h3>
<p>Kshitij Deshpande,Varad Mashalkar,Kaustubh Mhaisekar,Amaan Naikwadi,Archana Ghotkar</p>
<p><a href='http://arxiv.org/abs/2312.00392v1'>http://arxiv.org/abs/2312.00392v1</a></p>
<p><b>Compressor summary</b>: This paper surveys the application, methodology, data sources, and challenges of gesture recognition systems in various sectors and compares different techniques for capturing gestures.</p><hr><h3>LinguaLinked: A Distributed Large Language Model Inference System for  Mobile Devices</h3>
<p>Junchen Zhao,Yurun Song,Simeng Liu,Ian G. Harris,Sangeetha Abdu Jyothi</p>
<p><a href='http://arxiv.org/abs/2312.00388v1'>http://arxiv.org/abs/2312.00388v1</a></p>
<p><b>Compressor summary</b>: LinguaLinked is a system that enables efficient distributed inference of large language models on mobile devices by optimizing model assignment, data transmission, and runtime load balancing.</p><hr><h3>Enhancing Explainability in Mobility Data Science through a combination  of methods</h3>
<p>Georgios Makridis,Vasileios Koukos,Georgios Fatouros,Dimosthenis Kyriazis</p>
<p><a href='http://arxiv.org/abs/2312.00380v1'>http://arxiv.org/abs/2312.00380v1</a></p>
<p><b>Compressor summary</b>: The paragraph introduces a comprehensive framework that combines various XAI techniques to interpret models trained on trajectory data and improve the understanding of model decisions for different user demographics.</p><hr><h3>Optimal Sample Complexity of Contrastive Learning</h3>
<p>Noga Alon,Dmitrii Avdiukhin,Dor Elboim,Orr Fischer,Grigory Yaroslavtsev</p>
<p><a href='http://arxiv.org/abs/2312.00379v1'>http://arxiv.org/abs/2312.00379v1</a></p>
<p><b>Compressor summary</b>: The paper studies how many labeled examples are needed to learn good representations using contrastive learning, and gives optimal bounds for various distance functions.</p><hr><h3>SynFundus: Generating a synthetic fundus images dataset with millions of  samples and multi-disease annotations</h3>
<p>Fangxin Shang,Jie Fu,Yehui Yang,Lei Ma</p>
<p><a href='http://arxiv.org/abs/2312.00377v1'>http://arxiv.org/abs/2312.00377v1</a></p>
<p><b>Compressor summary</b>: The SynFundus-1M dataset provides over 1 million realistic synthetic retinal fundus images and annotations for medical imaging research, overcoming the challenge of privacy restrictions and outperforming existing methods.</p><hr><h3>Text-Guided 3D Face Synthesis -- From Generation to Editing</h3>
<p>Yunjie Wu,Yapeng Meng,Zhipeng Hu,Lincheng Li,Haoqian Wu,Kun Zhou,Weiwei Xu,Xin Yu</p>
<p><a href='http://arxiv.org/abs/2312.00375v1'>http://arxiv.org/abs/2312.00375v1</a></p>
<p><b>Compressor summary</b>: The paper presents a text-guided framework for generating and editing 3D faces using geometry-texture decoupling and diffusion models, with improved quality and consistency.</p><hr><h3>Streaming Bayesian Modeling for predicting Fat-Tailed Customer Lifetime  Value</h3>
<p>Alexey V. Calabourdin,Konstantin A. Aksenov</p>
<p><a href='http://arxiv.org/abs/2312.00373v1'>http://arxiv.org/abs/2312.00373v1</a></p>
<p><b>Compressor summary</b>: The authors present an online learning method for hierarchical bayesian models, a generalized fat-tailed LTV model, and its application to commercial LTV data.</p><hr><h3>Benchmarking Multi-Domain Active Learning on Image Classification</h3>
<p>Jiayi Li,Rohan Taori,Tatsunori B. Hashimoto</p>
<p><a href='http://arxiv.org/abs/2312.00364v1'>http://arxiv.org/abs/2312.00364v1</a></p>
<p><b>Compressor summary</b>: Active learning's effectiveness on large-real world datasets is underexplored; existing research mostly ignores multi-domain data, which our new benchmark and dataset aim to address.</p><hr><h3>Dancing with Images: Video Distillation via Static-Dynamic  Disentanglement</h3>
<p>Ziyu Wang,Yue Xu,Cewu Lu,Yong-Lu Li</p>
<p><a href='http://arxiv.org/abs/2312.00362v1'>http://arxiv.org/abs/2312.00362v1</a></p>
<p><b>Compressor summary</b>: The authors present a new method for efficient machine learning with videos by disentangling static and dynamic information using still images and a learnable memory block.</p><hr><h3>Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning</h3>
<p>Shaohua Dong,Yunhe Feng,Qing Yang,Yan Huang,Dongfang Liu,Heng Fan</p>
<p><a href='http://arxiv.org/abs/2312.00360v1'>http://arxiv.org/abs/2312.00360v1</a></p>
<p><b>Compressor summary</b>: The paper introduces DPLNet, a simple and efficient network for multimodal semantic segmentation that adapts a frozen pre-trained RGB model with two prompt learning modules.</p><hr><h3>Temperature Balancing, Layer-wise Weight Analysis, and Neural Network  Training</h3>
<p>Yefan Zhou,Tianyu Pang,Keqin Liu,Charles H. Martin,Michael W. Mahoney,Yaoqing Yang</p>
<p><a href='http://arxiv.org/abs/2312.00359v1'>http://arxiv.org/abs/2312.00359v1</a></p>
<p><b>Compressor summary</b>: TempBalance is a layer-wise learning rate method based on Heavy-Tailed Self-Regularization Theory, which improves performance in neural network training by balancing temperature across layers.</p><hr><h3>On Exploring the Reasoning Capability of Large Language Models with  Knowledge Graphs</h3>
<p>Pei-Chi Lo,Yi-Hang Tsai,Ee-Peng Lim,San-Yih Hwang</p>
<p><a href='http://arxiv.org/abs/2312.00353v1'>http://arxiv.org/abs/2312.00353v1</a></p>
<p><b>Compressor summary</b>: The paper studies how large language models use their pre-trained knowledge graphs for reasoning tasks and identifies two types of hallucinations that may occur.</p><hr><h3>Manipulating the Label Space for In-Context Classification</h3>
<p>Haokun Chen,Xu Yang,Yuhang Huang,Zihan Wu,Jing Wang,Xin Geng</p>
<p><a href='http://arxiv.org/abs/2312.00351v1'>http://arxiv.org/abs/2312.00351v1</a></p>
<p><b>Compressor summary</b>: The paper proposes two strategies to improve In-context Learning for Vision-Language Models by manipulating the label space of in-context examples, leading to better classification performance on various datasets.</p><hr><h3>The Case for Scalable, Data-Driven Theory: A Paradigm for Scientific  Progress in NLP</h3>
<p>Julian Michael</p>
<p><a href='http://arxiv.org/abs/2312.00349v1'>http://arxiv.org/abs/2312.00349v1</a></p>
<p><b>Compressor summary</b>: The author proposes a method to develop scalable theories of linguistic structure using machine learning and Question-Answer driven Semantic Role Labeling, aiming to contribute to intelligible AI systems.</p><hr><h3>RTQ: Rethinking Video-language Understanding Based on Image-text Model</h3>
<p>Xiao Wang,Yaoyu Li,Tian Gan,Zheng Zhang,Jingjing Lv,Liqiang Nie</p>
<p><a href='http://arxiv.org/abs/2312.00347v1'>http://arxiv.org/abs/2312.00347v1</a></p>
<p><b>Compressor summary</b>: The RTQ framework tackles challenges in video-language understanding by refining information, modeling temporal relations, and querying task-specific details, achieving high performance without pre-training.</p><hr><h3>OpenStereo: A Comprehensive Benchmark for Stereo Matching and Strong  Baseline</h3>
<p>Xianda Guo,Juntao Lu,Chenming Zhang,Yiqi Wang,Yiqun Duan,Tian Yang,Zheng Zhu,Long Chen</p>
<p><a href='http://arxiv.org/abs/2312.00343v1'>http://arxiv.org/abs/2312.00343v1</a></p>
<p><b>Compressor summary</b>: The paper introduces OpenStereo, a comprehensive and efficient stereo matching toolbox with over 12 network models, and evaluates its performance on the SceneFlow dataset.</p><hr><h3>Efficient Off-Policy Safe Reinforcement Learning Using Trust Region  Conditional Value at Risk</h3>
<p>Dohyeong Kim,Songhwai Oh</p>
<p><a href='http://arxiv.org/abs/2312.00342v1'>http://arxiv.org/abs/2312.00342v1</a></p>
<p><b>Compressor summary</b>: The paper presents off-policy TRC, an RL method with CVaR constraints that uses surrogate functions to reduce estimation error and adapts trust-region constraint to ensure policy stability in complex environments.</p><hr><h3>Hypergraph Node Representation Learning with One-Stage Message Passing</h3>
<p>Shilin Qu,Weiqing Wang,Yuan-Fang Li,Xin Zhou,Fajie Yuan</p>
<p><a href='http://arxiv.org/abs/2312.00336v1'>http://arxiv.org/abs/2312.00336v1</a></p>
<p><b>Compressor summary</b>: The paragraph describes a novel one-stage message passing paradigm for hypergraph node representation learning that combines Transformers and hypergraph Laplacian to model both global and local information, achieving state-of-the-art results on semi-supervised hypernode classification.</p><hr><h3>Learning Anatomically Consistent Embedding for Chest Radiography</h3>
<p>Ziyu Zhou,Haozhe Luo,Jiaxuan Pang,Xiaowei Ding,Michael Gotway,Jianming Liang</p>
<p><a href='http://arxiv.org/abs/2312.00335v1'>http://arxiv.org/abs/2312.00335v1</a></p>
<p><b>Compressor summary</b>: PEAC is a new self-supervised learning approach for medical images that leverages anatomical consistency to improve performance and interpretability in various downstream tasks.</p><hr><h3>Green Edge AI: A Contemporary Survey</h3>
<p>Yuyi Mao,Xianghao Yu,Kaibin Huang,Ying-Jun Angela Zhang,Jun Zhang</p>
<p><a href='http://arxiv.org/abs/2312.00333v1'>http://arxiv.org/abs/2312.00333v1</a></p>
<p><b>Compressor summary</b>: The text discusses how artificial intelligence technologies are becoming essential across various industries, but their resource-intensive nature and the need for large amounts of data pose challenges for edge AI on wireless networks near end-user devices, requiring an energy-conscious approach to ensure optimal performance.</p><hr><h3>Matching Weak Informative Ontologies</h3>
<p>Peng Wang</p>
<p><a href='http://arxiv.org/abs/2312.00332v1'>http://arxiv.org/abs/2312.00332v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a method for matching weak informative ontologies (WIOs) using semantic subgraphs and a similarity propagation model that balances efficiency and quality in ontology matching.</p><hr><h3>StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style  Adapter</h3>
<p>Gongye Liu,Menghan Xia,Yong Zhang,Haoxin Chen,Jinbo Xing,Xintao Wang,Yujiu Yang,Ying Shan</p>
<p><a href='http://arxiv.org/abs/2312.00330v1'>http://arxiv.org/abs/2312.00330v1</a></p>
<p><b>Compressor summary</b>: StyleCrafter is a method that improves text-to-video models to generate diverse, stylized videos by using a style control adapter trained with style-rich images and a decoupling learning strategy.</p><hr><h3>Agent-OM: Leveraging Large Language Models for Ontology Matching</h3>
<p>Zhangcheng Qiang,Weiqing Wang,Kerry Taylor</p>
<p><a href='http://arxiv.org/abs/2312.00326v1'>http://arxiv.org/abs/2312.00326v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel agent-powered language model approach for ontology matching, which improves performance on complex and few-shot tasks compared to existing systems.</p><hr><h3>Improving Efficiency of DNN-based Relocalization Module for Autonomous  Driving with Server-side Computing</h3>
<p>Dengbo Li,Jieren Cheng,Boyi Liu</p>
<p><a href='http://arxiv.org/abs/2312.00316v1'>http://arxiv.org/abs/2312.00316v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a new way to move cameras in self-driving cars using neural networks that works better by sharing some tasks with a remote server.</p><hr><h3>Improving Normalization with the James-Stein Estimator</h3>
<p>Seyedalireza Khoshsirat,Chandra Kambhamettu</p>
<p><a href='http://arxiv.org/abs/2312.00313v1'>http://arxiv.org/abs/2312.00313v1</a></p>
<p><b>Compressor summary</b>: The paper introduces a novel method to use the James-Stein estimator in deep learning normalization layers, which improves mean and variance estimation and enhances computer vision task performance without extra computational cost.</p><hr><h3>Segment Anything Model-guided Collaborative Learning Network for  Scribble-supervised Polyp Segmentation</h3>
<p>Yiming Zhao,Tao Zhou,Yunqi Gu,Yi Zhou,Yizhe Zhang,Ye Wu,Huazhu Fu</p>
<p><a href='http://arxiv.org/abs/2312.00312v1'>http://arxiv.org/abs/2312.00312v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a novel method, SAM-CLNet, for scribble-supervised polyp segmentation using a collaborative learning process between the segmentation network and SAM to boost performance and outperforms existing methods.</p><hr><h3>3D Face Reconstruction with the Geometric Guidance of Facial Part  Segmentation</h3>
<p>Zidu Wang,Xiangyu Zhu,Tianshuo Zhang,Baiqin Wang,Zhen Lei</p>
<p><a href='http://arxiv.org/abs/2312.00311v1'>http://arxiv.org/abs/2312.00311v1</a></p>
<p><b>Compressor summary</b>: The paper introduces Part Re-projection Distance Loss (PRDL), a method that uses facial part segmentation geometry to improve 3D face reconstruction with extreme expressions, outperforming renderer-based methods in various experiments.</p><hr><h3>A knowledge-based data-driven (KBDD) framework for all-day  identification of cloud types using satellite remote sensing</h3>
<p>Longfeng Nie,Yuntian Chen,Mengge Du,Changqi Sun,Dongxiao Zhang</p>
<p><a href='http://arxiv.org/abs/2312.00308v1'>http://arxiv.org/abs/2312.00308v1</a></p>
<p><b>Compressor summary</b>: The text describes a new cloud-type identification system called CldNet that uses satellite data and improves the accuracy of identifying different cloud types.</p><hr><h3>Developmental Pretraining (DPT) for Image Classification Networks</h3>
<p>Niranjan Rajesh,Debayan Gupta</p>
<p><a href='http://arxiv.org/abs/2312.00304v1'>http://arxiv.org/abs/2312.00304v1</a></p>
<p><b>Compressor summary</b>: DPT is a curriculum-based pre-training approach for deep neural networks that teaches basic features like edges and shapes, inspired by human visual development, to address data scarcity issues in object recognition tasks.</p><hr><h3>Towards Aligned Canonical Correlation Analysis: Preliminary Formulation  and Proof-of-Concept Results</h3>
<p>Biqian Cheng,Evangelos E. Papalexakis,Jia Chen</p>
<p><a href='http://arxiv.org/abs/2312.00296v1'>http://arxiv.org/abs/2312.00296v1</a></p>
<p><b>Compressor summary</b>: The proposed ACCA method aligns multiple data perspectives and embeds them in a correlated latent space using an iterative approach.</p><hr><h3>PsyAttention: Psychological Attention Model for Personality Detection</h3>
<p>Baohua Zhang,Yongyi Huang,Wenyao Cui,Huaping Zhang,Jianyun Shang</p>
<p><a href='http://arxiv.org/abs/2312.00293v1'>http://arxiv.org/abs/2312.00293v1</a></p>
<p><b>Compressor summary</b>: The paper proposes PsyAttention, a method for personality detection that adapts different psychological models, encodes features more effectively, and achieves higher accuracy than existing methods.</p><hr><h3>SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection</h3>
<p>Anku Rani,Dwip Dalal,Shreya Gautam,Pankaj Gupta,Vinija Jain,Aman Chadha,Amit Sheth,Amitava Das</p>
<p><a href='http://arxiv.org/abs/2312.00292v1'>http://arxiv.org/abs/2312.00292v1</a></p>
<p><b>Compressor summary</b>: This study proposes a novel framework using NLP techniques to detect lies of omission in deception, and analyzes their relationship with propaganda techniques.</p><hr><h3>Learning to forecast diagnostic parameters using pre-trained weather  embedding</h3>
<p>Peetak P. Mitra,Vivek Ramavajjala</p>
<p><a href='http://arxiv.org/abs/2312.00290v1'>http://arxiv.org/abs/2312.00290v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a two-stage method that enables adding new diagnostic variables to a weather prediction model without retraining the entire model, using an autoencoder to embed prognostic variables into a latent space and then training downstream models on these representations.</p><hr><h3>Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement  Learning Approach</h3>
<p>Xingqiu He,Chaoqun You,Tony Q. S. Quek</p>
<p><a href='http://arxiv.org/abs/2312.00279v1'>http://arxiv.org/abs/2312.00279v1</a></p>
<p><b>Compressor summary</b>: The text discusses a new definition of Age of Information for mobile edge computing applications, which can be minimized using reinforcement learning algorithms with post-decision states to improve performance and efficiency.</p><hr><h3>Text Attribute Control via Closed-Loop Disentanglement</h3>
<p>Lei Sha,Thomas Lukasiewicz</p>
<p><a href='http://arxiv.org/abs/2312.00277v1'>http://arxiv.org/abs/2312.00277v1</a></p>
<p><b>Compressor summary</b>: The paper proposes a semi-supervised contrastive learning method for disentangling attributes in text without changing content, which improves on previous methods by using a closed-loop process and reducing computation cost.</p><hr><h3>Automating Continual Learning</h3>
<p>Kazuki Irie,RÃ³bert CsordÃ¡s,JÃ¼rgen Schmidhuber</p>
<p><a href='http://arxiv.org/abs/2312.00276v1'>http://arxiv.org/abs/2312.00276v1</a></p>
<p><b>Compressor summary</b>: The text proposes Automated Continual Learning (ACL), a method that trains neural networks to meta-learn their own algorithms for preventing catastrophic forgetting in changing environments, and shows its effectiveness on various image classification tasks.</p><hr><h3>Towards Clinical Prediction with Transparency: An Explainable AI  Approach to Survival Modelling in Residential Aged Care</h3>
<p>Teo Susnjak,Elise Griffin,Mitchell McCutcheon,Kathleen Potter</p>
<p><a href='http://arxiv.org/abs/2312.00271v1'>http://arxiv.org/abs/2312.00271v1</a></p>
<p><b>Compressor summary</b>: The researchers developed an interpretable machine learning survival model for elderly aged care residents, which can predict 6-month survival probabilities based on various factors like age, gender, health status, and more.</p><hr><h3>Adaptability of Computer Vision at the Tactical Edge: Addressing  Environmental Uncertainty</h3>
<p>Hayden Moore</p>
<p><a href='http://arxiv.org/abs/2312.00269v1'>http://arxiv.org/abs/2312.00269v1</a></p>
<p><b>Compressor summary</b>: The paper proposes synchronizing robust data operations and model fine-tuning driven by uncertainty quantification (UQ) to improve adaptability of computer vision (CV) systems in command and control (C2) at the tactical edge.</p><hr><h3>Academic competitions</h3>
<p>Hugo Jair Escalante,Aleksandra Kruchinina</p>
<p><a href='http://arxiv.org/abs/2312.00268v1'>http://arxiv.org/abs/2312.00268v1</a></p>
<p><b>Compressor summary</b>: Academic challenges in machine learning and related fields advance research, highlight specific topics and problems, and promote diversity in participation and access to research.</p><hr><h3>Sample Efficient Reinforcement Learning from Human Feedback via Active  Exploration</h3>
<p>Viraj Mehta,Vikramjeet Das,Ojash Neopane,Yijia Dai,Ilija Bogunovic,Jeff Schneider,Willie Neiswanger</p>
<p><a href='http://arxiv.org/abs/2312.00267v1'>http://arxiv.org/abs/2312.00267v1</a></p>
<p><b>Compressor summary</b>: The paper proposes an algorithm that optimizes contextual choice for human feedback in reinforcement learning, improving performance and reducing sample cost.</p>