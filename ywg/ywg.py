from compressor.data import PaperDB
from pandas.core.dtypes.dtypes import datetime
from tqdm import tqdm
import pandas as pd
import sys
from util import get_pubdate
import shutil
import xml.etree.ElementTree as ET


def generate_html_report(df: pd.DataFrame, header: str, fname: str, full_text_summary: bool = False):
    # Summarise the latest results from arxiv.
    with open(fname, "w") as f:
        f.write(header)
        for _, paper in tqdm(df.iterrows(), total=len(df)):
            title = paper.title
            url = paper.url
            if full_text_summary:
                raise ValueError("Full text summary is not yet supported. Stay tuned.")
            else:
                summary = paper.abstract_compressed
            f.write(f"<hr>")
            f.write(f"<h3>{title}</h3>\n")
            #f.write(f"<p>{paper.authors}</p>\n")
            f.write(f"<p><a href='{url}'>{url}</a></p>\n")
            f.write(f"<p><b>Compressor summary</b>: {summary}</p>")

def arxiv_daily():
    db = PaperDB('../../compressor/papers.parquet')
    #crawler.crawl_arxiv(db)
    #c = ArxivCompressor(OrcaModel(), db)
    #c.compress()

    arxiv_df = db.get_papers_for_source("arxiv")
    latest_date = max(arxiv_df.date_published.values)
    arxiv_df = arxiv_df.loc[arxiv_df.date_published == latest_date]
    print(f"Summarising for date: {latest_date}")
    today = datetime.now().strftime("%Y-%m-%d")
    fname =f"../arxiv_compressed/{today}.html"
    header = f"""
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>arxiv compressed, {today}</h1>
            <p>This page contains one-sentence summaries of cs.AI/ML/CV/CL papers announced on {today} generated by the compressor, my personal LLM-based project.</p>
    """
    generate_html_report(arxiv_df, header, fname)
    with open('../arxiv_compressed.html', 'r') as f:
        lines = list(f.readlines())
    ul_idx = lines.index('<ul>\n')
    newline = f'  <li><a href="arxiv_compressed/{today}.html">{today}</li>\n'
    lines.insert(ul_idx+1, newline)
    with open('../arxiv_compressed.html', 'w') as f:
        f.writelines(lines)

def openreview_compressed():
    db = PaperDB('../../compressor/papers.parquet')

    venue = "ICLR.cc/2024/Conference"
    venue_df = db.get_papers_for_source(venue)
    fname ="../iclr2024_compressed.html"
    header = f"""
            <meta name="viewport" content="width=device-width, initial-scale=1.0" />
            <link rel="stylesheet" href="../style.css"/>
            <title>Welcome to yobihome</title>
            <a href="https://yobibyte.github.io/"><img src="../pics/socrat.png" class="center"></a>
            <h1>ICLR2024 compressed</h1>
            <p>This page contains one-sentence summaries of ICLR2024 accepted papers, generated by the compressor, my personal LLM-based project.</p>
    """
    generate_html_report(venue_df, header, fname)

def get_feed_item(page_name, title, desc):
    return """
        <item>
            <title>title_placeholder</title>
            <pubDate>date_placeholder</pubDate>
            <link>https://yobibyte.github.io/link_placeholder.html</link>
            <guid>https://yobibyte.github.io/guid_placeholder.html</guid>
            <description>description_placeholder</description>
        </item>
    """.replace("title_placeholder", title).replace("date_placeholder", get_pubdate()).replace("link_placeholder", page_name).replace("guid_placeholder", page_name).replace("description_placeholder", desc)

def add_page():
    page_name = input("Enter page filename... ")
    page_title = input("Enter page title... ")
    page_desc = input("Enter page description... ")

    # make a feed entry first
    new_item = get_feed_item(page_name, page_title, page_desc)

    feed_xml = ET.parse('../feed.xml')
    root = feed_xml.getroot()
    root.find('.//channel').append(ET.fromstring(new_item))
    feed_xml.write('../feed.xml')

    shutil.copyfile("../template.html", f"../{page_name}.html")

    

if __name__ == '__main__':
    args = sys.argv
    if args[1] == 'ad':
        print("Generating arxiv daily report.")
        arxiv_daily()
    elif args[1] == 'p':
        print("Adding a new html page...")
        add_page()
    elif args[1] == 'or':
        openreview_compressed()
